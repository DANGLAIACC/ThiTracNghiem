5053410
~~~
{"count": 100, "next": null, "previous": null, "results": [{"_class": "assessment", "id": 57171518, "assessment_type": "multiple-choice", "prompt": {"question": "Micro-partitioning is the on-demand feature of Snowflake. It is required to be enabled explicitly by ACCOUNTADMIN. (True / False)", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "<p><strong>Micro-partitioning is automatically performed</strong> on all Snowflake tables. Tables are transparently partitioned using the Ordering of the data as inserted or loaded.</p>", "answers": ["TRUE", "FALSE"]}, "correct_response": ["b"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "Micro-partitioning is the on-demand feature of Snowflake. It is required to be enabled explicitly by ACCOUNTADMIN. (True / False)", "related_lectures": []}, {"_class": "assessment", "id": 57171520, "assessment_type": "multi-select", "prompt": {"question": "Which systems function can help find the overlap depth of a table&#39;s micro-partitions?", "answers": ["SYSTEM$CLUSTERING_INFORMATION", "SYSTEM$CLUSTERING_DEPTH", "SYSTEM$CLUSTERING_INFO", "SYSTEM$CLUSTERING_WEIGHT", "SYSTEM$CLUSTERING_ALL"], "explanation": "For example, if you have an EMPLOYEE table - you can run any of these queries to find the depth - \n SELECT SYSTEM$CLUSTERING_INFORMATION(&#39;EMPLOYEE&#39;); \n SELECT SYSTEM$CLUSTERING_DEPTH(&#39;EMPLOYEE&#39;);"}, "correct_response": ["a", "b"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "Which systems function can help find the overlap depth of a table&#39;s micro-partitions?", "related_lectures": []}, {"_class": "assessment", "id": 57171522, "assessment_type": "multi-select", "prompt": {"question": "Select the correct statements for Table Clustering. (Select 3)", "relatedLectureIds": "", "feedbacks": ["", "", "", "", "", ""], "explanation": "<p>Clustering keys are not for every table. <strong>Tables in the multi-terabyte range are good candidates for clustering keys.</strong> Both automatic clustering and reclustering consume credit. A single clustering key can contain one or more columns or expressions. <strong>Snowflake recommends a maximum of three or four columns (or expressions) per key for most tables</strong>. Adding more than 3-4 columns tends to increase costs more than benefits.</p>", "answers": ["Clustering keys are not for every table", "Snowflake doesn\u2019t charge for Reclustering", "Automatic Clustering doesn\u2019t consume credit", "Tables in multi-terabytes range are good candidate for clustering keys", "Automatic clustering can not be suspended or resumed", "Snowflake recommends a maximum of three or four columns (or expressions) per key"]}, "correct_response": ["a", "d", "f"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "Select the correct statements for Table Clustering. (Select 3)", "related_lectures": []}, {"_class": "assessment", "id": 57171524, "assessment_type": "multi-select", "prompt": {"question": "<p>How can an ACCOUNTADMIN view the billing for Automatic Clustering? (Select all that apply)</p>", "relatedLectureIds": "", "feedbacks": ["", "", "", "", "", ""], "explanation": "<p>Users with the ACCOUNTADMIN role can view the billing for Automatic Clustering using Snowsight, the classic web interface, or SQL:\n\n<strong>Snowsight:</strong> Select Admin \u00bb Usage.\n\n<strong>Classic Web Interface:</strong> Click on Account tab \u00bb Billing &amp; Usage </p><p>The billing for Automatic Clustering shows up as a separate Snowflake-provided warehouse named AUTOMATIC_CLUSTERING.&nbsp; </p><p><strong>SQL</strong>:Query either of the following: AUTOMATIC_CLUSTERING_HISTORY table function (in the Snowflake Information Schema). AUTOMATIC_CLUSTERING_HISTORY View (in Account Usage).</p>", "answers": ["Snowsight: Select Admin &gt; Usage", "Classic Web Interface: Click on Account &gt; Billing &amp; Usage under warehouse named &#39;AUTOMATIC_CLUSTERING&#39;", "Query - AUTOMATIC_CLUSTERING_HISTORY table function (in the Snowflake Information Schema)", "Classic Web Interface: Click on Account &gt; Billing &amp; Usage under storage named &#39;AUTOMATIC_CLUSTERING&#39;", "There is no way to check the Automatic Clustering billing without contacting Snowflake Support Team", "Query - AUTOMATIC_CLUSTERING_HISTORY View (in Account Usage)"]}, "correct_response": ["a", "b", "c", "f"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "How can an ACCOUNTADMIN view the billing for Automatic Clustering? (Select all that apply)", "related_lectures": []}, {"_class": "assessment", "id": 57171526, "assessment_type": "multiple-choice", "prompt": {"question": "The data objects stored by Snowflake are not directly visible nor accessible by customers; they are only accessible through SQL query operations run using Snowflake. (True/False)", "answers": ["TRUE", "FALSE"], "explanation": "Snowflake manages all aspects of how this data is stored \u2014 the organization, file size, structure, compression, metadata, statistics, and other aspects of data storage are handled by Snowflake. The data objects stored by Snowflake are not directly visible nor accessible by customers; they are only accessible through SQL query operations run using Snowflake."}, "correct_response": ["a"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "The data objects stored by Snowflake are not directly visible nor accessible by customers; they are only accessible through SQL query operations run using Snowflake. (True/False)", "related_lectures": []}, {"_class": "assessment", "id": 57171528, "assessment_type": "multi-select", "prompt": {"question": "Which services are managed by Snowflake&#39;s cloud services layer? (Select all that apply)", "relatedLectureIds": "", "feedbacks": ["", "", "", "", "", ""], "explanation": "<p>The cloud services layer is a collection of services that coordinate activities across Snowflake. These services tie together all of the different components of Snowflake in order to process user requests, from login to query dispatch.&nbsp; &nbsp; </p><p>The cloud service layer manages Authentication, Infrastructure Management, Metadata Management, Query parsing and optimization, and Access control services.</p>", "answers": ["Authentication", "Infrastructure Management", "Metadata Management", "Query Parsing and Optimization", "Access Control", "Only Infrastructure Management"]}, "correct_response": ["a", "b", "c", "d", "e"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "Which services are managed by Snowflake&#39;s cloud services layer? (Select all that apply)", "related_lectures": []}, {"_class": "assessment", "id": 57171530, "assessment_type": "multi-select", "prompt": {"question": "Snowflake is available in four editions. Which are those? (Select 4)", "answers": ["Standard", "Enterprise", "Business Critical", "Virtual Private Snowflake (VPS)", "Professional", "Professional Plus"], "explanation": "Snowflake is available in four editions: Standard, Enterprise, Business Critical, and Virtual Private Snowflake (VPS). Standard comes with most of the available features. Enterprise adds on to Standard with things like: extra days of time travel, materialized view support, and data masking. Business Critical brings to the table: HIPAA support, Tri-secret Secure, and more. And Virtual Private Snowflake is everything that Business Critical has, but with the ability to have customer-dedicated metadata stores and customer-dedicated virtual service."}, "correct_response": ["a", "b", "c", "d"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "Snowflake is available in four editions. Which are those? (Select 4)", "related_lectures": []}, {"_class": "assessment", "id": 57171532, "assessment_type": "multiple-choice", "prompt": {"question": "Which primary tool loads data to Snowflake from a local file system?\t", "answers": ["Snowflake UI", "External Stage", "SnowSQL", "ETL tools"], "explanation": "SnowSQL is the primary tool used to load data to Snowflake from a local file system. You can run it in either interactive shell or batch mode."}, "correct_response": ["c"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "Which primary tool loads data to Snowflake from a local file system?", "related_lectures": []}, {"_class": "assessment", "id": 57171534, "assessment_type": "multiple-choice", "prompt": {"question": "<p>For which object the Kafka connector does create a topic?</p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>The connector creates the following objects for each topic:</p><ul><li><p>One internal stage to temporarily store data files for each topic. </p></li><li><p>One pipe to ingest the data files for each topic partition. </p></li><li><p>One table for each topic. If the table specified for each topic does not exist, the connector creates it; otherwise, the connector creates the RECORD_CONTENT and RECORD_METADATA columns in the existing table and verifies that the other columns are nullable (and produces an error if they are not).</p></li></ul>", "answers": ["One internal stage to temporarily store data files for each topic", "One pipe to ingest the data files for each topic partition", "One table for each topic. If the table specified for each topic does not exist", "All of these "]}, "correct_response": ["d"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "For which object the Kafka connector does create a topic?", "related_lectures": []}, {"_class": "assessment", "id": 57171536, "assessment_type": "multi-select", "prompt": {"question": "In which of the cloud platforms a Snowflake account can be hosted? (Select 3)", "answers": ["AWS", "AZURE", "GCP", "IBM Cloud", "Oracle Cloud"], "explanation": "A Snowflake account can be hosted on any of the following cloud platforms:\nAmazon Web Services (AWS), Google Cloud Platform (GCP), Microsoft Azure (Azure).\nOn each platform, Snowflake provides one or more regions where the account is provisioned."}, "correct_response": ["a", "b", "c"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "In which of the cloud platforms a Snowflake account can be hosted? (Select 3)", "related_lectures": []}, {"_class": "assessment", "id": 57171538, "assessment_type": "multi-select", "prompt": {"question": "Which of these types of VIEW does Snowflake support? (Select 3)", "relatedLectureIds": "", "feedbacks": ["", "", "", "", "", ""], "explanation": "<p>Snowflake supports three types of views. </p><p>Standard View, Secure View, and Materialized View.&nbsp; &nbsp;</p><p><strong>Standard View:</strong> It is a default view type. Its underlying DDL is available to any role with access to the view. When you create a standard view, Snowflake saves a definition of the view. Snowflake does not run the query. When someone accesses the view, that is when the query is run. The standard view will always execute as the owning role.</p><p> <strong>Secure View:</strong> The secure view is exactly like a standard view, except users cannot see how that view was defined. Sometimes a secure view will run a little slower than a standard view to protect the information in a secure view. Snowflake may bypass some of the optimizations.</p><p> <strong>Materialized View: </strong>A materialized view is more like a table. Unlike a standard or secure view, Snowflake runs the query right away when you create a materialized view. It takes the results set and stores that result set as a table in Snowflake. Because Snowflake is storing that materialized view as a table, creating micro partitions. Snowflake is creating metadata about those micro partitions. So when you query a materialized view, if you put a filter on the view, you get the same benefit of micro partition pruning that you would get from a table. With Snowflake, the materialized view is automatically refreshed every time there is a transaction against the base table. So it is always going to be in sync. If you want, you can also create a secure materialized view, which again will hide the logic from the user. A note about materialized views, because Snowflake is auto-refreshing them in the background, they use some credits, so there is a little bit of a cost there. Moreover, there is some storage, and Snowflake stores the result set as a table in Snowflake. So materialized views use more storage and compute than standard or secure views.</p>", "answers": ["PERMANENT VIEW", "EXTERNAL VIEW", "STANDARD VIEW", "SECURE VIEW", "MATERIALIZED VIEW", "TEMPORARY VIEW"]}, "correct_response": ["c", "d", "e"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "Which of these types of VIEW does Snowflake support? (Select 3)", "related_lectures": []}, {"_class": "assessment", "id": 57171712, "assessment_type": "multi-select", "prompt": {"question": "Which objects are not available for replication in the Standard Edition of Snowflake? (Select 3) ", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "Database and share replication are available in all editions, including the Standard edition. Replication of all other objects is only available for Business Critical Edition (or higher).", "answers": ["Integrations", "Roles", "Database", "Shares", "Users"]}, "correct_response": ["a", "b", "e"], "section": "Data Protection and Data Sharing", "question_plain": "Which objects are not available for replication in the Standard Edition of Snowflake? (Select 3)", "related_lectures": []}, {"_class": "assessment", "id": 57171714, "assessment_type": "multiple-choice", "prompt": {"question": "Which view in the Account Usage Schema can be used to query the replication history for a specified database?", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p><strong>This REPLICATION_USAGE_HISTORY view in the Account Usage Schema can be used to query the replication history for a specified database.</strong> The returned results include the database name, credits consumed, and bytes transferred for replication. Usage data is retained for 365 days (1 year).</p>", "answers": ["DATA_TRANSFER_HISTORY", "REPLICATION_USAGE_HISTORY", "DATABASE_REFRESH_HISTORY", "REPLICATION_GROUP_REFRESH_HISTORY"]}, "correct_response": ["b"], "section": "Data Protection and Data Sharing", "question_plain": "Which view in the Account Usage Schema can be used to query the replication history for a specified database?", "related_lectures": []}, {"_class": "assessment", "id": 57171716, "assessment_type": "multi-select", "prompt": {"question": "Which privileges are provided with a share by the provider? (Select 2)", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p>Shares are named Snowflake objects that encapsulate all of the information required to share a database. Each share consists of: </p><ul><li><p>The privileges that grant access to the database(s) and the schema containing the objects to share. </p></li><li><p>The privileges that grant access to the specific objects in the database. </p></li><li><p>The consumer accounts with which the database and its objects are shared.&nbsp; </p><p><br></p><p>Example: CREATE SHARE \"SHARED_DATA\" COMMENT=''; GRANT USAGE ON DATABASE \"DEMO_DB\" TO SHARE \"SHARED_DATA\"; GRANT USAGE ON SCHEMA \"DEMO_DB\".\"TWITTER_DATA\" TO SHARE \"SHARED_DATA\"; GRANT SELECT ON VIEW \"DEMO_DB\".\"TWITTER_DATA\".\"FOLLOWERS\" TO SHARE \"SHARED_DATA\";</p></li></ul>", "answers": ["Grant access(USAGE) to the database and the schema containing the tables to share", "Grant access(USAGE) to the specific tables in the database", "Grant access(SELECT) to the specific tables in the database", "Grant access(MODIFY) to the specific tables in the database", "Grant access(OPERATE) to the database and the schema containing the tables to share"]}, "correct_response": ["a", "c"], "section": "Data Protection and Data Sharing", "question_plain": "Which privileges are provided with a share by the provider? (Select 2)", "related_lectures": []}, {"_class": "assessment", "id": 57171540, "assessment_type": "multiple-choice", "prompt": {"question": "Which is not the DML (Data Manipulation Language) command?", "answers": ["INSERT", "MERGE", "UPDATE", "DELETE", "UNDROP", "TRUNCATE"], "explanation": "UNDROP is Snowflake&#39;s DDL (Data Definition Language) command."}, "correct_response": ["e"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "Which is not the DML (Data Manipulation Language) command?", "related_lectures": []}, {"_class": "assessment", "id": 57171542, "assessment_type": "multiple-choice", "prompt": {"question": "Monica wants to delete all the data from table t1. She wants to keep the table structure, so she does not need to create the table again. Which command will be appropriate for her need?", "answers": ["DELETE", "DROP", "UNDROP", "TRUNCATE", "REMOVE"], "explanation": "TRUNCATE will delete all of the data from a single table. So, once Monica truncates table t1, table t1&#39;s structure remains, but the data will be deleted. DELETE is usually used for deleting single rows of data."}, "correct_response": ["d"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "Monica wants to delete all the data from table t1. She wants to keep the table structure, so she does not need to create the table again. Which command will be appropriate for her need?", "related_lectures": []}, {"_class": "assessment", "id": 57171544, "assessment_type": "multiple-choice", "prompt": {"question": "A stored procedure can simultaneously run the caller\u2019s and the owner\u2019s rights. (True / False)\t", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "<p>A stored procedure runs with either the caller\u2019s rights or the owner\u2019s rights. It cannot run with both at the same time.\n\nA <strong>caller\u2019s rights stored procedure</strong> runs with the privileges of the caller. The primary advantage of a caller\u2019s rights stored procedure is that it can access information about that caller or about the caller\u2019s current session. For example, a caller\u2019s rights stored procedure can read the caller\u2019s session variables and use them in a query.\n\nAn <strong>owner\u2019s rights stored procedure</strong> runs mostly with the privileges of the stored procedure\u2019s owner. The primary advantage of an owner\u2019s rights stored procedure is that the owner can delegate specific administrative tasks, such as cleaning up old data, to another role without granting that role more general privileges, such as privileges to delete all data from a specific table.\n\nAt the time that the stored procedure is created, the creator specifies whether the procedure runs with owner\u2019s rights or caller\u2019s rights. The default is owner\u2019s rights.</p>", "answers": ["TRUE", "FALSE"]}, "correct_response": ["b"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "A stored procedure can simultaneously run the caller\u2019s and the owner\u2019s rights. (True / False)", "related_lectures": []}, {"_class": "assessment", "id": 57171546, "assessment_type": "multi-select", "prompt": {"question": "A task can execute any one of the following types of SQL code: (Select 3)", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>A task can execute any one of the following types of SQL code: </p><ul><li><p>Single SQL statement </p></li><li><p>Call to a stored procedure</p></li><li><p>Procedural logic using Snowflake Scripting.</p></li></ul>", "answers": ["Single SQL Statement", "Multiple SQL statements", "Call to a stored procedure", "Procedural logic using Snowflake Scripting"]}, "correct_response": ["a", "c", "d"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "A task can execute any one of the following types of SQL code: (Select 3)", "related_lectures": []}, {"_class": "assessment", "id": 57171548, "assessment_type": "multiple-choice", "prompt": {"question": "Monica has successfully created a task with the 5 minutes schedule.\n It has been 30 minutes, but the task did not run. What could be the reason?", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "The first time we create the TASK, we need to run the ALTER TASK command to RESUME the task. \n", "answers": ["Task schedule should not be less than 60 minutes", "Monica should run the ALTER TASK command to RESUME the task", "Monica should run the ALTER TASK command to SUSPEND the task, and then again run the ALTER TASK command to RESUME the task", "Monica doesn&#39;t have the authority to run the task"]}, "correct_response": ["b"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "Monica has successfully created a task with the 5 minutes schedule.\n It has been 30 minutes, but the task did not run. What could be the reason?", "related_lectures": []}, {"_class": "assessment", "id": 57171550, "assessment_type": "multiple-choice", "prompt": {"question": "Which stream type is supported for streams on the external table only?", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p><strong>Insert-only</strong> is supported for streams on external tables only. An insert-only stream tracks row inserts only; they do not record delete operations that remove rows from an inserted set (i.e. no-ops). </p>", "answers": ["External", "Standard", "Update-only", "Append-only", "Insert-only"]}, "correct_response": ["e"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "Which stream type is supported for streams on the external table only?", "related_lectures": []}, {"_class": "assessment", "id": 57171552, "assessment_type": "multiple-choice", "prompt": {"question": "Search optimization\u00a0is a Database-level property applied to all the tables within the database with supported data types. (True/False)", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "<p><strong>Search optimization</strong> is a table-level property and applies to all columns with supported data types. The search optimization service aims to significantly improve the performance of selective point lookup queries on tables. A point lookup query returns only one or a small number of distinct rows. A user can register one or more tables to the search optimization service.</p>", "answers": ["TRUE", "FALSE"]}, "correct_response": ["b"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "Search optimization\u00a0is a Database-level property applied to all the tables within the database with supported data types. (True/False)", "related_lectures": []}, {"_class": "assessment", "id": 57171554, "assessment_type": "multi-select", "prompt": {"question": "Which of these are not supported by the Search Optimization Service? (Select all that apply)", "relatedLectureIds": "", "feedbacks": ["", "", "", "", "", ""], "explanation": "<p><strong>None of these</strong> are currently supported by the <strong>Search Optimization Service</strong>. Additionally, Tables and views protected by row access policies cannot be used with the Search Optimization Search.</p>", "answers": ["External Tables", "Materialized Views", "Column Concatenation", "Casts on table columns", "Analytical Expressions", "Columns defined with COLLATE clause"]}, "correct_response": ["a", "b", "c", "d", "e", "f"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "Which of these are not supported by the Search Optimization Service? (Select all that apply)", "related_lectures": []}, {"_class": "assessment", "id": 57171556, "assessment_type": "multi-select", "prompt": {"question": "Which database objects can be shared using the Snowflake Secure Data Sharing feature? (Select all that apply)", "relatedLectureIds": "", "feedbacks": ["", "", "", "", "", ""], "explanation": "<p><strong>Secure Data Sharing</strong> enables sharing selected objects in a database in your account with other Snowflake accounts. The following Snowflake database objects can be shared:&nbsp; </p><ul><li><p>Tables&nbsp; </p></li><li><p>External tables&nbsp; </p></li><li><p>Secure views&nbsp; </p></li><li><p>Secure materialized views&nbsp; </p></li><li><p>Secure UDFs&nbsp; </p><p>Snowflake enables the sharing of databases through shares created by data providers and \u201cimported\u201d by data consumers.</p></li></ul>", "answers": ["Tables", "External Tables", "Roles", "Secure Materialized View", "Secure UDFs", "Secure Views"]}, "correct_response": ["a", "b", "d", "e", "f"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "Which database objects can be shared using the Snowflake Secure Data Sharing feature? (Select all that apply)", "related_lectures": []}, {"_class": "assessment", "id": 57171558, "assessment_type": "multiple-choice", "prompt": {"question": "How many maximum columns (or expressions) are recommended for a cluster key?", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>A single clustering key can contain one or more columns or expressions. <strong>Snowflake recommends a maximum of 3 or 4 columns (or expressions) per key for most tables.</strong> Adding more than 3-4 columns tends to increase costs more than benefits.</p>", "answers": ["12 to 16", "7 to 8", "3 to 4", "Higher the number of columns (or expressions) in the key, better will be the performance"]}, "correct_response": ["c"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "How many maximum columns (or expressions) are recommended for a cluster key?", "related_lectures": []}, {"_class": "assessment", "id": 57171560, "assessment_type": "multiple-choice", "prompt": {"question": "Snowflake automatically and transparently maintains materialized views. (True/False)", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "<p><strong>Snowflake automatically and transparently maintains materialized views</strong>. A background service updates the materialized view after changes to the base table. This is more efficient and less error-prone than manually maintaining the equivalent of a materialized view at the application level.</p>", "answers": ["TRUE", "FALSE"]}, "correct_response": ["a"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "Snowflake automatically and transparently maintains materialized views. (True/False)", "related_lectures": []}, {"_class": "assessment", "id": 57171562, "assessment_type": "multi-select", "prompt": {"question": "In what situations should you consider User-Managed Tasks over Serverless Tasks? (Select 2)", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p><strong>User-managed Tasks</strong> is recommended when you <strong>can fully utilize a single warehouse</strong> by scheduling multiple concurrent tasks to take advantage of available compute resources. Also, recommended when adherence to the schedule interval is less critical.\n\n<strong>Serverless Tasks</strong> is recommended when you <strong>cannot fully utilize a warehouse</strong> because too few tasks run concurrently or they run to completion quickly (in less than 1 minute). Also, recommended when adherence to the schedule interval is critical.</p>", "answers": ["Consider when you cannot fully utilize a warehouse because too few tasks run concurrently or they run to completion quickly (in less than 1 minute).", "Consider when you can fully utilize a single warehouse by scheduling multiple concurrent tasks to take advantage of available compute resources.", "Consider when adherence to the schedule interval is less important.", "Consider when adherence to the schedule interval is highly important."]}, "correct_response": ["b", "c"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "In what situations should you consider User-Managed Tasks over Serverless Tasks? (Select 2)", "related_lectures": []}, {"_class": "assessment", "id": 57171564, "assessment_type": "multiple-choice", "prompt": {"question": "Which command will list the pipes for which you have access privileges?", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p><strong>SHOW PIPES</strong> Command lists the pipes for which you have access privileges. This command can list the pipes for a specified database or schema (or the current database/schema for the session), or your entire account.</p>", "answers": ["LIST PIPES;", "DESCRIBE PIPES;", "SHOW PIPES();", "SHOW PIPES;", "LIST PIPES();"]}, "correct_response": ["d"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "Which command will list the pipes for which you have access privileges?", "related_lectures": []}, {"_class": "assessment", "id": 57171566, "assessment_type": "multi-select", "prompt": {"question": "Which of these are Snowgrid&#39;s capabilities? (Select all that apply)", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p><strong>Snowgrid allows you to use Secure Data Sharing features to provide access to live data, without any ETL or movement of files across environments. </strong>\n</p>", "answers": ["Zero-copy cloning", "Share internally with private data exchange or externally with public data exchange", "Secure, governed data sharing", "ETL dependent", "Live, ready to query data"]}, "correct_response": ["b", "c", "e"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "Which of these are Snowgrid&#39;s capabilities? (Select all that apply)", "related_lectures": []}, {"_class": "assessment", "id": 57171568, "assessment_type": "multiple-choice", "prompt": {"question": "Which of the Snowflake editions provides a federated authorization feature?", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "All Snowflake Editions (Standard, Enterprise, Business Critical, Virtual Private Snowflake) provide Federated Authentication.", "answers": ["Standard", "Enterprise", "Business Critical", "Virtual Private Snowflake(VPS)", "All of the Snowflake Editions"]}, "correct_response": ["e"], "section": "Account Access & Security", "question_plain": "Which of the Snowflake editions provides a federated authorization feature?", "related_lectures": []}, {"_class": "assessment", "id": 57171570, "assessment_type": "multiple-choice", "prompt": {"question": "Which of these system-defined roles can manage operations at the organization level?", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p>ORGADMIN role manages operations at the organizational level. More specifically, this role:</p><ul><li><p>Can create accounts in the organization. </p></li><li><p>Can view all accounts in the organization (using SHOW ORGANIZATION ACCOUNTS) and all regions enabled for the organization (using SHOW REGIONS). </p></li><li><p>Can view usage information across the organization.</p></li></ul>", "answers": ["ORGADMIN", "ACCOUNTADMIN", "SECURITYADMIN", "USERADMIN", "SYSADMIN"]}, "correct_response": ["a"], "section": "Account Access & Security", "question_plain": "Which of these system-defined roles can manage operations at the organization level?", "related_lectures": []}, {"_class": "assessment", "id": 57171572, "assessment_type": "multiple-choice", "prompt": {"question": "Which of these roles is dedicated to user and role management only?", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p>USERADMIN role is dedicated to user and role management only. More specifically, this role: </p><ul><li><p>Is granted the CREATE USER and CREATE ROLE security privileges. </p></li><li><p>Can create users and roles in the account. </p></li><li><p>This role can also manage users and roles that it owns. </p><p>Only the role with the OWNERSHIP privilege on an object (i.e. user or role), or a higher role, can modify the object properties.</p></li></ul>", "answers": ["ORGADMIN", "ACCOUNTADMIN", "SECURITYADMIN", "USERADMIN", "SYSADMIN"]}, "correct_response": ["d"], "section": "Account Access & Security", "question_plain": "Which of these roles is dedicated to user and role management only?", "related_lectures": []}, {"_class": "assessment", "id": 57171574, "assessment_type": "multiple-choice", "prompt": {"question": "Readers accounts enable providers to share data with consumers who are not already Snowflake customers without requiring the consumers to become Snowflake Customers. Which role can create the Reader account?", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "ACCOUNTADMIN role (or a role granted the CREATE ACCOUNT global privilege) only can create the Reader account.", "answers": ["SECURITYADMIN", "USERADMIN", "SYSADMIN", "ACCOUNTADMIN"]}, "correct_response": ["d"], "section": "Account Access & Security", "question_plain": "Readers accounts enable providers to share data with consumers who are not already Snowflake customers without requiring the consumers to become Snowflake Customers. Which role can create the Reader account?", "related_lectures": []}, {"_class": "assessment", "id": 57171576, "assessment_type": "multi-select", "prompt": {"question": "You can create an an account level network policy using _____ (Select all that apply)", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "Only security administrators (i.e., users with the SECURITYADMIN role) or higher or a role with the global CREATE NETWORK POLICY privilege can create network policies using Snowsight, Classic Web Interface, and SQL.", "answers": ["Snowsight", "Only Snowflake Support can create the Account level Network Policy", "SQL", "Classic Web Interface"]}, "correct_response": ["a", "c", "d"], "section": "Account Access & Security", "question_plain": "You can create an an account level network policy using _____ (Select all that apply)", "related_lectures": []}, {"_class": "assessment", "id": 57171578, "assessment_type": "multiple-choice", "prompt": {"question": "Which SQL command determines whether a network policy is set on the account or for a specific user?", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p>The <strong>SHOW PARAMETERS</strong> command determines whether a network policy is set on the account or for a specific user. </p><p><strong>For Account level:</strong> SHOW PARAMETERS LIKE 'network_policy' IN ACCOUNT; </p><p><strong>For User level :</strong> SHOW PARAMETERS LIKE 'network_policy' IN USER &lt;username&gt;;&nbsp; </p><p><strong>Example </strong>- SHOW PARAMETERS LIKE 'network_policy' IN USER john;</p>", "answers": ["SHOW POLICY", "SHOW POLICIES", "SHOW PARAMETER", "SHOW PARAMETERS", "SHOW NETWORK_POLICIES"]}, "correct_response": ["d"], "section": "Account Access & Security", "question_plain": "Which SQL command determines whether a network policy is set on the account or for a specific user?", "related_lectures": []}, {"_class": "assessment", "id": 57171580, "assessment_type": "multiple-choice", "prompt": {"question": "If you create a Network Policy by providing both &#39;Allowed IP Addresses&#39; and &#39;Blocked IP Addresses&#39;, which is applied first by Snowflake while validating the access? ", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "<p>If you provide both Allowed IP Addresses and Blocked IP Addresses, <strong>Snowflake applies the Blocked List first</strong>.</p>", "answers": ["Allowed IP Addresses", "Blocked IP Addresses"]}, "correct_response": ["b"], "section": "Account Access & Security", "question_plain": "If you create a Network Policy by providing both &#39;Allowed IP Addresses&#39; and &#39;Blocked IP Addresses&#39;, which is applied first by Snowflake while validating the access?", "related_lectures": []}, {"_class": "assessment", "id": 57171582, "assessment_type": "multiple-choice", "prompt": {"question": "What will happen if a policy is assigned to a user who is already signed in?", "relatedLectureIds": "", "feedbacks": ["", "", ""], "explanation": "If a policy is assigned to a user who already signed in, they can&#39;t do anything else until they sign and signed back in again to make use of the new policy", "answers": ["The user can continue running the SQL queries in the currently opened session. ", "There will be no interruption until the user logoffs and signs in again.", "The user can&#39;t do anything else until signed in and signed back in again."]}, "correct_response": ["c"], "section": "Account Access & Security", "question_plain": "What will happen if a policy is assigned to a user who is already signed in?", "related_lectures": []}, {"_class": "assessment", "id": 57171584, "assessment_type": "multiple-choice", "prompt": {"question": "If a user is logged in to Snowflake in a federated environment and IdP times out, what does happen to the user&#39;s snowflake session?", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "After a specified period of time (defined by the IdP), a user\u2019s session in the IdP automatically times out, but this does not affect their Snowflake sessions. Any Snowflake sessions that are active at the time remain open and do not require re-authentication. However, to initiate any new Snowflake sessions, the user must log into the IdP again.", "answers": ["The Snowflake web interface is disabled, and the prompt for IdP authentication is displayed.", "It does not affect the user&#39;s Snowflake sessions. However, to initiate any new Snowflake sessions, the user must log into the IdP again."]}, "correct_response": ["b"], "section": "Account Access & Security", "question_plain": "If a user is logged in to Snowflake in a federated environment and IdP times out, what does happen to the user&#39;s snowflake session?", "related_lectures": []}, {"_class": "assessment", "id": 57171586, "assessment_type": "multiple-choice", "prompt": {"question": "If you drop or disable a user in Snowflake in an Okta IdP federated environment, the user can still access Snowflake login through Okta. (True/False)", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "Users who are dropped or disabled in Snowflake are still able to log into their Okta accounts, but they will receive an error message when they attempt to connect to Snowflake. You must recreate or enable the user before they can log in.", "answers": ["TRUE", "FALSE"]}, "correct_response": ["b"], "section": "Account Access & Security", "question_plain": "If you drop or disable a user in Snowflake in an Okta IdP federated environment, the user can still access Snowflake login through Okta. (True/False)", "related_lectures": []}, {"_class": "assessment", "id": 57171588, "assessment_type": "multiple-choice", "prompt": {"question": "A user can be assigned multiple roles. (True / False)", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "<p>Roles are the entities to which privileges on securable objects can be granted and revoked. Roles are assigned to users to allow them to perform actions required for business functions in their organization. <strong>A user can be assigned multiple roles.</strong> It allows users to switch roles (i.e., choose which role is active in the current Snowflake session) to perform different actions using separate sets of privileges.</p>", "answers": ["TRUE", "FALSE"]}, "correct_response": ["a"], "section": "Account Access & Security", "question_plain": "A user can be assigned multiple roles. (True / False)", "related_lectures": []}, {"_class": "assessment", "id": 57171590, "assessment_type": "multiple-choice", "prompt": {"question": "Snowflake blocks certain IPs by default to ensure that customer is getting the highest level of Network security. (TRUE / FALSE)\t", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "<p><strong>By default, Snowflake allows users to connect to the service from any computer or device IP address.</strong> A security administrator (or higher) can create a network policy to allow or deny access to a single IP address or a list of addresses.</p>", "answers": ["TRUE", "FALSE"]}, "correct_response": ["b"], "section": "Account Access & Security", "question_plain": "Snowflake blocks certain IPs by default to ensure that customer is getting the highest level of Network security. (TRUE / FALSE)", "related_lectures": []}, {"_class": "assessment", "id": 57171592, "assessment_type": "multiple-choice", "prompt": {"question": "A user&#39;s default role is", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>A user's default role is the role a user gets set to each time the user logs in to Snowflake. Snowflake uses roles to control the objects (virtual warehouses, databases, tables, etc.) that users can access:&nbsp; &nbsp; &nbsp;</p><ul><li><p>Snowflake provides a set of predefined roles, as well as a framework for defining a hierarchy of custom roles.&nbsp; &nbsp; &nbsp; </p></li><li><p>All Snowflake users are automatically assigned the predefined PUBLIC role, which enables login to Snowflake and basic object access.&nbsp; &nbsp; &nbsp; </p></li><li><p>In addition to the PUBLIC role, each user can be assigned additional roles, with one of these roles designated as their default role. </p></li><li><p>A user\u2019s default role determines the role used in the Snowflake sessions initiated by the user; however, this is only a default. Users can change roles within a session at any time.&nbsp; &nbsp; &nbsp; </p></li><li><p>Roles can be assigned at user creation or afterward.</p></li></ul>", "answers": ["the name used to log in to the Snowflake WebUI.", "always the default PUBLIC role. ", "the role a user gets set to each time the user logs in to Snowflake.", "changed each time the user logs in to Snowflake."]}, "correct_response": ["c"], "section": "Account Access & Security", "question_plain": "A user&#39;s default role is", "related_lectures": []}, {"_class": "assessment", "id": 57171594, "assessment_type": "multiple-choice", "prompt": {"question": "Permissions on database objects such as databases or tables are granted to:", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p><strong>Snowflake supports Role-Based Access control</strong>. Permissions on database objects such as databases or tables are granted to Roles. </p>", "answers": ["Virtual Warehouses", "Roles", "Users", "Schemas"]}, "correct_response": ["b"], "section": "Account Access & Security", "question_plain": "Permissions on database objects such as databases or tables are granted to:", "related_lectures": []}, {"_class": "assessment", "id": 57171596, "assessment_type": "multiple-choice", "prompt": {"question": "<p>A user cannot view the result set from a query that another user executed except for the ACCOUNTADMIN role. (True / False)</p>", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "<p><strong>A user cannot view the result set from a query that another user executed.</strong> This behavior is intentional. For security reasons, only the user who executed a query can access the query results.\n\nThis behavior is not connected to the Snowflake access control model for objects. <strong>Even a user with the ACCOUNTADMIN role cannot view the results for a query run by another user</strong>.</p>", "answers": ["TRUE", "FALSE"]}, "correct_response": ["b"], "section": "Account Access & Security", "question_plain": "A user cannot view the result set from a query that another user executed except for the ACCOUNTADMIN role. (True / False)", "related_lectures": []}, {"_class": "assessment", "id": 57171598, "assessment_type": "multi-select", "prompt": {"question": "<p>Dynamic Data Masking is supported by (Select all that apply)</p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p><strong>Dynamic Data Masking</strong> <strong>features require Enterprise Edition (or higher).</strong></p>", "answers": ["Standard Edition", "Enterprise Edition", "Business Critical", "VPS"]}, "correct_response": ["b", "c", "d"], "section": "Account Access & Security", "question_plain": "Dynamic Data Masking is supported by (Select all that apply)", "related_lectures": []}, {"_class": "assessment", "id": 57171600, "assessment_type": "multiple-choice", "prompt": {"question": "At what frequency does Snowflake rotate the object keys?", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>All Snowflake-managed keys are automatically <strong>rotated by Snowflake when they are more than</strong> <strong>30 days</strong> old. Active keys are retired, and new keys are created. When Snowflake determines the retired key is no longer needed, the key is automatically destroyed. When active, a key is used to encrypt data and is available for usage by the customer. When retired, the key is used solely to decrypt data and is only available for accessing the data.</p>", "answers": ["16 Days", "30 Days", "60 Days", "1 Year"]}, "correct_response": ["b"], "section": "Account Access & Security", "question_plain": "At what frequency does Snowflake rotate the object keys?", "related_lectures": []}, {"_class": "assessment", "id": 57171602, "assessment_type": "multi-select", "prompt": {"question": "<p>Which IdP vendors provide native Snowflake support For federated authentication and SSO? (Select 2)</p>", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p><strong>Okta and Microsoft ADFS</strong> provide native Snowflake support for federated authentication and SSO. </p>", "answers": ["Onelogin", "Okta", "Microsoft ADFS", "Google G Suite", "Microsoft Azure Active Directory"]}, "correct_response": ["b", "c"], "section": "Account Access & Security", "question_plain": "Which IdP vendors provide native Snowflake support For federated authentication and SSO? (Select 2)", "related_lectures": []}, {"_class": "assessment", "id": 57171604, "assessment_type": "multiple-choice", "prompt": {"question": "If an account has federated authentication enabled. Can Snowflake admins still maintain user IDs and passwords in Snowflake?", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "<p>With federated authentication enabled on an account, Snowflake still allows maintaining and using Snowflake user credentials (login name and password). In other words:&nbsp; &nbsp; </p><ul><li><p>Account and security administrators can still create users with passwords maintained in Snowflake.&nbsp; &nbsp; </p></li><li><p>Users can still log into Snowflake using their Snowflake credentials.&nbsp; &nbsp;</p><p><br></p><p>However, if federated authentication is enabled for an account, Snowflake does not recommend maintaining user passwords in Snowflake. Instead, user passwords should be maintained solely in your IdP.\t&nbsp; &nbsp; </p></li></ul>", "answers": ["Yes", "No"]}, "correct_response": ["a"], "section": "Account Access & Security", "question_plain": "If an account has federated authentication enabled. Can Snowflake admins still maintain user IDs and passwords in Snowflake?", "related_lectures": []}, {"_class": "assessment", "id": 57171606, "assessment_type": "multiple-choice", "prompt": {"question": "The user access history can be found by querying the ", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>Access History in Snowflake refers to when the user query reads column data and when the SQL statement performs a data write operation, such as INSERT, UPDATE, and DELETE, along with variations of the COPY command, from the source data object to the target data object. <strong>The user access history can be found by querying the Account Usage ACCESS_HISTORY view.</strong></p>", "answers": ["Information Schema ACCESS_HISTORY view", "Account Usage ACCESS_HISTORY view", "Information Schema ACCESS_REPORT view", "Account Usage ACCESS_REPORT view"]}, "correct_response": ["b"], "section": "Account Access & Security", "question_plain": "The user access history can be found by querying the", "related_lectures": []}, {"_class": "assessment", "id": 57171608, "assessment_type": "multi-select", "prompt": {"question": "<p>The major benefits of defining Clustering Keys:&nbsp; (Select 2)</p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>Defining&nbsp;clustering keys&nbsp;for very large tables (in the multi-terabyte range) <strong>helps optimize table maintenance and query performance</strong>. Small tables are not a good candidate for clustering. </p>", "answers": ["To help optimize table maintenance", "To help improve query performance", "To help in faster data sharing", "To help in organizing small tables (&lt;1 GB)"]}, "correct_response": ["a", "b"], "section": "Performance Concepts", "question_plain": "The major benefits of defining Clustering Keys:&nbsp; (Select 2)", "related_lectures": []}, {"_class": "assessment", "id": 57171610, "assessment_type": "multiple-choice", "prompt": {"question": "Which of these are kind of Cache in Snowflake?", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>Snowflake has three types of cache. </p><ul><li><p>The <strong>metadata cache</strong> that lives in the cloud services layer. </p></li><li><p>The <strong>data cache/local disk cache</strong> that lives on the SSD drives in the virtual warehouses, and </p></li><li><p>The <strong>query result cache</strong>. If a result is small, it will be stored in the cloud services layer, but larger results are going to be stored in the storage layer. </p></li></ul>", "answers": ["Metadata Cache", "Data/Local Disk Cache", "Query Result Cache", "All of these"]}, "correct_response": ["d"], "section": "Performance Concepts", "question_plain": "Which of these are kind of Cache in Snowflake?", "related_lectures": []}, {"_class": "assessment", "id": 57171612, "assessment_type": "multiple-choice", "prompt": {"question": "How long do results remain in the Query results cache?", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p>Results are <strong>retained for 24 hours</strong> in Query Result Cache. Snowflake resets the 24-hour retention period for the result, <strong>up to a maximum of 31 days</strong> from the date and time that the query was first executed. After 31 days, the result is purged and the next time the query is submitted, a new result is generated and persisted.</p>", "answers": ["12 hours", "1 hours", "31 hours", "24 hours", "16 hours"]}, "correct_response": ["d"], "section": "Performance Concepts", "question_plain": "How long do results remain in the Query results cache?", "related_lectures": []}, {"_class": "assessment", "id": 57171614, "assessment_type": "multiple-choice", "prompt": {"question": "How can we turn off the query result cache?", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>We can turn off the query result cache by setting the parameter <strong>USE_CACHED_RESULT to FALSE</strong>. Though the only reason we would really want to do this is if we are doing performance testing.</p>", "answers": ["Setting the parameter USE_CACHED_INFO to FALSE", "Setting the parameter USE_CACHED_RESULT to FALSE", "Setting the parameter USE_QUERY_CACHED to FALSE", "Query result cache can be turned off. "]}, "correct_response": ["b"], "section": "Performance Concepts", "question_plain": "How can we turn off the query result cache?", "related_lectures": []}, {"_class": "assessment", "id": 57171616, "assessment_type": "multi-select", "prompt": {"question": "Monica ran a SELECT query on a large table t1. The query took longer than expected. She looked into the query profile and found that &#39; Bytes spilled to local storage&#39; and &#39;Bytes spilled to remote storage&#39; are very high. What advice will you give to her to improve the query performance? (Select 3)", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p>When Snowflake warehouse cannot fit an operation in memory, it starts spilling (storing) data first to the local disk of a warehouse node and then to remote storage. In such a case, Snowflake first tries to temporarily store the data on the warehouse's local disk. As this means extra IO operations, any query that requires spilling will take longer than a similar query running on similar data that is capable to fit the operations in memory. Also, if the local disk is insufficient to fit the spilled data, Snowflake further tries to write to the remote cloud storage, which will be shown in the query profile as \"Bytes spilled to remote storage\".&nbsp; </p><p><strong>The spilling can't always be avoided, especially for large batches of data, but it can be decreased by:&nbsp; </strong></p><ul><li><p>Reducing the amount of data processed. For example, by trying to improve partition pruning or projecting only the columns that are needed in the output. </p></li><li><p>Decreasing the number of parallel queries running in the warehouse. </p></li><li><p>Trying to split the processing into several steps (for example, by replacing the CTEs with temporary tables). </p></li><li><p>Using a larger warehouse - effectively means more memory and more local disk space.</p></li></ul>", "answers": ["Using a larger warehouse (effectively increasing the available memory/local disk space for the operation)", "Processing data in smaller batches", "Increasing the number of parallel queries running in the warehouse", "Trying to split the processing into several steps", "Processing data in larger batches"]}, "correct_response": ["a", "b", "d"], "section": "Performance Concepts", "question_plain": "Monica ran a SELECT query on a large table t1. The query took longer than expected. She looked into the query profile and found that &#39; Bytes spilled to local storage&#39; and &#39;Bytes spilled to remote storage&#39; are very high. What advice will you give to her to improve the query performance? (Select 3)", "related_lectures": []}, {"_class": "assessment", "id": 57171618, "assessment_type": "multiple-choice", "prompt": {"question": "Snowflake Query history page allows you to view the details of all the queries executed in the last 31 days. (True/False)", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "<p>Snowflake Query history page allows you to view the details of all the queries executed in the <strong>last 14 days</strong>. You can query the Query_History view in Snowflake's Account Usage schema for older queries.</p>", "answers": ["TRUE", "FALSE"]}, "correct_response": ["b"], "section": "Performance Concepts", "question_plain": "Snowflake Query history page allows you to view the details of all the queries executed in the last 31 days. (True/False)", "related_lectures": []}, {"_class": "assessment", "id": 57171620, "assessment_type": "multi-select", "prompt": {"question": "There are two modes to set up a multi-cluster warehouse. Select those from the given choices.", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p>There are two ways to set up a multi-cluster warehouse: in maximized mode, or auto-scaling mode. </p><p><strong>Maximized mode - You simply set your minimum equal to your maximum</strong>, and those values are something greater than one.</p><p><strong>Auto-Scaling mode</strong> - <strong>Specify different values for the maximum and the minimum number of clusters.</strong> In this mode, Snowflake starts and stops clusters as needed to dynamically manage the load on the warehouse:</p><ul><li><p>As the number of concurrent user sessions and/or queries for the warehouse increases, and queries start to queue due to insufficient resources, Snowflake automatically starts additional clusters, up to the maximum number defined for the warehouse.</p></li><li><p>Similarly, as the load on the warehouse decreases, Snowflake automatically shuts down clusters to reduce the number of running clusters and, correspondingly, the number of credits used by the warehouse.</p></li></ul>", "answers": ["Minimized mode", "Maximized mode", "Auto-scaling mode", "Maximum mode", "Minimum mode"]}, "correct_response": ["b", "c"], "section": "Performance Concepts", "question_plain": "There are two modes to set up a multi-cluster warehouse. Select those from the given choices.", "related_lectures": []}, {"_class": "assessment", "id": 57171622, "assessment_type": "multiple-choice", "prompt": {"question": "<p>Suppose you have an auto-scaling mode setup with an Economy policy. In what situation does Snowflake spin up an additional cluster?</p>", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "<p>In the <strong>Economy Scaling policy</strong>, Snowflake spins up an additional cluster only if the system estimates there\u2019s enough query load to keep the cluster busy for a <strong>least 6 minutes</strong>.</p>", "answers": ["Only if the system estimates there\u2019s enough query load to keep the cluster busy for at least 6 minutes.", "The first cluster starts immediately when either a query is queued or the system detects that there\u2019s one more query than the currently-running clusters can execute."]}, "correct_response": ["a"], "section": "Performance Concepts", "question_plain": "Suppose you have an auto-scaling mode setup with an Economy policy. In what situation does Snowflake spin up an additional cluster?", "related_lectures": []}, {"_class": "assessment", "id": 57171624, "assessment_type": "multiple-choice", "prompt": {"question": "Multi-cluster warehouses are beneficial in improving the performance of slow-running queries or data loading. (True/False)", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "<p>Multi-cluster warehouses are <strong>best utilized for scaling resources to improve concurrency</strong> for users/queries. They are not as beneficial for improving the performance of slow-running queries or data loading. For these types of operations, resizing the warehouse provides more benefits.</p>", "answers": ["TRUE", "FALSE"]}, "correct_response": ["b"], "section": "Performance Concepts", "question_plain": "Multi-cluster warehouses are beneficial in improving the performance of slow-running queries or data loading. (True/False)", "related_lectures": []}, {"_class": "assessment", "id": 57171626, "assessment_type": "multiple-choice", "prompt": {"question": "When deciding whether to suspend a warehouse or leave it running, what should you consider?", "relatedLectureIds": "", "feedbacks": ["", "", ""], "explanation": "<p>Consider the <strong>trade-off between saving credits by suspending a warehouse versus maintaining the cache of data</strong> from previous queries to help with performance.</p>", "answers": ["Consider the trade-off between saving credits by suspending the warehouse versus the operational cost of resuming the warehouse when needed. ", "Consider suspending the warehouse if the warehouse is large and there are no active queries.", "Consider the trade-off between saving credits by suspending the warehouse versus maintaining the cache of data from the previous queries to help with performance."]}, "correct_response": ["c"], "section": "Performance Concepts", "question_plain": "When deciding whether to suspend a warehouse or leave it running, what should you consider?", "related_lectures": []}, {"_class": "assessment", "id": 57171628, "assessment_type": "multiple-choice", "prompt": {"question": "What would happen if we suspend the warehouse while it is executing the SQL statement?", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>When we suspend a warehouse, Snowflake immediately shuts down all idle compute resources for the warehouse. However, <strong>it allows any compute resources executing statements to continue until the statements are complete.</strong> At this time, the resources are shut down, and the warehouse status changes to \u201cSuspended\u201d. Compute resources waiting to shut down are considered to be in \u201cquiesce\u201d mode.</p>", "answers": ["All the compute resources of the warehouse will be shut down immediately, and the running statement will be canceled.", "Only idle compute resources of the warehouse will be shut down, allowing any compute resources executing statements to continue until the statement is complete.", "All compute resources of the warehouse will be up until the statement is complete.", "When trying to suspend the warehouse, we will get an error while the same warehouse is executing SQL statements."]}, "correct_response": ["b"], "section": "Performance Concepts", "question_plain": "What would happen if we suspend the warehouse while it is executing the SQL statement?", "related_lectures": []}, {"_class": "assessment", "id": 57171630, "assessment_type": "multiple-choice", "prompt": {"question": "The suspended warehouse cannot be resized until they resume. (True / False)", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "<p>The suspended warehouse <strong>can be easily resized</strong>. Resizing a suspended warehouse <strong>does not provision any new compute</strong> resources for the warehouse. It simply <strong>instructs Snowflake to provision the additional compute resources when the warehouse is next resumed</strong>, at which time all the usage and credit rules associated with starting a warehouse apply.</p>", "answers": ["TRUE", "FALSE"]}, "correct_response": ["b"], "section": "Performance Concepts", "question_plain": "The suspended warehouse cannot be resized until they resume. (True / False)", "related_lectures": []}, {"_class": "assessment", "id": 57171632, "assessment_type": "multiple-choice", "prompt": {"question": "Which schema can be used to find out about storage, compute, and objects in a Snowflake account?", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p><strong>INFORMATION_SCHEMA can be used </strong>to find out about storage, compute, and objects in a Snowflake account. Every database that you create on Snowflake has a schema called INFORMATION_SCHEMA that's automatically created, and inside that schema, you can find views and table functions that provide metadata information about objects in your account.</p>", "answers": ["RESOURCE_SCHEMA", "SNOWFLAKE_SCHEMA", "USAGE_SCHEMA", "INFORMATION_SCHEMA"]}, "correct_response": ["d"], "section": "Performance Concepts", "question_plain": "Which schema can be used to find out about storage, compute, and objects in a Snowflake account?", "related_lectures": []}, {"_class": "assessment", "id": 57171634, "assessment_type": "multiple-choice", "prompt": {"question": "<p>David ran a query that took approximately 30 minutes to finish. He checked the Query profiler and noticed a high number for 'Bytes spilled to local storage'. What might be the problem?</p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>If a node lacks enough memory to finish its part of a query, it will resort to spilling to local SSD storage, which can harm performance but may still be tolerable. On the other hand, if the node lacks sufficient local SSD storage to complete its query, it will spill to remote cloud storage, which severely impacts performance. To resolve the issue, either the SQL query needs to be simplified or the warehouse size needs to be increased.</p>", "answers": ["David is using a comparatively larger warehouse.", "David is using a comparatively smaller warehouse. ", "Warehouse size has no impact on Bytes spilling.", "David should contact Snowflake Personnel.  "]}, "correct_response": ["b"], "section": "Performance Concepts", "question_plain": "David ran a query that took approximately 30 minutes to finish. He checked the Query profiler and noticed a high number for 'Bytes spilled to local storage'. What might be the problem?", "related_lectures": []}, {"_class": "assessment", "id": 57171636, "assessment_type": "multiple-choice", "prompt": {"question": "An account-level resource monitor overrides the resource monitor assignment for individual warehouses. (True/False)", "answers": ["TRUE", "FALSE"], "explanation": "An account-level resource monitor does not override resource monitor assignments for individual warehouses. If either the account resource monitor or the warehouse resource monitor reaches its defined threshold and a suspend action has been defined, the warehouse is suspended."}, "correct_response": ["b"], "section": "Performance Concepts", "question_plain": "An account-level resource monitor overrides the resource monitor assignment for individual warehouses. (True/False)", "related_lectures": []}, {"_class": "assessment", "id": 57171638, "assessment_type": "multi-select", "prompt": {"question": "<p>What all locations do Snowflake support for staging the data? (Select all that apply)</p>", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p>Snowflake supports loading data from files staged in any of the following locations <strong>(except Oracle Cloud Storage)</strong>, regardless of the cloud platform for your Snowflake account:</p><ul><li><p>Internal (i.e. Snowflake) stages</p></li><li><p>Amazon S3</p></li><li><p>Google Cloud Storage</p></li><li><p>Microsoft Azure blob storage</p></li></ul>", "answers": ["Snowflake Internal Stages", "Amazon S3", "Google Cloud Storage", "Microsoft Azure Blob Storage", "Oracle Cloud Storage"]}, "correct_response": ["a", "b", "c", "d"], "section": "Data Loading and Unloading", "question_plain": "What all locations do Snowflake support for staging the data? (Select all that apply)", "related_lectures": []}, {"_class": "assessment", "id": 57171640, "assessment_type": "multiple-choice", "prompt": {"question": "John is trying to load JSON data sets with a huge array containing multiple records. Considering the VARIANT data type imposed size of 16 MB, what do you recommend to John for optimally loading the data?", "answers": ["Separate the documents with line break of commas", "Enable the STRIP_OUTER_ARRAY file format option for the COPY INTO &lt;table&gt; command", "Enable VARIANT_OUTER_ARRAY file format for the COPY INTO &lt;table&gt; command", "No need to remove the outer array structure as Snowflake Intelligent Engine will take care of that"], "explanation": "If the data exceeds 16 MB, enable the STRIP_OUTER_ARRAY file format option for the COPY INTO &lt;table&gt; command to remove the outer array structure and load the records into separate table rows:\n\ncopy into &lt;table&gt;\n  from @~/&lt;file&gt;.json\n  file_format = (type = &#39;JSON&#39; strip_outer_array = true);\n"}, "correct_response": ["b"], "section": "Data Loading and Unloading", "question_plain": "John is trying to load JSON data sets with a huge array containing multiple records. Considering the VARIANT data type imposed size of 16 MB, what do you recommend to John for optimally loading the data?", "related_lectures": []}, {"_class": "assessment", "id": 57171642, "assessment_type": "multiple-choice", "prompt": {"question": "Which of the following file format is not supported by Snowflake?", "answers": ["CSV", "AVRO", "ORC", "PARQUET", "JSON", "EDI"], "explanation": "Snowflake supports - CSV, TSV, JSON, AVRO, ORC, PARQUET. Snowflake also supports XML which is a Preview feature as of now. EDI format is not supported by Snowflake. "}, "correct_response": ["f"], "section": "Data Loading and Unloading", "question_plain": "Which of the following file format is not supported by Snowflake?", "related_lectures": []}, {"_class": "assessment", "id": 57171644, "assessment_type": "multi-select", "prompt": {"question": "<p>What are the supported file formats for data unloading in Snowflake?</p>", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p>Currently, <strong>only JSON and Parquet file formats are supported for data unloading.</strong> Other formats are not supported at this time. However, all of these file formats are supported for data loading.</p>", "answers": ["<p>XML</p>", "<p>JSON</p>", "<p>Avro</p>", "<p>ORC</p>", "<p>Parquet</p>"]}, "correct_response": ["b", "e"], "section": "Data Loading and Unloading", "question_plain": "What are the supported file formats for data unloading in Snowflake?", "related_lectures": []}, {"_class": "assessment", "id": 57171646, "assessment_type": "multiple-choice", "prompt": {"question": "Which is generally the slowest option for selecting staged data files to load from a stage?", "answers": ["By path (internal stages) / prefix (Amazon S3 bucket)", "Using pattern matching to identify specific files by pattern\n", "Specifying a list of specific files to load"], "explanation": "Pattern matching using a regular expression is generally the slowest of the three options for identifying/specifying data files to load from a stage; however, this option works well if you exported your files in named order from your external application and want to batch load the files in the same order"}, "correct_response": ["b"], "section": "Data Loading and Unloading", "question_plain": "Which is generally the slowest option for selecting staged data files to load from a stage?", "related_lectures": []}, {"_class": "assessment", "id": 57171648, "assessment_type": "multiple-choice", "prompt": {"question": "If you recreate a pipe using CREATE OR REPLACE PIPE command.\nWhat does happen to load history if the Snowpipe gets recreated?", "answers": ["Snowflake still keeps load history", "The recreated Pipe still has tracks of the files loaded by the old Pipe", "The pipe can not be recreated", "The load history gets reset to empty"], "explanation": "When you recreate a pipe, if you do CREATE OR REPLACE PIPE, that load history is reset to empty, so Snowflake doesn&#39;t know which files we&#39;ve already loaded."}, "correct_response": ["d"], "section": "Data Loading and Unloading", "question_plain": "If you recreate a pipe using CREATE OR REPLACE PIPE command.\nWhat does happen to load history if the Snowpipe gets recreated?", "related_lectures": []}, {"_class": "assessment", "id": 57171650, "assessment_type": "multiple-choice", "prompt": {"question": "John has to create a PIPE that will be triggered for loading by calling the Snowpipe REST endpoints. What parameter does he need to specify in CREATE PIPE statement?", "answers": ["AUTO_INGEST = FALSE", "API_INGEST = TRUE", "AUTO_INGEST = TRUE", "API_INGEST = FALSE"], "explanation": "AUTO_INGEST = TRUE enables automatic data loading. Snowpipe supports loading from external stages (Amazon S3, Google Cloud Storage, or Microsoft Azure).\n\nAUTO_INGEST = FALSE disables automatic data loading. You must make calls to the Snowpipe REST API endpoints to load data files.\n"}, "correct_response": ["a"], "section": "Data Loading and Unloading", "question_plain": "John has to create a PIPE that will be triggered for loading by calling the Snowpipe REST endpoints. What parameter does he need to specify in CREATE PIPE statement?", "related_lectures": []}, {"_class": "assessment", "id": 57171652, "assessment_type": "multi-select", "prompt": {"question": "Which copyOptions can help load a file with expired metadata (if the LAST_MODIFIED date is older than 64 days and the initial set of data was loaded into the table more than 64 days earlier (and if the file was loaded into the table, that also occurred more than 64 days earlier))? (Select 2)", "relatedLectureIds": "", "feedbacks": ["", "", "", "", "", ""], "explanation": "To load files whose metadata has expired, set the LOAD_UNCERTAIN_FILES copy option to true. The copy option references load metadata, if available, to avoid data duplication, but also attempts to load files with expired load metadata.\n\nAlternatively, set the FORCE option to load all files, ignoring load metadata if it exists. Note that this option reloads files, potentially duplicating data in a table.", "answers": ["LOAD_FILES = TRUE", "LOAD_CERTAIN_FILES = TRUE", "LOAD_UNCERTAIN_FILES = TRUE", "FORCE = FALSE", "FORCE = TRUE", "ON_ERROR = CONTINUE"]}, "correct_response": ["c", "e"], "section": "Data Loading and Unloading", "question_plain": "Which copyOptions can help load a file with expired metadata (if the LAST_MODIFIED date is older than 64 days and the initial set of data was loaded into the table more than 64 days earlier (and if the file was loaded into the table, that also occurred more than 64 days earlier))? (Select 2)", "related_lectures": []}, {"_class": "assessment", "id": 57171654, "assessment_type": "multiple-choice", "prompt": {"question": "What is the purpose of VALIDATION_MODE in the COPY INTO &lt;table&gt; command?", "answers": ["VALIDATION_MODE is used to validate the load file and load it into the specified table if there is no error.", "VALIDATION_MODE is used to validate the load file for errors instead of loading it into the specified table.", "VALIDATION_MODE is used to validate the load file, skip the errored data and then load it into the specified table."], "explanation": "VALIDATION_MODE instructs the COPY command to validate the data files instead of loading them into the specified table; i.e., the COPY command tests the files for errors but does not load them. The command validates the data to be loaded and returns results based on the validation option specified:\n\nSyntax : VALIDATION_MODE = RETURN_n_ROWS | RETURN_ERRORS | RETURN_ALL_ERRORS\n\nRETURN_n_ROWS (e.g. RETURN_10_ROWS) - Validates the specified number of rows, if no errors are encountered; otherwise, fails at the first error encountered in the rows.\n\nRETURN_ERRORS - Returns all errors (parsing, conversion, etc.) across all files specified in the COPY statement.\n\nRETURN_ALL_ERRORS - Returns all errors across all files specified in the COPY statement, including files with errors that were partially loaded during an earlier load because the ON_ERROR copy option was set to CONTINUE during the load."}, "correct_response": ["b"], "section": "Data Loading and Unloading", "question_plain": "What is the purpose of VALIDATION_MODE in the COPY INTO &lt;table&gt; command?", "related_lectures": []}, {"_class": "assessment", "id": 57171656, "assessment_type": "multiple-choice", "prompt": {"question": "How can you unload the data from Snowflake using COPY INTO location statements in a Single file?", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>To unload data to a single output file (at the potential cost of decreased performance), specify the <strong>SINGLE = TRUE</strong> copy option in your statement. You can optionally specify a name for the file in the path.</p>", "answers": ["By specifying copy option SINGLE=TRUE", "By specifying copy option MULTIPLE=FALSE", "By specifying copy option ONE_FILE=TRUE", "By specifying copy option MULTIPLE_FILES=FALSE"]}, "correct_response": ["a"], "section": "Data Loading and Unloading", "question_plain": "How can you unload the data from Snowflake using COPY INTO location statements in a Single file?", "related_lectures": []}, {"_class": "assessment", "id": 57171658, "assessment_type": "multi-select", "prompt": {"question": "<p>What all options are available for data transformation while loading data into a table using the COPY command? (Select all that apply)</p>", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p><strong>Snowflake supports transforming data while loading it into a table using the COPY command. Options include: </strong></p><ul><li><p><strong>Column reordering </strong></p></li><li><p><strong>Column omission </strong></p></li><li><p><strong>Casts </strong></p></li><li><p><strong>Truncating text strings that exceed the target column length</strong></p></li></ul>", "answers": ["Column reordering", "Column omission", "Casts", "Truncation of Text Strings", "Join"]}, "correct_response": ["a", "b", "c", "d"], "section": "Data Transformation", "question_plain": "What all options are available for data transformation while loading data into a table using the COPY command? (Select all that apply)", "related_lectures": []}, {"_class": "assessment", "id": 57171660, "assessment_type": "multiple-choice", "prompt": {"question": "Which algorithm does Snowflake use to estimate the approximate number of distinct values in a data set?", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p><strong>Snowflake uses HyperLogLog to estimate the approximate number of distinct values in a data set.</strong> HyperLogLog is a state-of-the-art cardinality estimation algorithm, capable of estimating distinct cardinalities of trillions of rows with an average relative error of a few percent.</p>", "answers": ["HyperEstimateLog", "HyperLogLog", "HyerAccumulateLog", "HyperMedianLog", "HyperMeanLog"]}, "correct_response": ["b"], "section": "Data Transformation", "question_plain": "Which algorithm does Snowflake use to estimate the approximate number of distinct values in a data set?", "related_lectures": []}, {"_class": "assessment", "id": 57171662, "assessment_type": "multiple-choice", "prompt": {"question": "select * from t1 sample row(100);\nWhat would the above query return?", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p><strong>Return an entire table</strong>, including all rows in the table. The sampling method is optional. If no method is applied after the sample keyword, the <strong>default it takes is BERNOULLI</strong>.</p>", "answers": ["Return an empty sample", "Return an entire table, including all rows in the table", "Return a sample of a table in which each row has a 10% probability of being included in the sample", "samplingMethod is not applied in the query. The query will result in an error."]}, "correct_response": ["b"], "section": "Data Transformation", "question_plain": "select * from t1 sample row(100);\nWhat would the above query return?", "related_lectures": []}, {"_class": "assessment", "id": 57171664, "assessment_type": "multi-select", "prompt": {"question": "<p>Which of these SQL functions does Snowflake support? (Select all that apply)</p>", "relatedLectureIds": "", "feedbacks": ["", "", "", "", "", ""], "explanation": "Snowflake Supports all these SQL functions.", "answers": ["Scalar", "Aggregate", "Window", "System", "Table", "User-Defined"]}, "correct_response": ["a", "b", "c", "d", "e", "f"], "section": "Data Transformation", "question_plain": "Which of these SQL functions does Snowflake support? (Select all that apply)", "related_lectures": []}, {"_class": "assessment", "id": 57171666, "assessment_type": "multiple-choice", "prompt": {"question": "Select the type of function that can operate on a subset of rows within the set of input rows.", "relatedLectureIds": "", "feedbacks": ["", "", "", "", "", ""], "explanation": "A window function is any function that operates over a window of rows.\n", "answers": ["Aggregate Function", "Scalar Function", "Window Function", "Table Function", "User-Defined Function", "System Function"]}, "correct_response": ["c"], "section": "Data Transformation", "question_plain": "Select the type of function that can operate on a subset of rows within the set of input rows.", "related_lectures": []}, {"_class": "assessment", "id": 57171668, "assessment_type": "multi-select", "prompt": {"question": "<p>Which of the following languages does Snowflake support for writing UDFs (User-Defined Functions)? (Select 4)</p>", "relatedLectureIds": "", "feedbacks": ["", "", "", "", "", ""], "explanation": "<p><strong>User-defined functions (UDFs) let you extend the system to perform operations that are not available through the built-in, system-defined functions provided by Snowflake. Snowflake currently supports the following languages for writing UDFs:</strong>\n\n<strong>Java: </strong>A Java UDF lets you use the Java programming language to manipulate data and return either scalar or tabular results.\n\n<strong>JavaScript:</strong> A JavaScript UDF lets you use the JavaScript programming language to manipulate data and return either scalar or tabular results.\n\n<strong>Python:</strong> A Python UDF lets you use the Python programming language to manipulate data and return either scalar or tabular results.\n\n<strong>SQL: </strong>A SQL UDF evaluates an arbitrary SQL expression and returns either scalar or tabular results.</p>", "answers": ["JAVA", "JavaScript", "GO", "SQL", "Python", "C#"]}, "correct_response": ["a", "b", "d", "e"], "section": "Data Transformation", "question_plain": "Which of the following languages does Snowflake support for writing UDFs (User-Defined Functions)? (Select 4)", "related_lectures": []}, {"_class": "assessment", "id": 57171670, "assessment_type": "multiple-choice", "prompt": {"question": "What would you create (UDF or Stored procedure) if you need a function that can be called as part of a SQL statement and must return a value that will be used in the statement?", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "<p>A <strong>UDF</strong> evaluates to a value and can be used in contexts in which a general expression can be used (e.g. SELECT my_function() ...).&nbsp; </p><p><br></p><p>A <strong>stored procedure</strong> does not evaluate to a value, and cannot be used in all contexts in which a general expression can be used. For example, you cannot execute SELECT my_stored_procedure()....</p>", "answers": ["Stored Procedure", "UDF"]}, "correct_response": ["b"], "section": "Data Transformation", "question_plain": "What would you create (UDF or Stored procedure) if you need a function that can be called as part of a SQL statement and must return a value that will be used in the statement?", "related_lectures": []}, {"_class": "assessment", "id": 57171672, "assessment_type": "multiple-choice", "prompt": {"question": "The VALIDATION_MODE parameter does not support COPY statements that transform data during a load. (True / False)", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "<p>True.&nbsp; </p><p><strong>VALIDATION_MODE instructs the COPY command to validate the data files instead of loading them into the specified table;</strong> i.e., the COPY command tests the files for errors but does not load them. </p><p><br></p><p>The command validates the data to be loaded and returns results based on the validation option specified:&nbsp; </p><p>Syntax: <strong>VALIDATION_MODE = RETURN_n_ROWS | RETURN_ERRORS | RETURN_ALL_ERRORS </strong> </p><p><strong>RETURN_n_ROWS (e.g. RETURN_10_ROWS)</strong> - Validates the specified number of rows, if no errors are encountered; otherwise, fails at the first error encountered in the rows.&nbsp; </p><p><strong>RETURN_ERRORS</strong> - Returns all errors (parsing, conversion, etc.) across all files specified in the COPY statement.&nbsp; </p><p><strong>RETURN_ALL_ERRORS</strong> - Returns all errors across all files specified in the COPY statement, including files with errors that were partially loaded during an earlier load because the ON_ERROR copy option was set to CONTINUE during the load.\"</p>", "answers": ["TRUE", "FALSE"]}, "correct_response": ["a"], "section": "Data Transformation", "question_plain": "The VALIDATION_MODE parameter does not support COPY statements that transform data during a load. (True / False)", "related_lectures": []}, {"_class": "assessment", "id": 57171674, "assessment_type": "multiple-choice", "prompt": {"question": "While transforming Semi-structure data, If you want expansion for all the sub-elements recursively using FLATTEN function, what argument would you need to set with FLATTEN function?", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>The expansion is performed for all sub-elements recursively by argument <strong>RECURSIVE =&gt; TRUE</strong>. \n\nOnly the element referenced by PATH is expanded BY RECURSIVE =&gt; FALSE.\n\nThe OUTER argument is used to handle the input rows that cannot be expanded, either because they cannot be accessed in the path or because they have zero fields or entries.</p>", "answers": ["OUTER =&gt; TRUE ", "RECURSIVE =&gt; TRUE ", "OUTER =&gt; FALSE", "RECURSIVE =&gt; FALSE"]}, "correct_response": ["b"], "section": "Data Transformation", "question_plain": "While transforming Semi-structure data, If you want expansion for all the sub-elements recursively using FLATTEN function, what argument would you need to set with FLATTEN function?", "related_lectures": []}, {"_class": "assessment", "id": 57171676, "assessment_type": "multiple-choice", "prompt": {"question": "<p>What value will be returned by the following query?&nbsp; </p><p><br></p><p>SELECT * FROM TABLE(FLATTEN(input =&gt; parse_json('[]'))) f;</p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "If you don\u2019t specify OUTER argument with FLATTEN, it would be defaulted to FALSE. \n\nThe OUTER =&gt; FALSE argument with FLATTEN omits the output of the input rows that cannot be expanded, either because they cannot be accessed in the path or because they have zero fields or entries.", "answers": ["0", "[]", "NULL", "nothing will return / output of the input row will be omitted"]}, "correct_response": ["d"], "section": "Data Transformation", "question_plain": "What value will be returned by the following query?&nbsp; SELECT * FROM TABLE(FLATTEN(input =&gt; parse_json('[]'))) f;", "related_lectures": []}, {"_class": "assessment", "id": 57171678, "assessment_type": "multiple-choice", "prompt": {"question": "Which data does not fit into a predefined data model or schema?", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p><strong>Unstructured data is information that does not fit into a predefined data model or schema. </strong>Typically text-heavy, such as form responses and social media conversations, unstructured data encompasses images, video, and audio. Industry-specific file types such as VCF (genomics), KDF (semiconductors), or HDF5 (aeronautics) are included in this category.</p>", "answers": ["Structured-data", "Semi-Structured Data", "Unstructured Data", "All of these"]}, "correct_response": ["c"], "section": "Data Transformation", "question_plain": "Which data does not fit into a predefined data model or schema?", "related_lectures": []}, {"_class": "assessment", "id": 57171680, "assessment_type": "multiple-choice", "prompt": {"question": "Both external (external cloud storage) and internal (i.e., Snowflake) stages support unstructured data. (True / False)", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "True, both external (external cloud storage, such as, Amazon S3, Google Cloud Storage, Azure Blob Storage etc.) and internal (i.e. Snowflake) stages support unstructured data.", "answers": ["TRUE", "FALSE"]}, "correct_response": ["a"], "section": "Data Transformation", "question_plain": "Both external (external cloud storage) and internal (i.e., Snowflake) stages support unstructured data. (True / False)", "related_lectures": []}, {"_class": "assessment", "id": 57171682, "assessment_type": "multiple-choice", "prompt": {"question": "Which of these functions helps generate the FILE URL to access the unstructured data file?", "relatedLectureIds": "", "feedbacks": ["", "", "", "", "", ""], "explanation": "<p><strong>BUILD_STAGE_FILE_URL</strong> generates a Snowflake-hosted file URL to a staged file using the stage name and relative file path as inputs. A file URL permits prolonged access to a specified file. That is, the file URL does not expire.\n\nFile URL: URL that identifies the database, schema, stage, and file path to a set of files. A role that has sufficient privileges on the stage can access the files.</p>", "answers": ["BUILD_SCOPED_FILE_URL", "GET_STAGE_LOCATION", "GET_RELATIVE_PATH", "<p>BUILD_STAGE_FILE_URL</p>", "GET_PRESIGNED_URL", "GET_ABSOLUTE_PATH"]}, "correct_response": ["d"], "section": "Data Transformation", "question_plain": "Which of these functions helps generate the FILE URL to access the unstructured data file?", "related_lectures": []}, {"_class": "assessment", "id": 57171684, "assessment_type": "multiple-choice", "prompt": {"question": "Which of these SQL functions helps returns the absolute path of a staged file using the stage name and path of the file relative to its location in the stage as inputs.?", "relatedLectureIds": "", "feedbacks": ["", "", "", "", "", ""], "explanation": "<p><strong>GET_ABSOLUTE_PATH returns the absolute path of a staged file</strong> using the stage name and path of the file relative to its location in the stage as inputs.</p>", "answers": ["BUILD_SCOPED_FILE_URL", "GET_STAGE_LOCATION", "GET_RELATIVE_PATH", "BUILD_STAGE_FILE_URI", "GET_PRESIGNED_URL", "GET_ABSOLUTE_PATH"]}, "correct_response": ["f"], "section": "Data Transformation", "question_plain": "Which of these SQL functions helps returns the absolute path of a staged file using the stage name and path of the file relative to its location in the stage as inputs.?", "related_lectures": []}, {"_class": "assessment", "id": 57171686, "assessment_type": "multiple-choice", "prompt": {"question": "How can we add a Directory table explicitly to a stage to store a catalog of staged files?", "relatedLectureIds": "", "feedbacks": ["", "", ""], "explanation": "A Directory table is not a separate database object; it stores a catalog of staged files in cloud storage. Roles with sufficient privileges can query a directory table to retrieve file URLs to access the staged files and other metadata. \n\nA directory table can be added explicitly to a stage when the stage is created (using CREATE STAGE) or later (using ALTER STAGE) with supplying directoryTableParams.\n\ndirectoryTableParams (for internal stages) ::=\n  [ DIRECTORY = ( ENABLE = { TRUE | FALSE }\n                  [ REFRESH_ON_CREATE =  { TRUE | FALSE } ] ) ]\n\nENABLE = TRUE | FALSE     Specifies whether to add a directory table to the stage. When the value is TRUE, a directory table is created with the stage.", "answers": ["Using CREATE DIRECTORY TABLE command and then add to the stage by ALTER STAGE command", "Using CREATE DIRECTORY TABLES command and then add to the stage by ALTER STAGE command", "Using CREATE STAGE command "]}, "correct_response": ["c"], "section": "Data Transformation", "question_plain": "How can we add a Directory table explicitly to a stage to store a catalog of staged files?", "related_lectures": []}, {"_class": "assessment", "id": 57171688, "assessment_type": "multiple-choice", "prompt": {"question": "The Snowflake Information Schema includes table functions you can query to retrieve information about your directory tables. Which table function can be used to query the history of data files registered in the metadata of specified objects and the credits billed for these operations?", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>\n<strong>AUTO_REFRESH_REGISTRATION_HISTORY</strong> table function can be used to query the history of data files registered in the metadata of specified objects and the credits billed for these operations. The table function returns the billing history within a specified date range for your entire Snowflake account. <strong>This function returns billing activity within the last 14 days.</strong>&nbsp; </p><p><br></p><p>Please note, STAGE_DIRECTORY_FILE_REGISTRATION_HISTORY table function can be used to query information about the metadata history for a directory table, including:&nbsp; &nbsp; &nbsp; </p><ul><li><p>Files added or removed automatically as part of a metadata refresh.&nbsp; &nbsp; &nbsp;</p></li><li><p>Any errors found when refreshing the metadata.</p></li></ul>", "answers": ["DATABASE_REFRESH_HISTORY", "AUTO_REFRESH_REGISTRATION_HISTORY", "STAGE_DIRECTORY_FILE_REGISTRATION_HISTORY", "STAGE_STORAGE_USAGE_HISTORY"]}, "correct_response": ["b"], "section": "Data Transformation", "question_plain": "The Snowflake Information Schema includes table functions you can query to retrieve information about your directory tables. Which table function can be used to query the history of data files registered in the metadata of specified objects and the credits billed for these operations?", "related_lectures": []}, {"_class": "assessment", "id": 57171690, "assessment_type": "multi-select", "prompt": {"question": "<p>What authentication methods does Snowflake support for REST API authentication? (Select 2)</p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>Snowflake SQL API supports <strong>Oauth, and Key Pair authentication</strong>.</p>", "answers": ["OAuth", "Snowflake Account User ID and Password", "Key Pair Authentication ", "Authentication is not required in case Snowflake SQL API"]}, "correct_response": ["a", "c"], "section": "Data Transformation", "question_plain": "What authentication methods does Snowflake support for REST API authentication? (Select 2)", "related_lectures": []}, {"_class": "assessment", "id": 57171692, "assessment_type": "multiple-choice", "prompt": {"question": "Only the user who generated the scoped URL can use the URL to access the referenced file. (True/False)", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "True, only the user who generated the scoped URL can use the URL to access the referenced file. I case of File URL, any role that has sufficient privileges on the stage can access the file.", "answers": ["TRUE", "FALSE"]}, "correct_response": ["a"], "section": "Data Transformation", "question_plain": "Only the user who generated the scoped URL can use the URL to access the referenced file. (True/False)", "related_lectures": []}, {"_class": "assessment", "id": 57171694, "assessment_type": "multiple-choice", "prompt": {"question": "File URL is ideal for", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p><strong>File URL:</strong> URL that identifies the database, schema, stage, and file path to a set of files. A role that has sufficient privileges on the stage can access the files. <strong>Ideal for custom applications that require access to unstructured data files. </strong></p><p><br></p><p><strong>Scoped URL:</strong> Encoded URL that permits temporary access to a staged file without granting privileges to the stage. The URL expires when the persisted query result period ends (i.e., the results cache expires), which is currently 24 hours. <strong>Ideal for use in custom applications, providing unstructured data to other accounts via a share, or for downloading and ad hoc analysis of unstructured data via Snowsight. </strong> </p><p><br></p><p><strong>Pre-signed URL:</strong> Simple HTTPS URL used to access a file via a web browser. A file is temporarily accessible to users via this URL using a pre-signed access token. The expiration time for the access token is configurable. <strong>Ideal for business intelligence applications or reporting tools that need to display unstructured file contents.</strong></p>", "answers": ["<p>custom applications that require access to unstructured data files</p>", "<p>use in custom applications, providing unstructured data to other accounts via a share</p>", "<p>business intelligence applications or reporting tools that need to display the unstructured file contents</p>", "None of these"]}, "correct_response": ["a"], "section": "Data Transformation", "question_plain": "File URL is ideal for", "related_lectures": []}, {"_class": "assessment", "id": 57171696, "assessment_type": "multiple-choice", "prompt": {"question": "What is the expiration period of a File URL?", "relatedLectureIds": "", "feedbacks": ["", "", ""], "explanation": "<p>The expiration period of <strong>Scoped URL:</strong> The URL expires when the persisted query result period ends.\n</p><p>The expiration period of the <strong>File URL:</strong> It is permanent.\n</p><p>The expiration period of <strong>Pre-Signed URL:</strong> Length of time specified in the expiration_time argument.</p>", "answers": ["The URL expires when the persisted query result period ends", "It is Permanent", "Length of time specified in the expiration_time argument"]}, "correct_response": ["b"], "section": "Data Transformation", "question_plain": "What is the expiration period of a File URL?", "related_lectures": []}, {"_class": "assessment", "id": 57171698, "assessment_type": "multiple-choice", "prompt": {"question": "<p>Which of these Snowflake Editions automatically stores data in an encrypted state? </p>", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p><strong>All</strong> of the Snowflake Editions (Standard, Enterprise, Business Critical, Virtual Private Snowflake) automatically store data in an encrypted state.</p>", "answers": ["Standard", "Enterprise", "Business Critical", "Virtual Private Snowflake(VPS)", "All of the Snowflake Editions"]}, "correct_response": ["e"], "section": "Data Protection and Data Sharing", "question_plain": "Which of these Snowflake Editions automatically stores data in an encrypted state?", "related_lectures": []}, {"_class": "assessment", "id": 57171700, "assessment_type": "multiple-choice", "prompt": {"question": "If we make any changes to the original table, then", "relatedLectureIds": "", "feedbacks": ["", "", ""], "explanation": "<p><strong>Zero-copy cloning allows us to make a snapshot </strong>of any table, schema, or database without actually copying data.\n\n<strong>A clone is writable and is independent of its source (i.e., changes made to the source or clone are not reflected in the other object).</strong>\n\nA new clone of a table points to the original table's micro partitions, using no data storage. If we make any changes in the cloned table, then only its changed micro partitions are written to storage. </p>", "answers": ["The changes get immediately reflected in the cloned table", "The changes do not reflect in the cloned table", "The cloned table data get refreshed with the entire new data of the source table"]}, "correct_response": ["b"], "section": "Data Protection and Data Sharing", "question_plain": "If we make any changes to the original table, then", "related_lectures": []}, {"_class": "assessment", "id": 57171702, "assessment_type": "multiple-choice", "prompt": {"question": "Which of these Snowflake features does enable accessing historical data (i.e., data that has been changed or deleted) at any point within a defined period?", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>Snowflake <strong>Time Travel enables accessing historical data</strong> (i.e. data that has been changed or deleted) at any point within a defined period. It serves as a powerful tool for performing the following tasks:&nbsp; </p><ul><li><p>Restoring data-related objects (tables, schemas, and databases) that might have been accidentally or intentionally deleted. - Duplicating and backing up data from key points in the past. </p></li><li><p>Analyzing data usage/manipulation over specified periods of time.</p></li></ul>", "answers": ["Zero Copy Cloning", "Data Sharing", "Time Travel", "Search Optimization Service"]}, "correct_response": ["c"], "section": "Data Protection and Data Sharing", "question_plain": "Which of these Snowflake features does enable accessing historical data (i.e., data that has been changed or deleted) at any point within a defined period?", "related_lectures": []}, {"_class": "assessment", "id": 57171704, "assessment_type": "multiple-choice", "prompt": {"question": "What happens to the data when the retention period ends for an object?", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>When the retention period ends for an object, the <strong>historical data is moved into Snowflake Fail-safe</strong>. Snowflake support needs to be contacted to get the data restored from Fail-safe.</p>", "answers": ["Data is permanently lost ", "Data can be restored by increasing the retention period", "Data is moved to Snowflake Fail-safe", "SYSADMIN can restore the data from Fail-safe"]}, "correct_response": ["c"], "section": "Data Protection and Data Sharing", "question_plain": "What happens to the data when the retention period ends for an object?", "related_lectures": []}, {"_class": "assessment", "id": 57171706, "assessment_type": "multiple-choice", "prompt": {"question": "Which object parameter can users with the ACCOUNTADMIN role use to set the default retention period for their account?", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>Users can use the <strong>DATA_RETENTION_TIME_IN_DAYS</strong> object parameter with the ACCOUNTADMIN role to set the default retention period for their account.</p>", "answers": ["DATA_RETENTION_TIME_IN_HOURS", "DATA_RETENTION_IN_TIME_TRAVEL", "DATA_RETENTION_TIME_MAX", "DATA_RETENTION_TIME_IN_DAYS"]}, "correct_response": ["d"], "section": "Data Protection and Data Sharing", "question_plain": "Which object parameter can users with the ACCOUNTADMIN role use to set the default retention period for their account?", "related_lectures": []}, {"_class": "assessment", "id": 57171708, "assessment_type": "multiple-choice", "prompt": {"question": "Time Travel can be disabled for an account by ACCOUNTADMIN. (True/False)", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "<p>\n<strong>Time Travel cannot be disabled for an account.</strong> A user with the ACCOUNTADMIN role can set DATA_RETENTION_TIME_IN_DAYS to 0 at the account level, which means that all databases (and subsequently all schemas and tables) created in the account have no retention period by default; however, this default can be overridden at any time for any database, schema, or table.</p>", "answers": ["TRUE", "FALSE"]}, "correct_response": ["b"], "section": "Data Protection and Data Sharing", "question_plain": "Time Travel can be disabled for an account by ACCOUNTADMIN. (True/False)", "related_lectures": []}, {"_class": "assessment", "id": 57171710, "assessment_type": "multiple-choice", "prompt": {"question": "<p>You have a table with a 30-day retention period. If you decrease the retention period to 20 days, how would it affect the data that would have been removed after 30 days?</p>", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "<p>Decreasing Retention reduces the amount of time data is retained in Time Travel: </p><ul><li><p>For active data modified after the retention period is reduced, the new shorter period applies.</p></li><li><p>For data that is currently in Time Travel:&nbsp; &nbsp; &nbsp;</p><ul><li><p>If the data is still within the new shorter period, it remains in Time Travel.&nbsp; &nbsp; &nbsp;</p></li><li><p>If the data is outside the new period, it moves into Fail-safe.&nbsp; </p></li></ul><p><br></p></li></ul><p>For example, if you have a table with a 30-day retention period and you decrease the period to 20-day, data from days 21 to 30 will be moved into Fail-safe, leaving only the data from day 1 to 20 accessible through Time Travel.&nbsp; However, the process of moving the data from Time Travel into Fail-safe is performed by a background process, so the change is not immediately visible. Snowflake guarantees that the data will be moved, but does not specify when the process will complete; until the background process completes, the data is still accessible through Time Travel.</p>", "answers": ["The data will still retain for 30-day before moving to Fail-safe", "The data will now retain for a shorter period of 20 days"]}, "correct_response": ["b"], "section": "Data Protection and Data Sharing", "question_plain": "You have a table with a 30-day retention period. If you decrease the retention period to 20 days, how would it affect the data that would have been removed after 30 days?", "related_lectures": []}]}
5053408
~~~
{"count": 100, "next": null, "previous": null, "results": [{"_class": "assessment", "id": 58445890, "assessment_type": "multiple-choice", "prompt": {"question": "<p>How much-uncompressed data does a micro-partition contain in Snowflake?</p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>Each micro-partition contains <strong>between 50 MB and 500 MB of uncompressed data</strong> (Note that the actual size in Snowflake is smaller because data is always stored compressed.). Groups of rows in tables are mapped into individual micro-partitions, organized in a columnar fashion. This size is between 50 MB and 500 MB, and <strong>the structure allows for extremely granular pruning of very large tables</strong>, which can be comprised of millions, or even hundreds of millions, of micro-partitions. It enables extremely efficient DML and fine-grained pruning for faster queries.</p>", "answers": ["Between 5 MB to 50 MB", "Between 1 MB to 100 MB", "Between 50 MB to 500 MB", "Between 1 GB to 10 GB"]}, "correct_response": ["c"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "How much-uncompressed data does a micro-partition contain in Snowflake?", "related_lectures": []}, {"_class": "assessment", "id": 58445892, "assessment_type": "multi-select", "prompt": {"question": "While choosing the clustering key, what should we consider? (Select 3)", "relatedLectureIds": "", "feedbacks": ["", "", "", "", "", ""], "explanation": "<p>Best Practices for choosing clustering key:&nbsp; </p><ol><li><p>Columns which are more often used in where clause&nbsp; </p></li><li><p>Columns that are more often used in join conditions&nbsp; </p></li><li><p>Order you specify the clustering key is important. </p><p><br></p><p>As a general rule, Snowflake recommends ordering the lowest to highest cardinality columns.</p></li></ol>", "answers": ["Columns which are more often used in join conditions", "Columns which are more often used in where clause", "Ordering the columns from lowest cardinality to highest cardinality", "Ordering the columns from highest cardinality to lowest cardinality", "Columns which are more less used in join conditions", "Columns which are less often used in where clause"]}, "correct_response": ["a", "b", "c"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "While choosing the clustering key, what should we consider? (Select 3)", "related_lectures": []}, {"_class": "assessment", "id": 58445894, "assessment_type": "multiple-choice", "prompt": {"question": "<p>What is the name of the Snowflake tool utilized for diagnosing network connectivity issues?</p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>The <strong>Snowflake Connectivity Diagnostic Tool (SnowCD)</strong> aids users in diagnosing and resolving network connection issues to Snowflake.</p>", "answers": ["<p>SnowCLI</p>", "<p>SnowCD</p>", "<p>SnowSQL</p>", "<p>SnowND</p>"]}, "correct_response": ["b"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "What is the name of the Snowflake tool utilized for diagnosing network connectivity issues?", "related_lectures": []}, {"_class": "assessment", "id": 58445896, "assessment_type": "multiple-choice", "prompt": {"question": "Snowflake architecture is", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>Snowflake\u2019s architecture <strong>is a hybrid of traditional shared-disk and shared-nothing database architectures.</strong> Like shared-disk architectures, Snowflake uses a central data repository for persisted data accessible from all compute nodes in the platform. But similar to shared-nothing architectures, Snowflake processes queries using MPP (massively parallel processing) compute clusters where each node in the cluster stores a portion of the entire data set locally. This approach offers the data management simplicity of a shared-disk architecture but with the performance and scale-out benefits of a shared-nothing architecture. It is also termed as Multi-Cluster Shared Data Architecture.\t</p>", "answers": ["Shared-disk architecture", "Shared-nothing architecture", "Hybrid of Shared-disk and Shared-nothing database architectures", "None of these"]}, "correct_response": ["c"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "Snowflake architecture is", "related_lectures": []}, {"_class": "assessment", "id": 58445898, "assessment_type": "multiple-choice", "prompt": {"question": "Snowflake stores data into its", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>When data is loaded into Snowflake, Snowflake reorganizes that data into its <strong>internal optimized, compressed columnar format</strong>. Snowflake stores this optimized data in cloud storage.</p>", "answers": ["internal optimized, compressed, columnar format", "internal optimized, uncompressed, columnar format", "internal optimized, compressed, row format", "internal optimized, uncompressed, row format"]}, "correct_response": ["a"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "Snowflake stores data into its", "related_lectures": []}, {"_class": "assessment", "id": 58445900, "assessment_type": "multi-select", "prompt": {"question": "Snowflake supports multiple ways of connecting to the service. (Select 3)", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p>Snowflake supports the following multiple ways of connecting to its service:&nbsp; </p><p><strong>A web-based user interface</strong> from which all aspects of managing and using Snowflake can be accessed.&nbsp; </p><p><strong>Command line clients (e.g. SnowSQL)</strong> can also access all aspects of managing and using Snowflake.&nbsp; </p><p><strong>ODBC and JDBC drivers</strong> that can be used by other applications (e.g. Tableau) to connect to Snowflake. </p><p><strong>Native connectors (e.g. Python, Spark)</strong> that can be used to develop applications for connecting to Snowflake. </p><p><strong>Third-party connectors</strong> that can be used to connect applications such as ETL tools (e.g. Informatica) and BI tools (e.g. ThoughtSpot) to Snowflake.</p>", "answers": ["A web-based user interface", "Command line clients (e.g. SnowSQL) ", "ODBC and JDBC drivers ", "Only JDBC", "Only ODBC"]}, "correct_response": ["a", "b", "c"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "Snowflake supports multiple ways of connecting to the service. (Select 3)", "related_lectures": []}, {"_class": "assessment", "id": 58445902, "assessment_type": "multi-select", "prompt": {"question": "Which of the Snowflake editions provides HIPPA Support feature? (Select 2)", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p><strong>Business Critical and Virtual Private Snowflake (VPS) editions provide HIPPA support.</strong></p>", "answers": ["Standard", "Enterprise", "Business Critical", "Virtual Private Snowflake (VPS)", "All of the Snowflake Editions"]}, "correct_response": ["c", "d"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "Which of the Snowflake editions provides HIPPA Support feature? (Select 2)", "related_lectures": []}, {"_class": "assessment", "id": 58445904, "assessment_type": "multi-select", "prompt": {"question": "Which of these Snowflake Connectors are available? (Select all that apply)", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p><strong>ODBC and JDBC are drivers.</strong> <strong>Connectors available for Snowflake are Python, Kafka, and Spark.</strong> Snowflake also provides several drivers like ODBC, JDBC, Node.js, Go,.Net, and PHP PDO. The Snowflake SQL API is a REST API that you can use to access and update data in a Snowflake database.</p>", "answers": ["Snowflake Connector for ODBC", "Snowflake Connector of Python", "Snowflake Connector for JDBC", "Snowflake Connector for Kafka ", "Snowflake Connector for Spark"]}, "correct_response": ["b", "d", "e"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "Which of these Snowflake Connectors are available? (Select all that apply)", "related_lectures": []}, {"_class": "assessment", "id": 58445906, "assessment_type": "multi-select", "prompt": {"question": "Which capabilities are available in Snowsight (the new Snowflake web interface)? (Select all that apply)", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p>Snowsight is the new Snowflake Web Interface. It can be used to perform the following operations:&nbsp; </p><p><br></p><ul><li><p>Building and running queries.&nbsp; </p></li><li><p>Loading data into tables.&nbsp; </p></li><li><p>Monitoring query performance and copy history.&nbsp; </p></li><li><p>Creating and managing users and other account-level objects.&nbsp; </p></li><li><p>Creating and using virtual warehouses.&nbsp; </p></li><li><p>Creating and modifying databases and all database objects.&nbsp; </p></li><li><p>Sharing data with other Snowflake accounts.&nbsp; </p></li><li><p>Exploring and using the Snowflake Marketplace.&nbsp; &nbsp; </p></li></ul><p>One of the cool features is the smart autocomplete, which suggests SQL or object syntax to insert.</p>", "answers": ["You can display visual statistics on columns (SUM, MIN, MAX, etc.) without re-running the query", "Sharing data with other Snowflake accounts", "Creating and managing users and other account-level objects", "The smart autocompletes feature suggests SQL or object syntax to insert", "Snowflake Marketplace is not available with Snowsight currently"]}, "correct_response": ["a", "b", "c", "d"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "Which capabilities are available in Snowsight (the new Snowflake web interface)? (Select all that apply)", "related_lectures": []}, {"_class": "assessment", "id": 58445908, "assessment_type": "multiple-choice", "prompt": {"question": "Which of the following is the correct hierarchy for the Snowflake objects?", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "The top-most container is the customer organization. Securable objects such as tables, views, functions, and stages are contained in a schema object, which are in turn contained in a database. All databases for your Snowflake account are contained in the account object. USER, ROLE, DATABASE, WAREHOUSE are at same level and contained in a Snowflake Account Object. \n", "answers": ["ACCOUNT &gt; ORGANIZATION &gt; ROLE &gt; USER &gt; DATABASE &gt; SCHEMA &gt; TABLE", "ORGANIZATION &gt; ACCOUNT &gt; DATABASE &gt; SCHEMA &gt; TABLE &gt; STAGE", "ORGANIZATION &gt; ACCOUNT &gt; DATABASE &gt; SCHEMA &gt; TABLE ", "ORGANIZATION &gt; ACCOUNT &gt; ROLE &gt; USER &gt; DATABASE &gt; SCHEMA &gt; STAGE &gt; TABLE"]}, "correct_response": ["c"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "Which of the following is the correct hierarchy for the Snowflake objects?", "related_lectures": []}, {"_class": "assessment", "id": 58445910, "assessment_type": "multi-select", "prompt": {"question": "Which of the following Data Types are supported by Snowflake? (Select all that apply)", "relatedLectureIds": "", "feedbacks": ["", "", "", "", "", ""], "explanation": "All of these data types are supported by Snowflake except BOOL. BOOLEAN is the correct data type.", "answers": ["NUMERIC", "INTEGER", "FLOAT", "CHAR", "VARCHAR", "BOOL"]}, "correct_response": ["a", "b", "c", "d", "e"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "Which of the following Data Types are supported by Snowflake? (Select all that apply)", "related_lectures": []}, {"_class": "assessment", "id": 58445912, "assessment_type": "multiple-choice", "prompt": {"question": "Which is not the DDL (Data Definition Language) command?", "relatedLectureIds": "", "feedbacks": ["", "", "", "", "", ""], "explanation": "<p><strong>TRUNCATE</strong> is DML (Data Manipulation Language) command.</p>", "answers": ["CREATE", "ALTER", "DROP    ", "UNDROP", "SHOW SHARES", "TRUNCATE"]}, "correct_response": ["f"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "Which is not the DDL (Data Definition Language) command?", "related_lectures": []}, {"_class": "assessment", "id": 58445914, "assessment_type": "multiple-choice", "prompt": {"question": "How long does Snowflake keep batch load history (from Stage) using COPY statement?", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p><strong>Snowflake keeps the batch load history for 64 days.</strong></p>", "answers": ["30 days", "31 days", "14 days", "64 days", "1 day"]}, "correct_response": ["d"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "How long does Snowflake keep batch load history (from Stage) using COPY statement?", "related_lectures": []}, {"_class": "assessment", "id": 58445916, "assessment_type": "multiple-choice", "prompt": {"question": "UDF runs with either the caller\u2019s or the owner\u2019s rights. (True / False)", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "<p><strong>UDF only runs as the function owner</strong>. <strong>A stored procedure runs with either the caller\u2019s rights or the owner\u2019s rights. It cannot run with both at the same time.</strong>\n\n<strong>A caller\u2019s rights stored procedure </strong>runs with the privileges of the caller. The primary advantage of a caller\u2019s rights stored procedure is that it can access information about that caller or about the caller\u2019s current session. For example, a caller\u2019s rights stored procedure can read the caller\u2019s session variables and use them in a query.&nbsp; </p><p><strong>An owner\u2019s rights stored procedure</strong> runs mostly with the privileges of the stored procedure\u2019s owner. The primary advantage of an owner\u2019s rights stored procedure is that the owner can delegate specific administrative tasks, such as cleaning up old data, to another role without granting that role more general privileges, such as privileges to delete all data from a specific table.&nbsp; </p><p>At the time that the stored procedure is created, the creator specifies whether the procedure runs with the owner\u2019s rights or the caller\u2019s rights. The default is owner\u2019s rights.</p>", "answers": ["TRUE", "FALSE"]}, "correct_response": ["b"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "UDF runs with either the caller\u2019s or the owner\u2019s rights. (True / False)", "related_lectures": []}, {"_class": "assessment", "id": 58445918, "assessment_type": "multiple-choice", "prompt": {"question": "Tasks require compute resources to execute code. Either Snowflake-managed or User-managed compute models can be chosen for individual tasks. (True / False)\n", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "<p><strong>True, Tasks require compute resources to execute SQL code</strong>. Either of the following compute models can be chosen for individual tasks:\n\nSnowflake-managed (i.e. serverless compute model), \n\nUser-managed (i.e. virtual warehouse)\n</p>", "answers": ["TRUE", "FALSE"]}, "correct_response": ["a"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "Tasks require compute resources to execute code. Either Snowflake-managed or User-managed compute models can be chosen for individual tasks. (True / False)", "related_lectures": []}, {"_class": "assessment", "id": 58445920, "assessment_type": "multi-select", "prompt": {"question": "Which of these columns gets appended on creating a stream on a table? (Select 3)", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p><strong>Adding a stream to a table appends three metadata columns: METADATA$ACTION, METADATA$ISUPDATE, METADATA$ROW_ID.</strong>&nbsp; &nbsp; </p><p>These columns track the CDC records and their type:&nbsp; appends,&nbsp; deletes, or both (updates = inserts + deletes).</p><p><br></p><ul><li><p>METADATA$ACTION - Indicates the DML operation (INSERT, DELETE) recorded. </p><p><br></p></li><li><p>METADATA$ISUPDATE - Indicates whether the operation was part of an UPDATE statement.&nbsp; </p></li><li><p><br></p></li><li><p>METADATA$ROW_ID - Specifies the unique and immutable ID for the row, which can be used to track changes to specific rows over time.&nbsp; </p></li></ul>", "answers": ["METADATA$ACTION", "METADATA$ISUPDATE", "METADATA$ROW_ID", "METADATA$ISINSERT", "METADATA$ISDELETE"]}, "correct_response": ["a", "b", "c"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "Which of these columns gets appended on creating a stream on a table? (Select 3)", "related_lectures": []}, {"_class": "assessment", "id": 58445922, "assessment_type": "multiple-choice", "prompt": {"question": "You have a table t1 with a column j that gets populated by a sequence s1. s1 is defined to start from 1 and with an increment of 1. \n\ncreate or replace sequence s1\n   start = 1\n   increment = 1\n   ;\n\ncreate or replace table t1 (\n    i int,\n    j int default s1.nextval\n    );\n\nYou inserted 3 records in table t1:\n\n insert into t1 values\n     (1,s1.nextval),\n     (2,s1.nextval),\n     (3,s1.nextval);\n\nAfter that insert statement, you altered the sequence s1 to set the increment to -4:\nalter sequence s1 set increment = -4;\n\nYou again inserted 2 records in table t1:\ninsert into t1 values\n     (4,s1.nextval),\n     (5,s1.nextval);\n\nWhat would be the result of the following query?\nselect j from t1 where i = 4;", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p><strong>ALTER SEQUENCE command takes effect after the second use of the sequence after executing the ALTER SEQUENCE command.</strong>\n</p><p>So, if you fetch row where i = 5, you will find j = 0 [row 4 value of j i.e., 4 + (-4) = 0]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n</p>", "answers": ["-1", "0", "4", "3", "5"]}, "correct_response": ["c"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "You have a table t1 with a column j that gets populated by a sequence s1. s1 is defined to start from 1 and with an increment of 1. \n\ncreate or replace sequence s1\n   start = 1\n   increment = 1\n   ;\n\ncreate or replace table t1 (\n    i int,\n    j int default s1.nextval\n    );\n\nYou inserted 3 records in table t1:\n\n insert into t1 values\n     (1,s1.nextval),\n     (2,s1.nextval),\n     (3,s1.nextval);\n\nAfter that insert statement, you altered the sequence s1 to set the increment to -4:\nalter sequence s1 set increment = -4;\n\nYou again inserted 2 records in table t1:\ninsert into t1 values\n     (4,s1.nextval),\n     (5,s1.nextval);\n\nWhat would be the result of the following query?\nselect j from t1 where i = 4;", "related_lectures": []}, {"_class": "assessment", "id": 58445924, "assessment_type": "multiple-choice", "prompt": {"question": "The search optimization service speeds only equality searches. (True/False)", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "<p><strong>The search optimization service speeds Equality and IN predicates searches.</strong> </p>", "answers": ["TRUE", "FALSE"]}, "correct_response": ["b"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "The search optimization service speeds only equality searches. (True/False)", "related_lectures": []}, {"_class": "assessment", "id": 58445926, "assessment_type": "multi-select", "prompt": {"question": "How can you view the data storage across your entire Snowflake account? (Select 2)", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>Suppose you have been assigned the ACCOUNTADMIN role (i.e., you serve as the top-level administrator for your Snowflake account). In that case, you can use Snowsight or the classic web interface to view data storage across your entire account:&nbsp; </p><ul><li><p><strong>Using Snowsight: </strong>Select Admin &gt; Usage &gt; Storage&nbsp; </p></li><li><p><strong>Using Classic Web Interface: </strong>Click on Account &gt; Billing &amp; Usage &gt; Average Storage Used\t</p></li></ul>", "answers": ["Using Snowsight: Select Data &gt; Usage &gt; Storage", "Using Snowsight: Select Admin &gt; Usage &gt; Storage", "Using Classic Web Interface:\u00a0Click on Account &gt; Billing &amp; Usage &gt; Average Storage Used", "Using Classic Web Interface: Click on Account &gt; Resource Monitors &gt; Average Storage Used"]}, "correct_response": ["b", "c"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "How can you view the data storage across your entire Snowflake account? (Select 2)", "related_lectures": []}, {"_class": "assessment", "id": 58445928, "assessment_type": "multiple-choice", "prompt": {"question": "If a warehouse runs for 61 seconds, shuts down, and then restarts and runs for less than 60 seconds, for how much duration will the billing be charged?", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p>It will be billed for 121 seconds (60 + 1 + 60). Please note - minimum billing if for 60 secs every time the warehouse starts, even if the warehouse is suspended within 60 seconds.</p>", "answers": ["60 seconds", "120 seconds", "61 seconds", "121 seconds", "180 seconds"]}, "correct_response": ["d"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "If a warehouse runs for 61 seconds, shuts down, and then restarts and runs for less than 60 seconds, for how much duration will the billing be charged?", "related_lectures": []}, {"_class": "assessment", "id": 58445930, "assessment_type": "multiple-choice", "prompt": {"question": "SQL clause that helps define the clustering key:", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>Example - \n\ncreate or replace table t1 (c1 date, c2 string, c3 number) <strong>cluster by (c1, c2);</strong>\n</p>", "answers": ["CLUSERTING ON ", "CLUSTER ON", "CLUSTERING BY", "CLUSTER BY"]}, "correct_response": ["d"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "SQL clause that helps define the clustering key:", "related_lectures": []}, {"_class": "assessment", "id": 58445932, "assessment_type": "multiple-choice", "prompt": {"question": "User-managed tasks are recommended when you cannot fully utilize a warehouse because only a few tasks run concurrently or they run to completion quickly (in less than 1 minute). (True / False)\t", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "<p><strong>Serverless Tasks </strong>is recommended when you cannot fully utilize a warehouse because too few tasks run concurrently or they run to completion quickly (in less than 1 minute).\n</p><p><strong>User-managed Tasks</strong> is recommended when you can fully utilize a single warehouse by scheduling multiple concurrent tasks to take advantage of available compute resources.</p>", "answers": ["TRUE", "FALSE"]}, "correct_response": ["b"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "User-managed tasks are recommended when you cannot fully utilize a warehouse because only a few tasks run concurrently or they run to completion quickly (in less than 1 minute). (True / False)", "related_lectures": []}, {"_class": "assessment", "id": 58445934, "assessment_type": "multiple-choice", "prompt": {"question": "LIST command returns a list of files that have been staged. Which of these stages supports the LIST command? ", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p><strong>LIST command returns a list of files staged from all of these specified snowflake stages.</strong></p>", "answers": ["Named internal stage.", "Named external stage.", "Stage for a specified table.", "Stage for the current user.", "All of these"]}, "correct_response": ["e"], "section": "", "question_plain": "LIST command returns a list of files that have been staged. Which of these stages supports the LIST command?", "related_lectures": []}, {"_class": "assessment", "id": 58445936, "assessment_type": "multi-select", "prompt": {"question": "Which of these stages can not be dropped or altered? (Select 2)", "relatedLectureIds": "", "feedbacks": ["", "", ""], "explanation": "<p><strong>User Stage:</strong> <strong>User stages cannot be altered or dropped.</strong> A user stage is allocated to each user for storing files. This stage type is designed to store staged and managed files by a single user but can be loaded into multiple tables.&nbsp; &nbsp; </p><p><strong>Table Stage:</strong> <strong>Table stages cannot be altered or dropped.</strong> A table stage is available for each table created in Snowflake. This stage type is designed to store staged and managed files by one or more users but only loaded into a single table. Note that a table stage is not a separate database object but an implicit stage tied to the table itself. A table stage has no grantable privileges of its own.&nbsp; &nbsp; &nbsp;</p><p><strong>Named Stage:</strong> A named internal stage is a database object created in a schema. This stage type can store files staged and managed by one or more users and loaded into one or more tables. <strong>Because named stages are database objects, the ability to create, modify, use, or drop them can be controlled using security access control privileges.\t</strong></p>", "answers": ["User Stage", "Table Stage", "Named Stage"]}, "correct_response": ["a", "b"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "Which of these stages can not be dropped or altered? (Select 2)", "related_lectures": []}, {"_class": "assessment", "id": 58445938, "assessment_type": "multiple-choice", "prompt": {"question": "The snowflake data warehouse is not built on an existing database or \u201cbig data\u201d software platform like Hadoop.(True/False)", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "<p><strong>Snowflake is a 100% cloud-native data platform.</strong></p>", "answers": ["TRUE", "FALSE"]}, "correct_response": ["a"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "The snowflake data warehouse is not built on an existing database or \u201cbig data\u201d software platform like Hadoop.(True/False)", "related_lectures": []}, {"_class": "assessment", "id": 58445940, "assessment_type": "multiple-choice", "prompt": {"question": "Snowflake supports multi-factor authentication (i.e., MFA) to provide increased login security for users connecting to Snowflake. Which role is strongly recommended for using MFA?", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>Snowflake strongly recommends that all users with the <strong>ACCOUNTADMIN role</strong> be required to use MFA.</p>", "answers": ["SYSADMIN", "USERADMIN", "ACCOUNTADMIN", "USERADMIN"]}, "correct_response": ["c"], "section": "Account Access & Security", "question_plain": "Snowflake supports multi-factor authentication (i.e., MFA) to provide increased login security for users connecting to Snowflake. Which role is strongly recommended for using MFA?", "related_lectures": []}, {"_class": "assessment", "id": 58445942, "assessment_type": "multiple-choice", "prompt": {"question": "Which of these system-defined roles encapsulates the SYSADMIN and SECURITYADMIN roles?", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p><strong>ACCOUNTADMIN role encapsulates the SYSADMIN and SECURITYADMIN system-defined roles.</strong> </p><p>It is the top-level role in the system and should be granted only to a limited/controlled number of users in your account.</p>", "answers": ["ORGADMIN", "ACCOUNTADMIN", "SECURITYADMIN", "USERADMIN", "SYSADMIN"]}, "correct_response": ["b"], "section": "Account Access & Security", "question_plain": "Which of these system-defined roles encapsulates the SYSADMIN and SECURITYADMIN roles?", "related_lectures": []}, {"_class": "assessment", "id": 58445944, "assessment_type": "multiple-choice", "prompt": {"question": "Which role has privileges to create warehouses and databases (and other objects) in an account?", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p><strong>SYSADMIN role has privileges to create warehouses and databases</strong> (and other objects) in an account. This role also has the ability to grant privileges on warehouses, databases, and other objects to other roles.</p>", "answers": ["ORGADMIN", "ACCOUNTADMIN", "SECURITYADMIN", "USERADMIN", "SYSADMIN"]}, "correct_response": ["e"], "section": "Account Access & Security", "question_plain": "Which role has privileges to create warehouses and databases (and other objects) in an account?", "related_lectures": []}, {"_class": "assessment", "id": 58445946, "assessment_type": "multiple-choice", "prompt": {"question": "ACCOUNTADMIN role cannot view the results for a query run by another user.(True/ False)", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "<p><strong>A user cannot view the result set from a query that another user executed. </strong>This behavior is intentional. For security reasons, only the user who executed a query can access the query results. <strong>This behavior is not connected to the Snowflake access control model for objects.</strong> Even a user with the ACCOUNTADMIN role cannot view the results for a query run by another user.</p>", "answers": ["TRUE", "FALSE"]}, "correct_response": ["a"], "section": "Account Access & Security", "question_plain": "ACCOUNTADMIN role cannot view the results for a query run by another user.(True/ False)", "related_lectures": []}, {"_class": "assessment", "id": 58445948, "assessment_type": "multiple-choice", "prompt": {"question": "How many network policies can be activated for a user at a time?", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p><strong>Only a single network policy can be activated for each user at a time</strong>; however, different network policies can be activated for different users for granular control. Associating a network policy with a user automatically removes the currently-associated network policy (if any)</p>", "answers": ["99", "31", "1", "16", "100"]}, "correct_response": ["c"], "section": "Account Access & Security", "question_plain": "How many network policies can be activated for a user at a time?", "related_lectures": []}, {"_class": "assessment", "id": 58445950, "assessment_type": "multi-select", "prompt": {"question": "Network policies allow restricting access to your account based on_____ (Select all that apply)", "relatedLectureIds": "", "feedbacks": ["", "", ""], "explanation": "Network policies allow restricting access to your account based on user IP address. Effectively, a network policy enables you to create an IP allowed list, as well as an IP blocked list, if desired.", "answers": ["User Operating System Type (example - MAC, Windows)", "IP address", "CIDR Notaion based IP ranges"]}, "correct_response": ["b", "c"], "section": "Account Access & Security", "question_plain": "Network policies allow restricting access to your account based on_____ (Select all that apply)", "related_lectures": []}, {"_class": "assessment", "id": 58445952, "assessment_type": "multiple-choice", "prompt": {"question": "What will happen if you add 0.0.0.0/0 to BLOCKED_IP_LIST and your IP address to ALLOWED_IP_LIST of a Network policy?", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "<p><strong>If you provide both Allowed IP Addresses and Blocked IP Addresses, Snowflake applies the Blocked List first.</strong> This would block your own access.\nAdditionally, in order to block all IP addresses except a select list, you only need to add IP addresses to ALLOWED_IP_LIST. Snowflake automatically blocks all IP addresses not included in the allowed list.</p>", "answers": ["You will be able to access the Snowflake account from your IP address", "You will not be able to access the Snowflake account from your IP address."]}, "correct_response": ["b"], "section": "Account Access & Security", "question_plain": "What will happen if you add 0.0.0.0/0 to BLOCKED_IP_LIST and your IP address to ALLOWED_IP_LIST of a Network policy?", "related_lectures": []}, {"_class": "assessment", "id": 58445954, "assessment_type": "multiple-choice", "prompt": {"question": "Which of these is not a valid authentication method supported by Snowflake?", "relatedLectureIds": "", "feedbacks": ["", "", "", "", "", ""], "explanation": "<p>Snowflake supports the following authentication methods: Username and password, MFA, SAML, and other authentication methods such as OAuth, Key-pair, and SCIM.</p>", "answers": ["Username and password", "Username and one-time generated pin", "Muti-factor authentication", "Federated Authentication (SAM 2.0)", "Oauth, Key Pair", "SCIM (System for Cross-domain Identity Management specification)"]}, "correct_response": ["b"], "section": "Account Access & Security", "question_plain": "Which of these is not a valid authentication method supported by Snowflake?", "related_lectures": []}, {"_class": "assessment", "id": 58445956, "assessment_type": "multiple-choice", "prompt": {"question": "In a federated Snowflake environment, can a user still log into Snowflake using their Snowflake credentials?", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "<p><strong>Users can still log into Snowflake using their Snowflake credentials.</strong></p>", "answers": ["Yes", "No"]}, "correct_response": ["a"], "section": "Account Access & Security", "question_plain": "In a federated Snowflake environment, can a user still log into Snowflake using their Snowflake credentials?", "related_lectures": []}, {"_class": "assessment", "id": 58445958, "assessment_type": "multiple-choice", "prompt": {"question": "If you create a user with MUST_CHANGE_PASSWORD = TRUE in a Snowflake federated environment, will that user be forced to change the password while logging through IdP the first time?", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "<p><strong>The MUST_CHANGE_PASSWORD user property does not apply for federated authentication and should not be used. </strong>In particular, if you choose not to maintain passwords in Snowflake for users, ensure this property is set to FALSE for these users.</p>", "answers": ["Yes", "No"]}, "correct_response": ["b"], "section": "Account Access & Security", "question_plain": "If you create a user with MUST_CHANGE_PASSWORD = TRUE in a Snowflake federated environment, will that user be forced to change the password while logging through IdP the first time?", "related_lectures": []}, {"_class": "assessment", "id": 58445960, "assessment_type": "multi-select", "prompt": {"question": "A row access policy contains an expression that can specify Snowflake database objects (e.g., table or view) and use functions to determine which rows should be visible in a given context. Which of these functions are used in determining row access policy?(Select 2)", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p><strong>A row access policy uses Conditional Expression Functions and Context Functions </strong>to determine which rows should be visible in a given context. Context Functions such as CURRENT_USER(), CURRENT_ROLE(), and CURRENT_ACCOUNT(), act as dynamic filters and are commonly used with secure views to limit row access in a table.</p>", "answers": ["Conversion Functions", "Context Functions", "Metadata Functions", "Conditional Expression Functions"]}, "correct_response": ["b", "d"], "section": "Account Access & Security", "question_plain": "A row access policy contains an expression that can specify Snowflake database objects (e.g., table or view) and use functions to determine which rows should be visible in a given context. Which of these functions are used in determining row access policy?(Select 2)", "related_lectures": []}, {"_class": "assessment", "id": 58445962, "assessment_type": "multiple-choice", "prompt": {"question": "What is the best practice after creating a custom role in a Snowflake account?", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>The custom role gets mainly created for specific access to specific objects. <strong>As per best practice, grant ownership to SYSADMIN or a child role under SYSADMIN so that SYSADMIN can control access to the objects.\t</strong></p>", "answers": ["Grant PUBLIC to the role so all database objects owned by PUBLIC will be available to the new role.\t", "Grant the custom role to the SYSADMIN role so administrators can manage all objects in the account.", "Grant ownership of the role to itself so a member of the role can control access to the role.\t", "Grant the role to the USERADMIN role so users can be added to the role.\t"]}, "correct_response": ["b"], "section": "Account Access & Security", "question_plain": "What is the best practice after creating a custom role in a Snowflake account?", "related_lectures": []}, {"_class": "assessment", "id": 58445964, "assessment_type": "multi-select", "prompt": {"question": "Which of these security features are supported in Snowflake? (Select all that apply)", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>Snowflake is a highly secured platform and provides multi-level security like Multi-Factor Authentication (MFA), provision to set up Network policy to block access by unwanted IPs, Single Sign On (SSO), Role-Based Access Control, and Tri Secret Secure, and so on. </p><p>Tri-Secret Secure is the combination of a Snowflake-maintained key and a customer-managed key in the cloud provider platform that hosts your Snowflake account to create a composite master key to protect your Snowflake data.</p>", "answers": ["Role-Based Access Control", "Multi-Factor Authentication", "Tri-Secret Secure Encryption", "Network Policy"]}, "correct_response": ["a", "b", "c", "d"], "section": "Account Access & Security", "question_plain": "Which of these security features are supported in Snowflake? (Select all that apply)", "related_lectures": []}, {"_class": "assessment", "id": 58445966, "assessment_type": "multiple-choice", "prompt": {"question": "Which role is inherited to every other role in the account?", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p>The <strong>PUBLIC role</strong> is Pseudo-role, which is automatically granted to every user and every role in your account. \n \nThis role is typically used in cases where explicit access control is not needed, and all users are viewed as equal with regard to their access rights.\t</p>", "answers": ["SECURITYADMIN", "USERADMIN", "PUBLIC", "ACCOUNTADMIN", "SYSADMIN"]}, "correct_response": ["c"], "section": "Account Access & Security", "question_plain": "Which role is inherited to every other role in the account?", "related_lectures": []}, {"_class": "assessment", "id": 58445968, "assessment_type": "multiple-choice", "prompt": {"question": "Which command will help you to view the current permissions on a Schema?", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>To view the current set of privileges granted on an object, you can execute the <strong>SHOW GRANTS</strong> command. To view the current permissions on a schema, execute the following command: \n\nSHOW GRANTS ON SCHEMA&nbsp; &lt;database_name&gt;.&lt;schema_name&gt;;</p>", "answers": ["SHOW ROLES ON SCHEMA &lt;database_name&gt;.&lt;schema_name&gt;;", "SHOW GRANTS OF SCHEMA &lt;database_name&gt;.&lt;schema_name&gt;;", "SHOW GRANTS ON SCHEMA &lt;database_name&gt;.&lt;schema_name&gt;;", "SHOW ALL PREIVILEGE ON SCHEMA  &lt;database_name&gt;.&lt;schema_name&gt;;"]}, "correct_response": ["c"], "section": "Account Access & Security", "question_plain": "Which command will help you to view the current permissions on a Schema?", "related_lectures": []}, {"_class": "assessment", "id": 58445970, "assessment_type": "multi-select", "prompt": {"question": "<p>Which objects are the securable objects in Snowflake? (Select all that apply)</p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p><strong>All of these are securable objects in Snowflake. </strong>\n\nSecurable Object is an entity to which access can be granted. Unless allowed by a grant, access will be denied.</p>", "answers": ["Database", "Warehouse", "Table", "File Format "]}, "correct_response": ["a", "b", "c", "d"], "section": "Account Access & Security", "question_plain": "Which objects are the securable objects in Snowflake? (Select all that apply)", "related_lectures": []}, {"_class": "assessment", "id": 58445972, "assessment_type": "multiple-choice", "prompt": {"question": "<p>All files stored in internal stages for data loading and unloading are automatically encrypted using AES-256 strong encryption. (True/False)</p>", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "All files stored in internal stages for data loading and unloading automatically encrypted using AES-256 strong encryption.", "answers": ["TRUE", "FALSE"]}, "correct_response": ["a"], "section": "Account Access & Security", "question_plain": "All files stored in internal stages for data loading and unloading are automatically encrypted using AES-256 strong encryption. (True/False)", "related_lectures": []}, {"_class": "assessment", "id": 58445974, "assessment_type": "multi-select", "prompt": {"question": "Which features of Snowflake provide Column-level security? (Select 2)", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p><strong>Dynamic Data Masking</strong> is a Column-level Security feature that uses masking policies to selectively mask plain-text data in table and view columns at query time.</p><p>\n<strong>External Tokenization</strong> enables accounts to tokenize data before loading it into Snowflake and detokenize the data at query runtime. Tokenization is the process of removing sensitive data by replacing it with an undecipherable token. External Tokenization makes use of masking policies with external functions.\n\n</p>", "answers": ["Internal Tokenization", "Dynamic Data Masking", "External Tokenization", "Column Masking"]}, "correct_response": ["b", "c"], "section": "Account Access & Security", "question_plain": "Which features of Snowflake provide Column-level security? (Select 2)", "related_lectures": []}, {"_class": "assessment", "id": 58445976, "assessment_type": "multiple-choice", "prompt": {"question": "Both non-materialized and materialized views can be defined as secure. (True / False)", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "<p><strong>Yes, both non-materialized and materialized views can be defined as secure. </strong></p>", "answers": ["TRUE", "FALSE"]}, "correct_response": ["a"], "section": "Account Access & Security", "question_plain": "Both non-materialized and materialized views can be defined as secure. (True / False)", "related_lectures": []}, {"_class": "assessment", "id": 58445978, "assessment_type": "multiple-choice", "prompt": {"question": "Which privilege is required to enable altering any properties of the resource monitor, such as changing the monthly credit quote?", "relatedLectureIds": "", "feedbacks": ["", "", ""], "explanation": "<ul><li><p><strong>MODIFY</strong> - <strong>Enables altering any properties of a resource monitor, such as changing the monthly credit quota.</strong></p><p><br></p></li><li><p>MONITOR - Enables viewing a resource monitor.</p></li></ul>", "answers": ["USAGE", "MODIFY", "MONITOR"]}, "correct_response": ["b"], "section": "Account Access & Security", "question_plain": "Which privilege is required to enable altering any properties of the resource monitor, such as changing the monthly credit quote?", "related_lectures": []}, {"_class": "assessment", "id": 58445980, "assessment_type": "multiple-choice", "prompt": {"question": "The closer the ratio of scanned micro-partitions and columnar data is to the ratio of actual data selected, the more efficient is the pruning performed on the table. (TRUE/FALSE)", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "Snowflake uses columnar scanning of partitions so that an entire partition is not scanned if a query only filters by one column. The closer the ratio of scanned micro-partitions and columnar data is to the ratio of actual data selected, the more efficient is the pruning performed on the table", "answers": ["TRUE", "FALSE"]}, "correct_response": ["a"], "section": "Performance Concepts", "question_plain": "The closer the ratio of scanned micro-partitions and columnar data is to the ratio of actual data selected, the more efficient is the pruning performed on the table. (TRUE/FALSE)", "related_lectures": []}, {"_class": "assessment", "id": 58445982, "assessment_type": "multi-select", "prompt": {"question": "Which of these SQL Queries can be answered completely by Metadata? (Select 3)", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p><strong>SHOW Commands, MIN, MAX (integers and dates), and COUNT SQL queries take advantage of the Metadata cache and do not require the virtual warehouse, but you still have some cloud service charges.</strong></p>", "answers": ["SHOW Commands", "MIN, MAX (integers and dates)", "COUNT", "AVG", "None of these"]}, "correct_response": ["a", "b", "c"], "section": "Performance Concepts", "question_plain": "Which of these SQL Queries can be answered completely by Metadata? (Select 3)", "related_lectures": []}, {"_class": "assessment", "id": 58445984, "assessment_type": "multiple-choice", "prompt": {"question": "Will these queries be considered as same to get the benefit of the Query Result cache?\n\nQuery 1 :  SELECT * FROM t1;\nQuery 2 : select * FROM t1;", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "These queries will not be considered as same to get the benefit of the Query Result cache. First Query has &#39;SELECT&#39; is upper case, and the Second query has &#39;select&#39; in lower case.", "answers": ["YES", "NO"]}, "correct_response": ["b"], "section": "Performance Concepts", "question_plain": "Will these queries be considered as same to get the benefit of the Query Result cache?\n\nQuery 1 :  SELECT * FROM t1;\nQuery 2 : select * FROM t1;", "related_lectures": []}, {"_class": "assessment", "id": 58445986, "assessment_type": "multiple-choice", "prompt": {"question": "When the Virtual Warehouse data cache gets filled up, in which fashion does the data get flushed out from the data cache?", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>If the cache does fill up, it is flushed out in a <strong>least-recently used</strong> fashion.</p>", "answers": ["First In First Out (FIFO)", "Last In Last Out (LILO)", "MOST-RECENTLY USED (MRU)", "LEAST-RECENTLY USED (LRU)"]}, "correct_response": ["d"], "section": "Performance Concepts", "question_plain": "When the Virtual Warehouse data cache gets filled up, in which fashion does the data get flushed out from the data cache?", "related_lectures": []}, {"_class": "assessment", "id": 58445988, "assessment_type": "multi-select", "prompt": {"question": "<p>Which of the Snowflake shared view can be used to query the Snowflake Query History? (Select 1)</p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p><strong>QUERY_HISTORY view in ACCOUNT_USAGE</strong> view can be used to query Snowflake query history by various dimensions (time range, session, user, warehouse, etc.) <strong>within the last 365 days (1 year).</strong></p>", "answers": ["<p>QUERY_HISTORY_VIEW view in INFORMATION_USAGE </p>", "<p>QUERY_HISTORY_VIEW view in ACCOUNT_USAGE </p>", "<p>QUERY_HISTORY view in ACCOUNT_USAGE </p>", "QUERY_HISTORY view in INFORMATION_SCHEMA"]}, "correct_response": ["c"], "section": "Performance Concepts", "question_plain": "Which of the Snowflake shared view can be used to query the Snowflake Query History? (Select 1)", "related_lectures": []}, {"_class": "assessment", "id": 58445990, "assessment_type": "multiple-choice", "prompt": {"question": "If you have privileges to view queries executed by another user, the Query Detail page displays the details for the query and the actual query result. (TRUE/FALSE)", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "<p>If you have privileges to view queries executed by another user, the Query Detail page displays the details for the query, but, for data privacy reasons, <strong>the page does not display the actual query result.</strong></p>", "answers": ["TRUE", "FALSE"]}, "correct_response": ["b"], "section": "Performance Concepts", "question_plain": "If you have privileges to view queries executed by another user, the Query Detail page displays the details for the query and the actual query result. (TRUE/FALSE)", "related_lectures": []}, {"_class": "assessment", "id": 58445992, "assessment_type": "multi-select", "prompt": {"question": "<p>Which of these are types of Scaling policies? (Select 2)</p>", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p><strong>There are two different scaling policies, one is the standard policy, and one is the economy policy.</strong></p>", "answers": ["Maximized", "Standard", "Business", "Economy", "Minimized"]}, "correct_response": ["b", "d"], "section": "Performance Concepts", "question_plain": "Which of these are types of Scaling policies? (Select 2)", "related_lectures": []}, {"_class": "assessment", "id": 58445994, "assessment_type": "multiple-choice", "prompt": {"question": "Which of these configurations will set up a warehouse in maximized mode?", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p><strong>Maximized mode is enabled by specifying the same value for both the maximum and a minimum number of clusters (note that the specified value must be larger than 1).</strong> In this mode, when the warehouse is started, Snowflake starts all the clusters so that maximum resources are available while the warehouse is running. This mode is effective for statically controlling the available compute resources, particularly if you have large numbers of concurrent user sessions and/or queries and the numbers do not fluctuate significantly.</p>", "answers": ["Minimum Clusters = 1 and Maximum Clusters = 10", "Minimum Clusters = 6 and Maximum Clusters = 6", "Minimum Clusters = 1 and Maximum Clusters = 1", "Minimum Clusters = 9 and Maximum Clusters = 10"]}, "correct_response": ["b"], "section": "Performance Concepts", "question_plain": "Which of these configurations will set up a warehouse in maximized mode?", "related_lectures": []}, {"_class": "assessment", "id": 58445996, "assessment_type": "multiple-choice", "prompt": {"question": "What is the minimum billing charge for provisioning compute resources?", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p><strong>The minimum billing charge for provisioning compute resources is 1 minute (i.e. 60 seconds).</strong> There is no benefit to stopping a warehouse before the first 60-second period is over because the credits have already been billed for that period.</p>", "answers": ["1 second", "30 seconds", "60 seconds", "120 seconds"]}, "correct_response": ["c"], "section": "Performance Concepts", "question_plain": "What is the minimum billing charge for provisioning compute resources?", "related_lectures": []}, {"_class": "assessment", "id": 58445998, "assessment_type": "multiple-choice", "prompt": {"question": "What is a key benefit of scaling up a warehouse?", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "<p><strong>Resizing a warehouse generally improves query performance</strong>, particularly for larger, more complex queries. It can also help reduce the queuing that occurs if a warehouse does not have enough compute resources to process all the queries that are submitted concurrently. <strong>Note that warehouse resizing is not intended for handling concurrency issues</strong>; instead, use additional warehouses to handle the workload or use a multi-cluster warehouse.</p>", "answers": ["Scaling up improves performance.", "Scaling up improves concurrency."]}, "correct_response": ["a"], "section": "Performance Concepts", "question_plain": "What is a key benefit of scaling up a warehouse?", "related_lectures": []}, {"_class": "assessment", "id": 58446000, "assessment_type": "multiple-choice", "prompt": {"question": "Suppose we resize a warehouse to a larger size while it is executing SQL statements. In that case, the already running SQL statements will finish faster. (True / False)", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "<p><strong>Resizing a warehouse doesn\u2019t have any impact on statements that are currently being executed by the warehouse.</strong> When resizing to a larger size, the new compute resources, once fully provisioned, are used only to execute statements that are already in the warehouse queue, as well as all future statements submitted to the warehouse.</p>", "answers": ["TRUE", "FALSE"]}, "correct_response": ["b"], "section": "Performance Concepts", "question_plain": "Suppose we resize a warehouse to a larger size while it is executing SQL statements. In that case, the already running SQL statements will finish faster. (True / False)", "related_lectures": []}, {"_class": "assessment", "id": 58446002, "assessment_type": "multiple-choice", "prompt": {"question": "During Warehouse provisioning, if any of the compute resources fail to provision, then Snowflake kills the entire warehouse provisioning and tries to provision a new warehouse of the same requested size. (True/False)", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "<p>Snowflake does not begin executing SQL statements submitted to a warehouse until all of the compute resources for the warehouse are successfully provisioned unless any of the resources fail to provision:&nbsp; </p><p><strong>If any of the compute resources for the warehouse fail to provision during start-up, Snowflake attempts to repair the failed resources</strong>.\n\nDuring the repair process, the warehouse starts processing SQL statements once 50% or more of the requested compute resources are successfully provisioned.</p>", "answers": ["TRUE", "FALSE"]}, "correct_response": ["b"], "section": "Performance Concepts", "question_plain": "During Warehouse provisioning, if any of the compute resources fail to provision, then Snowflake kills the entire warehouse provisioning and tries to provision a new warehouse of the same requested size. (True/False)", "related_lectures": []}, {"_class": "assessment", "id": 58446004, "assessment_type": "multiple-choice", "prompt": {"question": "The BI group is complaining about their queries taking too long to run. Checking the virtual warehouse information shows that the queued time is pretty high. What is the best way to fix this issue?", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p><strong>Queuing can be solved by SCALE-OUT (provision new clusters)</strong>, i.e., increasing MAX_CLUSTER_COUNT helps in additional cluster provisioning to handle the concurrent workloads.&nbsp; </p>", "answers": ["Provide a virtual warehouse for every user in the group", "Increase the size of the virtual warehouse", "Determine which users have the high priority queries and set the other users", "Set the STATEMENT_QUEUED_TIMEOUT_IN_SECONDS parameter to a low value to cancel those queries if they get in the queue", "Increase the virtual warehouse MAX_CLUSTER_COUNT property"]}, "correct_response": ["e"], "section": "Performance Concepts", "question_plain": "The BI group is complaining about their queries taking too long to run. Checking the virtual warehouse information shows that the queued time is pretty high. What is the best way to fix this issue?", "related_lectures": []}, {"_class": "assessment", "id": 58446006, "assessment_type": "multi-select", "prompt": {"question": "<p>Materialized views are particularly useful when:</p><p>(Select 3)</p>", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p>Materialized views are advantageous when:&nbsp; </p><p><br></p><ul><li><p><strong>Query results contain a small number of rows and/or columns</strong> relative to the base table (the table on which the view is defined).&nbsp; </p><p><br></p></li><li><p>Query results contain <strong>results that require significant processing</strong>, including \t</p><ul><li><p>Analysis of semi-structured data. \t</p></li><li><p>Aggregates that take a long time to calculate. </p><p><br></p></li></ul></li><li><p>The query is on an external table (i.e., data sets stored in files in an external stage), which might perform slower than querying native database tables.&nbsp; </p><p><br></p></li><li><p><strong>The view\u2019s base table does not change frequently</strong>.</p></li></ul>", "answers": ["Query results contain a small number of rows and/or columns relative to the base table (the table on which the view is defined).", "Query results contain results that require simple processing.", "Query results contain results that require significant processing.", "The view\u2019s base table changes frequently.", "The view\u2019s base table does not change frequently."]}, "correct_response": ["a", "c", "e"], "section": "Performance Concepts", "question_plain": "Materialized views are particularly useful when:(Select 3)", "related_lectures": []}, {"_class": "assessment", "id": 58446008, "assessment_type": "multiple-choice", "prompt": {"question": "<p>Which privilege is required to change a warehouse's state (stop, start, suspend, resume)?</p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p><strong>Virtual Warehouse Privileges:</strong></p><p><br></p><p><strong>OPERATE</strong> - <strong>Enables changing the state of a warehouse (stop, start, suspend, resume)</strong>. In addition, enables viewing current and past queries executed on a warehouse and aborting any executing queries.</p><p><br></p><p><strong>MODIFY</strong> - Enables altering any properties of a warehouse, including changing its size. Required assigning a warehouse to a resource monitor. Note that only the ACCOUNTADMIN role can assign warehouses to resource monitors.&nbsp; </p><p><br></p><p><strong>MONITOR</strong> - Enables viewing of current and past queries executed on a warehouse as well as usage statistics on that warehouse.&nbsp; &nbsp; </p><p><br></p><p><strong>USAGE</strong> - Enables using a virtual warehouse and, as a result, executing queries on the warehouse. If the warehouse is configured to auto-resume when a SQL statement (e.g. query) is submitted to it, the warehouse resumes automatically and executes the statement.&nbsp; </p><p><br></p><p><strong>OWNERSHIP</strong> - Grants full control over a warehouse. Only a single role can hold this privilege on a specific object at a time.&nbsp; </p><p><br></p><p><strong>ALL</strong> [ PRIVILEGES ] - Grants all privileges, except OWNERSHIP, on the warehouse.</p>", "answers": ["MODIFY", "MONITOR", "OPERATE", "USAGE"]}, "correct_response": ["c"], "section": "Performance Concepts", "question_plain": "Which privilege is required to change a warehouse's state (stop, start, suspend, resume)?", "related_lectures": []}, {"_class": "assessment", "id": 58446010, "assessment_type": "multiple-choice", "prompt": {"question": "What is the recommended compressed size of data files for optimal bulk data loads?", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>To optimize the number of parallel operations for a load, Snowflake recommends aiming to produce data files roughly <strong>100-250 MB (or larger) in size compressed</strong>. The number of load operations that run in parallel cannot exceed the number of data files to be loaded. </p>", "answers": ["10-50 MB", "10-50 GB", "100-250 MB", "100-250 GB"]}, "correct_response": ["c"], "section": "Data Loading and Unloading", "question_plain": "What is the recommended compressed size of data files for optimal bulk data loads?", "related_lectures": []}, {"_class": "assessment", "id": 58446012, "assessment_type": "multiple-choice", "prompt": {"question": "The best use of Snowpipe is to load large volumes of data and incrementally make them available for analysis. (True/False)", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "<p>Snowpipe is <strong>designed to load small volumes of data</strong> (i.e., micro-batches) and incrementally make them available for analysis.</p>", "answers": ["TRUE", "FALSE"]}, "correct_response": ["b"], "section": "Data Loading and Unloading", "question_plain": "The best use of Snowpipe is to load large volumes of data and incrementally make them available for analysis. (True/False)", "related_lectures": []}, {"_class": "assessment", "id": 58446014, "assessment_type": "multiple-choice", "prompt": {"question": "What of the following is the default character set for delimited files (CSV, TSV, etc.)?", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p><strong>UTF-8 is the default character set for delimited files (CSV, TSV, etc.)</strong>. Snowflake also supports all others in the provided options, but you must explicitly specify the encoding to use for loading.</p>", "answers": ["UTF-16BE", "UTF-8", "UTF-16", "UTF-32", "UTF-32LE"]}, "correct_response": ["b"], "section": "Data Loading and Unloading", "question_plain": "What of the following is the default character set for delimited files (CSV, TSV, etc.)?", "related_lectures": []}, {"_class": "assessment", "id": 58446016, "assessment_type": "multi-select", "prompt": {"question": "Which options for selecting staged data files are supported by COPY command in Snowflake? (Select that all apply)", "relatedLectureIds": "", "feedbacks": ["", "", ""], "explanation": "<p><strong>All of these are supported. </strong>This allows you to execute concurrent COPY statements that match a subset of files, taking advantage of parallel operations.</p>", "answers": ["By path (internal stages) / prefix (Amazon S3 bucket)", "Using pattern matching to identify specific files by pattern\n", "Specifying a list of specific files to load"]}, "correct_response": ["a", "b", "c"], "section": "Data Loading and Unloading", "question_plain": "Which options for selecting staged data files are supported by COPY command in Snowflake? (Select that all apply)", "related_lectures": []}, {"_class": "assessment", "id": 58446018, "assessment_type": "multiple-choice", "prompt": {"question": "Loading into Snowflake from a local file system is a straightforward affair. Which command is used to grab files from the local system, compress them and encrypt them, and then it copies them to Snowflake?", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p><strong>Using the PUT command in SnowSQL.</strong> It grabs the file or files, compresses them, encrypts them, and then copies them up into the stage you chose. Once in the stage, you can use a COPY INTO command to load the data from the stage into Snowflake tables.</p>", "answers": ["GET command", "PUT command", "COPY INTO &lt;table&gt;", "MOVE command"]}, "correct_response": ["b"], "section": "Data Loading and Unloading", "question_plain": "Loading into Snowflake from a local file system is a straightforward affair. Which command is used to grab files from the local system, compress them and encrypt them, and then it copies them to Snowflake?", "related_lectures": []}, {"_class": "assessment", "id": 58446020, "assessment_type": "multi-select", "prompt": {"question": "<p>There are multiple ways you can trigger the loading of files from the stage into Snowpipe. <strong>Select two ways </strong>generally used to trigger the loading with Snowpipe. </p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p><strong>Automating Snowpipe using cloud messaging (notification) and Calling Snowpipe REST endpoints are the mostly used methods for triggering loading with Snowpipe. </strong></p>", "answers": ["Automating Snowpipe using cloud messaging (notification)", "Calling Snowpipe SOAP endpoints", "By executing START PIPE &lt;pipe_name&gt;", "Calling Snowpipe REST endpoints"]}, "correct_response": ["a", "d"], "section": "Data Loading and Unloading", "question_plain": "There are multiple ways you can trigger the loading of files from the stage into Snowpipe. Select two ways generally used to trigger the loading with Snowpipe.", "related_lectures": []}, {"_class": "assessment", "id": 58446022, "assessment_type": "multi-select", "prompt": {"question": "<p>Which methods can be used to check the status of a COPY INTO command? (Select 2)</p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p><strong>The status of COPY INTO command can be checked from the Resource Monitors tab in the Snowflake user interface, as well as by querying the INFORMATION_SCHEMA.LOAD_HISTORY view.</strong></p>", "answers": ["Use the resource monitor.", "Write a SQL query against the INFORMATION_SCHEMA.LOAD_HISTORY view.", "Write a SQL query against the ACCOUNT_USAGE.LOAD_HISTORY view.", "Use the Query History tab in the Snowflake user interface."]}, "correct_response": ["b", "d"], "section": "Data Loading and Unloading", "question_plain": "Which methods can be used to check the status of a COPY INTO command? (Select 2)", "related_lectures": []}, {"_class": "assessment", "id": 58446080, "assessment_type": "multiple-choice", "prompt": {"question": "If DATA_RETENTION_TIME_IN_DAYS is set to a value of 0, and MIN_DATA_RETENTION_TIME_IN_DAYS is set higher at the account level and is greater than 0, which value (0 or higher) setting takes precedence?", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "<p>If DATA_RETENTION_TIME_IN_DAYS is set to a value of 0, and MIN_DATA_RETENTION_TIME_IN_DAYS is set at the account level and is greater than 0, the higher value setting takes precedence. The data retention period for an object is determined by <strong>MAX(DATA_RETENTION_TIME_IN_DAYS, MIN_DATA_RETENTION_TIME_IN_DAYS).</strong></p>", "answers": ["Higher value (set in MIN_DATA_RETENTION_TIME_IN_DAYS)", "0 (set in DATA_RETENTION_TIME_IN_DAYS)"]}, "correct_response": ["a"], "section": "Data Protection and Data Sharing", "question_plain": "If DATA_RETENTION_TIME_IN_DAYS is set to a value of 0, and MIN_DATA_RETENTION_TIME_IN_DAYS is set higher at the account level and is greater than 0, which value (0 or higher) setting takes precedence?", "related_lectures": []}, {"_class": "assessment", "id": 58446082, "assessment_type": "multiple-choice", "prompt": {"question": "Suppose we have a table t1. We drop the table t1 and then create a new table t1 again. What will happen if we execute the UNDROP command to restore dropped t1 table now?", "relatedLectureIds": "", "feedbacks": ["", "", ""], "explanation": "<p><strong>If an object with the same name already exists, UNDROP fails</strong>. We must rename the existing object, which then enables us to restore the previous version of the object.</p>", "answers": ["The dropped table t1 will be restored with name t1", "The dropped table t1 will be restored with a new arbitrary name set by Snowflake", "UNDROP command will fail"]}, "correct_response": ["c"], "section": "Data Protection and Data Sharing", "question_plain": "Suppose we have a table t1. We drop the table t1 and then create a new table t1 again. What will happen if we execute the UNDROP command to restore dropped t1 table now?", "related_lectures": []}, {"_class": "assessment", "id": 58446084, "assessment_type": "multi-select", "prompt": {"question": "<p>Which database objects are currently not supported for replication? (Select 2)</p>", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p><strong>Temporary tables, stages, tasks, pipes, and external tables are not currently supported for replication.</strong></p>", "answers": ["Transient tables", "Temporary tables", "Views", "Stages", "Streams"]}, "correct_response": ["b", "d"], "section": "Data Protection and Data Sharing", "question_plain": "Which database objects are currently not supported for replication? (Select 2)", "related_lectures": []}, {"_class": "assessment", "id": 58446086, "assessment_type": "multi-select", "prompt": {"question": "What types of accounts are involved in data sharing? (Select 3)", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p>There are three types of accounts involved in data sharing.</p><p>\n<strong>Data Providers:</strong>&nbsp; Share data with others\n</p><p><strong>Data Consumers: </strong>Accesses shared data with their own Snowflake account. \n</p><p><strong>Reader Accounts: </strong>Query data using compute from the data provider's account. Reader Accounts are what you can use to share data with somebody who does not already have a Snowflake account.\n</p>", "answers": ["Data Publishers", "Data Consumers", "Data Providers", "Reader Accounts", "Shared Accounts"]}, "correct_response": ["b", "c", "d"], "section": "Data Protection and Data Sharing", "question_plain": "What types of accounts are involved in data sharing? (Select 3)", "related_lectures": []}, {"_class": "assessment", "id": 58446088, "assessment_type": "multiple-choice", "prompt": {"question": "Snowflake data providers can share data from one database per share. Data from multiple databases can not be shared with a share. (True/False)", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "<p><strong>Snowflake data providers can share data that resides in different databases by using secure views.</strong> A secure view can reference objects such as schemas, tables, and other views from one or more databases, as long as these databases belong to the same account.</p>", "answers": ["TRUE", "FALSE"]}, "correct_response": ["b"], "section": "Data Protection and Data Sharing", "question_plain": "Snowflake data providers can share data from one database per share. Data from multiple databases can not be shared with a share. (True/False)", "related_lectures": []}, {"_class": "assessment", "id": 58446024, "assessment_type": "multiple-choice", "prompt": {"question": "David wants to load a JSON file using the COPY INTO &lt;table&gt; command. He found that there are null values in the data for missing values and have no other special meaning. What file format option would you recommend him to use with COPY INTO &lt;table&gt; command to handle the JSON null values?", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p>In a VARIANT column, NULL values are stored as a string containing the word \u201cnull,\u201d not the SQL NULL value. If the \u201cnull\u201d values in your JSON documents indicate missing values and have no other special meaning, you should <strong>recommend setting the file format option STRIP_NULL_VALUES to TRUE for the COPY INTO &lt;table&gt; command when loading the JSON files</strong>. Retaining the \u201cnull\u201d values often wastes storage and slows query processing.</p>", "answers": ["David should use REPLACE_INVALID_CHARACTERS = TRUE", "David should use STRIP_OUTER_ELEMENT = TRUE", "David should use STRIP_OUTER_ELEMENT = FALSE", "David should use STRIP_NULL_VALUES = TRUE", "David should use STRIP_NULL_VALUES = FALSE"]}, "correct_response": ["d"], "section": "Data Loading and Unloading", "question_plain": "David wants to load a JSON file using the COPY INTO &lt;table&gt; command. He found that there are null values in the data for missing values and have no other special meaning. What file format option would you recommend him to use with COPY INTO &lt;table&gt; command to handle the JSON null values?", "related_lectures": []}, {"_class": "assessment", "id": 58446026, "assessment_type": "multiple-choice", "prompt": {"question": "What is the default compression method used by Snowflake while unloading data?", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "By default, all unloaded data files are compressed using gzip, unless compression is explicitly disabled or one of the other supported compression methods is explicitly specified.  \n ", "answers": ["bzip2", "gzip", "Brotli", "Zstandard"]}, "correct_response": ["b"], "section": "Data Loading and Unloading", "question_plain": "What is the default compression method used by Snowflake while unloading data?", "related_lectures": []}, {"_class": "assessment", "id": 58446028, "assessment_type": "multiple-choice", "prompt": {"question": "Which function can be used in combination with COPY command to convert the rows in a relational table to a single VARIANT column and unload the rows into a file?", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>The <strong>OBJECT_CONSTRUCT function</strong> can be used in combination with the COPY command to convert the rows in a relational table to a single VARIANT column and unload the rows into a file.</p>", "answers": ["UNLOAD_CONSTRUCT", "COPY_CONSTRUCT", "VARIANT_CONSTRUCT", "OBJECT_CONSTRUCT"]}, "correct_response": ["d"], "section": "Data Loading and Unloading", "question_plain": "Which function can be used in combination with COPY command to convert the rows in a relational table to a single VARIANT column and unload the rows into a file?", "related_lectures": []}, {"_class": "assessment", "id": 58446030, "assessment_type": "multiple-choice", "prompt": {"question": "When loading data using COPY INTO &lt;table&gt; command, it is a must that the data files have the same number and order of columns as your target table. (True/False)", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "There is no requirement for your data files to have the same number and ordering of columns as your target table.", "answers": ["TRUE", "FALSE"]}, "correct_response": ["b"], "section": "Data Transformation", "question_plain": "When loading data using COPY INTO &lt;table&gt; command, it is a must that the data files have the same number and order of columns as your target table. (True/False)", "related_lectures": []}, {"_class": "assessment", "id": 58446032, "assessment_type": "multiple-choice", "prompt": {"question": "When should we use HyperLogLog?", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>Snowflake recommends <strong>using HyperLogLog whenever the input is potentially large</strong>, and an approximate result is acceptable. </p>", "answers": ["Whenever the input is potentially large, and an approximate result is not acceptable.", "Whenever the input is potentially small, and an approximate result is acceptable.", "Whenever the input is potentially large, and an approximate result is acceptable.", "Whenever the input is potentially small, and an approximate result is not acceptable."]}, "correct_response": ["c"], "section": "Data Transformation", "question_plain": "When should we use HyperLogLog?", "related_lectures": []}, {"_class": "assessment", "id": 58446034, "assessment_type": "multi-select", "prompt": {"question": "Which of these sampling method keywords are used to specify which method to use? (Select 2)", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p><strong>BERNOULLI | ROW and SYSTEM | BLOCK are used to specify the sampling method in SELECT query</strong>. \n\n<strong>BERNOULLI (or ROW):</strong> Includes each row with a &lt;probability&gt; of p/100. Similar to flipping a weighted coin for each row.\n\n<strong>SYSTEM (or BLOCK):</strong> Includes each block of rows with a &lt;probability&gt; of p/100. Similar to flipping a weighted coin for each block of rows. This method does not support fixed-size sampling.\n\nSampling method is optional. If no method is specified, the default is BERNOULLI.\n\n<strong>Example :</strong>\n\n<strong>select * from t1 tablesample bernoulli (25); </strong>\n<strong>This query will return a sample of a table in which each row has a 25% probability of being included in the sample</strong></p>", "answers": ["BERNOULLI | ROW", "SYSTEM | ROW", "BERNOULLI | BLOCK", "SYSTEM | BLOCK"]}, "correct_response": ["a", "d"], "section": "Data Transformation", "question_plain": "Which of these sampling method keywords are used to specify which method to use? (Select 2)", "related_lectures": []}, {"_class": "assessment", "id": 58446036, "assessment_type": "multiple-choice", "prompt": {"question": "Select the type of function that returns one value per invocation (one value per row). ", "relatedLectureIds": "", "feedbacks": ["", "", "", "", "", ""], "explanation": "<p><strong>A scalar function is a function that returns one value per invocation</strong>; in most cases, you can think of this as returning one value per row. This contrasts with Aggregate Functions, which return one value per group of rows. Scalar functions take every row in your table, perform some calculations on that row and give you another value back.</p>", "answers": ["Aggregate Function", "Scalar Function", "Window Function", "Table Function", "User-Defined Function", "System Function"]}, "correct_response": ["b"], "section": "Data Transformation", "question_plain": "Select the type of function that returns one value per invocation (one value per row).", "related_lectures": []}, {"_class": "assessment", "id": 58446038, "assessment_type": "multiple-choice", "prompt": {"question": "Select the type of function that returns multiple rows for each individual input.", "relatedLectureIds": "", "feedbacks": ["", "", "", "", "", ""], "explanation": "<p><strong>A table function returns a set of rows for each input row.</strong> The returned set can contain zero, one, or more rows. Each row can contain one or more columns.\n\nTable functions are sometimes called \u201ctabular functions\u201d.</p>", "answers": ["Aggregate Function", "Scalar Function", "Window Function", "Table Function", "User-Defined Function", "System Function"]}, "correct_response": ["d"], "section": "Data Transformation", "question_plain": "Select the type of function that returns multiple rows for each individual input.", "related_lectures": []}, {"_class": "assessment", "id": 58446040, "assessment_type": "multiple-choice", "prompt": {"question": "<p>UDF does not support SQL DDL / DML? (True/Fales)</p>", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "<p>UDF does not support SQL DDL / DML. That means you can select from a table, but you can't create or modify tables inside of a UDF.</p>", "answers": ["TRUE", "FALSE"]}, "correct_response": ["a"], "section": "Data Transformation", "question_plain": "UDF does not support SQL DDL / DML? (True/Fales)", "related_lectures": []}, {"_class": "assessment", "id": 58446042, "assessment_type": "multiple-choice", "prompt": {"question": "A stored procedure can run both the caller\u2019s and the owner\u2019s rights simultaneously. (TRUE / FALSE)", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "<p><strong>A stored procedure runs with either the caller\u2019s rights or the owner\u2019s rights</strong>. It cannot run with both at the same time.\n\nA <strong>caller\u2019s rights</strong> stored procedure runs with the privileges of the caller. The primary advantage of a caller\u2019s rights stored procedure is that it can access information about that caller or about the caller\u2019s current session. For example, a caller\u2019s rights stored procedure can read the caller\u2019s session variables and use them in a query.\n\nAn <strong>owner\u2019s rights</strong> stored procedure runs mostly with the privileges of the stored procedure\u2019s owner. The primary advantage of an owner\u2019s rights stored procedure is that the owner can delegate specific administrative tasks, such as cleaning up old data, to another role without granting that role more general privileges, such as privileges to delete all data from a specific table.\n\nAt the time that the stored procedure is created, the creator specifies whether the procedure runs with owner\u2019s rights or caller\u2019s rights. The default is owner\u2019s rights.</p>", "answers": ["TRUE", "FALSE"]}, "correct_response": ["b"], "section": "Data Transformation", "question_plain": "A stored procedure can run both the caller\u2019s and the owner\u2019s rights simultaneously. (TRUE / FALSE)", "related_lectures": []}, {"_class": "assessment", "id": 58446044, "assessment_type": "multiple-choice", "prompt": {"question": "How does Snowflake store semi-structured data, such as JSON, Avro, Parquet, ORC, and XML?", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>Snowflake stores semi-structured data, such as JSON, Avro, Parquet, ORC, and XML, as <strong>VARIANT data type</strong>. A VARIANT can store a value of any other type, including OBJECT and ARRAY.</p>", "answers": ["Stores as VARCHAR data type", "Stores as JSON data type", "Stores as VARIANT data type", "Stores as FLATTEN data type"]}, "correct_response": ["c"], "section": "Data Transformation", "question_plain": "How does Snowflake store semi-structured data, such as JSON, Avro, Parquet, ORC, and XML?", "related_lectures": []}, {"_class": "assessment", "id": 58446046, "assessment_type": "multiple-choice", "prompt": {"question": "While transforming Semi-structure data, what argument would you need to set with FLATTEN function to omit the output of the input rows that cannot be expanded, either because they cannot be accessed in the path or because they have zero fields or entries?", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p>The <strong>OUTER =&gt; FALSE argument with FLATTEN omits the output of the input rows that cannot be expanded</strong>, either because they cannot be accessed in the path or because they have zero fields or entries.\n\nThe <strong>OUTER =&gt; TRUE argument with FLATTEN generates exactly one row for zero-row expansions</strong> (with NULL in the KEY, INDEX, and VALUE columns).&nbsp; </p><p><br></p><p>RECURSIVE&nbsp; is used to instruct if only the element referenced by PATH is expanded or expansion is performed for all sub-elements recursively&nbsp; MODE Specifies whether only objects, arrays, or both should be flattened.</p>", "answers": ["OUTER =&gt; TRUE ", "RECURSIVE =&gt; TRUE ", "OUTER =&gt; FALSE", "RECURSIVE =&gt; FALSE", "MODE =&gt; OBJECT"]}, "correct_response": ["c"], "section": "Data Transformation", "question_plain": "While transforming Semi-structure data, what argument would you need to set with FLATTEN function to omit the output of the input rows that cannot be expanded, either because they cannot be accessed in the path or because they have zero fields or entries?", "related_lectures": []}, {"_class": "assessment", "id": 58446048, "assessment_type": "multiple-choice", "prompt": {"question": "What is an &quot;object&quot; in semi-structured data?", "relatedLectureIds": "", "feedbacks": ["", "", ""], "explanation": "OBJECT is also called a \u201cdictionary\u201d, \u201chash\u201d, or \u201cmap\u201d in many languages. This contains key-value pairs.", "answers": ["Collection of values in an array", "Collection of semi-structure data files", "Collection of key-value pairs"]}, "correct_response": ["c"], "section": "Data Transformation", "question_plain": "What is an &quot;object&quot; in semi-structured data?", "related_lectures": []}, {"_class": "assessment", "id": 58446050, "assessment_type": "multi-select", "prompt": {"question": "Which of these are unstructured data? (Select 2)", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p><strong>Unstructured data is information that does not fit into a predefined data model or schema.</strong> Typically text-heavy, such as form responses and social media conversations, unstructured data also encompasses images, video, and audio. Industry-specific file types such as VCF (genomics), KDF (semiconductors), or HDF5 (aeronautics) are included in this category.</p>", "answers": ["JSON", "Relational Data", "Images", "XML", "Videos"]}, "correct_response": ["c", "e"], "section": "Data Transformation", "question_plain": "Which of these are unstructured data? (Select 2)", "related_lectures": []}, {"_class": "assessment", "id": 58446052, "assessment_type": "multi-select", "prompt": {"question": "Snowflake supports the secured access of unstructured data files in cloud storage. What types of URLs are available to access files in cloud storage? (Select 3)", "relatedLectureIds": "", "feedbacks": ["", "", "", "", "", ""], "explanation": "<p>The following types of URLs are available to access files in cloud storage:\n\n<strong>Scoped URL:</strong> Encoded URL that permits temporary access to a staged file without granting privileges to the stage. The URL expires when the persisted query result period ends (i.e., the results cache expires), which is currently 24 hours.\n\n<strong>File URL:</strong> URL that identifies the database, schema, stage, and file path to a set of files. A role that has sufficient privileges on the stage can access the files.\n\n<strong>Pre-signed URL: </strong>Simple HTTPS URL used to access a file via a web browser. A file is temporarily accessible to users via this URL using a pre-signed access token. The expiration time for the access token is configurable.</p>", "answers": ["Unstructured URL", "Scoped URL", "Descoped URL", "File URL", "Signed URL", "Pre-signed URL"]}, "correct_response": ["b", "d", "f"], "section": "Data Transformation", "question_plain": "Snowflake supports the secured access of unstructured data files in cloud storage. What types of URLs are available to access files in cloud storage? (Select 3)", "related_lectures": []}, {"_class": "assessment", "id": 58446054, "assessment_type": "multiple-choice", "prompt": {"question": "Which of these functions helps generate the Pre-signed URL to access the unstructured data file?", "relatedLectureIds": "", "feedbacks": ["", "", "", "", "", ""], "explanation": "<p><strong>GET_PRESIGNED_URL generates the pre-signed URL to a staged file using the stage name and relative file path as inputs.</strong>\n\nPre-signed URL: Simple HTTPS URL used to access a file via a web browser. A file is temporarily accessible to users via this URL using a pre-signed access token. The expiration time for the access token is configurable.</p>", "answers": ["BUILD_SCOPED_FILE_URL", "GET_STAGE_LOCATION", "GET_RELATIVE_PATH", "BUILD_STAGE_FILE_URI", "GET_PRESIGNED_URL", "GET_ABSOLUTE_PATH"]}, "correct_response": ["e"], "section": "Data Transformation", "question_plain": "Which of these functions helps generate the Pre-signed URL to access the unstructured data file?", "related_lectures": []}, {"_class": "assessment", "id": 58446056, "assessment_type": "multiple-choice", "prompt": {"question": "Which of these SQL functions helps retrieve the URL for an external or internal named stage using the stage name as the input?", "relatedLectureIds": "", "feedbacks": ["", "", "", "", "", ""], "explanation": "<p><strong>GET_STAGE_LOCATION</strong> retrieves the URL for an external or internal named stage using the stage name as the input.\n</p><p> </p>", "answers": ["BUILD_SCOPED_FILE_URL", "GET_STAGE_LOCATION", "GET_RELATIVE_PATH", "BUILD_STAGE_FILE_URI", "GET_PRESIGNED_URL", "GET_ABSOLUTE_PATH"]}, "correct_response": ["b"], "section": "Data Transformation", "question_plain": "Which of these SQL functions helps retrieve the URL for an external or internal named stage using the stage name as the input?", "related_lectures": []}, {"_class": "assessment", "id": 58446058, "assessment_type": "multiple-choice", "prompt": {"question": "How can a directory table metadata be refreshed automatically and efficiently to synchronize the metadata with the latest associated files in the external stage and path?", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p>The metadata for a directory table can be refreshed automatically <strong>using the event notification service</strong> for your cloud storage service. The refresh operation synchronizes the metadata with the latest set of associated files in the external stage and path, i.e.:&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </p><ul><li><p>New files in the path are added to the table metadata.&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </p></li><li><p>Changes to files in the path are updated in the table metadata.&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </p></li><li><p>Files no longer in the path are removed from the table metadata. </p></li></ul>", "answers": ["Using Tasks", "Using Cloud event notification service", "Using Stream", "Using both Tasks and Stream", "It is a manual process and cant be automatically refreshed"]}, "correct_response": ["b"], "section": "Data Transformation", "question_plain": "How can a directory table metadata be refreshed automatically and efficiently to synchronize the metadata with the latest associated files in the external stage and path?", "related_lectures": []}, {"_class": "assessment", "id": 58446060, "assessment_type": "multiple-choice", "prompt": {"question": "Suppose files downloaded from an internal stage are corrupted. What should be verified with the stage creator to determine why the downloaded file is corrupted?", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "<p>If files downloaded from an internal stage are corrupted, verify with the stage creator that <strong>ENCRYPTION = (TYPE = 'SNOWFLAKE_SSE'</strong>) is set for the stage.</p>", "answers": ["Verify if ENCRYPTION = (TYPE = &#39;SNOWFLAKE_SSE&#39;) set for the stage", "Verify if ENCRYPTION = (TYPE = &#39;SNOWFLAKE_FULL&#39;) set for the stage"]}, "correct_response": ["a"], "section": "Data Transformation", "question_plain": "Suppose files downloaded from an internal stage are corrupted. What should be verified with the stage creator to determine why the downloaded file is corrupted?", "related_lectures": []}, {"_class": "assessment", "id": 58446062, "assessment_type": "multiple-choice", "prompt": {"question": "Which command is used to create a security integration to enable an HTTP client that supports OAuth to redirect users to an authorization page and generate access tokens for access to the REST API endpoint?", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p><strong>CREATE SECURITY INTEGRATION command is used to create a security integration</strong> that supports OAuth to redirect users to an authorization page and generate access tokens for access to the REST API endpoint.</p>", "answers": ["CREATE OAUTH INTEGRATION", "CREATE INTEGRATION", "CREATE SECURITY INTEGRATION", "CREATE SECURITY API"]}, "correct_response": ["c"], "section": "Data Transformation", "question_plain": "Which command is used to create a security integration to enable an HTTP client that supports OAuth to redirect users to an authorization page and generate access tokens for access to the REST API endpoint?", "related_lectures": []}, {"_class": "assessment", "id": 58446064, "assessment_type": "multiple-choice", "prompt": {"question": "Python UDFs and tabular Python UDFs can read and process unstructured data in staged files using SnowflakeFile class. (True/False)", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "<p><strong>Java UDFs and tabular Java UDFs</strong> can read and process unstructured data in staged files using either the <strong>SnowflakeFile</strong> class or the <strong>InputStream</strong> class in the UDF code.</p>", "answers": ["TRUE", "FALSE"]}, "correct_response": ["b"], "section": "Data Transformation", "question_plain": "Python UDFs and tabular Python UDFs can read and process unstructured data in staged files using SnowflakeFile class. (True/False)", "related_lectures": []}, {"_class": "assessment", "id": 58446066, "assessment_type": "multiple-choice", "prompt": {"question": "<p>A Pre-Signed URL is ideal for</p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p><strong>Pre-signed URL:</strong> Simple HTTPS URL used to access a file via a web browser. A file is temporarily accessible to users via this URL using a pre-signed access token. The expiration time for the access token is configurable. <strong>Ideal for business intelligence applications or reporting tools that need to display unstructured file contents.</strong></p><p><br></p><p><strong>Scoped URL:</strong> Encoded URL that permits temporary access to a staged file without granting privileges to the stage. The URL expires when the persisted query result period ends (i.e., the results cache expires), which is currently 24 hours. <strong>Ideal for use in custom applications, providing unstructured data to other accounts via a share, or for downloading and ad hoc analysis of unstructured data via Snowsight. </strong></p><p><br></p><p><strong>File URL:</strong> URL that identifies the database, schema, stage, and file path to a set of files. A role that has sufficient privileges on the stage can access the files. <strong>Ideal for custom applications that require access to unstructured data files.&nbsp; </strong></p>", "answers": ["<p>custom applications that require access to unstructured data files</p>", "<p>use in custom applications, providing unstructured data to other accounts via a share</p>", "<p>business intelligence applications or reporting tools that need to display the unstructured file contents</p>", "None of these"]}, "correct_response": ["c"], "section": "Data Transformation", "question_plain": "A Pre-Signed URL is ideal for", "related_lectures": []}, {"_class": "assessment", "id": 58446068, "assessment_type": "multiple-choice", "prompt": {"question": "What is the expiration period of a Pre-signed URL?", "relatedLectureIds": "", "feedbacks": ["", "", ""], "explanation": "<p><strong>The expiration period of Pre-Signed URL: Length of time specified in the expiration_time argument.</strong></p><p>The expiration period of Scoped URL: The URL expires when the persisted query result period ends.\nThe expiration period of the File URL: It is permanent.\n</p>", "answers": ["The URL expires when the persisted query result period ends", "It is Permanent", "Length of time specified in the expiration_time argument"]}, "correct_response": ["c"], "section": "Data Transformation", "question_plain": "What is the expiration period of a Pre-signed URL?", "related_lectures": []}, {"_class": "assessment", "id": 58446070, "assessment_type": "multiple-choice", "prompt": {"question": "Cloning a table replicates the source table&#39;s structure, data, load history, and certain other properties (e.g., STAGE FILE FORMAT). (True/False)", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "<p>Cloning a table replicates the source table's structure, data, and certain other properties (e.g., STAGE FILE FORMAT).\n\nA cloned table <strong>does not include the load history</strong> of the source table. One consequence is that data files loaded into a source table can be loaded again into its clones.</p>", "answers": ["TRUE", "FALSE"]}, "correct_response": ["b"], "section": "Data Protection and Data Sharing", "question_plain": "Cloning a table replicates the source table&#39;s structure, data, load history, and certain other properties (e.g., STAGE FILE FORMAT). (True/False)", "related_lectures": []}, {"_class": "assessment", "id": 58446072, "assessment_type": "multi-select", "prompt": {"question": "Which of these objects do not clone? (Select 2)", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "\nDatabases and Schemas can be cloned. External Table and Internal (Snowflake) stages do not get cloned.", "answers": ["Databases", "Schemas", "External Table", "Internal (Snowflake) stages"]}, "correct_response": ["c", "d"], "section": "Data Protection and Data Sharing", "question_plain": "Which of these objects do not clone? (Select 2)", "related_lectures": []}, {"_class": "assessment", "id": 58446074, "assessment_type": "multi-select", "prompt": {"question": "Which of these Snowflake tasks can be performed by Time Travel? (Select 3)", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>Using Time Travel, you can perform the following actions within a defined period:&nbsp; &nbsp; &nbsp; </p><ul><li><p>Query data in the past that has since been updated or deleted.&nbsp; &nbsp; &nbsp; </p></li></ul><ul><li><p>Create clones of entire tables, schemas, and databases at or before specific points in the past.&nbsp; &nbsp; &nbsp; </p></li></ul><ul><li><p>Restore tables, schemas, and databases that have been dropped.</p></li></ul>", "answers": ["Query data in the past that has since been updated or deleted", "Share the restored data objects over a specified period of time", "Create clones of entire tables, schemas, and databases at or before specific points in the past", "Restore tables, schemas, and databases that have been dropped."]}, "correct_response": ["a", "c", "d"], "section": "Data Protection and Data Sharing", "question_plain": "Which of these Snowflake tasks can be performed by Time Travel? (Select 3)", "related_lectures": []}, {"_class": "assessment", "id": 58446076, "assessment_type": "multiple-choice", "prompt": {"question": "What is the maximum data retention period for permanent databases, schemas, and tables for Snowflake Enterprise Edition (and higher)?", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p><strong>For Snowflake Enterprise Edition (and higher): </strong></p><ul><li><p><strong>For permanent databases, schemas, and tables, the retention period can be set to any value from 0 up to 90 days.</strong></p></li><li><p>For transient databases, schemas, and tables, the retention period can be set to 0 (or unset back to the default of 1 day). The same is also true for temporary tables. </p><p><br></p></li></ul>", "answers": ["90 days", "30 days", "1 day", "0 days"]}, "correct_response": ["a"], "section": "Data Protection and Data Sharing", "question_plain": "What is the maximum data retention period for permanent databases, schemas, and tables for Snowflake Enterprise Edition (and higher)?", "related_lectures": []}, {"_class": "assessment", "id": 58446078, "assessment_type": "multiple-choice", "prompt": {"question": "The data retention period for a database, schema, or table can not be changed once ACCOUNTADMIN sets it at the account level. (True/False)", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "The data retention period for a database, schema, or table can be changed at any time. DATA_RETENTION_TIME_IN_DAYS parameter can be used to explicitly override the default when creating a database, schema, and individual table.\n\nFor example: CREATE TABLE t1 (c1 int) DATA_RETENTION_IN DAYS=90;", "answers": ["TRUE", "FALSE"]}, "correct_response": ["b"], "section": "Data Protection and Data Sharing", "question_plain": "The data retention period for a database, schema, or table can not be changed once ACCOUNTADMIN sets it at the account level. (True/False)", "related_lectures": []}]}
5053406
~~~
{"count": 100, "next": null, "previous": null, "results": [{"_class": "assessment", "id": 58447012, "assessment_type": "multiple-choice", "prompt": {"question": "If the micro-partitions are constant, how much is the Clustering Overlap Depth?", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p>When there is no overlap in the range of values across all micro-partitions, the micro-partitions are considered to be in a constant state (i.e. they cannot be improved by clustering). </p><p><br></p><p>In the case of micro-partitions are in a constant state Overlap depth = 1.</p>", "answers": ["2", "20", "1", "10", "0"]}, "correct_response": ["c"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "If the micro-partitions are constant, how much is the Clustering Overlap Depth?", "related_lectures": []}, {"_class": "assessment", "id": 58447104, "assessment_type": "multiple-choice", "prompt": {"question": "Monica has run a query SELECT * FROM t1; After a couple of hours, John ran the same query. John has the same role as Monica and has the SELECT permissions on table t1. John got the result sooner than Monica. What could be the reason for the faster result?", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p><strong>It is a typical use case of Query Result Cache.</strong> It is stored and managed by the Cloud Services Layer. It is used if the identical query is run and base tables (t1 in this case) have not changed. Query Result Cache doesn't require Virtual Warehouse and is available for other users in the same role with SELECT permissions on all tables in the query.</p>", "answers": ["John&#39;s query resulted from the Metadata cache.", "John&#39;s query resulted from the Query Result cache.", "John&#39;s query resulted from the Local Disk cache.", "John&#39;s query resulted from Remote disk."]}, "correct_response": ["b"], "section": "Performance Concepts", "question_plain": "Monica has run a query SELECT * FROM t1; After a couple of hours, John ran the same query. John has the same role as Monica and has the SELECT permissions on table t1. John got the result sooner than Monica. What could be the reason for the faster result?", "related_lectures": []}, {"_class": "assessment", "id": 58447106, "assessment_type": "multi-select", "prompt": {"question": "Choose the false statements. (Select 2)", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p>As a best practice, <strong>Group and Execute similar queries on the same virtual warehouse</strong> to maximize local disk cache reuse for performance and cost optimization. The results get stored in the SSD of the Virtual Warehouse. So, if the Virtual Warehouse gets suspended, then results get lost. </p>", "answers": ["Group and Execute similar queries on the same virtual warehouse to maximize local disk cache reuse, for performance and cost optimization.", "Group and Execute similar queries on the different virtual warehouses to maximize local disk cache reuse, for performance and cost optimization.", "Results are stored in SSD in Virtual Warehouse in case of Local Disk Cache.", "Results are stored in the Cloud Storage layer in the case of Local Disk Cache. ", "If Virtual Warehouse is suspended, then results in Local Disk Cache will be lost"]}, "correct_response": ["b", "d"], "section": "Performance Concepts", "question_plain": "Choose the false statements. (Select 2)", "related_lectures": []}, {"_class": "assessment", "id": 58447108, "assessment_type": "multi-select", "prompt": {"question": "What key insights can we get from the Explain plan in Snowflake? (Select 3)", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p>The key insights that the explain plan gives us in its results output are information on <strong>partition pruning, join ordering, and join types.</strong></p><p>\nThe explain plan is a useful tool for determining the efficiency of your query. It's a command that compiles your query to figure out all the steps Snowflake would have to work through if it were actually to run the query.</p>", "answers": ["Partition Pruning", "Join Ordering", "Join Types", "Estimated Query Time", "Exact Query Time"]}, "correct_response": ["a", "b", "c"], "section": "Performance Concepts", "question_plain": "What key insights can we get from the Explain plan in Snowflake? (Select 3)", "related_lectures": []}, {"_class": "assessment", "id": 58447110, "assessment_type": "multiple-choice", "prompt": {"question": "John has a table EMPLOYEE_DATA, and he wants to create another table EMPLOYEE_DATA_OTHER, which should be the same as EMPLOYEE_DATA table with the same data. What is the best option for John?", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "The best option is to Clone the table as EMPLOYEE_DATA and EMPLOYEE_DATA_OTHER have the same structure and data. It will help save the storage cost. LIKE command only creates the empty table. CREATE TABLE \u2026 AS SELECT (also referred to as CTAS)\nCreates a new table populated with the data returned by a query but consumes additional storage.", "answers": ["Create the table with same data with SQL command as follows - \n\nCREATE TABLE EMPLOYEE_DATA_OTHER AS SELECT * FROM EMPLOYEE_DATA;", "Clone the table with same data with SQL command as follows - \n\nCREATE TABLE EMPLOYEE_DATA_OTHER CLONE EMPLOYEE_DATA;", "CREATE SHARE EMPLOYEE_DATA;", "Create the table with LIKE SQL command as follows -\n\n CREATE TABLE EMPLOYEE_DATA_OTHER LIKE EMPLOYEE_DATA;"]}, "correct_response": ["b"], "section": "Performance Concepts", "question_plain": "John has a table EMPLOYEE_DATA, and he wants to create another table EMPLOYEE_DATA_OTHER, which should be the same as EMPLOYEE_DATA table with the same data. What is the best option for John?", "related_lectures": []}, {"_class": "assessment", "id": 58447112, "assessment_type": "multiple-choice", "prompt": {"question": "How many servers are available in a large-sized cluster warehouse?", "relatedLectureIds": "", "feedbacks": ["", "", "", "", "", ""], "explanation": "<p>There are eight servers available in a large-sized cluster warehouse.</p><p><strong>Important: You may be asked for a Medium or any other-sized warehouse.&nbsp; (X - 1, S - 2, M - 4, L - 8, XL - 16, and so on)</strong></p>", "answers": ["1", "8", "16", "32", "64", "128"]}, "correct_response": ["b"], "section": "Performance Concepts", "question_plain": "How many servers are available in a large-sized cluster warehouse?", "related_lectures": []}, {"_class": "assessment", "id": 58447114, "assessment_type": "multiple-choice", "prompt": {"question": "Suppose you have an auto-scaling mode setup with a Standard policy. In what situation does Snowflake spin up an additional cluster?", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "<p><strong>In Standard Scaling policy</strong>, the first cluster starts immediately when either a query is queued, or the system detects that there\u2019s one more query than the currently-running clusters can execute.</p><p>\nEach successive cluster waits to start 20 seconds after the prior one has started. For example, if your warehouse is configured with ten max clusters, it can take 200+ seconds to start all 10 clusters.</p>", "answers": ["Only if the system estimates there\u2019s enough query load to keep the cluster busy for at least 6 minutes.", "The first cluster starts immediately when either a query is queued or the system detects that there\u2019s one more query than the currently-running clusters can execute."]}, "correct_response": ["b"], "section": "Performance Concepts", "question_plain": "Suppose you have an auto-scaling mode setup with a Standard policy. In what situation does Snowflake spin up an additional cluster?", "related_lectures": []}, {"_class": "assessment", "id": 58447116, "assessment_type": "multiple-choice", "prompt": {"question": "Which of these configurations will set up a warehouse in auto-scale mode?", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "<p><strong>Auto-scale mode is enabled by specifying different values for the maximum and the minimum number of clusters. </strong></p><p><br></p><p><strong>Note:</strong> In the exam, you may be asked what you will be set to make it maximized. Look for an answer which says - both (Minimum and Maximum) with the same value.</p>", "answers": ["Minimum Clusters = 2 and Maximum Clusters = 6", "Minimum Clusters = 6 and Maximum Clusters = 6"]}, "correct_response": ["a"], "section": "Performance Concepts", "question_plain": "Which of these configurations will set up a warehouse in auto-scale mode?", "related_lectures": []}, {"_class": "assessment", "id": 58447118, "assessment_type": "multiple-choice", "prompt": {"question": "What is the best way to analyze the optimum warehouse size?", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "<p>To achieve the best results, <strong>try to execute relatively homogeneous queries (size, complexity, data sets, etc.) on the same warehouse</strong>; executing queries of widely-varying size and/or complexity on the same warehouse makes it more difficult to analyze warehouse load, which can make it more difficult to select the best size to match the size, composition, and number of queries in your workload.</p>", "answers": ["Execute queries of widely-varying size and/or complexity on the same warehouse", "Execute relatively homogeneous queries (size, complexity, data sets, etc.) on the same warehouse"]}, "correct_response": ["b"], "section": "Performance Concepts", "question_plain": "What is the best way to analyze the optimum warehouse size?", "related_lectures": []}, {"_class": "assessment", "id": 58447120, "assessment_type": "multiple-choice", "prompt": {"question": "What is a key benefit of scaling out a warehouse?", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "<p><strong>Scaling out is explicitly designed for handling queuing and performance issues related to large numbers of concurrent users and/or queries. </strong></p>", "answers": ["Scaling out improves performance.", "Scaling out improves concurrency."]}, "correct_response": ["b"], "section": "Performance Concepts", "question_plain": "What is a key benefit of scaling out a warehouse?", "related_lectures": []}, {"_class": "assessment", "id": 58447122, "assessment_type": "multiple-choice", "prompt": {"question": "Suppose we resize a warehouse to a smaller size while it is executing SQL statements. There will be no impact on already executing SQL statements. (True / False)", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "<p><strong>Resizing a warehouse does not impact the statements that the warehouse is executing. </strong>When resizing to a smaller size, compute resources are removed from the warehouse only when they are no longer used to execute any current statements.</p>", "answers": ["TRUE", "FALSE"]}, "correct_response": ["a"], "section": "Performance Concepts", "question_plain": "Suppose we resize a warehouse to a smaller size while it is executing SQL statements. There will be no impact on already executing SQL statements. (True / False)", "related_lectures": []}, {"_class": "assessment", "id": 58447124, "assessment_type": "multiple-choice", "prompt": {"question": "The warehouse performance can be evaluated by querying the ", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p><strong>The warehouse performance can be evaluated by querying the Account Usage QUERY_HISTORY view.</strong></p>", "answers": ["Account Usage LOAD_HISTORY view", "Account Usage QUERY_HISTORY view", "Information Schema QUERY_HISTORY view", "Information Schema LOAD_HISTORY view"]}, "correct_response": ["b"], "section": "Performance Concepts", "question_plain": "The warehouse performance can be evaluated by querying the", "related_lectures": []}, {"_class": "assessment", "id": 58447126, "assessment_type": "multi-select", "prompt": {"question": " You have a dashboard that connects to Snowflake via JDBC. The dashboard is refreshed hundreds of times per day. The data is very stable, only changing once or twice per day. The query run by the dashboard user never changes. How will Snowflake manage changing and non-changing data? Mark all true statements. ", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p><strong>Until data has not changed and the query is the same - Snowflake reuses the data from the cache. </strong>Please note,&nbsp; Each time the persisted result for a query is reused, Snowflake resets the 24-hour retention period for the result up to a maximum of 31 days from the date and time that the query was first executed. After 31 days, the result is purged, and the next time the query is submitted, a new result is generated and persisted.\t</p>", "answers": ["Snowflake will show the most up-to-date data each time the dashboard is refreshed.", "<p>Snowflake will spin up a warehouse only if the underlying data has changed.</p>", "<p> Snowflake will compile result cache data from all user results, so no warehouse is needed.</p>", "<p>&nbsp; Snowflake will re-use data from the Results Cache as long as it is still the most up-to-date data available.\t&nbsp; \n </p>"]}, "correct_response": ["a", "b", "d"], "section": "Performance Concepts", "question_plain": "You have a dashboard that connects to Snowflake via JDBC. The dashboard is refreshed hundreds of times per day. The data is very stable, only changing once or twice per day. The query run by the dashboard user never changes. How will Snowflake manage changing and non-changing data? Mark all true statements.", "related_lectures": []}, {"_class": "assessment", "id": 58447128, "assessment_type": "multiple-choice", "prompt": {"question": "Materialized views can improve the performance of queries that use the same subquery results repeatedly. (True/False)", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "<p><strong>Materialized views are designed to improve query performance for workloads composed of common, repeated query patterns.</strong> However, materializing intermediate results incur additional costs. As such, before creating any materialized views, you should consider whether the costs are offset by the savings from re-using these results frequently enough.</p>", "answers": ["TRUE", "FALSE"]}, "correct_response": ["a"], "section": "Performance Concepts", "question_plain": "Materialized views can improve the performance of queries that use the same subquery results repeatedly. (True/False)", "related_lectures": []}, {"_class": "assessment", "id": 58447130, "assessment_type": "multiple-choice", "prompt": {"question": "If you want to create a warehouse that remains in a suspended state initially, which property do you need to set for that warehouse?", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p><strong>INITIALLY_SUSPENDED = TRUE | FALSE&nbsp; Specifies whether the warehouse is created initially in the \u2018Suspended\u2019 state.</strong>\nThe valid values are TRUE and FALSE.\n\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; TRUE: The warehouse is created, but suspended.\n\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; FALSE: The warehouse starts running after it is created.\n\n&nbsp; &nbsp; Default is&nbsp; FALSE\n</p>", "answers": ["AUTO_SUSPEND = 0", " INITIALLY_SUSPENDED = TRUE", "AUTO_RESUME = TRUE", "AUTO_RESUME = FALSE", "AUTO_SUSPEND = TRUE"]}, "correct_response": ["b"], "section": "Performance Concepts", "question_plain": "If you want to create a warehouse that remains in a suspended state initially, which property do you need to set for that warehouse?", "related_lectures": []}, {"_class": "assessment", "id": 58447132, "assessment_type": "multiple-choice", "prompt": {"question": "What size limit does VARIANT data type impose on individual rows?", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p><strong>The VARIANT data type imposes a 16 MB size limit on individual rows.</strong></p>", "answers": ["16 GB", "10 GB", "16 MB", "10 MB", "100 MB"]}, "correct_response": ["c"], "section": "Data Loading and Unloading", "question_plain": "What size limit does VARIANT data type impose on individual rows?", "related_lectures": []}, {"_class": "assessment", "id": 58447134, "assessment_type": "multiple-choice", "prompt": {"question": "What size of the virtual warehouse needs to be created by the sysadmin while loading using Snowpipe? (Select the best answer)", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p><strong>Snowpipe uses compute resources provided and managed by Snowflake (i.e. a serverless compute model).</strong> These Snowflake-provided resources are automatically resized and scaled up or down as required, and are charged and itemized using per-second billing. Data ingestion is charged based upon the actual workloads. User doesn't need to create any warehouse as it is taken care by Snowflake.</p>", "answers": ["L Size", "4XL Size", "XS Size", "M Size", "None of these"]}, "correct_response": ["e"], "section": "Data Loading and Unloading", "question_plain": "What size of the virtual warehouse needs to be created by the sysadmin while loading using Snowpipe? (Select the best answer)", "related_lectures": []}, {"_class": "assessment", "id": 58447136, "assessment_type": "multiple-choice", "prompt": {"question": "When staging uncompressed files in a Snowflake stage, Snowflake automatically compresses the files unless compression is explicitly disabled. Which of the options is used by Snowflake for compressing the file?", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p><strong>When staging uncompressed files in a Snowflake stage, the files are automatically compressed using gzip, unless compression is explicitly disabled.</strong></p>", "answers": ["deflate", "bzip2", "Brotli", "gzip", "Zstandard"]}, "correct_response": ["d"], "section": "Data Loading and Unloading", "question_plain": "When staging uncompressed files in a Snowflake stage, Snowflake automatically compresses the files unless compression is explicitly disabled. Which of the options is used by Snowflake for compressing the file?", "related_lectures": []}, {"_class": "assessment", "id": 58447138, "assessment_type": "multiple-choice", "prompt": {"question": "Which is the fastest option for selecting staged data files to load from a stage?", "relatedLectureIds": "", "feedbacks": ["", "", ""], "explanation": "<p>Of the three options for identifying/specifying data files to load from a stage, <strong>providing a discrete list of files is generally the fastest;</strong> however, the FILES parameter supports a maximum of 1,000 files, meaning a COPY command executed with the FILES parameter can only load up to 1,000 files.\n\nExample:\n\ncopy into load1 from @%load1/data1/ files=('test1.csv', 'test2.csv', 'test3.csv', 'test4.csv')</p>", "answers": ["By path (internal stages) / prefix (Amazon S3 bucket)", "Using pattern matching to identify specific files by pattern\n", "Specifying a list of specific files to load"]}, "correct_response": ["c"], "section": "Data Loading and Unloading", "question_plain": "Which is the fastest option for selecting staged data files to load from a stage?", "related_lectures": []}, {"_class": "assessment", "id": 58447140, "assessment_type": "multiple-choice", "prompt": {"question": "John wants to load data files from an external stage to Snowflake. He has split the large file into smaller 100 - 250 MB data files, and there is a total of 16 smaller data files. What warehouse size would you recommend him to use for loading these data files quickly and cost-effectively?", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p>XS sized warehouse can load eight files parallelly. \n<strong>S sized warehouse can load sixteen files parallelly. </strong>\nM sized warehouse can load thirty-two files parallelly.\nL sized warehouse can load sixty-four files parallelly.\nXL sized warehouse can load one hundred twenty-eight files parallelly and so on. </p>", "answers": ["XS", "S", "M", "L", "XL"]}, "correct_response": ["b"], "section": "Data Loading and Unloading", "question_plain": "John wants to load data files from an external stage to Snowflake. He has split the large file into smaller 100 - 250 MB data files, and there is a total of 16 smaller data files. What warehouse size would you recommend him to use for loading these data files quickly and cost-effectively?", "related_lectures": []}, {"_class": "assessment", "id": 58447142, "assessment_type": "multiple-choice", "prompt": {"question": "<p>What does OVERWRITE parameter do with the INSERT command?</p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p><strong>OVERWRITE specifies that the target table should be truncated before inserting the values into the table.</strong> Note that specifying this option does not affect the access control privileges on the table.</p>", "answers": ["It de-duplicates while inserting and skips the insert if there is an exact similar record in the table.", "It specifies that the target table should be truncated before inserting the values into the table.", "It helps ignore any errors while inserting the values into the table.", "It drops the table, recreates, and inserts the values into the table. "]}, "correct_response": ["b"], "section": "Data Loading and Unloading", "question_plain": "What does OVERWRITE parameter do with the INSERT command?", "related_lectures": []}, {"_class": "assessment", "id": 58447144, "assessment_type": "multiple-choice", "prompt": {"question": "If a file in a stage has the LAST_MODIFIED date older than 64 days and the initial set of data was loaded into the table more than 64 days earlier. In this case, to prevent any data loss, the COPY command loads the file by default. (True / False)", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "<p>The COPY command cannot definitively determine whether a file has been loaded already if the LAST_MODIFIED date is older than 64 days and the initial set of data was loaded into the table more than 64 days earlier (and if the file was loaded into the table, that also occurred more than 64 days earlier). In this case, <strong>to prevent accidental reload, the command skips the file by default.</strong></p>", "answers": ["TRUE", "FALSE"]}, "correct_response": ["b"], "section": "Data Loading and Unloading", "question_plain": "If a file in a stage has the LAST_MODIFIED date older than 64 days and the initial set of data was loaded into the table more than 64 days earlier. In this case, to prevent any data loss, the COPY command loads the file by default. (True / False)", "related_lectures": []}, {"_class": "assessment", "id": 58447146, "assessment_type": "multiple-choice", "prompt": {"question": "Which copy option is used to delete the file from the Snowflake stage when data from staged files are loaded successfully?", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>Staged files can be deleted from a Snowflake stage (user stage, table stage, or named stage) using the following methods:</p><p><br></p><ol><li><p><strong>Files that were loaded successfully can be deleted from the stage during a load by specifying the PURGE copy option in the COPY INTO &lt;table&gt; command.</strong></p><p><br></p></li><li><p><strong>After the load completes, use the REMOVE command to remove the files in the stage.</strong>\n</p></li></ol><p>Please note, DELETE or REMOVE are not COPY command options. REMOVE is a different DML command which is used to remove files in the stage. </p><p><br></p>", "answers": ["REMOVE = TRUE", "PURGE = TRUE", "DELETE = TRUE", "DEL = TRUE"]}, "correct_response": ["b"], "section": "Data Loading and Unloading", "question_plain": "Which copy option is used to delete the file from the Snowflake stage when data from staged files are loaded successfully?", "related_lectures": []}, {"_class": "assessment", "id": 58447148, "assessment_type": "multiple-choice", "prompt": {"question": "What is the default encoding used by Snowflake while unloading data?", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>Output files are always encoded using <strong>UTF-8</strong>, regardless of the file format; no other character sets are supported.</p>", "answers": ["UTF ", "UTF-8", "UTF-16", "UTF-32"]}, "correct_response": ["b"], "section": "Data Loading and Unloading", "question_plain": "What is the default encoding used by Snowflake while unloading data?", "related_lectures": []}, {"_class": "assessment", "id": 58447150, "assessment_type": "multiple-choice", "prompt": {"question": "What is the preferred way to distinguish empty strings from NULLs while unloading in CSV files?", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>An empty string is typically represented by a quoted empty string (e.g. '') to indicate that the string contains zero characters. <strong>The preferred way is to enclose strings in quotes by setting the FIELD_OPTIONALLY_ENCLOSED_BY option, to distinguish empty strings from NULLs in output CSV files.</strong></p>", "answers": ["Leave string fields unenclosed by setting the FIELD_OPTIONALLY_ENCLOSED_BY option to NONE.", "Enclose strings in quotes by setting the FIELD_OPTIONALLY_ENCLOSED_BY option.", "Set EMPTY_FIELD_AS_NULL to TRUE", "Set EMPTY_FIELD_AS_NULL to FALSE"]}, "correct_response": ["b"], "section": "Data Loading and Unloading", "question_plain": "What is the preferred way to distinguish empty strings from NULLs while unloading in CSV files?", "related_lectures": []}, {"_class": "assessment", "id": 58447152, "assessment_type": "multi-select", "prompt": {"question": "During data loading using COPY INTO &lt;table&gt; command, if the string exceeds the target column length, what options do you have to truncate the string? (Select 2)", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p><strong>ENFORCE_LENGTH:&nbsp; &nbsp;</strong></p><ul><li><p>If TRUE, the COPY statement produces an error if a loaded string exceeds the target column length. </p></li><li><p>If FALSE, strings are automatically truncated to the target column length.&nbsp; </p><p><br></p></li></ul><p><strong>TRUNCATECOLUMNS: </strong></p><ul><li><p>If TRUE, strings are automatically truncated to the target column length. </p></li><li><p>If FALSE, the COPY statement produces an error if a loaded string exceeds the target column length.</p></li></ul>", "answers": ["ENFORCE_LENGTH = TRUE ", "ENFORCE_LENGTH = FALSE", "TRUNCATECOLUMNS = TRUE", "TRUNCATECOLUMNS = FALSE"]}, "correct_response": ["b", "c"], "section": "Data Transformation", "question_plain": "During data loading using COPY INTO &lt;table&gt; command, if the string exceeds the target column length, what options do you have to truncate the string? (Select 2)", "related_lectures": []}, {"_class": "assessment", "id": 58447154, "assessment_type": "multi-select", "prompt": {"question": "<p>Which of these Sampling methods does Snowflake support? (Select 2)</p>", "relatedLectureIds": "", "feedbacks": ["", "", ""], "explanation": "<p>SAMPLE / TABLESAMPLE returns a subset of rows sampled randomly from the specified table. The following sampling methods are supported:\n\n<strong>Sample a fraction of a table</strong>, with a specified probability for including a given row. The number of rows returned depends on the size of the table and the requested probability. A seed can be specified to make the sampling deterministic.\n\n<strong>Sample a fixed</strong>, specified number of rows. The exact number of specified rows is returned unless the table contains fewer rows.\n\nSAMPLE and TABLESAMPLE are synonymous and can be used interchangeably.</p>", "answers": ["Sample a fraction of the table with a specified probability of including a given row", "Sample exact rows of the table with the specified sequence keys", "Sample a fixed, specified number of rows"]}, "correct_response": ["a", "c"], "section": "Data Transformation", "question_plain": "Which of these Sampling methods does Snowflake support? (Select 2)", "related_lectures": []}, {"_class": "assessment", "id": 58447156, "assessment_type": "multiple-choice", "prompt": {"question": "<p>Monica is confused about which sampling method she should use with one of the very large tables, considering better performance. Which sampling method would you recommend from BERNOULLI | ROW and SYSTEM | BLOCK?</p>", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "<p><strong>SYSTEM | BLOCK sampling is often faster than BERNOULLI | ROW sampling.</strong> Also, BERNOULLI | ROW method is good for Smaller Tables, and SYSTEM | BLOCK method is for Larger Tables.</p>", "answers": ["SYSTEM | BLOCK", "BERNOULLI | ROW"]}, "correct_response": ["a"], "section": "Data Transformation", "question_plain": "Monica is confused about which sampling method she should use with one of the very large tables, considering better performance. Which sampling method would you recommend from BERNOULLI | ROW and SYSTEM | BLOCK?", "related_lectures": []}, {"_class": "assessment", "id": 58447158, "assessment_type": "multiple-choice", "prompt": {"question": "Select the type of function that returns one value per group of rows (for example - AVG, MAX, MIN)", "relatedLectureIds": "", "feedbacks": ["", "", "", "", "", ""], "explanation": "<p><strong>Aggregate functions operate on values across rows to perform mathematical calculations such as sum, average, counting, minimum/maximum values, standard deviation, and estimation, as well as some non-mathematical operations.</strong>\n\nAn aggregate function takes multiple rows (actually, zero, one, or more rows) as input and produces a single output. In contrast, scalar functions take one row as input and produce one row (one value) as output.\n\nAn aggregate function always returns exactly one row, even when the input contains zero rows. Typically, if the input contained zero rows, the output is NULL. However, an aggregate function could return 0, an empty string, or some other value when passed zero rows.</p>", "answers": ["Aggregate Function", "Scalar Function", "Window Function", "Table Function", "User-Defined Function", "System Function"]}, "correct_response": ["a"], "section": "Data Transformation", "question_plain": "Select the type of function that returns one value per group of rows (for example - AVG, MAX, MIN)", "related_lectures": []}, {"_class": "assessment", "id": 58447160, "assessment_type": "multiple-choice", "prompt": {"question": "Select the type of function that is used to execute an action in the system or return information about the system.", "relatedLectureIds": "", "feedbacks": ["", "", "", "", "", ""], "explanation": "<p><strong>System function</strong> that is used to execute an action in the system or return information about the system.&nbsp; &nbsp;</p><p>Snowflake provides the following types of system functions:</p><ul><li><p>Control functions that allow you to execute actions in the system (e.g. aborting a query).&nbsp; </p></li><li><p>Information functions that return information about the system (e.g. calculating the clustering depth of a table).&nbsp; </p></li><li><p>Information functions that return information about queries (e.g. information about EXPLAIN plans).</p></li></ul>", "answers": ["Aggregate Function", "Scalar Function", "Window Function", "Table Function", "User-Defined Function", "System Function"]}, "correct_response": ["f"], "section": "Data Transformation", "question_plain": "Select the type of function that is used to execute an action in the system or return information about the system.", "related_lectures": []}, {"_class": "assessment", "id": 58447162, "assessment_type": "multiple-choice", "prompt": {"question": "Monica wants to share a UDF with other users. She wants to permit other users to use it, but she doesn&#39;t want them to be able to see how it was defined or the underlying logic behind it. What would you recommend to Monica?", "relatedLectureIds": "", "feedbacks": ["", "", ""], "explanation": "<p>We can create a user-defined function to be unsecure or secure.&nbsp; <strong>A secure user-defined function</strong> means if we permit someone else to use this UDF, they will not be able to see how it was defined or the underlying logic behind it.</p>", "answers": ["Underlying logic can not be hidden with UDF", "Monica should create an unsecure UDF and then block the logic in the sql statement", "Monica should create a secure UDF"]}, "correct_response": ["c"], "section": "Data Transformation", "question_plain": "Monica wants to share a UDF with other users. She wants to permit other users to use it, but she doesn&#39;t want them to be able to see how it was defined or the underlying logic behind it. What would you recommend to Monica?", "related_lectures": []}, {"_class": "assessment", "id": 58447164, "assessment_type": "multiple-choice", "prompt": {"question": "UDF runs with either the caller\u2019s or the owner\u2019s rights. (TRUE / FALSE)", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "<p><strong>UDF only runs as the function owner.</strong> <strong>A stored procedure runs with either the caller\u2019s rights or the owner\u2019s rights</strong>. It cannot run with both at the same time.&nbsp; </p><p><br></p><p><strong>A caller\u2019s rights stored procedure </strong>runs with the privileges of the caller. The primary advantage of a caller\u2019s rights stored procedure is that it can access information about that caller or about the caller\u2019s current session. For example, a caller\u2019s rights stored procedure can read the caller\u2019s session variables and use them in a query.&nbsp; </p><p><br></p><p><strong>An owner\u2019s rights stored procedure</strong> runs mostly with the privileges of the stored procedure\u2019s owner. The primary advantage of an owner\u2019s rights stored procedure is that the owner can delegate specific administrative tasks, such as cleaning up old data, to another role without granting that role more general privileges, such as privileges to delete all data from a specific table.&nbsp; </p><p><br></p><p>At the time that the stored procedure is created, the creator specifies whether the procedure runs with the owner\u2019s rights or the caller\u2019s rights. The default is owner\u2019s rights.</p>", "answers": ["TRUE", "FALSE"]}, "correct_response": ["b"], "section": "Data Transformation", "question_plain": "UDF runs with either the caller\u2019s or the owner\u2019s rights. (TRUE / FALSE)", "related_lectures": []}, {"_class": "assessment", "id": 58447166, "assessment_type": "multiple-choice", "prompt": {"question": "How can you produce a lateral view of a VARIANT, OBJECT or ARRAY Column?", "answers": ["Using INFER_SCHEMA table function", "Using RESULT_SCAN table function", "Using SPLIT_TO_TABLE table function", "Using FLATTEN table function"], "explanation": "FLATTEN is a table function that produces a lateral view of a VARIANT, OBJECT, or ARRAY column.\n\nINFER_SCHEMA table function is used to detect the file metadata schema in a set of staged data files that contain semi-structured data and retrieves the column definitions.\n\nRESULT SCAN returns the result set of a previous command (within 24 hours of when you executed the query) as if the result was a table.\n\nSPLIT_TO_TABLE table function splits a string (based on a specified delimiter) and flattens the results into rows.\n"}, "correct_response": ["d"], "section": "Data Transformation", "question_plain": "How can you produce a lateral view of a VARIANT, OBJECT or ARRAY Column?", "related_lectures": []}, {"_class": "assessment", "id": 58447014, "assessment_type": "multi-select", "prompt": {"question": "<p>Snowflake stores metadata about all rows stored in a micro-partition, including (Select 3)</p>", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p>Micro-partitioning is automatically performed on all Snowflake tables. Tables are transparently partitioned using the Ordering of the data as inserted/loaded. Snowflake stores metadata about all rows stored in a micro-partition, including:</p><ul><li><p>The range of values for each of the columns in the micro-partition. </p></li><li><p>The number of distinct values.&nbsp; </p></li><li><p>Additional properties used for both optimization and efficient query processing.</p></li></ul>", "answers": ["The range of values for each of the columns in the micro-partition", "The number of distinct values", "Additional properties used for both optimization and efficient query processing", "The number of similar values", "The range of values for the first column in the micro-partition"]}, "correct_response": ["a", "b", "c"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "Snowflake stores metadata about all rows stored in a micro-partition, including (Select 3)", "related_lectures": []}, {"_class": "assessment", "id": 58447016, "assessment_type": "multiple-choice", "prompt": {"question": "Which command can be used to resume Automatic Clustering for a table?", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>Example - <strong>ALTER TABLE EMPLOYEE RESUME RECLUSTER</strong>; please note that RESUME RECLUSTER is a clause, not a command.</p>", "answers": ["ALTER TABLE", "START TABLE", "TRIGGER CLUSTERING", "RESUME RECLUSTER"]}, "correct_response": ["a"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "Which command can be used to resume Automatic Clustering for a table?", "related_lectures": []}, {"_class": "assessment", "id": 58447018, "assessment_type": "multi-select", "prompt": {"question": "What are the three layers in Snowflake&#39;s unique architecture? (Select 3)", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>Snowflake's unique architecture consists of three key layers:</p><ul><li><p>Database Storage </p></li><li><p>Query Processing </p></li><li><p>Cloud Services</p></li></ul>", "answers": ["Database Storage", "Query Processing", "Cloud Services", "Computation Services"]}, "correct_response": ["a", "b", "c"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "What are the three layers in Snowflake&#39;s unique architecture? (Select 3)", "related_lectures": []}, {"_class": "assessment", "id": 58447020, "assessment_type": "multiple-choice", "prompt": {"question": "In which layer does Snowflake perform query execution?", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p><strong>Query execution is performed in the processing layer.</strong> Snowflake processes queries using \u201cvirtual warehouses.\u201d</p>", "answers": ["Cloud Services", "Query Processing", "Database Storage", "None of these"]}, "correct_response": ["b"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "In which layer does Snowflake perform query execution?", "related_lectures": []}, {"_class": "assessment", "id": 58447022, "assessment_type": "multi-select", "prompt": {"question": "What are the key benefits of The Data Cloud? (Select 3)", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p>The benefits of The Data Cloud are <strong>Access, Governance, and Action</strong>. </p><p><strong>Access</strong> means that organizations can easily discover data and share it internally or with third parties without regard to geographical location. </p><p><strong>Governance</strong> is about setting policies and rules and protecting the data in a way that can unlock new value and collaboration while maintaining the highest levels of security and compliance. </p><p><strong>Action</strong> means you can empower every part of your business with data to build better products, make faster decisions, create new revenue streams and realize the value of your greatest untapped asset, your data.</p>", "answers": ["Access", "Governance", "Action", "Maintenance", "Backup"]}, "correct_response": ["a", "b", "c"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "What are the key benefits of The Data Cloud? (Select 3)", "related_lectures": []}, {"_class": "assessment", "id": 58447024, "assessment_type": "multi-select", "prompt": {"question": "Which of these are Snowflake Cloud Partner Categories? (Select 3)", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>Snowflake has the following Cloud Partner Categories:</p><ul><li><p>Data Integration</p></li><li><p>Business Intelligence (BI)</p></li><li><p>Machine Learning &amp; Data Science</p></li><li><p>Security Governance &amp; Observability</p></li><li><p>SQL Development &amp; Management, and </p></li><li><p>Native Programmatic Interfaces.\t</p></li></ul>", "answers": ["Application Integration", "Data Integration", "Machine Learning &amp; Data Science", "Native Programmatic Interfaces"]}, "correct_response": ["b", "c", "d"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "Which of these are Snowflake Cloud Partner Categories? (Select 3)", "related_lectures": []}, {"_class": "assessment", "id": 58447026, "assessment_type": "multi-select", "prompt": {"question": "Which of these are applicable for Snowflake Connector for Kafka? (Select all that apply)", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p>Kafka topics can be mapped to existing Snowflake tables in the Kafka configuration. If the topics are not mapped, then the <strong>Kafka connector creates a new table</strong> for each topic using the topic name. The Kafka connector subscribes to one or more Kafka topics based on the configuration information provided via the Kafka configuration file or command line (Or the Confluent Control Center; Confluent only).</p>", "answers": ["Reads data from one or more Kafka topics and loads the data into a Snowflake table", "Kafka topics can be mapped to existing Snowflake tables in the Kafka configuration", "If the topics are not mapped, then the Kafka connector creates a new table for each topic using the topic name", "Kafka connector required a pre-configured Snowflake table to map the topics with that Snowflake table", "The Kafka connector subscribes to one or more Kafka topics"]}, "correct_response": ["a", "b", "c", "e"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "Which of these are applicable for Snowflake Connector for Kafka? (Select all that apply)", "related_lectures": []}, {"_class": "assessment", "id": 58447028, "assessment_type": "multiple-choice", "prompt": {"question": "Which Snowsight interface does help in setting up Multi-factor authentication (MFA)?", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p>There are three interfaces in Snowsight. Left Nav, User Menu, and Account Selector. </p><p><strong>Left Navigation</strong> consists of Worksheets, Dashboards, Data, Marketplace, Activity, Admin, Help &amp; Support. </p><p><strong>User Menu</strong> lets you Switch Roles, <strong>Profile including multi-factor authentication (MFA)</strong>, Partner Connect, Documentation, Support and Sign Out. </p><p><strong>The account selector</strong>, located at the bottom of the left nav, lets you sign in to other Snowflake accounts.</p>", "answers": ["You can not setup Multi-factor authentication (MFA) using Snowsight interface", "Left Nav interface", "User Menu Interface", "Account Selector Interface", "Admin Interface"]}, "correct_response": ["c"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "Which Snowsight interface does help in setting up Multi-factor authentication (MFA)?", "related_lectures": []}, {"_class": "assessment", "id": 58447030, "assessment_type": "multi-select", "prompt": {"question": "Which table types does Snowflake support? (Select all that apply)", "relatedLectureIds": "", "feedbacks": ["", "", "", "", "", ""], "explanation": "<p><strong>Snowflake supports four different table types: Permanent Table, Temporary Table, Transient Table, and External Table.</strong>&nbsp; </p><p><strong>Permanent Table:</strong> It persists until dropped. It is designed for data requiring the highest data protection and recovery level and is the default table type. Permanent Tables can be protected by up to 90 days of time travel with Enterprise Edition or above. Moreover, the failsafe is covered on all the Permanent Tables.&nbsp; &nbsp; &nbsp; </p><p><strong>Temporary Table:</strong> A Temporary table is tied to a specific session, which means it is tied to a single user. Temporary tables are used for things like materializing subquery. You can only cover temporary tables by up to one day of time travel, and they are not covered by a failsafe.&nbsp; &nbsp; &nbsp; </p><p><strong>Transient Table:</strong> A Transient table is essentially a temporary table that more than one user can share because multiple users share a transient table. You have to drop it when you are finished with it, and it also is only covered by up to one day of time travel and is not covered by a failsafe. <em>NOTE - WE CAN ALSO HAVE TRANSIENT DATABASES AND SCHEMAS.&nbsp; &nbsp; &nbsp; </em></p><p><strong>External Table:</strong> An External Table is used to access data in a data lake. It is always read-only because it is based on files that live outside of Snowflake and are not managed by Snowflake, and Time Travel and Failsafe do not cover it.\t</p>", "answers": ["PERMANENT TABLE", "TEMPORARY TABLE", "TRANSIENT TABLE", "EXTERNAL TABLE", "SECURED TABLE", "MATERIALIZED TABLE"]}, "correct_response": ["a", "b", "c", "d"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "Which table types does Snowflake support? (Select all that apply)", "related_lectures": []}, {"_class": "assessment", "id": 58447032, "assessment_type": "multiple-choice", "prompt": {"question": "Which is the default timestamp in Snowflake?", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p><strong>TIMESTAMP_NTZ is the default timestamp type if you just define a column as a timestamp.</strong> Hint to remember: NTZ represents NO TIME ZONES.</p>", "answers": ["TIMESTAMP_LTZ", "TIMESTAMP_NTZ", "TIMESTAMP_TZ", "None of these"]}, "correct_response": ["b"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "Which is the default timestamp in Snowflake?", "related_lectures": []}, {"_class": "assessment", "id": 58447034, "assessment_type": "multi-select", "prompt": {"question": "<p>Which of the following commands are File staging commands? (Select all that apply)</p>", "relatedLectureIds": "", "feedbacks": ["", "", "", "", "", ""], "explanation": "<p>\n</p><p><strong>File Staging Commands</strong> \u2013 PUT (to a stage), GET (from a stage), LIST, and REMOVE. These commands are specific for working with stages. </p><p>\n</p>", "answers": ["UNDROP", "PUT", "GET", "LIST ", "REMOVE", "COPY INTO &lt;table&gt;"]}, "correct_response": ["b", "c", "d", "e"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "Which of the following commands are File staging commands? (Select all that apply)", "related_lectures": []}, {"_class": "assessment", "id": 58447036, "assessment_type": "multiple-choice", "prompt": {"question": "How long does Snowflake keep Snowpipe&#39;s load history?", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p>Snowflake keeps the Snowpipe's load history for 14 days. <strong>If you recreate&nbsp; [CREATE OR REPLACE ..] the PIPE then the load history will reset to empty [ very important for the exam ].</strong></p>", "answers": ["30 days", "31 days", "14 days", "64 days", "1 day"]}, "correct_response": ["c"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "How long does Snowflake keep Snowpipe&#39;s load history?", "related_lectures": []}, {"_class": "assessment", "id": 58447038, "assessment_type": "multiple-choice", "prompt": {"question": "Snowflake supports SQL UDFs that return a set of rows. Which keyword in CREATE FUNCTION statement does need to be specified to enable UDF (i.e., UDTF) to return a set of rows? ", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p><strong>TABLE keyword after RETURNS needs to be specified to create a UDTF (user-defined table function).</strong> Example :&nbsp; </p><p><br></p><p>create function t()</p><p>returns <strong>table</strong>(msg varchar)</p><p>as</p><p>$$</p><p>select 'Hello'</p><p>union</p><p>select 'World'</p><p>$$;&nbsp; </p><p><br></p><p>Remember - UDF returns a singular scalar value or if defined as a TABLE function, a set of rows. If you see UDTF in the exam, that simply means UDF that returns a set of rows.</p>", "answers": ["SCALAR", "MULTIPLE", "ROWS", "TABLE "]}, "correct_response": ["d"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "Snowflake supports SQL UDFs that return a set of rows. Which keyword in CREATE FUNCTION statement does need to be specified to enable UDF (i.e., UDTF) to return a set of rows?", "related_lectures": []}, {"_class": "assessment", "id": 58447040, "assessment_type": "multi-select", "prompt": {"question": "Which roles can use SQL to view the task history within a specified date range? (Select all that apply)", "relatedLectureIds": "", "feedbacks": ["", "", ""], "explanation": "All of these roles can use SQL to view the task history within a specified date range.\nTo view the run history for a single task: Query the TASK_HISTORY table function (in the Snowflake Information Schema).\n\nTo view details on a DAG run that is currently scheduled or is executing: Query the CURRENT_TASK_GRAPHS table function (in the Snowflake Information Schema).\n\nTo view the history for DAG runs that executed successfully, failed, or were canceled in the past 60 minutes: Query the COMPLETE_TASK_GRAPHS table function (in the Snowflake Information Schema).\n\nQuery the COMPLETE_TASK_GRAPHS View  (in Account Usage). ", "answers": ["Account Administrator (ACCOUNTADMIN)", "Task Owner having OWNERSHIP privilege on a task", "Role that has the global MONITOR EXECUTION privilege"]}, "correct_response": ["a", "b", "c"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "Which roles can use SQL to view the task history within a specified date range? (Select all that apply)", "related_lectures": []}, {"_class": "assessment", "id": 58447042, "assessment_type": "multi-select", "prompt": {"question": "Which of these are types of the stream? (Select 3)", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p><strong>The following stream types are available based on the metadata recorded by each:</strong> </p><p><strong>Standard</strong> - Supported for streams on tables, directory tables, or views. A standard (i.e., delta) stream tracks all DML changes to the source object, including inserts, updates, and deletes (including table truncates).&nbsp; </p><p><strong>Append-only</strong> - Supported for streams on standard tables, directory tables, or views. An append-only stream tracks row inserts only. Update and delete operations (including table truncates) are not recorded. </p><p><strong>Insert-only</strong> - Supported for streams on external tables only. An insert-only stream tracks row inserts only; they do not record delete operations that remove rows from an inserted set (i.e., no-ops). </p>", "answers": ["External", "Standard", "Update-only", "Append-only", "Insert-only"]}, "correct_response": ["b", "d", "e"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "Which of these are types of the stream? (Select 3)", "related_lectures": []}, {"_class": "assessment", "id": 58447044, "assessment_type": "multi-select", "prompt": {"question": "Snowpark is a new developer framework for Snowflake. It allows data engineers, data scientists, and data developers to code in their familiar way with their language of choice and execute the pipeline, ML workflow, and data apps faster and more securely in a single platform. \n\nWhich of these following languages does Snowpark support? (Select 3)", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p><strong>Snowpark support starts with Scala API, Java UDFs, and External Functions and expands to Java &amp; Python.</strong></p><p><br></p><p>Snowpark is a new developer framework for Snowflake. It allows data engineers, data scientists, and data developers to code in their familiar way with their language of choice and execute the pipeline, ML workflow, and data apps faster and more securely in a single platform. \n \n It brings deeply integrated, DataFrame-style programming to the languages developers like to use and functions to help you efficiently expand more data use cases. Now all these can be executed inside Snowflake using the elastic performance engine.&nbsp; \n </p><p><strong>[Please note about External Functions, Important for the exam: ]</strong></p><p><strong>External Functions - External functions are user-defined functions that are stored and executed outside of Snowflake.&nbsp; &nbsp;</strong></p>", "answers": ["C#", "Java", "C++", "Python", "Scala"]}, "correct_response": ["b", "d", "e"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "Snowpark is a new developer framework for Snowflake. It allows data engineers, data scientists, and data developers to code in their familiar way with their language of choice and execute the pipeline, ML workflow, and data apps faster and more securely in a single platform. \n\nWhich of these following languages does Snowpark support? (Select 3)", "related_lectures": []}, {"_class": "assessment", "id": 58447046, "assessment_type": "multi-select", "prompt": {"question": "<p>Which data types are not supported by the Search Optimization Service? (Select 2)</p>", "relatedLectureIds": "", "feedbacks": ["", "", "", "", "", ""], "explanation": "<p><br></p><p><strong>The search optimization service currently supports equality predicate and IN list predicate searches for the following data types:</strong>\n\nFixed-point numbers (e.g. INTEGER, NUMERIC).\n\nDATE, TIME, and TIMESTAMP.\n\nVARCHAR.\n\nBINARY.\n\nCurrently, the search optimization service does not support floating point data types, semi-structured data types, or other data types not listed above. </p><p><strong><em>[Improtant term for exam: EQUALITY for Search Optimization Service]</em></strong></p>", "answers": ["Fixed-point numbers (e.g. INTEGER, NUMERIC)", "DATE, TIME, and TIMESTAMP", "VARCHAR", "BINARY", "Floating-point data types", "Semi-structured data types"]}, "correct_response": ["e", "f"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "Which data types are not supported by the Search Optimization Service? (Select 2)", "related_lectures": []}, {"_class": "assessment", "id": 58447048, "assessment_type": "multi-select", "prompt": {"question": "Which of the following data storage does incur the cost? (Select 3)", "relatedLectureIds": "", "feedbacks": ["", "", "", "", "", ""], "explanation": "<p><strong>Storage is calculated and charged for data regardless of whether it is in the Active, Time Travel, or Fail-safe state.</strong></p>", "answers": ["Active data Storage", "Time Travel Storage", "All storage except Fail-Safe storage", "Only Active and Time Travel Storage", "Fail-Safe Storage", "Only Active and Fail-Sage storage"]}, "correct_response": ["a", "b", "e"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "Which of the following data storage does incur the cost? (Select 3)", "related_lectures": []}, {"_class": "assessment", "id": 58447050, "assessment_type": "multiple-choice", "prompt": {"question": "What sized tables will experience the most benefit from clustering?", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>Generally, <strong>tables in the multi-terabyte (TB) range</strong> will experience the most benefit from clustering, mainly if DML is performed regularly/continually on these tables.</p>", "answers": ["Tables with sizes between the range of 100 MB to 1 GB compressed", "Tables with sizes between the range of 1 GB to 10 GB compressed", "Tables in the multi-terabyte (TB) range", "All sizes of tables"]}, "correct_response": ["c"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "What sized tables will experience the most benefit from clustering?", "related_lectures": []}, {"_class": "assessment", "id": 58447052, "assessment_type": "multiple-choice", "prompt": {"question": "<p>John has a SECURITYADMIN role. He created a custom DBA_ROLE and granted the SYSADMIN role to DBA_ROLE. Then, John created a user, 'Monica.' John then granted DBA_ROLE to Monica. Monica creates a Database Monica_DB. Monica then created a Table T1 in Monica_DB under the PUBLIC schema. What should John do to access Table T1, created by Monica?</p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p><strong>It does not matter if John has created the DBA_ROLE. If John wants to access the object created by DBA_ROLE, he needs to grant DBA_ROLE to himself.</strong></p>", "answers": ["USE ROLE dba_role;\nUSE DATABASE monica_db;\nSelect * from t1;", "USE ROLE SECURITYADMIN;\nUSE DATABASE monica_db;\nSelect * from t1;\n", "GRANT ROLE DBA_ROLE TO John;\nUSE DATABASE monica_db;\nSelect * from t1;\n", "GRANT ROLE DBA_ROLE TO John;\nUSE ROLE DBA_ROLE;\nUSE DATABASE monica_db;\nSelect * from t1;"]}, "correct_response": ["d"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "John has a SECURITYADMIN role. He created a custom DBA_ROLE and granted the SYSADMIN role to DBA_ROLE. Then, John created a user, 'Monica.' John then granted DBA_ROLE to Monica. Monica creates a Database Monica_DB. Monica then created a Table T1 in Monica_DB under the PUBLIC schema. What should John do to access Table T1, created by Monica?", "related_lectures": []}, {"_class": "assessment", "id": 58447054, "assessment_type": "multiple-choice", "prompt": {"question": "User-managed Tasks is recommended when you can fully utilize a single warehouse by scheduling multiple concurrent tasks to take advantage of available compute resources. (True /False)", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "<p><strong>User-managed Tasks</strong> is recommended when you <strong>can fully utilize a single warehouse</strong> by scheduling multiple concurrent tasks to take advantage of available compute resources.\n</p><p><strong>Serverless Tasks</strong> is recommended when you <strong>cannot fully utilize a warehouse </strong>because too few tasks run concurrently or they run to completion quickly (in less than 1 minute).</p>", "answers": ["TRUE", "FALSE"]}, "correct_response": ["a"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "User-managed Tasks is recommended when you can fully utilize a single warehouse by scheduling multiple concurrent tasks to take advantage of available compute resources. (True /False)", "related_lectures": []}, {"_class": "assessment", "id": 58447056, "assessment_type": "multiple-choice", "prompt": {"question": "Which of the following is not a type of Snowflake&#39;s Internal stage?", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>An internal stage is a cloud repository that resides within a Snowflake account and is managed by Snowflake. An external stage is a pointer to a cloud file repository outside a Snowflake account, which the customer manages independently. </p><p><strong>There are three types of stages, and they are table stage, user stage, and named stage.&nbsp; </strong> </p><p><br></p><p><strong>Table Stage: </strong>When you create a table, the system will create a table stage with the same name but with the prefix @%.&nbsp; </p><p><br></p><p><strong>User Stage:</strong> A user stage is created whenever you create a new user in Snowflake. The user stage uses the @~.&nbsp; </p><p><br></p><p><strong>Named Stage:</strong> Named stages are created manually. They can be internal or external and are prefixed with an @ and then the stage's name. </p><p><br></p><p><strong>[Please note, Important for the exam: Table Stage and User Stage can not be dropped.]</strong></p>", "answers": ["User Stage", "Table Stage", "Schema Stage", "Name Stage"]}, "correct_response": ["c"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "Which of the following is not a type of Snowflake&#39;s Internal stage?", "related_lectures": []}, {"_class": "assessment", "id": 58447058, "assessment_type": "multi-select", "prompt": {"question": "Which products does Snowflake offer for secure data sharing? (Select 3)", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p><strong>Snowflake provides three product offerings for data sharing that utilize Snowflake Secure Data Sharing to connect providers of data with consumers.\n</strong>\n<strong>Direct Share:</strong> It is the simplest form of data sharing that enables account-to-account sharing of data utilizing Snowflake\u2019s Secure Data Sharing. As a data provider, you can easily share data with another company so that your data shows up in their Snowflake account without having to copy it over or move it.&nbsp; </p><p><br></p><p><strong>Data Exchange: </strong>With a Snowflake data exchange, you actually set up a private exchange between partners that you want to have in this exchange, and any member of that exchange can share data in this private exchange. And any member of the exchange can also consume data from that exchange. So instead of one-to-one or one-to-many, it's many-to-many. But it's a very exclusive club. Only people who are invited into this exchange can access any of that data. </p><p><br></p><p><strong>Data Marketplace: </strong>The Snowflake Data Marketplace is where companies can publish their data to be consumed by anybody who has a Snowflake account and wants to connect to the marketplace and download that data.</p>", "answers": ["Direct share", "Indirect share", "Data Exchange", "Data Marketplace", "Data Replication"]}, "correct_response": ["a", "c", "d"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "Which products does Snowflake offer for secure data sharing? (Select 3)", "related_lectures": []}, {"_class": "assessment", "id": 58447060, "assessment_type": "multi-select", "prompt": {"question": "Which of these are types of Snowflake releases? (Select 3)", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p><strong>There are three types of releases:</strong>\n</p><ul><li><p><strong>Full Release</strong>: A full release may include any of the following: -</p><ul><li><p>New features </p></li><li><p>Feature enhancements or updates </p></li><li><p>Fixes&nbsp; </p></li></ul></li><li><p><strong>Patch Release</strong>: A patch release includes fixes only.&nbsp; </p></li><li><p><strong>Behavior Release</strong>: Every month, Snowflake deploys one behavior change release. Behavior change releases contain changes to existing behaviors that may impact customers. </p></li></ul>", "answers": ["Full Release", "Part Release", "Patch Release", "Behavior Change Release", "Bug Fix Release"]}, "correct_response": ["a", "c", "d"], "section": "", "question_plain": "Which of these are types of Snowflake releases? (Select 3)", "related_lectures": []}, {"_class": "assessment", "id": 58447062, "assessment_type": "multiple-choice", "prompt": {"question": "Which one is not the Snowflake System-Defined role?", "relatedLectureIds": "", "feedbacks": ["", "", "", "", "", ""], "explanation": "The following are the Snowflake System-Defined roles:\nORGADMIN, ACCOUTADMIN, SECURITYADMIN, USERADMIN, SYSADMIN, PUBLIC. \nSystem-defined roles cannot be dropped. In addition, the privileges granted to these roles by Snowflake cannot be revoked.", "answers": ["ORGADMIN", "ACCOUNTADMIN", "DATABASEADMIN", "SECURITYADMIN", "USERADMIN", "SYSADMIN"]}, "correct_response": ["c"], "section": "Account Access & Security", "question_plain": "Which one is not the Snowflake System-Defined role?", "related_lectures": []}, {"_class": "assessment", "id": 58447064, "assessment_type": "multiple-choice", "prompt": {"question": "Which of these roles is granted the MANAGE GRANTS security privilege to be able to modify any grant globally, including revoking it?", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p><strong>SECURITYADMIN role can manage any object grant globally, as well as create, monitor, and manage users and roles.</strong> </p><p>More specifically, this role: </p><ul><li><p>Is granted the MANAGE GRANTS security privilege to be able to modify any grant, including revoking it. </p></li><li><p>Inherits the privileges of the USERADMIN role via the system role hierarchy (i.e. USERADMIN role is granted to SECURITYADMIN).</p></li></ul>", "answers": ["ORGADMIN", "ACCOUNTADMIN", "SECURITYADMIN", "USERADMIN", "SYSADMIN"]}, "correct_response": ["c"], "section": "Account Access & Security", "question_plain": "Which of these roles is granted the MANAGE GRANTS security privilege to be able to modify any grant globally, including revoking it?", "related_lectures": []}, {"_class": "assessment", "id": 58447066, "assessment_type": "multiple-choice", "prompt": {"question": "ACCOUNTADMIN role should not be used to create objects in Snowflake?(True/False)", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "<p><strong>The ACOOUNTADMIN role is intended for performing initial setup tasks in the system and managing account-level objects and tasks on a day-to-day basis.</strong> It should not be used to create objects in your account unless you absolutely need these objects to have the highest level of secure access.</p>", "answers": ["TRUE", "FALSE"]}, "correct_response": ["a"], "section": "Account Access & Security", "question_plain": "ACCOUNTADMIN role should not be used to create objects in Snowflake?(True/False)", "related_lectures": []}, {"_class": "assessment", "id": 58447068, "assessment_type": "multi-select", "prompt": {"question": "<p>Which of these roles can configure a network policy? (Select 2)</p>", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p>Only <strong>security administrators (i.e., users with the SECURITYADMIN role) or higher </strong>or a role with the global CREATE NETWORK POLICY privilege can create network policies.</p>", "answers": ["ACCOUNTADMIN", "SYSADMIN", "USERADMIN", "SECURITYADMIN", "PUBLIC"]}, "correct_response": ["a", "d"], "section": "Account Access & Security", "question_plain": "Which of these roles can configure a network policy? (Select 2)", "related_lectures": []}, {"_class": "assessment", "id": 58447070, "assessment_type": "multiple-choice", "prompt": {"question": "<p>You can create a user-level network policy using _____</p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p><strong>You can set a policy at the user level, but this can only be done through the SQL commands. </strong></p><p>To activate a network policy for an individual user, set the NETWORK_POLICY parameter for the user using ALTER USER.</p>", "answers": ["Snowsight", "Only Snowflake Support can create the Account level Network Policy", "SQL", "Classic Web Interface"]}, "correct_response": ["c"], "section": "Account Access & Security", "question_plain": "You can create a user-level network policy using _____", "related_lectures": []}, {"_class": "assessment", "id": 58447072, "assessment_type": "multi-select", "prompt": {"question": "Which are the required parameters for creating a Network Policy? (Select 2)", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p><strong>Policy Name and Allowed IP Addresses are mandatory for creating a Network Policy. </strong></p><p>Blocked IP Addresses and Comment Parameters are optional.\n</p><p><strong>Please Note -</strong><em> If you provide both Allowed IP Addresses and Blocked IP Addresses, Snowflake applies the Blocked List first.</em></p>", "answers": ["Policy Name", "Allowed IP Addresses", "Blocked IP Addresses", "Comment"]}, "correct_response": ["a", "b"], "section": "Account Access & Security", "question_plain": "Which are the required parameters for creating a Network Policy? (Select 2)", "related_lectures": []}, {"_class": "assessment", "id": 58447074, "assessment_type": "multiple-choice", "prompt": {"question": "<p>Snowflake network policies currently support both Internet Protocol versions 4 and 6 (i.e., IPv4 as well as IPv6). (True/False)</p>", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "Network policies currently support only Internet Protocol version 4 (i.e. IPv4) addresses.", "answers": ["TRUE", "FALSE"]}, "correct_response": ["b"], "section": "Account Access & Security", "question_plain": "Snowflake network policies currently support both Internet Protocol versions 4 and 6 (i.e., IPv4 as well as IPv6). (True/False)", "related_lectures": []}, {"_class": "assessment", "id": 58447076, "assessment_type": "multiple-choice", "prompt": {"question": "In a Snowflake federated environment, Snowflake serves as the Identity provider (IdP). (True/False)", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "<p><strong>In a Snowflake federated environment, Snowflake serves as the Service Provider (SP).</strong> The external, independent entity like Okta serves as the Identify Provider (IdP)</p>", "answers": ["TRUE", "FALSE"]}, "correct_response": ["b"], "section": "Account Access & Security", "question_plain": "In a Snowflake federated environment, Snowflake serves as the Identity provider (IdP). (True/False)", "related_lectures": []}, {"_class": "assessment", "id": 58447078, "assessment_type": "multiple-choice", "prompt": {"question": "Is it possible to create a user without a password?", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "Yes, it is possible to create a user in Snowflake without a password. We cannot use the Snowflake web interface to create users with no passwords or remove passwords from existing users, and we must use CREATE USER or ALTER USER. Without a password in Snowflake, a user cannot log in using Snowflake authentication and must use federated authentication instead.", "answers": ["Yes", "No"]}, "correct_response": ["a"], "section": "Account Access & Security", "question_plain": "Is it possible to create a user without a password?", "related_lectures": []}, {"_class": "assessment", "id": 58447080, "assessment_type": "multi-select", "prompt": {"question": "<p>Snowflake\u2019s approach to access control combines aspects from which of the following models?(Select 2)</p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>Snowflake\u2019s approach to access control combines aspects from both of the following models:</p><ul><li><p><strong>Discretionary Access Control (DAC):</strong> Each object has an owner, who can in turn grant access to that object.&nbsp; &nbsp;</p></li><li><p><strong>Role-based Access Control (RBAC):</strong> Access privileges are assigned to roles, which are in turn assigned to users.</p></li></ul>", "answers": ["Rule-based access control (RBAC)", "Role-based Access Control (RBAC)", "Discretionary Access Control (DAC)", "Mandatory Access Control (MAC)"]}, "correct_response": ["b", "c"], "section": "Account Access & Security", "question_plain": "Snowflake\u2019s approach to access control combines aspects from which of the following models?(Select 2)", "related_lectures": []}, {"_class": "assessment", "id": 58447082, "assessment_type": "multiple-choice", "prompt": {"question": "A DBA_ROLE created a database. Later the DBA_ROLE was dropped. Who will own the database now, which was created by the DBA_ROLE?\t", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>The role that dropped the DBA_ROLE will own the database. It is an important question for the exam.\t </p>", "answers": ["The database will get dropped too.", "No one will be able to access the database.", "The role that dropped the DBA_ROLE will own the database.", "The DBA_ROLE can&#39;t get dropped as it is the database owner."]}, "correct_response": ["c"], "section": "Account Access & Security", "question_plain": "A DBA_ROLE created a database. Later the DBA_ROLE was dropped. Who will own the database now, which was created by the DBA_ROLE?", "related_lectures": []}, {"_class": "assessment", "id": 58447084, "assessment_type": "multiple-choice", "prompt": {"question": "A role inherits all the privileges of those higher in the hierarchy. (True / False)", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "<p><strong>A role inherits all the privileges of its underlying roles (those \"lower\" in the hierarchy). </strong> </p><ul><li><p>ACOOUNTADMIN inherits privileges from SECURITYADMIN</p></li><li><p>USERADMIN, SYSADMIN, and PUBLIC.&nbsp; </p></li><li><p>SECURITYADMIN inherits privileges from USERADMIN and PUBLIC.&nbsp; </p></li><li><p>USERADMIN and SYSADMIN inherit privileges from PUBLIC&nbsp; </p></li><li><p>PUBLIC inherits nothing.</p></li></ul>", "answers": ["TRUE", "FALSE"]}, "correct_response": ["b"], "section": "Account Access & Security", "question_plain": "A role inherits all the privileges of those higher in the hierarchy. (True / False)", "related_lectures": []}, {"_class": "assessment", "id": 58447086, "assessment_type": "multi-select", "prompt": {"question": "<p>What are the security layers that Snowflake takes care of?(Select 4)</p>", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p><strong>Infrastructure Security is managed by the cloud provider. </strong></p>", "answers": ["Access", "Authentication", "Authorization", "Data Protection", "Infrastructure"]}, "correct_response": ["a", "b", "c", "d"], "section": "Account Access & Security", "question_plain": "What are the security layers that Snowflake takes care of?(Select 4)", "related_lectures": []}, {"_class": "assessment", "id": 58447088, "assessment_type": "multiple-choice", "prompt": {"question": "How can you create a &quot;Super-User&quot; or &quot;Super-Role&quot; in Snowflake who can bypass all the authorization checks?", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p><strong>There is no concept of a \u201csuper-user\u201d or \u201csuper-role\u201d in Snowflake that can bypass authorization checks.</strong> All-access requires appropriate access privileges.&nbsp; </p>", "answers": ["ACCOUNTADMIN role is same as Super-Role", "CREATE ROLE SUPER_ROLE;", "Contact Snowflake personnel to create a Super-Role or Super-User for your account", "There is no concept of SUPER-ROLE or SUPER-USER in Snowflake"]}, "correct_response": ["d"], "section": "Account Access & Security", "question_plain": "How can you create a &quot;Super-User&quot; or &quot;Super-Role&quot; in Snowflake who can bypass all the authorization checks?", "related_lectures": []}, {"_class": "assessment", "id": 58447090, "assessment_type": "multi-select", "prompt": {"question": "<p>Federated Authentication is supported by the following:</p><p>(Select all that apply)</p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p><strong>Federated authentication is supported by all of the Snowflake editions.</strong></p>", "answers": ["Standard Edition", "Enterprise Edition", "Business Critical", "VPS"]}, "correct_response": ["a", "b", "c", "d"], "section": "Account Access & Security", "question_plain": "Federated Authentication is supported by the following:(Select all that apply)", "related_lectures": []}, {"_class": "assessment", "id": 58447092, "assessment_type": "multiple-choice", "prompt": {"question": "Which type of object key is only used for decryption?", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p><strong>Retired Key is used for decryption only.</strong></p><p>Active Key is used for both encryption and decryption.&nbsp; &nbsp;</p><p>Destroyed Key is no longer used.</p>", "answers": ["Active key", "Retired Key", "Destroyed key", "None of these"]}, "correct_response": ["b"], "section": "Account Access & Security", "question_plain": "Which type of object key is only used for decryption?", "related_lectures": []}, {"_class": "assessment", "id": 58447094, "assessment_type": "multiple-choice", "prompt": {"question": "Which AWS service is used to create private VPC endpoints that allow direct, secure connectivity between your AWS VPCs and the Snowflake VPC without traversing the public internet?", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p><strong>AWS PrivateLink</strong> is an AWS service for creating private VPC endpoints that allow direct, secure connectivity between your AWS VPCs and the Snowflake VPC without traversing the public internet. The connectivity is for AWS VPCs in the same AWS region.\n</p><p>For External Functions, you can also use AWS PrivateLink with private endpoints.\n</p><p>In addition, if you have an on-premises environment (e.g. a non-hosted data center), you can choose to use AWS Direct Connect, in conjunction with AWS PrivateLink, to connect all your virtual and physical environments in a single, private network.</p>", "answers": ["AWS Direct Connect", "AWS PrivateVPC", "AWS PrivateLink", "Snowflake PrivateLink"]}, "correct_response": ["c"], "section": "Account Access & Security", "question_plain": "Which AWS service is used to create private VPC endpoints that allow direct, secure connectivity between your AWS VPCs and the Snowflake VPC without traversing the public internet?", "related_lectures": []}, {"_class": "assessment", "id": 58447096, "assessment_type": "multi-select", "prompt": {"question": "Which of these objects are not replicated? (Select 2)", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p><strong>Temporary Tables, External Tables, Stages, Temporary Stages, Streams, and Tasks do not get replicated.</strong></p>", "answers": ["Permanent Tables", "Transient Tables", "Temporary Tables", "External Tables", "Views"]}, "correct_response": ["c", "d"], "section": "Account Access & Security", "question_plain": "Which of these objects are not replicated? (Select 2)", "related_lectures": []}, {"_class": "assessment", "id": 58447098, "assessment_type": "multi-select", "prompt": {"question": "Choose the true statements about Secure views. (Select 2)", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p><strong>Both non-materialized and materialized views can be defined as secure. Secure views have advantages over standard views, including improved data privacy and data sharing;</strong> however, they also have some performance impacts to take into consideration.</p>", "answers": ["Secure views provide improved data privacy and data sharing", "Secure views allow faster access than Standard views", "Only materialized views can be defined as secure", "Only non-materialized views can be defined as secure", "Both non-materialized and materialized views can be defined as secure"]}, "correct_response": ["a", "e"], "section": "Account Access & Security", "question_plain": "Choose the true statements about Secure views. (Select 2)", "related_lectures": []}, {"_class": "assessment", "id": 58447100, "assessment_type": "multiple-choice", "prompt": {"question": "Which privilege is required to execute queries using a virtual warehouse?", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p><strong>Virtual Warehouse Privileges:</strong>\n\n<strong>USAGE: </strong>Enables using a virtual warehouse and, as a result, executing queries on the warehouse. If the warehouse is configured to auto-resume when a SQL statement (e.g. query) is submitted to it, the warehouse resumes automatically and executes the statement.</p><p><strong>MODIFY: </strong> Enables altering any properties of a warehouse, including changing its size.&nbsp; &nbsp;Required assigning a warehouse to a resource monitor. Note that only the ACCOUNTADMIN role can assign warehouses to resource monitors. \t&nbsp; </p><p><strong>MONITOR: </strong>Enables viewing of current and past queries executed on a warehouse as well as usage statistics on that warehouse. \t&nbsp; </p><p><strong>OPERATE: </strong>Enables changing the state of a warehouse (stop, start, suspend, resume). In addition, enables viewing current and past queries executed on a warehouse and aborting any executing queries. \t&nbsp; &nbsp;</p><p><strong> OWNERSHIP: </strong>Grants full control over a warehouse. Only a single role can hold this privilege on a specific object at a time.</p>", "answers": ["USAGE", "MODIFY", "MONITOR", "OPERATE"]}, "correct_response": ["a"], "section": "Account Access & Security", "question_plain": "Which privilege is required to execute queries using a virtual warehouse?", "related_lectures": []}, {"_class": "assessment", "id": 58447102, "assessment_type": "multiple-choice", "prompt": {"question": "Snowflake prunes micro-partitions based on a predicate with a subquery, even if the subquery result is constant. (TRUE/FALSE)", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "Please note, not all predicate expressions can be used to prune. Snowflake does not prune micro-partitions based on a predicate with a subquery, even if the subquery results in a constant.", "answers": ["TRUE", "FALSE"]}, "correct_response": ["b"], "section": "Performance Concepts", "question_plain": "Snowflake prunes micro-partitions based on a predicate with a subquery, even if the subquery result is constant. (TRUE/FALSE)", "related_lectures": []}, {"_class": "assessment", "id": 58447168, "assessment_type": "multiple-choice", "prompt": {"question": "What value will be return by the following query?\n\nSELECT * FROM TABLE(FLATTEN(input =&gt; parse_json(&#39;[]&#39;), outer =&gt; true)) f;\n\n", "answers": ["0", "[]", "NULL"], "explanation": "The OUTER =&gt; TRUE argument with FLATTEN generates exactly one row for zero-row expansions (with NULL in the KEY, INDEX, and VALUE columns)."}, "correct_response": ["c"], "section": "Data Transformation", "question_plain": "What value will be return by the following query?\n\nSELECT * FROM TABLE(FLATTEN(input =&gt; parse_json(&#39;[]&#39;), outer =&gt; true)) f;", "related_lectures": []}, {"_class": "assessment", "id": 58447170, "assessment_type": "multiple-choice", "prompt": {"question": "VARIANT is used to FLATTEN hierarchical data. (True / False)", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "<p><strong>VARIANT is a data type that can hold a value of any other data type</strong> (including ARRAY and OBJECT). VARIANT is used to build and store hierarchical data. VARIANT is not a function to FLATTEN. \n\n<strong>FLATTEN is a table function</strong> that is used to produce a lateral view of a VARIANT, OBJECT, or ARRAY column.</p>", "answers": ["TRUE", "FALSE"]}, "correct_response": ["b"], "section": "Data Transformation", "question_plain": "VARIANT is used to FLATTEN hierarchical data. (True / False)", "related_lectures": []}, {"_class": "assessment", "id": 58447172, "assessment_type": "multiple-choice", "prompt": {"question": "Snowflake supports various actions for Unstructured Data. Which one is not supported by Snowflake?", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>Snowflake supports the following actions for Unstructured data: </p><ul><li><p>Securely access data files located in cloud storage. </p></li><li><p>Share file access URLs with collaborators and partners. </p></li><li><p>Load file access URLs and other file metadata into Snowflake tables.</p></li></ul>", "answers": ["Extract actual data from PDF and load it into Snowflake tables using Snowflake WebUI out of the box option.", "Load file access URLs and other file metadata into Snowflake tables.", "Share file access URLs with collaborators and partners.", "Securely access data files located in cloud storage."]}, "correct_response": ["a"], "section": "Data Transformation", "question_plain": "Snowflake supports various actions for Unstructured Data. Which one is not supported by Snowflake?", "related_lectures": []}, {"_class": "assessment", "id": 58447174, "assessment_type": "multiple-choice", "prompt": {"question": "Which of these SQL functions helps generate the Scoped URL to access the unstructured data file?", "relatedLectureIds": "", "feedbacks": ["", "", "", "", "", ""], "explanation": "<p><strong>BUILD_SCOPED_FILE_URL generates a scoped Snowflake-hosted URL</strong> to a staged file using the stage name and relative file path as inputs. A scoped URL is encoded and permits access to a specified file for a limited period of time.\n\nScoped URL: Encoded URL that permits temporary access to a staged file without granting privileges to the stage. The URL expires when the persisted query result period ends (i.e., the results cache expires), which is currently 24 hours.\n</p>", "answers": ["BUILD_SCOPED_FILE_URL", "GET_STAGE_LOCATION", "GET_RELATIVE_PATH", "BUILD_STAGE_FILE_URI", "GET_PRESIGNED_URL", "GET_ABSOLUTE_PATH"]}, "correct_response": ["a"], "section": "Data Transformation", "question_plain": "Which of these SQL functions helps generate the Scoped URL to access the unstructured data file?", "related_lectures": []}, {"_class": "assessment", "id": 58447176, "assessment_type": "multiple-choice", "prompt": {"question": "Which of these SQL functions helps extract the path of a staged file relative to its location in the stage using the stage name and absolute file path in cloud storage as inputs?", "relatedLectureIds": "", "feedbacks": ["", "", "", "", "", ""], "explanation": "<p><strong>GET_RELATIVE_PATH extracts the path of a staged file relative to its location in the stage using the stage name and absolute file path in cloud storage as inputs.</strong></p>", "answers": ["BUILD_SCOPED_FILE_URL", "GET_STAGE_LOCATION", "GET_RELATIVE_PATH", "BUILD_STAGE_FILE_URI", "GET_PRESIGNED_URL", "GET_ABSOLUTE_PATH"]}, "correct_response": ["c"], "section": "Data Transformation", "question_plain": "Which of these SQL functions helps extract the path of a staged file relative to its location in the stage using the stage name and absolute file path in cloud storage as inputs?", "related_lectures": []}, {"_class": "assessment", "id": 58447178, "assessment_type": "multiple-choice", "prompt": {"question": "A\u00a0Directory table\u00a0is a separate database object that stores a catalog of staged files in cloud storage. (True/False)", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "<p>\n<strong>A Directory table is not a separate database object;</strong> it stores a catalog of staged files in cloud storage. Roles with sufficient privileges can query a directory table to retrieve file URLs to access the staged files and other metadata.</p>", "answers": ["TRUE", "FALSE"]}, "correct_response": ["b"], "section": "Data Transformation", "question_plain": "A\u00a0Directory table\u00a0is a separate database object that stores a catalog of staged files in cloud storage. (True/False)", "related_lectures": []}, {"_class": "assessment", "id": 58447180, "assessment_type": "multiple-choice", "prompt": {"question": "The automatic refresh of metadata of the directory table in the cloud storage does not incur any charges to Snowflake Customers. (True/False)", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "<p><strong>Snowflake customers' charges include an overhead to manage event notifications for automatically refreshing directory table metadata.</strong> This overhead increases in relation to the number of files added in cloud storage for customers' stages that include directory tables. Snowflake charges 0.06 credits per 1000 event notifications received.</p>", "answers": ["TRUE", "FALSE"]}, "correct_response": ["b"], "section": "Data Transformation", "question_plain": "The automatic refresh of metadata of the directory table in the cloud storage does not incur any charges to Snowflake Customers. (True/False)", "related_lectures": []}, {"_class": "assessment", "id": 58447182, "assessment_type": "multi-select", "prompt": {"question": "<p>What are all operations performed using Snowflake SQL API? (Select 4)</p>", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p>The Snowflake SQL API provides operations that we can use to: </p><ul><li><p>Submit SQL statements for execution. </p></li><li><p>Check the status of the execution of a statement. </p></li><li><p>Cancel the execution of a statement. </p></li><li><p>Fetch query results concurrently.&nbsp; </p><p><br></p></li></ul><p>Currently, Snowflake SQL API has limitations for the call command with stored procedures that return a table (stored procedures with the RETURNS TABLE clause).</p>", "answers": ["Submit SQL statements for execution", "Check the status of the execution of a statement", "Calling stored procedures that returns a table", "Cancel the execution of a statement", "Fetch query results concurrently"]}, "correct_response": ["a", "b", "d", "e"], "section": "Data Transformation", "question_plain": "What are all operations performed using Snowflake SQL API? (Select 4)", "related_lectures": []}, {"_class": "assessment", "id": 58447184, "assessment_type": "multiple-choice", "prompt": {"question": "An HTTP client that sends a URL (either scoped URL or file URL) to the REST API must be configured to allow redirects. (True/False)", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "True, An HTTP client that sends a URL (either scoped URL or file URL) to the REST API must be configured to allow redirects.", "answers": ["TRUE", "FALSE"]}, "correct_response": ["a"], "section": "Data Transformation", "question_plain": "An HTTP client that sends a URL (either scoped URL or file URL) to the REST API must be configured to allow redirects. (True/False)", "related_lectures": []}, {"_class": "assessment", "id": 58447186, "assessment_type": "multiple-choice", "prompt": {"question": "Scoped URL is ideal for ", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p><strong>Scoped URL:</strong> Encoded URL that permits temporary access to a staged file without granting privileges to the stage. The URL expires when the persisted query result period ends (i.e., the results cache expires), which is currently 24 hours. <strong>Ideal for use in custom applications, providing unstructured data to other accounts via a share, or for downloading and ad hoc analysis of unstructured data via Snowsight.</strong>\n\n<strong>File URL:</strong> URL that identifies the database, schema, stage, and file path to a set of files. A role that has sufficient privileges on the stage can access the files. <strong>Ideal for custom applications that require access to unstructured data files.</strong>&nbsp; </p><p><br></p><p><strong>Pre-signed URL:</strong> Simple HTTPS URL used to access a file via a web browser. A file is temporarily accessible to users via this URL using a pre-signed access token. The expiration time for the access token is configurable.<strong> Ideal for business intelligence applications or reporting tools that need to display unstructured file contents.</strong></p>", "answers": ["Ideal for custom applications that require access to unstructured data files", "Ideal for use in custom applications, providing unstructured data to other accounts via a share", "Ideal for business intelligence applications or reporting tools that need to display the unstructured file contents", "None of these"]}, "correct_response": ["b"], "section": "Data Transformation", "question_plain": "Scoped URL is ideal for", "related_lectures": []}, {"_class": "assessment", "id": 58447188, "assessment_type": "multiple-choice", "prompt": {"question": "What is the expiration period of a Scoped URL?", "relatedLectureIds": "", "feedbacks": ["", "", ""], "explanation": "<p>The expiration period of <strong>Scoped URL</strong>: The URL expires when the persisted query result period ends.\nThe expiration period of the <strong>File URL</strong>: It is permanent.\nThe expiration period of <strong>Pre-Signed URL</strong>: Length of time specified in the expiration_time argument.</p>", "answers": ["The URL expires when the persisted query result period ends", "The URL never expires. It is permanent", "Length of time specified in the expiration_time argument"]}, "correct_response": ["a"], "section": "Data Transformation", "question_plain": "What is the expiration period of a Scoped URL?", "related_lectures": []}, {"_class": "assessment", "id": 58447190, "assessment_type": "multiple-choice", "prompt": {"question": "Snowflake supports _______", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p><strong>Currently, Snowflake only supports REST API for unstructured data.</strong></p>", "answers": ["SOAP for unstructured data", "REST API for unstructured data", "Both of these", "None of these"]}, "correct_response": ["b"], "section": "Data Transformation", "question_plain": "Snowflake supports _______", "related_lectures": []}, {"_class": "assessment", "id": 58447192, "assessment_type": "multiple-choice", "prompt": {"question": "If you make any changes (e.g., insert, update) in a cloned table, then __", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>Zero-copy cloning allows us to make a snapshot of any table, schema, or database without actually copying data.\n\nA clone is writable and is independent of its source (i.e., changes made to the source or clone are not reflected in the other object).\n\nA new clone of a table points to the original table's micro partitions, using no data storage. <strong>If we make any changes in the cloned table, then only its changed micro partitions are written to storage. </strong></p>", "answers": ["The source table also gets updated with the new changes in the cloned table", "Only the changed micro partitions are written to the data storage", "The entire table is written to data storage", "Cloned tables are read-only, you can not make any changes"]}, "correct_response": ["b"], "section": "Data Protection and Data Sharing", "question_plain": "If you make any changes (e.g., insert, update) in a cloned table, then __", "related_lectures": []}, {"_class": "assessment", "id": 58447194, "assessment_type": "multiple-choice", "prompt": {"question": "In the case of cloning massive databases or schemas, the original databases and schemas get locked while the cloning operation is running. While cloning is in progress, no DML operation can be done on the original databases and schemas. (True/False)", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "<p><strong>Cloning is not instantaneous, particularly for large objects (databases, schemas, tables), and does not lock the object being cloned.</strong> A clone does not reflect any DML statements applied to table data, if applicable, while the cloning operation is still running.</p>", "answers": ["TRUE", "FALSE"]}, "correct_response": ["b"], "section": "Data Protection and Data Sharing", "question_plain": "In the case of cloning massive databases or schemas, the original databases and schemas get locked while the cloning operation is running. While cloning is in progress, no DML operation can be done on the original databases and schemas. (True/False)", "related_lectures": []}, {"_class": "assessment", "id": 58447196, "assessment_type": "multiple-choice", "prompt": {"question": "What is the default standard data retention period automatically enabled for all Snowflake accounts?", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p><strong>The standard retention period is 1 day (24 hours) and is automatically enabled for all Snowflake accounts.</strong></p>", "answers": ["30 days", "90 days", "1 day", "0 days"]}, "correct_response": ["c"], "section": "Data Protection and Data Sharing", "question_plain": "What is the default standard data retention period automatically enabled for all Snowflake accounts?", "related_lectures": []}, {"_class": "assessment", "id": 58447198, "assessment_type": "multiple-choice", "prompt": {"question": "What is the maximum data retention period for transient databases, schemas, and tables for Snowflake Enterprise Edition (and higher)?", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>For Snowflake Enterprise Edition (and higher): </p><ul><li><p><strong>For</strong> <strong>transient databases, schemas, and tables, the retention period can be set to 0</strong> (or unset back to the default of 1 day). The same is also true for temporary tables. </p></li><li><p>For permanent databases, schemas, and tables, the retention period can be set to any value from 0 up to 90 days.</p></li></ul>", "answers": ["90 days", "30 days", "1 day", "0 days"]}, "correct_response": ["c"], "section": "Data Protection and Data Sharing", "question_plain": "What is the maximum data retention period for transient databases, schemas, and tables for Snowflake Enterprise Edition (and higher)?", "related_lectures": []}, {"_class": "assessment", "id": 58447200, "assessment_type": "multiple-choice", "prompt": {"question": "\nWhich object parameter can users with the ACCOUNTADMIN role use to set the minimum retention period for their account?\t", "answers": ["DATA_RETENTION_TIME_IN_DAYS", "MIN_DATA_RETENTION_TIME_IN_HOURS", "DATA_RETENTION_TIME_IN_MIN_DAYS", "MIN_DATA_RETENTION_TIME_IN_DAYS"], "explanation": "The MIN_DATA_RETENTION_TIME_IN_DAYS account parameter can be set by users with the ACCOUNTADMIN role to set a minimum retention period for the account. This parameter does not alter or replace the DATA_RETENTION_TIME_IN_DAYS parameter value. However, it may change the effective data retention time. When this parameter is set at the account level, the effective minimum data retention period for an object is determined by MAX(DATA_RETENTION_TIME_IN_DAYS, MIN_DATA_RETENTION_TIME_IN_DAYS)."}, "correct_response": ["d"], "section": "Data Protection and Data Sharing", "question_plain": "Which object parameter can users with the ACCOUNTADMIN role use to set the minimum retention period for their account?", "related_lectures": []}, {"_class": "assessment", "id": 58447202, "assessment_type": "multiple-choice", "prompt": {"question": "<p>You have a table with a 30-day retention period. If you increase the retention period to 40 days, how would it affect the data that would have been removed after 30 days?</p>", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "<p><strong>Increasing Retention causes the data currently in Time Travel to be retained for a more extended time. </strong>For example, suppose you have a table with a 30-day retention period and increase the period to 40 days. In that case, data that would have been removed after 30 days is now retained for an additional 10 days before moving into Fail-safe.&nbsp; </p><p>Note that this does not apply to any data that is older than 30 days and has already moved into Fail-safe.</p>", "answers": ["The data will now retain an additional 10 days before moving into Fail-safe", "The data will still be moved to Fail-safe at the end of the 30-day retention period"]}, "correct_response": ["a"], "section": "Data Protection and Data Sharing", "question_plain": "You have a table with a 30-day retention period. If you increase the retention period to 40 days, how would it affect the data that would have been removed after 30 days?", "related_lectures": []}, {"_class": "assessment", "id": 58447204, "assessment_type": "multiple-choice", "prompt": {"question": "<p>Fail-safe helps access historical data after the Time Travel retention period has ended. (True/False)</p>", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "<p><strong>Fail-safe is not provided as a means for accessing historical data after the Time Travel retention period has ended. </strong>It is for use only by Snowflake to recover data that may have been lost or damaged due to extreme operational failures. Data recovery through Fail-safe may take from several hours to several days to complete.</p>", "answers": ["TRUE", "FALSE"]}, "correct_response": ["b"], "section": "Data Protection and Data Sharing", "question_plain": "Fail-safe helps access historical data after the Time Travel retention period has ended. (True/False)", "related_lectures": []}, {"_class": "assessment", "id": 58447206, "assessment_type": "multiple-choice", "prompt": {"question": "Which table function in the Snowflake Information Schema can be used to query the replication history for a specified database within a specified date range?", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>The table function <strong>REPLICATION_USAGE_HISTORY</strong> in Snowflake Information Schema <strong>can be used to query the replication history for a specified database within a specified date range.</strong> The information returned by the function includes the database name, credits consumed and bytes transferred for replication.</p>", "answers": ["DATA_TRANSFER_HISTORY", "DATABASE_REFRESH_HISTORY", "REPLICATION_GROUP_REFRESH_HISTORY", "REPLICATION_USAGE_HISTORY"]}, "correct_response": ["d"], "section": "Data Protection and Data Sharing", "question_plain": "Which table function in the Snowflake Information Schema can be used to query the replication history for a specified database within a specified date range?", "related_lectures": []}, {"_class": "assessment", "id": 58447208, "assessment_type": "multi-select", "prompt": {"question": "What actions can a consumer perform on a share? (Select 2)", "relatedLectureIds": "", "feedbacks": ["", "", "", "", "", ""], "explanation": "<p><strong>Shared databases are read-only. </strong>A consumer cannot UPDATE a share. However, <strong>the consumer can do a CREATE TABLE AS to make a point-in-time copy of the data that's been shared.</strong> The consumer cannot clone and re-share a share or forward it. And also, time travel data on a share is not available to the consumer. A share can be imported into one database.</p><p><br></p><p><strong>Note: </strong>In the exam, you may be asked for Reader Account as well.</p>", "answers": ["Clone a share", "Import the same share to more than one database", "Copy shared data into another table in their own account with CREATE TABLE AS", "Execute Time Travel on a share", "Query the shared data and join it with an existing table in their own account", "Re-share the share"]}, "correct_response": ["c", "e"], "section": "Data Protection and Data Sharing", "question_plain": "What actions can a consumer perform on a share? (Select 2)", "related_lectures": []}, {"_class": "assessment", "id": 58447210, "assessment_type": "multiple-choice", "prompt": {"question": "Direct data sharing can only be done with accounts in the same region and the same cloud provider. (TRUE/FALSE)", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "<p><strong>Direct data sharing can only be done with accounts in the same region and the same cloud provider.</strong> Suppose you want to share with someone outside of your region. In that case, you simply do a replication of that database into the region you want to share with and share from there.</p>", "answers": ["TRUE", "FALSE"]}, "correct_response": ["a"], "section": "Data Protection and Data Sharing", "question_plain": "Direct data sharing can only be done with accounts in the same region and the same cloud provider. (TRUE/FALSE)", "related_lectures": []}]}
5053376
~~~
{"count": 105, "next": null, "previous": null, "results": [{"_class": "assessment", "id": 58447224, "assessment_type": "multiple-choice", "prompt": {"question": "Micro-partitioning is the on-demand feature of Snowflake. It is required to be enabled explicitly by ACCOUNTADMIN. (True / False)", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "Micro-partitioning is automatically performed on all Snowflake tables. Tables are transparently partitioned using the Ordering of the data as inserted or loaded.", "answers": ["TRUE", "FALSE"]}, "correct_response": ["b"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "Micro-partitioning is the on-demand feature of Snowflake. It is required to be enabled explicitly by ACCOUNTADMIN. (True / False)", "related_lectures": []}, {"_class": "assessment", "id": 58447226, "assessment_type": "multiple-choice", "prompt": {"question": "How much uncompressed data does a micro-partition contain in Snowflake?", "answers": ["Between 5 MB to 50 MB", "Between 1 MB to 100 MB", "Between 50 MB to 500 MB", "Between 1 GB to 10 GB"], "explanation": "Each micro-partition contains between 50 MB and 500 MB of uncompressed data (Note that the actual size in Snowflake is smaller because data is always stored compressed.). Groups of rows in tables are mapped into individual micro-partitions, organized in a columnar fashion. This size between 50 MB and 500 MB, and the structure allows for extremely granular pruning of very large tables, which can be comprised of millions, or even hundreds of millions, of micro-partitions. It enables extremely efficient DML and fine-grained pruning for faster queries."}, "correct_response": ["c"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "How much uncompressed data does a micro-partition contain in Snowflake?", "related_lectures": []}, {"_class": "assessment", "id": 58447228, "assessment_type": "multiple-choice", "prompt": {"question": "If the micro-partitions are constant, how much is the Clustering Overlap Depth?", "answers": ["2", "20", "1", "10", "0"], "explanation": "When there is no overlap in the range of values across all micro-partitions, the micro-partitions are considered to be in a constant state (i.e. they cannot be improved by clustering). "}, "correct_response": ["c"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "If the micro-partitions are constant, how much is the Clustering Overlap Depth?", "related_lectures": []}, {"_class": "assessment", "id": 58447230, "assessment_type": "multi-select", "prompt": {"question": "Which systems function can help find the overlap depth of a table&#39;s micro-partitions?", "answers": ["SYSTEM$CLUSTERING_INFORMATION", "SYSTEM$CLUSTERING_DEPTH", "SYSTEM$CLUSTERING_INFO", "SYSTEM$CLUSTERING_WEIGHT", "SYSTEM$CLUSTERING_ALL"], "explanation": "For example, if you have an EMPLOYEE table - you can run any of these queries to find the depth - \n SELECT SYSTEM$CLUSTERING_INFORMATION(&#39;EMPLOYEE&#39;); \n SELECT SYSTEM$CLUSTERING_DEPTH(&#39;EMPLOYEE&#39;);"}, "correct_response": ["a", "b"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "Which systems function can help find the overlap depth of a table&#39;s micro-partitions?", "related_lectures": []}, {"_class": "assessment", "id": 58447232, "assessment_type": "multi-select", "prompt": {"question": "While choosing the clustering key, what should we consider? (Select 3)", "answers": ["Columns which are more often used in join conditions", "Columns which are more often used in where clause", "Ordering the columns from lowest cardinality to highest cardinality", "Ordering the columns from highest cardinality to lowest cardinality", "Columns which are more less used in join conditions", "Columns which are less often used in where clause"], "explanation": "Best Practices for choosing clustering key:\n 1.\tColumns which are more often used in where clause\n 2.\tColumns that are more often used in join conditions\n 3.\tOrder you specify the clustering key is important. As a general rule, Snowflake recommends ordering the lowest to highest cardinality columns."}, "correct_response": ["a", "b", "c"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "While choosing the clustering key, what should we consider? (Select 3)", "related_lectures": []}, {"_class": "assessment", "id": 58447234, "assessment_type": "multi-select", "prompt": {"question": "<p>Snowflake stores metadata about all rows stored in a micro-partition, including (Select 3)</p>", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p>Micro-partitioning is automatically performed on all Snowflake tables. Tables are transparently partitioned using the Ordering of the data as inserted/loaded.</p><p> Snowflake stores metadata about all rows stored in a micro-partition, including:</p><ul><li><p> The range of values for each of the columns in the micro-partition. </p></li><li><p>The number of distinct values.&nbsp; </p></li><li><p>Additional properties used for both optimization and efficient query processing.</p></li></ul>", "answers": ["The range of values for each of the columns in the micro-partition", "The number of distinct values", "Additional properties used for both optimization and efficient query processing", "The number of similar values", "The range of values for the first column in the micro-partition"]}, "correct_response": ["a", "b", "c"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "Snowflake stores metadata about all rows stored in a micro-partition, including (Select 3)", "related_lectures": []}, {"_class": "assessment", "id": 58447236, "assessment_type": "multi-select", "prompt": {"question": "Select the correct statements for Table Clustering. (Select 3)", "answers": ["Clustering keys are not for every table", "Snowflake doesn\u2019t charge for Reclustering", "Automatic Clustering doesn\u2019t consume credit", "Tables in multi-terabytes range are good candidate for clustering keys", "Automatic clustering can not be suspended or resumed", "Snowflake recommends a maximum of three or four columns (or expressions) per key"], "explanation": "Clustering keys are not for every table. Tables in the multi-terabyte range are good candidates for clustering keys. Both automatic clustering and reclustering consume credit. A single clustering key can contain one or more columns or expressions. Snowflake recommends a maximum of three or four columns (or expressions) per key for most tables. Adding more than 3-4 columns tends to increase costs more than benefits."}, "correct_response": ["a", "d", "f"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "Select the correct statements for Table Clustering. (Select 3)", "related_lectures": []}, {"_class": "assessment", "id": 58447238, "assessment_type": "multiple-choice", "prompt": {"question": "Which command can be used to suspend Automatic Clustering for a table?", "answers": ["ALTER TABLE", "STOP TABLE", "DROP CLUSTERING", "SUSPEND RECLUSTER"], "explanation": "Example - ALTER TABLE EMPLOYEE SUSPEND RECLUSTER; please note, SUSPEND RECLUSTER is a clause here, not a command."}, "correct_response": ["a"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "Which command can be used to suspend Automatic Clustering for a table?", "related_lectures": []}, {"_class": "assessment", "id": 58447240, "assessment_type": "multiple-choice", "prompt": {"question": "Which command can be used to resume Automatic Clustering for a table?", "answers": ["ALTER TABLE", "START TABLE", "TRIGGER CLUSTERING", "RESUME RECLUSTER"], "explanation": "Example - ALTER TABLE EMPLOYEE RESUME RECLUSTER; please note that RESUME RECLUSTER is a clause, not a command."}, "correct_response": ["a"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "Which command can be used to resume Automatic Clustering for a table?", "related_lectures": []}, {"_class": "assessment", "id": 58447242, "assessment_type": "multi-select", "prompt": {"question": "<p>How can an ACCOUNTADMIN view the billing for Automatic Clustering? (Select all that apply)</p>", "relatedLectureIds": "", "feedbacks": ["", "", "", "", "", ""], "explanation": "<p>Users with the ACCOUNTADMIN role can view the billing for Automatic Clustering using Snowsight, the classic web interface, or SQL:&nbsp; </p><p><strong>Snowsight:</strong> Select Admin \u00bb Usage.&nbsp; </p><p><strong>Classic Web Interface:</strong> Click on Account tab \u00bb Billing &amp; Usage </p><p>The billing for Automatic Clustering shows up as a separate Snowflake-provided warehouse named AUTOMATIC_CLUSTERING.&nbsp; </p><p><strong>SQL</strong>:Query either of the following: AUTOMATIC_CLUSTERING_HISTORY table function (in the Snowflake Information Schema). AUTOMATIC_CLUSTERING_HISTORY View (in Account Usage).</p>", "answers": ["Snowsight: Select Admin &gt; Usage", "Classic Web Interface: Click on Account &gt; Billing &amp; Usage under warehouse named &#39;AUTOMATIC_CLUSTERING&#39;", "Query - AUTOMATIC_CLUSTERING_HISTORY table function (in the Snowflake Information Schema)", "Classic Web Interface: Click on Account &gt; Billing &amp; Usage under storage named &#39;AUTOMATIC_CLUSTERING&#39;", "There is no way to check the Automatic Clustering billing without contacting Snowflake Support Team", "Query - AUTOMATIC_CLUSTERING_HISTORY View (in Account Usage)"]}, "correct_response": ["a", "b", "c", "f"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "How can an ACCOUNTADMIN view the billing for Automatic Clustering? (Select all that apply)", "related_lectures": []}, {"_class": "assessment", "id": 58447244, "assessment_type": "multiple-choice", "prompt": {"question": "Snowflake architecture is", "answers": ["Shared-disk architecture", "Shared-nothing architecture", "Hybrid of Shared-disk and Shared-nothing database architectures", "None of these"], "explanation": "Snowflake\u2019s architecture is a hybrid of traditional shared-disk and shared-nothing database architectures. Like shared-disk architectures, Snowflake uses a central data repository for persisted data accessible from all compute nodes in the platform. But similar to shared-nothing architectures, Snowflake processes queries using MPP (massively parallel processing) compute clusters where each node in the cluster stores a portion of the entire data set locally. This approach offers the data management simplicity of a shared-disk architecture but with the performance and scale-out benefits of a shared-nothing architecture. It is also termed as Multi-Cluster Shared Data Architecture.\t"}, "correct_response": ["c"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "Snowflake architecture is", "related_lectures": []}, {"_class": "assessment", "id": 58447246, "assessment_type": "multi-select", "prompt": {"question": "What are the three layers in Snowflake&#39;s unique architecture? (Select 3)", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>Snowflake's unique architecture consists of three key layers:&nbsp; </p><ul><li><p>Database Storage </p></li><li><p>Query Processing </p></li><li><p>Cloud Services</p></li></ul>", "answers": ["Database Storage", "Query Processing", "Cloud Services", "Computation Services"]}, "correct_response": ["a", "b", "c"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "What are the three layers in Snowflake&#39;s unique architecture? (Select 3)", "related_lectures": []}, {"_class": "assessment", "id": 58447248, "assessment_type": "multiple-choice", "prompt": {"question": "The data objects stored by Snowflake are not directly visible nor accessible by customers; they are only accessible through SQL query operations run using Snowflake. (True/False)", "answers": ["TRUE", "FALSE"], "explanation": "Snowflake manages all aspects of how this data is stored \u2014 the organization, file size, structure, compression, metadata, statistics, and other aspects of data storage are handled by Snowflake. The data objects stored by Snowflake are not directly visible nor accessible by customers; they are only accessible through SQL query operations run using Snowflake."}, "correct_response": ["a"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "The data objects stored by Snowflake are not directly visible nor accessible by customers; they are only accessible through SQL query operations run using Snowflake. (True/False)", "related_lectures": []}, {"_class": "assessment", "id": 58447250, "assessment_type": "multiple-choice", "prompt": {"question": "Snowflake stores data into its", "answers": ["internal optimized, compressed, columnar format", "internal optimized, uncompressed, columnar format", "internal optimized, compressed, row format", "internal optimized, uncompressed, row format"], "explanation": "When data is loaded into Snowflake, Snowflake reorganizes that data into its internal optimized, compressed columnar format. Snowflake stores this optimized data in cloud storage."}, "correct_response": ["a"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "Snowflake stores data into its", "related_lectures": []}, {"_class": "assessment", "id": 58447252, "assessment_type": "multiple-choice", "prompt": {"question": "In which layer does Snowflake perform query execution?", "answers": ["Cloud Services", "Query Processing", "Database Storage", "None of these"], "explanation": "Query execution is performed in the processing layer. Snowflake processes queries using \u201cvirtual warehouses.\u201d"}, "correct_response": ["b"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "In which layer does Snowflake perform query execution?", "related_lectures": []}, {"_class": "assessment", "id": 58447254, "assessment_type": "multi-select", "prompt": {"question": "Which services are managed by Snowflake&#39;s cloud services layer? (Select all that apply)", "answers": ["Authentication", "Infrastructure Management", "Metadata Management", "Query Parsing and Optimization", "Access Control", "Only Infrastructure Management"], "explanation": "The cloud services layer is a collection of services that coordinate activities across Snowflake. These services tie together all of the different components of Snowflake in order to process user requests, from login to query dispatch. \n \n The cloud service layer manages Authentication, Infrastructure Management, Metadata Management, Query parsing and optimization, and Access control services."}, "correct_response": ["a", "b", "c", "d", "e"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "Which services are managed by Snowflake&#39;s cloud services layer? (Select all that apply)", "related_lectures": []}, {"_class": "assessment", "id": 58447256, "assessment_type": "multi-select", "prompt": {"question": "Snowflake supports multiple ways of connecting to the service. (Select 3)", "answers": ["A web-based user interface", "Command line clients (e.g. SnowSQL) ", "ODBC and JDBC drivers ", "Only JDBC", "Only ODBC"], "explanation": "Snowflake supports following multiple ways of connecting to its service:\n\nA web-based user interface from which all aspects of managing and using Snowflake can be accessed.\n\nCommand line clients (e.g. SnowSQL) which can also access all aspects of managing and using Snowflake.\n\nODBC and JDBC drivers that can be used by other applications (e.g. Tableau) to connect to Snowflake.\n\nNative connectors (e.g. Python, Spark) that can be used to develop applications for connecting to Snowflake.\n\nThird-party connectors that can be used to connect applications such as ETL tools (e.g. Informatica) and BI tools (e.g. ThoughtSpot) to Snowflake."}, "correct_response": ["a", "b", "c"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "Snowflake supports multiple ways of connecting to the service. (Select 3)", "related_lectures": []}, {"_class": "assessment", "id": 58447258, "assessment_type": "multi-select", "prompt": {"question": "What are the key benefits of The Data Cloud? (Select 3)", "answers": ["Access", "Governance", "Action", "Maintenance", "Backup"], "explanation": "The benefits of The Data Cloud are Access, Governance, and Action. Access means that organizations can easily discover data and share it internally or with third parties without regard to geographical location. Governance is about setting policies and rules and protecting the data in a way that can unlock new value and collaboration while maintaining the highest levels of security and compliance. Action means you can empower every part of your business with data to build better products, make faster decisions, create new revenue streams and realize the value of your greatest untapped asset, your data."}, "correct_response": ["a", "b", "c"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "What are the key benefits of The Data Cloud? (Select 3)", "related_lectures": []}, {"_class": "assessment", "id": 58447260, "assessment_type": "multi-select", "prompt": {"question": "Snowflake is available in four editions. Which are those? (Select 4)", "relatedLectureIds": "", "feedbacks": ["", "", "", "", "", ""], "explanation": "<p><strong>Snowflake is available in four editions: Standard, Enterprise, Business Critical, and Virtual Private Snowflake (VPS). </strong></p><p><br></p><p>Standard comes with most of the available features. </p><p><br></p><p>Enterprise adds on to Standard with things like extra days of time travel, materialized view support, and data masking. </p><p><br></p><p>Business Critical brings to the table: HIPAA support, Tri-secret Secure, and more.&nbsp; </p><p><br></p><p>Virtual Private Snowflake is everything that Business Critical has, but with the ability to have customer-dedicated metadata stores and customer-dedicated virtual service.</p>", "answers": ["Standard", "Enterprise", "Business Critical", "Virtual Private Snowflake (VPS)", "Professional", "Professional Plus"]}, "correct_response": ["a", "b", "c", "d"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "Snowflake is available in four editions. Which are those? (Select 4)", "related_lectures": []}, {"_class": "assessment", "id": 58447262, "assessment_type": "multi-select", "prompt": {"question": "Which of the Snowflake editions provides HIPPA Support feature? (Select 2)", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p><strong>Business Critical and Virtual Private Snowflake (VPS) editions provide HIPPA support.</strong></p>", "answers": ["Standard", "Enterprise", "Business Critical", "Virtual Private Snowflake (VPS)", "All of the Snowflake Editions"]}, "correct_response": ["c", "d"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "Which of the Snowflake editions provides HIPPA Support feature? (Select 2)", "related_lectures": []}, {"_class": "assessment", "id": 58447264, "assessment_type": "multi-select", "prompt": {"question": "Which of these are Snowflake Cloud Partner Categories? (Select 3)", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>Snowflake has the following Cloud Partner Categories: </p><ul><li><p>Data Integration</p></li><li><p>Business Intelligence (BI)</p></li><li><p>Machine Learning &amp; Data Science</p></li><li><p>Security Governance &amp; Observability</p></li><li><p>SQL Development &amp; Management</p></li><li><p>Native Programmatic Interfaces.\t</p></li></ul>", "answers": ["Application Integration", "Data Integration", "Machine Learning &amp; Data Science", "Native Programmatic Interfaces"]}, "correct_response": ["b", "c", "d"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "Which of these are Snowflake Cloud Partner Categories? (Select 3)", "related_lectures": []}, {"_class": "assessment", "id": 58447266, "assessment_type": "multiple-choice", "prompt": {"question": "Which primary tool loads data to Snowflake from a local file system?\t", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p><strong>SnowSQL is the primary tool to load data to Snowflake from a local file system.</strong> You can run it in either interactive shell or batch mode.</p><p><br></p><p><strong>Note: Don't get confused between SnowSQL and SnowCD. SnowCD (i.e. Snowflake Connectivity Diagnostic Tool) helps users to diagnose and troubleshoot their network connection to Snowflake.</strong></p>", "answers": ["Snowflake UI", "External Stage", "SnowSQL", "ETL tools"]}, "correct_response": ["c"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "Which primary tool loads data to Snowflake from a local file system?", "related_lectures": []}, {"_class": "assessment", "id": 58447268, "assessment_type": "multi-select", "prompt": {"question": "Which of these Snowflake Connectors are available? (Select all that apply)", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p>ODBC and JDBC are drivers. <strong>Connectors available for Snowflake are Python, Kafka, and Spark.</strong> Snowflake also provides several drivers like ODBC, JDBC, Node.js, Go,.Net, and PHP PDO. The Snowflake SQL API is a REST API that you can use to access and update data in a Snowflake database.</p>", "answers": ["Snowflake Connector for ODBC", "Snowflake Connector of Python", "Snowflake Connector for JDBC", "Snowflake Connector for Kafka ", "Snowflake Connector for Spark"]}, "correct_response": ["b", "d", "e"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "Which of these Snowflake Connectors are available? (Select all that apply)", "related_lectures": []}, {"_class": "assessment", "id": 58447270, "assessment_type": "multi-select", "prompt": {"question": "Which of these are applicable for Snowflake Connector for Kafka? (Select all that apply)", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p>Kafka topics can be mapped to existing Snowflake tables in the Kafka configuration. <strong>If the topics are not mapped, then the Kafka connector creates a new table for each topic using the topic name. </strong>The Kafka connector subscribes to one or more Kafka topics based on the configuration information provided via the Kafka configuration file or command line (Or the Confluent Control Center; Confluent only).</p>", "answers": ["Reads data from one or more Kafka topics and loads the data into a Snowflake table", "Kafka topics can be mapped to existing Snowflake tables in the Kafka configuration", "If the topics are not mapped, then the Kafka connector creates a new table for each topic using the topic name", "Kafka connector required a pre-configured Snowflake table to map the topics with that Snowflake table", "The Kafka connector subscribes to one or more Kafka topics"]}, "correct_response": ["a", "b", "c", "e"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "Which of these are applicable for Snowflake Connector for Kafka? (Select all that apply)", "related_lectures": []}, {"_class": "assessment", "id": 58447272, "assessment_type": "multiple-choice", "prompt": {"question": "The Kafka connector creates Snowflake Objects for each topic. ", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>The connector creates the following objects for each topic:</p><ul><li><p>One internal stage to temporarily store data files for each topic. </p></li><li><p>One pipe to ingest the data files for each topic partition. </p></li><li><p>One table for each topic. If the table specified for each topic does not exist, the connector creates it; otherwise, the connector creates the RECORD_CONTENT and RECORD_METADATA columns in the existing table and verifies that the other columns are nullable (and produces an error if they are not).</p></li></ul>", "answers": ["One internal stage to temporarily store data files for each topic", "One pipe to ingest the data files for each topic partition", "One table for each topic. If the table specified for each topic does not exist", "All of these "]}, "correct_response": ["d"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "The Kafka connector creates Snowflake Objects for each topic.", "related_lectures": []}, {"_class": "assessment", "id": 58447274, "assessment_type": "multi-select", "prompt": {"question": "Which capabilities are available in Snowsight (the new Snowflake web interface)? (Select all that apply)", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p>Snowsight is the new Snowflake Web Interface. It can be used to perform the following operations:</p><ul><li><p>Building and running queries.&nbsp; </p></li><li><p>Loading data into tables.&nbsp; </p></li><li><p>Monitoring query performance and copy history.&nbsp; </p></li><li><p>Creating and managing users and other account-level objects.&nbsp; </p></li><li><p>Creating and using virtual warehouses.&nbsp; </p></li><li><p>Creating and modifying databases and all database objects.&nbsp; </p></li><li><p>Sharing data with other Snowflake accounts.&nbsp; </p></li><li><p>Exploring and using the Snowflake Marketplace.&nbsp; &nbsp; </p></li><li><p>One of the cool features is the smart autocomplete, which suggests SQL or object syntax to insert.</p></li></ul>", "answers": ["You can display visual statistics on columns (SUM, MIN, MAX, etc.) without re-running the query", "Sharing data with other Snowflake accounts", "Creating and managing users and other account-level objects", "The smart autocompletes feature suggests SQL or object syntax to insert", "Snowflake Marketplace is not available with Snowsight currently"]}, "correct_response": ["a", "b", "c", "d"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "Which capabilities are available in Snowsight (the new Snowflake web interface)? (Select all that apply)", "related_lectures": []}, {"_class": "assessment", "id": 58447276, "assessment_type": "multiple-choice", "prompt": {"question": "Which Snowsight interface does help in setting up Multi-factor authentication (MFA)?", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p><strong>There are three interfaces in Snowsight. Left Nav, User Menu, and Account Selector.</strong> </p><ul><li><p>Left Navigation consists of Worksheets, Dashboards, Data, Marketplace, Activity, Admin, Help &amp; Support. </p></li><li><p>User Menu lets you Switch Role, Profile including multi-factor authentication (MFA) , Partner Connect, Documentation, Support and Sign Out. </p></li><li><p>The account selector, located at the bottom of the left nav, lets you sign in to other Snowflake accounts.</p></li></ul>", "answers": ["You can not setup Multi-factor authentication (MFA) using Snowsight interface", "Left Nav interface", "User Menu Interface", "Account Selector Interface", "Admin Interface"]}, "correct_response": ["c"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "Which Snowsight interface does help in setting up Multi-factor authentication (MFA)?", "related_lectures": []}, {"_class": "assessment", "id": 58447360, "assessment_type": "multiple-choice", "prompt": {"question": "Which of the following is not a type of Snowflake&#39;s Internal stage?", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>An internal stage is a cloud repository that resides within a Snowflake account and is managed by Snowflake. An external stage is a pointer to a cloud file repository outside a Snowflake account, which the customer manages independently. <strong>There are three types of stages, and they are table stage, user stage, and named stage.</strong>\n \n <strong>Table Stage: </strong>When you create a table, the system will create a table stage with the same name but with the prefix @%.\n \n <strong>User Stage: </strong>A user stage is created whenever you create a new user in Snowflake. The user stage uses the @~.\n \n <strong>Named Stage:</strong> Named stages are created manually. They can be internal or external and are prefixed with an @ and then the stage's name.</p>", "answers": ["User Stage", "Table Stage", "Schema Stage", "Name Stage"]}, "correct_response": ["c"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "Which of the following is not a type of Snowflake&#39;s Internal stage?", "related_lectures": []}, {"_class": "assessment", "id": 58447362, "assessment_type": "multiple-choice", "prompt": {"question": "Which command will list the pipes for which you have access privileges?", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p><strong>SHOW PIPES Command lists the pipes for which you have access privileges. </strong>This command can list the pipes for a specified database or schema (or the current database/schema for the session) or your entire account.</p>", "answers": ["LIST PIPES;", "DESCRIBE PIPES;", "SHOW PIPES();", "SHOW PIPES;", "LIST PIPES();"]}, "correct_response": ["d"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "Which command will list the pipes for which you have access privileges?", "related_lectures": []}, {"_class": "assessment", "id": 58447364, "assessment_type": "multi-select", "prompt": {"question": "Which of these stages can not be dropped or altered? (Select 2)", "relatedLectureIds": "", "feedbacks": ["", "", ""], "explanation": "<p><strong>User Stage: </strong><em>User stages cannot be altered or dropped.</em> A user stage is allocated to each user for storing files. This stage type is designed to store staged and managed files by a single user but can be loaded into multiple tables.&nbsp; &nbsp; </p><p><strong>Table Stage: </strong><em>Table stages cannot be altered or dropped. </em>A table stage is available for each table created in Snowflake. This stage type is designed to store staged and managed files by one or more users but only loaded into a single table. Note that a table stage is not a separate database object but an implicit stage tied to the table itself. A table stage has no grantable privileges of its own.&nbsp; &nbsp; </p><p><strong>Named Stage:</strong> A named internal stage is a database object created in a schema. This stage type can store files staged and managed by one or more users and loaded into one or more tables. Because named stages are database objects, the ability to create, modify, use, or drop them can be controlled using security access control privileges.\t</p>", "answers": ["User Stage", "Table Stage", "Named Stage"]}, "correct_response": ["a", "b"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "Which of these stages can not be dropped or altered? (Select 2)", "related_lectures": []}, {"_class": "assessment", "id": 58447366, "assessment_type": "multi-select", "prompt": {"question": "Which products does Snowflake offer for secure data sharing? (Select 3)", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p>Snowflake provides three product offerings for data sharing that utilize Snowflake Secure Data Sharing to connect providers of data with consumers.\n\n<strong>Direct Share:</strong> It is the simplest form of data sharing that enables account-to-account sharing of data utilizing Snowflake\u2019s Secure Data Sharing.\nAs a data provider, you can easily share data with another company so that your data shows up in their Snowflake account without having to copy it over or move it.\n\n<strong>Data Exchange: </strong>With a Snowflake data exchange, you actually set up a private exchange between partners that you want to have in this exchange, and any member of that exchange can share data in this private exchange. And any member of the exchange can also consume data from that exchange. So instead of one-to-one or one-to-many, it's many-to-many. But it's a very exclusive club. Only people who are invited into this exchange can access any of that data.\n\n<strong>Data Marketplace: </strong>The Snowflake Data Marketplace is where companies can publish their data to be consumed by anybody who has a Snowflake account and wants to connect to the marketplace and download that data.</p>", "answers": ["Direct share", "Indirect share", "Data Exchange", "Data Marketplace", "Data Replication"]}, "correct_response": ["a", "c", "d"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "Which products does Snowflake offer for secure data sharing? (Select 3)", "related_lectures": []}, {"_class": "assessment", "id": 58447368, "assessment_type": "multi-select", "prompt": {"question": "Which of these are Snowgrid&#39;s capabilities? (Select all that apply)", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p><strong>Snowgrid allows you to use Secure Data Sharing features to provide access to live data, without any ETL or movement of files across environments. </strong>\n</p>", "answers": ["Zero-copy cloning", "Share internally with private data exchange or externally with public data exchange", "Secure, governed data sharing", "ETL dependent", "Live, ready to query data"]}, "correct_response": ["b", "c", "e"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "Which of these are Snowgrid&#39;s capabilities? (Select all that apply)", "related_lectures": []}, {"_class": "assessment", "id": 58447370, "assessment_type": "multiple-choice", "prompt": {"question": "The snowflake data warehouse is not built on an existing database or \u201cbig data\u201d software platform like Hadoop.(True/False)", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "<p><strong>Snowflake is a 100% cloud-native data platform. </strong></p>", "answers": ["TRUE", "FALSE"]}, "correct_response": ["a"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "The snowflake data warehouse is not built on an existing database or \u201cbig data\u201d software platform like Hadoop.(True/False)", "related_lectures": []}, {"_class": "assessment", "id": 58447372, "assessment_type": "multi-select", "prompt": {"question": "Which of these are types of Snowflake releases? (Select 3)", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p>There are three types of releases: </p><p><strong>Full Release:</strong> A full release may include any of the following: </p><ul><li><p>New features </p></li><li><p>Feature enhancements or updates </p></li><li><p>Fixes&nbsp; </p></li></ul><p><strong>Patch Release:</strong> A patch release includes fixes only.&nbsp; </p><p><br></p><p><strong>Behavior Release: </strong>Every month, Snowflake deploys one behavior change release. Behavior change releases contain changes to existing behaviors that may impact customers. </p>", "answers": ["Full Release", "Part Release", "Patch Release", "Behavior Change Release", "Bug Fix Release"]}, "correct_response": ["a", "c", "d"], "section": "", "question_plain": "Which of these are types of Snowflake releases? (Select 3)", "related_lectures": []}, {"_class": "assessment", "id": 58447374, "assessment_type": "multiple-choice", "prompt": {"question": "<p>Which of these Snowflake Editions automatically stores data in an encrypted state? </p>", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p><strong>All of the Snowflake Editions (Standard, Enterprise, Business Critical, Virtual Private Snowflake) automatically store data in an encrypted state.</strong></p>", "answers": ["Standard", "Enterprise", "Business Critical", "Virtual Private Snowflake(VPS)", "All of the Snowflake Editions"]}, "correct_response": ["e"], "section": "Data Protection and Data Sharing", "question_plain": "Which of these Snowflake Editions automatically stores data in an encrypted state?", "related_lectures": []}, {"_class": "assessment", "id": 58447376, "assessment_type": "multiple-choice", "prompt": {"question": "Cloning a table replicates the source table&#39;s structure, data, load history, and certain other properties (e.g., STAGE FILE FORMAT). (True/False)", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "<p>Cloning a table replicates the source table's structure, data, and certain other properties (e.g., STAGE FILE FORMAT).\n\n<strong>A cloned table does not include the load history of the source table. </strong>One consequence is that data files loaded into a source table can be loaded again into its clones.</p>", "answers": ["TRUE", "FALSE"]}, "correct_response": ["b"], "section": "Data Protection and Data Sharing", "question_plain": "Cloning a table replicates the source table&#39;s structure, data, load history, and certain other properties (e.g., STAGE FILE FORMAT). (True/False)", "related_lectures": []}, {"_class": "assessment", "id": 58447378, "assessment_type": "multiple-choice", "prompt": {"question": "If you make any changes (e.g., insert, update) in a cloned table, then __", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>Zero-copy cloning allows us to make a snapshot of any table, schema, or database without actually copying data.\n\nA clone is writable and is independent of its source (i.e., changes made to the source or clone are not reflected in the other object).\n\nA new clone of a table points to the original table's micro partitions, using no data storage. <strong>If we make any changes in the cloned table, then only its changed micro partitions are written to storage. </strong></p>", "answers": ["The source table also gets updated with the new changes in the cloned table", "Only the changed micro partitions are written to the data storage", "The entire table is written to data storage", "Cloned tables are read-only, you can not make any changes"]}, "correct_response": ["b"], "section": "Data Protection and Data Sharing", "question_plain": "If you make any changes (e.g., insert, update) in a cloned table, then __", "related_lectures": []}, {"_class": "assessment", "id": 58447380, "assessment_type": "multiple-choice", "prompt": {"question": "If we make any changes to the original table, then", "relatedLectureIds": "", "feedbacks": ["", "", ""], "explanation": "<p>Zero-copy cloning allows us to make a snapshot of any table, schema, or database without actually copying data.\n\n<strong>A clone is writable and is independent of its source (i.e., changes made to the source or clone are not reflected in the other object).</strong>\n\nA new clone of a table points to the original table's micro partitions, using no data storage. If we make any changes in the cloned table, then only its changed micro partitions are written to storage. </p>", "answers": ["The changes get immediately reflected in the cloned table", "The changes do not reflect in the cloned table", "The cloned table data get refreshed with the entire new data of the source table"]}, "correct_response": ["b"], "section": "Data Protection and Data Sharing", "question_plain": "If we make any changes to the original table, then", "related_lectures": []}, {"_class": "assessment", "id": 58447382, "assessment_type": "multi-select", "prompt": {"question": "Which of these objects do not clone? (Select 2)", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>\nDatabases and Schemas can be cloned. <strong>External Table and Internal (Snowflake) stages do not get cloned.</strong></p>", "answers": ["Databases", "Schemas", "External Table", "Internal (Snowflake) stages"]}, "correct_response": ["c", "d"], "section": "Data Protection and Data Sharing", "question_plain": "Which of these objects do not clone? (Select 2)", "related_lectures": []}, {"_class": "assessment", "id": 58447384, "assessment_type": "multiple-choice", "prompt": {"question": "In the case of cloning massive databases or schemas, the original databases and schemas get locked while the cloning operation is running. While cloning is in progress, no DML operation can be done on the original databases and schemas. (True/False)", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "<p>Cloning is not instantaneous, particularly for large objects (databases, schemas, tables), and <strong>does not lock the object being cloned. </strong>A clone does not reflect any DML statements applied to table data, if applicable, while the cloning operation is still running.</p>", "answers": ["TRUE", "FALSE"]}, "correct_response": ["b"], "section": "Data Protection and Data Sharing", "question_plain": "In the case of cloning massive databases or schemas, the original databases and schemas get locked while the cloning operation is running. While cloning is in progress, no DML operation can be done on the original databases and schemas. (True/False)", "related_lectures": []}, {"_class": "assessment", "id": 58447386, "assessment_type": "multiple-choice", "prompt": {"question": "Which of these Snowflake features does enable accessing historical data (i.e., data that has been changed or deleted) at any point within a defined period?", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p><strong>Snowflake Time Travel enables accessing historical data</strong> (i.e. data that has been changed or deleted) at any point within a defined period. It serves as a powerful tool for performing the following tasks:&nbsp; </p><ul><li><p>Restoring data-related objects (tables, schemas, and databases) that might have been accidentally or intentionally deleted. </p></li><li><p>Duplicating and backing up data from key points in the past. </p></li><li><p>Analyzing data usage/manipulation over specified periods of time.</p></li></ul>", "answers": ["Zero Copy Cloning", "Data Sharing", "Time Travel", "Search Optimization Service"]}, "correct_response": ["c"], "section": "Data Protection and Data Sharing", "question_plain": "Which of these Snowflake features does enable accessing historical data (i.e., data that has been changed or deleted) at any point within a defined period?", "related_lectures": []}, {"_class": "assessment", "id": 58447388, "assessment_type": "multi-select", "prompt": {"question": "Which of these Snowflake tasks can be performed by Time Travel? (Select 3)", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>Using Time Travel, you can perform the following actions within a defined period:&nbsp; &nbsp; &nbsp; </p><ul><li><p>Query data in the past that has since been updated or deleted.&nbsp; &nbsp; &nbsp; </p></li><li><p>Create clones of entire tables, schemas, and databases at or before specific points in the past.&nbsp; &nbsp; &nbsp; </p></li><li><p>Restore tables, schemas, and databases that have been dropped.</p></li></ul>", "answers": ["Query data in the past that has since been updated or deleted", "Share the restored data objects over a specified period of time", "Create clones of entire tables, schemas, and databases at or before specific points in the past", "Restore tables, schemas, and databases that have been dropped."]}, "correct_response": ["a", "c", "d"], "section": "Data Protection and Data Sharing", "question_plain": "Which of these Snowflake tasks can be performed by Time Travel? (Select 3)", "related_lectures": []}, {"_class": "assessment", "id": 58447390, "assessment_type": "multiple-choice", "prompt": {"question": "What is the default standard data retention period automatically enabled for all Snowflake accounts?", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p><strong>The standard retention period is 1 day (24 hours) and is automatically enabled for all Snowflake accounts.</strong></p>", "answers": ["30 days", "90 days", "1 day", "0 days"]}, "correct_response": ["c"], "section": "Data Protection and Data Sharing", "question_plain": "What is the default standard data retention period automatically enabled for all Snowflake accounts?", "related_lectures": []}, {"_class": "assessment", "id": 58447392, "assessment_type": "multiple-choice", "prompt": {"question": "What happens to the data when the retention period ends for an object?", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p><strong>When the retention period ends for an object, the historical data is moved into Snowflake Fail-safe.</strong> Snowflake support needs to be contacted to get the data restored from Fail-safe.</p>", "answers": ["Data is permanently lost ", "Data can be restored by increasing the retention period", "Data is moved to Snowflake Fail-safe", "SYSADMIN can restore the data from Fail-safe"]}, "correct_response": ["c"], "section": "Data Protection and Data Sharing", "question_plain": "What happens to the data when the retention period ends for an object?", "related_lectures": []}, {"_class": "assessment", "id": 58447394, "assessment_type": "multiple-choice", "prompt": {"question": "What is the maximum data retention period for permanent databases, schemas, and tables for Snowflake Enterprise Edition (and higher)?", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>For Snowflake Enterprise Edition (and higher): </p><p><br></p><ul><li><p>For transient databases, schemas, and tables, the retention period can be set to 0 (or unset back to the default of 1 day). The same is also true for temporary tables. </p></li><li><p><strong>For permanent databases, schemas, and tables, the retention period can be set to any value from 0 up to 90 days.</strong></p></li></ul>", "answers": ["90 days", "30 days", "1 day", "0 days"]}, "correct_response": ["a"], "section": "Data Protection and Data Sharing", "question_plain": "What is the maximum data retention period for permanent databases, schemas, and tables for Snowflake Enterprise Edition (and higher)?", "related_lectures": []}, {"_class": "assessment", "id": 58447396, "assessment_type": "multiple-choice", "prompt": {"question": "What is the maximum data retention period for transient databases, schemas, and tables for Snowflake Enterprise Edition (and higher)?", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>For Snowflake Enterprise Edition (and higher): </p><ul><li><p><strong>For transient databases, schemas, and tables, the retention period can be set to 0 (or unset back to the default of 1 day). The same is also true for temporary tables. </strong></p></li><li><p>For permanent databases, schemas, and tables, the retention period can be set to any value from 0 up to 90 days.</p></li></ul>", "answers": ["90 days", "30 days", "1 day", "0 days"]}, "correct_response": ["c"], "section": "Data Protection and Data Sharing", "question_plain": "What is the maximum data retention period for transient databases, schemas, and tables for Snowflake Enterprise Edition (and higher)?", "related_lectures": []}, {"_class": "assessment", "id": 58447398, "assessment_type": "multiple-choice", "prompt": {"question": "Which object parameter can users with the ACCOUNTADMIN role use to set the default retention period for their account?", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>Users can use the <strong>DATA_RETENTION_TIME_IN_DAYS</strong> object parameter with the ACCOUNTADMIN role to set the default retention period for their account.</p>", "answers": ["DATA_RETENTION_TIME_IN_HOURS", "DATA_RETENTION_IN_TIME_TRAVEL", "DATA_RETENTION_TIME_MAX", "DATA_RETENTION_TIME_IN_DAYS"]}, "correct_response": ["d"], "section": "Data Protection and Data Sharing", "question_plain": "Which object parameter can users with the ACCOUNTADMIN role use to set the default retention period for their account?", "related_lectures": []}, {"_class": "assessment", "id": 58447400, "assessment_type": "multiple-choice", "prompt": {"question": "The data retention period for a database, schema, or table can not be changed once ACCOUNTADMIN sets it at the account level. (True/False)", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "<p><strong>The data retention period for a database, schema, or table can be changed at any time. </strong>DATA_RETENTION_TIME_IN_DAYS parameter can be used to explicitly override the default when creating a database, schema, and individual table.\n\nFor example: CREATE TABLE t1 (c1 int) <strong>DATA_RETENTION_IN DAYS=90;</strong></p>", "answers": ["TRUE", "FALSE"]}, "correct_response": ["b"], "section": "Data Protection and Data Sharing", "question_plain": "The data retention period for a database, schema, or table can not be changed once ACCOUNTADMIN sets it at the account level. (True/False)", "related_lectures": []}, {"_class": "assessment", "id": 58447402, "assessment_type": "multiple-choice", "prompt": {"question": "\nWhich object parameter can users with the ACCOUNTADMIN role use to set the minimum retention period for their account?\t", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p><strong>The MIN_DATA_RETENTION_TIME_IN_DAYS account parameter can be set by users with the ACCOUNTADMIN role to set a minimum retention period for the account. </strong>This parameter does not alter or replace the DATA_RETENTION_TIME_IN_DAYS parameter value. However, it may change the effective data retention time. When this parameter is set at the account level, the effective minimum data retention period for an object is determined by <strong>MAX(DATA_RETENTION_TIME_IN_DAYS, MIN_DATA_RETENTION_TIME_IN_DAYS).</strong></p>", "answers": ["DATA_RETENTION_TIME_IN_DAYS", "MIN_DATA_RETENTION_TIME_IN_HOURS", "DATA_RETENTION_TIME_IN_MIN_DAYS", "MIN_DATA_RETENTION_TIME_IN_DAYS"]}, "correct_response": ["d"], "section": "Data Protection and Data Sharing", "question_plain": "Which object parameter can users with the ACCOUNTADMIN role use to set the minimum retention period for their account?", "related_lectures": []}, {"_class": "assessment", "id": 58447404, "assessment_type": "multiple-choice", "prompt": {"question": "Time Travel can be disabled for an account by ACCOUNTADMIN. (True/False)", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "<p>\n<strong>Time Travel cannot be disabled for an account. </strong>A user with the ACCOUNTADMIN role can set DATA_RETENTION_TIME_IN_DAYS to 0 at the account level, which means that all databases (and subsequently all schemas and tables) created in the account have no retention period by default; however, this default can be overridden at any time for any database, schema, or table.</p>", "answers": ["TRUE", "FALSE"]}, "correct_response": ["b"], "section": "Data Protection and Data Sharing", "question_plain": "Time Travel can be disabled for an account by ACCOUNTADMIN. (True/False)", "related_lectures": []}, {"_class": "assessment", "id": 58447406, "assessment_type": "multiple-choice", "prompt": {"question": "If DATA_RETENTION_TIME_IN_DAYS is set to a value of 0, and MIN_DATA_RETENTION_TIME_IN_DAYS is set higher at the account level and is greater than 0, which value (0 or higher) setting takes precedence?", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "<p>If DATA_RETENTION_TIME_IN_DAYS is set to a value of 0, and MIN_DATA_RETENTION_TIME_IN_DAYS is set at the account level and is greater than 0, the higher value setting takes precedence. The data retention period for an object is determined by <strong>MAX(DATA_RETENTION_TIME_IN_DAYS, MIN_DATA_RETENTION_TIME_IN_DAYS).</strong></p>", "answers": ["Higher value (set in MIN_DATA_RETENTION_TIME_IN_DAYS)", "0 (set in DATA_RETENTION_TIME_IN_DAYS)"]}, "correct_response": ["a"], "section": "Data Protection and Data Sharing", "question_plain": "If DATA_RETENTION_TIME_IN_DAYS is set to a value of 0, and MIN_DATA_RETENTION_TIME_IN_DAYS is set higher at the account level and is greater than 0, which value (0 or higher) setting takes precedence?", "related_lectures": []}, {"_class": "assessment", "id": 58447408, "assessment_type": "multiple-choice", "prompt": {"question": "<p>You have a table with a 30-day retention period. If you increase the retention period to 40 days, how would it affect the data that would have been removed after 30 days?</p>", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "<p>Increasing Retention causes the data currently in Time Travel to be retained for a more extended time.\nFor example, suppose you have a table with a 30-day retention period and increase the period to 40 days. In that case, <strong>data that would have been removed after 30 days is now retained for an additional 10 days before moving into Fail-safe.</strong>&nbsp; </p><p>Note that this does not apply to any data that is older than 30 days and has already moved into Fail-safe.</p>", "answers": ["The data will now retain an additional 10 days before moving into Fail-safe", "The data will still be moved to Fail-safe at the end of the 30-day retention period"]}, "correct_response": ["a"], "section": "Data Protection and Data Sharing", "question_plain": "You have a table with a 30-day retention period. If you increase the retention period to 40 days, how would it affect the data that would have been removed after 30 days?", "related_lectures": []}, {"_class": "assessment", "id": 58447410, "assessment_type": "multiple-choice", "prompt": {"question": "<p>You have a table with a 30-day retention period. If you decrease the retention period to 20 days, how would it affect the data that would have been removed after 30 days?</p>", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "<p>Decreasing Retention reduces the amount of time data is retained in Time Travel: </p><ul><li><p>For active data modified after the retention period is reduced, the new shorter period applies. </p></li><li><p>For data that is currently in Time Travel:&nbsp; &nbsp; &nbsp;</p><ul><li><p>If the data is still within the new shorter period, it remains in Time Travel.&nbsp; &nbsp; &nbsp;</p></li><li><p>If the data is outside the new period, it moves into Fail-safe.&nbsp; </p></li></ul></li></ul><p>For example, if you have a table with a 30-day retention period and you decrease the period to 20-day, data from days 21 to 30 will be moved into Fail-safe, leaving only the data from day 1 to 20 accessible through Time Travel.&nbsp; </p><p>However, the process of moving the data from Time Travel into Fail-safe is performed by a background process, so the change is not immediately visible. Snowflake guarantees that the data will be moved, but does not specify when the process will complete; until the background process completes, the data is still accessible through Time Travel.</p>", "answers": ["The data will still retain for 30-day before moving to Fail-safe", "The data will now retain for a shorter period of 20 days"]}, "correct_response": ["b"], "section": "Data Protection and Data Sharing", "question_plain": "You have a table with a 30-day retention period. If you decrease the retention period to 20 days, how would it affect the data that would have been removed after 30 days?", "related_lectures": []}, {"_class": "assessment", "id": 58447412, "assessment_type": "multiple-choice", "prompt": {"question": "Suppose we have a table t1. We drop the table t1 and then create a new table t1 again. What will happen if we execute the UNDROP command to restore dropped t1 table now?", "relatedLectureIds": "", "feedbacks": ["", "", ""], "explanation": "<p><strong>If an object with the same name already exists, UNDROP fails.</strong> We must rename the existing object, which then enables us to restore the previous version of the object.</p>", "answers": ["The dropped table t1 will be restored with name t1", "The dropped table t1 will be restored with a new arbitrary name set by Snowflake", "UNDROP command will fail"]}, "correct_response": ["c"], "section": "Data Protection and Data Sharing", "question_plain": "Suppose we have a table t1. We drop the table t1 and then create a new table t1 again. What will happen if we execute the UNDROP command to restore dropped t1 table now?", "related_lectures": []}, {"_class": "assessment", "id": 58447414, "assessment_type": "multiple-choice", "prompt": {"question": "Fail-safe helps access historical data after the Time Travel retention period has ended.(True/False)", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "<p><strong>Fail-safe is not provided as a means for accessing historical data after the Time Travel retention period has ended. </strong>It is for use only by Snowflake to recover data that may have been lost or damaged due to extreme operational failures. Data recovery through Fail-safe may take from several hours to several days to complete.</p>", "answers": ["TRUE", "FALSE"]}, "correct_response": ["b"], "section": "Data Protection and Data Sharing", "question_plain": "Fail-safe helps access historical data after the Time Travel retention period has ended.(True/False)", "related_lectures": []}, {"_class": "assessment", "id": 58447416, "assessment_type": "multi-select", "prompt": {"question": "Which objects are not available for replication in the Standard Edition of Snowflake? (Select 3) ", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "Database and share replication are available in all editions, including the Standard edition. Replication of all other objects is only available for Business Critical Edition (or higher).", "answers": ["Integrations", "Roles", "Database", "Shares", "Users"]}, "correct_response": ["a", "b", "e"], "section": "Data Protection and Data Sharing", "question_plain": "Which objects are not available for replication in the Standard Edition of Snowflake? (Select 3)", "related_lectures": []}, {"_class": "assessment", "id": 58447418, "assessment_type": "multi-select", "prompt": {"question": "<p>Which database objects are currently not supported for replication? (Select 2)</p>", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p><strong>Temporary tables, stages, tasks, pipes, and external tables are not currently supported for replication.</strong></p>", "answers": ["Transient tables", "Temporary tables", "Views", "Stages", "Streams"]}, "correct_response": ["b", "d"], "section": "Data Protection and Data Sharing", "question_plain": "Which database objects are currently not supported for replication? (Select 2)", "related_lectures": []}, {"_class": "assessment", "id": 58447420, "assessment_type": "multiple-choice", "prompt": {"question": "Which table function in the Snowflake Information Schema can be used to query the replication history for a specified database within a specified date range?", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>The table function <strong>REPLICATION_USAGE_HISTORY</strong> in Snowflake Information Schema can be used to query the replication history for a specified database within a specified date range. The information returned by the function includes the database name, credits consumed and bytes transferred for replication.</p>", "answers": ["DATA_TRANSFER_HISTORY", "DATABASE_REFRESH_HISTORY", "REPLICATION_GROUP_REFRESH_HISTORY", "REPLICATION_USAGE_HISTORY"]}, "correct_response": ["d"], "section": "Data Protection and Data Sharing", "question_plain": "Which table function in the Snowflake Information Schema can be used to query the replication history for a specified database within a specified date range?", "related_lectures": []}, {"_class": "assessment", "id": 58447422, "assessment_type": "multiple-choice", "prompt": {"question": "Which view in the Account Usage Schema can be used to query the replication history for a specified database?", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>This <strong>REPLICATION_USAGE_HISTORY</strong> view in the Account Usage Schema can be used to query the replication history for a specified database. The returned results include the database name, credits consumed, and bytes transferred for replication. Usage data is retained for 365 days (1 year).</p>", "answers": ["DATA_TRANSFER_HISTORY", "REPLICATION_USAGE_HISTORY", "DATABASE_REFRESH_HISTORY", "REPLICATION_GROUP_REFRESH_HISTORY"]}, "correct_response": ["b"], "section": "Data Protection and Data Sharing", "question_plain": "Which view in the Account Usage Schema can be used to query the replication history for a specified database?", "related_lectures": []}, {"_class": "assessment", "id": 58447424, "assessment_type": "multi-select", "prompt": {"question": "What types of accounts are involved in data sharing? (Select 3)", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p>There are three types of accounts involved in data sharing.</p><p>\n<strong>Data Providers: </strong> Share data with others</p><p>\n<strong>Data Consumers: </strong>Accesses shared data with their own Snowflake account. </p><p>\n<strong>Reader Accounts: </strong>Query data using compute from the data provider's account. Reader Accounts are what you can use to share data with somebody who does not already have a Snowflake account.\n</p>", "answers": ["Data Publishers", "Data Consumers", "Data Providers", "Reader Accounts", "Shared Accounts"]}, "correct_response": ["b", "c", "d"], "section": "Data Protection and Data Sharing", "question_plain": "What types of accounts are involved in data sharing? (Select 3)", "related_lectures": []}, {"_class": "assessment", "id": 58447426, "assessment_type": "multi-select", "prompt": {"question": "What actions can a consumer perform on a share? (Select 2)", "relatedLectureIds": "", "feedbacks": ["", "", "", "", "", ""], "explanation": "<p>Shared databases are read-only. A consumer cannot UPDATE a share. However, the consumer can do a CREATE TABLE AS to make a point-in-time copy of the data that's been shared. The consumer cannot clone and re-share a share or forward it. And also, time travel data on a share is not available to the consumer. A share can be imported into one database.</p><p><strong>Note: Very important for the exam. You can expect 2-3 questions on what a consumer can or can not do with a share.</strong></p>", "answers": ["Clone a share", "Import the same share to more than one database", "Copy shared data into another table in their own account with CREATE TABLE AS", "Execute Time Travel on a share", "Query the shared data and join it with an existing table in their own account", "Re-share the share"]}, "correct_response": ["c", "e"], "section": "Data Protection and Data Sharing", "question_plain": "What actions can a consumer perform on a share? (Select 2)", "related_lectures": []}, {"_class": "assessment", "id": 58447428, "assessment_type": "multi-select", "prompt": {"question": "Which privileges are provided with a share by the provider? (Select 2)", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p>Shares are named Snowflake objects that encapsulate all of the information required to share a database. Each share consists of: </p><ul><li><p>The privileges that grant access to the database(s) and the schema containing the objects to share. </p></li><li><p>The privileges that grant access to the specific objects in the database. </p></li><li><p>The consumer accounts with which the database and its objects are shared.&nbsp; </p></li></ul><p>Example: </p><p>CREATE SHARE \"SHARED_DATA\" COMMENT=''; </p><p>GRANT USAGE ON DATABASE \"DEMO_DB\" TO SHARE \"SHARED_DATA\"; </p><p>GRANT USAGE ON SCHEMA \"DEMO_DB\".\"TWITTER_DATA\" TO SHARE \"SHARED_DATA\"; </p><p>GRANT SELECT ON VIEW \"DEMO_DB\".\"TWITTER_DATA\".\"FOLLOWERS\" TO SHARE \"SHARED_DATA\";</p>", "answers": ["Grant access(USAGE) to the database and the schema containing the tables to share", "Grant access(USAGE) to the specific tables in the database", "Grant access(SELECT) to the specific tables in the database", "Grant access(MODIFY) to the specific tables in the database", "Grant access(OPERATE) to the database and the schema containing the tables to share"]}, "correct_response": ["a", "c"], "section": "Data Protection and Data Sharing", "question_plain": "Which privileges are provided with a share by the provider? (Select 2)", "related_lectures": []}, {"_class": "assessment", "id": 58447430, "assessment_type": "multiple-choice", "prompt": {"question": "Snowflake data providers can share data from one database per share. Data from multiple databases can not be shared with a share. (True/False)", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "<p><strong>Snowflake data providers can share data that resides in different databases by using secure views. </strong>A secure view can reference objects such as schemas, tables, and other views from one or more databases, as long as these databases belong to the same account.</p>", "answers": ["TRUE", "FALSE"]}, "correct_response": ["b"], "section": "Data Protection and Data Sharing", "question_plain": "Snowflake data providers can share data from one database per share. Data from multiple databases can not be shared with a share. (True/False)", "related_lectures": []}, {"_class": "assessment", "id": 58447432, "assessment_type": "multiple-choice", "prompt": {"question": "Direct data sharing can only be done with accounts in the same region and the same cloud provider. (TRUE/FALSE)", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "<p><strong>Direct data sharing can only be done with accounts in the same region and the same cloud provider.</strong> Suppose you want to share with someone outside of your region. In that case, you replicate that database into the region you want to share with and share from there.</p>", "answers": ["TRUE", "FALSE"]}, "correct_response": ["a"], "section": "Data Protection and Data Sharing", "question_plain": "Direct data sharing can only be done with accounts in the same region and the same cloud provider. (TRUE/FALSE)", "related_lectures": []}, {"_class": "assessment", "id": 58447278, "assessment_type": "multi-select", "prompt": {"question": "In which of the cloud platforms a Snowflake account can be hosted? (Select 3)", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p>A Snowflake account can be hosted on any of the following cloud platforms: </p><ul><li><p>Amazon Web Services (AWS)</p></li><li><p>Google Cloud Platform (GCP)</p></li><li><p>Microsoft Azure (Azure). </p></li></ul><p>On each platform, Snowflake provides one or more regions where the account is provisioned.</p>", "answers": ["AWS", "AZURE", "GCP", "IBM Cloud", "Oracle Cloud"]}, "correct_response": ["a", "b", "c"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "In which of the cloud platforms a Snowflake account can be hosted? (Select 3)", "related_lectures": []}, {"_class": "assessment", "id": 58447280, "assessment_type": "multiple-choice", "prompt": {"question": "Which of the following is the correct hierarchy for the Snowflake objects?", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p><strong>The topmost container is the customer organization. Securable objects such as tables, views, functions, and stages are contained in a schema object, which are in turn contained in a database.</strong> All databases for your Snowflake account are contained in the account object. USER, ROLE, DATABASE, WAREHOUSE are at same level and contained in a Snowflake Account Object.&nbsp; </p>", "answers": ["ACCOUNT &gt; ORGANIZATION &gt; ROLE &gt; USER &gt; DATABASE &gt; SCHEMA &gt; TABLE", "ORGANIZATION &gt; ACCOUNT &gt; DATABASE &gt; SCHEMA &gt; TABLE &gt; STAGE", "ORGANIZATION &gt; ACCOUNT &gt; DATABASE &gt; SCHEMA &gt; TABLE ", "ORGANIZATION &gt; ACCOUNT &gt; ROLE &gt; USER &gt; DATABASE &gt; SCHEMA &gt; STAGE &gt; TABLE"]}, "correct_response": ["c"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "Which of the following is the correct hierarchy for the Snowflake objects?", "related_lectures": []}, {"_class": "assessment", "id": 58447282, "assessment_type": "multi-select", "prompt": {"question": "Which table types does Snowflake support? (Select all that apply)", "relatedLectureIds": "", "feedbacks": ["", "", "", "", "", ""], "explanation": "<p>Snowflake supports four different table types: Permanent Table, Temporary Table, Transient Table, and External Table.&nbsp; </p><ul><li><p><strong>Permanent Table:</strong> It persists until dropped. It is designed for data requiring the highest data protection and recovery level and is the default table type. Permanent Tables can be protected by up to 90 days of time travel with Enterprise Edition or above. Moreover, the failsafe is covered on all the Permanent Tables.&nbsp; &nbsp; &nbsp; </p></li></ul><ul><li><p><strong>Temporary Table:</strong> A Temporary table is tied to a specific session, which means it is tied to a single user. Temporary tables are used for things like materializing subquery. You can only cover temporary tables by up to one day of time travel, and they are not covered by a failsafe.&nbsp; &nbsp; &nbsp; </p></li></ul><ul><li><p><strong>Transient Table:</strong> A Transient table is essentially a temporary table that more than one user can share because multiple users share a transient table. You have to drop it when you are finished with it, and it also is only covered by up to one day of time travel and is not covered by a failsafe. NOTE - WE CAN ALSO HAVE TRANSIENT DATABASES AND SCHEMAS.&nbsp; &nbsp; &nbsp; </p></li></ul><ul><li><p><strong>External Table:</strong> An External Table is used to access data in a data lake. It is always read-only because it is based on files that live outside of Snowflake and are not managed by Snowflake, and Time Travel and Failsafe do not cover it.\t</p></li></ul>", "answers": ["PERMANENT TABLE", "TEMPORARY TABLE", "TRANSIENT TABLE", "EXTERNAL TABLE", "SECURED TABLE", "MATERIALIZED TABLE"]}, "correct_response": ["a", "b", "c", "d"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "Which table types does Snowflake support? (Select all that apply)", "related_lectures": []}, {"_class": "assessment", "id": 58447284, "assessment_type": "multi-select", "prompt": {"question": "Which of these types of VIEW does Snowflake support? (Select 3)", "relatedLectureIds": "", "feedbacks": ["", "", "", "", "", ""], "explanation": "<p><strong>Snowflake supports three types of views. </strong></p><p><strong>Standard View, Secure View, and Materialized View.&nbsp; &nbsp;</strong></p><p><br></p><ul><li><p><strong>Standard View:</strong> It is a default view type. Its underlying DDL is available to any role with access to the view. When you create a standard view, Snowflake saves a definition of the view. Snowflake does not run the query. When someone accesses the view, that is when the query is run. The standard view will always execute as the owning role.&nbsp; </p><p><br></p></li><li><p><strong>Secure View:</strong> The secure view is exactly like a standard view, except users cannot see how that view was defined. Sometimes a secure view will run a little slower than a standard view to protect the information in a secure view. Snowflake may bypass some of the optimizations.&nbsp; </p><p><br></p></li><li><p><strong>Materialized View: </strong>A materialized view is more like a table. Unlike a standard or secure view, Snowflake runs the query right away when you create a materialized view. It takes the results set and stores that result set as a table in Snowflake. Because Snowflake is storing that materialized view as a table, creating micro partitions. Snowflake is creating metadata about those micro partitions. So when you query a materialized view, if you put a filter on the view, you get the same benefit of micro partition pruning that you would get from a table. With Snowflake, the materialized view is automatically refreshed every time there is a transaction against the base table. So it is always going to be in sync. If you want, you can also create a secure materialized view, which again will hide the logic from the user. A note about materialized views, because Snowflake is auto-refreshing them in the background, they use some credits, so there is a little bit of a cost there. Moreover, there is some storage, and Snowflake stores the result set as a table in Snowflake. So materialized views use more storage and compute than standard or secure views.</p></li></ul>", "answers": ["PERMANENT VIEW", "EXTERNAL VIEW", "STANDARD VIEW", "SECURE VIEW", "MATERIALIZED VIEW", "TEMPORARY VIEW"]}, "correct_response": ["c", "d", "e"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "Which of these types of VIEW does Snowflake support? (Select 3)", "related_lectures": []}, {"_class": "assessment", "id": 58447286, "assessment_type": "multi-select", "prompt": {"question": "Which of the following Data Types are supported by Snowflake? (Select all that apply)", "relatedLectureIds": "", "feedbacks": ["", "", "", "", "", ""], "explanation": "<p><strong>All of these data types are supported by Snowflake except BOOL. BOOLEAN is the correct data type.</strong></p>", "answers": ["NUMERIC", "INTEGER", "FLOAT", "CHAR", "VARCHAR", "BOOL"]}, "correct_response": ["a", "b", "c", "d", "e"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "Which of the following Data Types are supported by Snowflake? (Select all that apply)", "related_lectures": []}, {"_class": "assessment", "id": 58447288, "assessment_type": "multiple-choice", "prompt": {"question": "Which is the default timestamp in Snowflake?", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p><strong>TIMESTAMP_NTZ is the default timestamp type if you just define a column as a timestamp. Hint to remember : NTZ represents NO TIME ZONES.</strong></p>", "answers": ["TIMESTAMP_LTZ", "TIMESTAMP_NTZ", "TIMESTAMP_TZ", "None of these"]}, "correct_response": ["b"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "Which is the default timestamp in Snowflake?", "related_lectures": []}, {"_class": "assessment", "id": 58447290, "assessment_type": "multiple-choice", "prompt": {"question": "Which is not the DML (Data Manipulation Language) command?", "relatedLectureIds": "", "feedbacks": ["", "", "", "", "", ""], "explanation": "<p><strong>UNDROP is Snowflake's DDL (Data Definition Language) command.</strong></p>", "answers": ["INSERT", "MERGE", "UPDATE", "DELETE", "UNDROP", "TRUNCATE"]}, "correct_response": ["e"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "Which is not the DML (Data Manipulation Language) command?", "related_lectures": []}, {"_class": "assessment", "id": 58447292, "assessment_type": "multiple-choice", "prompt": {"question": "Which is not the DDL (Data Definition Language) command?", "relatedLectureIds": "", "feedbacks": ["", "", "", "", "", ""], "explanation": "TRUNCATE is DML (Data Manipulation Language) command.", "answers": ["CREATE", "ALTER", "DROP    ", "UNDROP", "SHOW SHARES", "TRUNCATE"]}, "correct_response": ["f"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "Which is not the DDL (Data Definition Language) command?", "related_lectures": []}, {"_class": "assessment", "id": 58447294, "assessment_type": "multi-select", "prompt": {"question": "<p>Which of the following are file staging commands? (Select all that apply)</p>", "relatedLectureIds": "", "feedbacks": ["", "", "", "", "", ""], "explanation": "<p><br></p><p><strong>File Staging Commands</strong> \u2013 PUT (to a stage), GET (from a stage), LIST and REMOVE. These commands are specific for working with stages. \n</p>", "answers": ["UNDROP", "PUT", "GET", "LIST ", "REMOVE", "COPY INTO &lt;table&gt;"]}, "correct_response": ["b", "c", "d", "e"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "Which of the following are file staging commands? (Select all that apply)", "related_lectures": []}, {"_class": "assessment", "id": 58447296, "assessment_type": "multiple-choice", "prompt": {"question": "Monica wants to delete all the data from table t1. She wants to keep the table structure, so she does not need to create the table again. Which command will be appropriate for her need?", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "TRUNCATE will delete all of the data from a single table. So, once Monica truncates table t1, table t1&#39;s structure remains, but the data will be deleted. DELETE is usually used for deleting single rows of data.", "answers": ["DELETE", "DROP", "UNDROP", "TRUNCATE", "REMOVE"]}, "correct_response": ["d"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "Monica wants to delete all the data from table t1. She wants to keep the table structure, so she does not need to create the table again. Which command will be appropriate for her need?", "related_lectures": []}, {"_class": "assessment", "id": 58447298, "assessment_type": "multiple-choice", "prompt": {"question": "How long does Snowflake keep batch load history (from Stage) using COPY statement?", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p><strong>Snowflake keeps the batch load history for 64 days.</strong></p>", "answers": ["30 days", "31 days", "14 days", "64 days", "1 day"]}, "correct_response": ["d"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "How long does Snowflake keep batch load history (from Stage) using COPY statement?", "related_lectures": []}, {"_class": "assessment", "id": 58447300, "assessment_type": "multiple-choice", "prompt": {"question": "How long does Snowflake keep Snowpipe&#39;s load history?", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p><strong>Snowflake keeps the Snowpipe's load history for 14 days. </strong></p><p><br></p><p><strong>[Note / Important for exam]: If you recreate the PIPE then the load history will reset to empty.</strong></p>", "answers": ["30 days", "31 days", "14 days", "64 days", "1 day"]}, "correct_response": ["c"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "How long does Snowflake keep Snowpipe&#39;s load history?", "related_lectures": []}, {"_class": "assessment", "id": 58447302, "assessment_type": "multiple-choice", "prompt": {"question": "A stored procedure can simultaneously run the caller\u2019s and the owner\u2019s rights. (True / False)\t", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "<p><strong>A stored procedure runs with either the caller\u2019s rights or the owner\u2019s rights. It cannot run with both at the same time.</strong>\n\n<strong>A caller\u2019s rights stored procedure</strong> runs with the privileges of the caller. The primary advantage of a caller\u2019s rights stored procedure is that it can access information about that caller or about the caller\u2019s current session. For example, a caller\u2019s rights stored procedure can read the caller\u2019s session variables and use them in a query.&nbsp; <strong>An </strong></p><p><strong>owner\u2019s rights stored procedure</strong> runs mostly with the privileges of the stored procedure\u2019s owner. The primary advantage of an owner\u2019s rights stored procedure is that the owner can delegate specific administrative tasks, such as cleaning up old data, to another role without granting that role more general privileges, such as privileges to delete all data from a specific table.&nbsp; </p><p>At the time that the stored procedure is created, the creator specifies whether the procedure runs with the owner\u2019s rights or the caller\u2019s rights. The default is owner\u2019s rights.</p>", "answers": ["TRUE", "FALSE"]}, "correct_response": ["b"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "A stored procedure can simultaneously run the caller\u2019s and the owner\u2019s rights. (True / False)", "related_lectures": []}, {"_class": "assessment", "id": 58447304, "assessment_type": "multiple-choice", "prompt": {"question": "UDF runs with either the caller\u2019s or the owner\u2019s rights. (True / False)", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "<p><strong>UDF only runs as the function owner. </strong>A stored procedure runs with either the caller\u2019s rights or the owner\u2019s rights. It cannot run with both at the same time.\n\n<strong>A caller\u2019s rights stored procedure</strong> runs with the privileges of the caller. The primary advantage of a caller\u2019s rights stored procedure is that it can access information about that caller or about the caller\u2019s current session. For example, a caller\u2019s rights stored procedure can read the caller\u2019s session variables and use them in a query.&nbsp; <strong>An </strong></p><p><strong>owner\u2019s rights stored procedure</strong> runs mostly with the privileges of the stored procedure\u2019s owner. The primary advantage of an owner\u2019s rights stored procedure is that the owner can delegate specific administrative tasks, such as cleaning up old data, to another role without granting that role more general privileges, such as privileges to delete all data from a specific table.&nbsp; </p><p>At the time that the stored procedure is created, the creator specifies whether the procedure runs with the owner\u2019s rights or the caller\u2019s rights. The default is owner\u2019s rights.</p>", "answers": ["TRUE", "FALSE"]}, "correct_response": ["b"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "UDF runs with either the caller\u2019s or the owner\u2019s rights. (True / False)", "related_lectures": []}, {"_class": "assessment", "id": 58447306, "assessment_type": "multiple-choice", "prompt": {"question": "Snowflake supports SQL UDFs that return a set of rows. Which keyword in CREATE FUNCTION statement does need to be specified to enable UDF (i.e., UDTF) to return a set of rows? ", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>TABLE keyword after RETURNS needs to be specified to create a UDTF (user-defined table function). Example :&nbsp; </p><p>create function t()</p><p>returns <strong>table</strong>(msg varchar)</p><p>as</p><p>$$</p><p>select 'Hello'</p><p>union</p><p>select 'World'</p><p>$$;</p><p><br></p><p><strong>Note:</strong> UDF returns a singular scalar value or if defined as a TABLE function, a set of rows. If you see UDTF in the exam, that simply means UDF that returns a set of rows.</p>", "answers": ["SCALAR", "MULTIPLE", "ROWS", "TABLE "]}, "correct_response": ["d"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "Snowflake supports SQL UDFs that return a set of rows. Which keyword in CREATE FUNCTION statement does need to be specified to enable UDF (i.e., UDTF) to return a set of rows?", "related_lectures": []}, {"_class": "assessment", "id": 58447308, "assessment_type": "multi-select", "prompt": {"question": "A task can execute any one of the following types of SQL code: (Select 3)", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>A task can execute any one of the following types of SQL code:&nbsp; </p><ul><li><p>Single SQL statement</p></li><li><p>Call to a stored procedure</p></li><li><p>Procedural logic using Snowflake Scripting.</p></li></ul><p><br></p>", "answers": ["Single SQL Statement", "Multiple SQL statements", "Call to a stored procedure", "Procedural logic using Snowflake Scripting"]}, "correct_response": ["a", "c", "d"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "A task can execute any one of the following types of SQL code: (Select 3)", "related_lectures": []}, {"_class": "assessment", "id": 58447310, "assessment_type": "multiple-choice", "prompt": {"question": "Tasks require compute resources to execute code. Either Snowflake-managed or User-managed compute models can be chosen for individual tasks. (True / False)\n", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "<p>Tasks require compute resources to execute SQL code. Either of the following compute models can be chosen for individual tasks: </p><ul><li><p>Snowflake-managed (i.e. serverless compute model)&nbsp; </p></li><li><p>User-managed (i.e. virtual warehouse) </p></li></ul>", "answers": ["TRUE", "FALSE"]}, "correct_response": ["a"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "Tasks require compute resources to execute code. Either Snowflake-managed or User-managed compute models can be chosen for individual tasks. (True / False)", "related_lectures": []}, {"_class": "assessment", "id": 58447312, "assessment_type": "multi-select", "prompt": {"question": "Which roles can use SQL to view the task history within a specified date range? (Select all that apply)", "relatedLectureIds": "", "feedbacks": ["", "", ""], "explanation": "All of these roles can use SQL to view the task history within a specified date range.\nTo view the run history for a single task: Query the TASK_HISTORY table function (in the Snowflake Information Schema).\n\nTo view details on a DAG run that is currently scheduled or is executing: Query the CURRENT_TASK_GRAPHS table function (in the Snowflake Information Schema).\n\nTo view the history for DAG runs that executed successfully, failed, or were canceled in the past 60 minutes: Query the COMPLETE_TASK_GRAPHS table function (in the Snowflake Information Schema).\n\nQuery the COMPLETE_TASK_GRAPHS View  (in Account Usage). ", "answers": ["Account Administrator (ACCOUNTADMIN)", "Task Owner having OWNERSHIP privilege on a task", "Role that has the global MONITOR EXECUTION privilege"]}, "correct_response": ["a", "b", "c"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "Which roles can use SQL to view the task history within a specified date range? (Select all that apply)", "related_lectures": []}, {"_class": "assessment", "id": 58447314, "assessment_type": "multiple-choice", "prompt": {"question": "Monica has successfully created a task with the 5 minutes schedule.\n It has been 30 minutes, but the task did not run. What could be the reason?", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p><strong>The first time we create the TASK, we must run the ALTER TASK command to RESUME the task.&nbsp; </strong></p>", "answers": ["Task schedule should not be less than 60 minutes", "Monica should run the ALTER TASK command to RESUME the task", "Monica should run the ALTER TASK command to SUSPEND the task, and then again run the ALTER TASK command to RESUME the task", "Monica doesn&#39;t have the authority to run the task"]}, "correct_response": ["b"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "Monica has successfully created a task with the 5 minutes schedule.\n It has been 30 minutes, but the task did not run. What could be the reason?", "related_lectures": []}, {"_class": "assessment", "id": 58447316, "assessment_type": "multi-select", "prompt": {"question": "Which of these columns gets appended on creating a stream on a table? (Select 3)", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p><strong>Adding a stream to a table appends three metadata columns: METADATA$ACTION, METADATA$ISUPDATE, METADATA$ROW_ID.&nbsp; \n</strong>\nThese columns track the CDC records and their type:&nbsp; appends,&nbsp; deletes, or both (updates = inserts + deletes).\n</p><p><strong>METADATA$ACTION</strong> - Indicates the DML operation (INSERT, DELETE) recorded.\n</p><p><strong>METADATA$ISUPDATE</strong> - Indicates whether the operation was part of an UPDATE statement. \n</p><p><strong>METADATA$ROW_ID</strong> - Specifies the unique and immutable ID for the row, which can be used to track changes to specific rows over time.\n\n</p>", "answers": ["METADATA$ACTION", "METADATA$ISUPDATE", "METADATA$ROW_ID", "METADATA$ISINSERT", "METADATA$ISDELETE"]}, "correct_response": ["a", "b", "c"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "Which of these columns gets appended on creating a stream on a table? (Select 3)", "related_lectures": []}, {"_class": "assessment", "id": 58447318, "assessment_type": "multi-select", "prompt": {"question": "Which of these are types of the stream? (Select 3)", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p>The following stream types are available based on the metadata recorded by each:\n</p><p><strong>Standard - </strong>Supported for streams on tables, directory tables, or views. A standard (i.e. delta) stream tracks all DML changes to the source object, including inserts, updates, and deletes (including table truncates). \n</p><p><strong>Append-only - </strong>Supported for streams on standard tables, directory tables, or views. An append-only stream tracks row inserts only. Update and delete operations (including table truncates) are not recorded.\n</p><p><strong>Insert-only -</strong> Supported for streams on external tables only. An insert-only stream tracks row inserts only; they do not record delete operations that remove rows from an inserted set (i.e. no-ops).\n</p>", "answers": ["External", "Standard", "Update-only", "Append-only", "Insert-only"]}, "correct_response": ["b", "d", "e"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "Which of these are types of the stream? (Select 3)", "related_lectures": []}, {"_class": "assessment", "id": 58447320, "assessment_type": "multiple-choice", "prompt": {"question": "Which stream type is supported for streams on the external table only?", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p><strong>Insert-only is supported for streams on external tables only. </strong>An insert-only stream tracks row inserts only; they do not record delete operations that remove rows from an inserted set (i.e. no-ops). </p>", "answers": ["External", "Standard", "Update-only", "Append-only", "Insert-only"]}, "correct_response": ["e"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "Which stream type is supported for streams on the external table only?", "related_lectures": []}, {"_class": "assessment", "id": 58447322, "assessment_type": "multiple-choice", "prompt": {"question": "You have a table t1 with a column j that gets populated by a sequence s1. s1 is defined to start from 1 and with an increment of 1. \n\ncreate or replace sequence s1\n   start = 1\n   increment = 1\n   ;\n\ncreate or replace table t1 (\n    i int,\n    j int default s1.nextval\n    );\n\nYou inserted 3 records in table t1:\n\n insert into t1 values\n     (1,s1.nextval),\n     (2,s1.nextval),\n     (3,s1.nextval);\n\nAfter that insert statement, you altered the sequence s1 to set the increment to -4:\nalter sequence s1 set increment = -4;\n\nYou again inserted 2 records in table t1:\ninsert into t1 values\n     (4,s1.nextval),\n     (5,s1.nextval);\n\nWhat would be the result of the following query?\nselect j from t1 where i = 4;", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p><strong>ALTER SEQUENCE command takes effect after the second use of the sequence after executing the ALTER SEQUENCE command.</strong>\nSo, if you fetch row where i = 5, you will find j = 0 [row 4 value of j i.e., 4 + (-4) = 0]</p>", "answers": ["-1", "0", "4", "3", "5"]}, "correct_response": ["c"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "You have a table t1 with a column j that gets populated by a sequence s1. s1 is defined to start from 1 and with an increment of 1. \n\ncreate or replace sequence s1\n   start = 1\n   increment = 1\n   ;\n\ncreate or replace table t1 (\n    i int,\n    j int default s1.nextval\n    );\n\nYou inserted 3 records in table t1:\n\n insert into t1 values\n     (1,s1.nextval),\n     (2,s1.nextval),\n     (3,s1.nextval);\n\nAfter that insert statement, you altered the sequence s1 to set the increment to -4:\nalter sequence s1 set increment = -4;\n\nYou again inserted 2 records in table t1:\ninsert into t1 values\n     (4,s1.nextval),\n     (5,s1.nextval);\n\nWhat would be the result of the following query?\nselect j from t1 where i = 4;", "related_lectures": []}, {"_class": "assessment", "id": 58447324, "assessment_type": "multi-select", "prompt": {"question": "Snowpark is a new developer framework for Snowflake. It allows data engineers, data scientists, and data developers to code in their familiar way with their language of choice and execute the pipeline, ML workflow, and data apps faster and more securely in a single platform. \n\nWhich of these following languages does Snowpark support? (Select 3)", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p>Snowpark is a new developer framework for Snowflake. It allows data engineers, data scientists, and data developers to code in their familiar way with their language of choice and execute the pipeline, ML workflow, and data apps faster and more securely in a single platform. \n \n It brings deeply integrated, DataFrame-style programming to the languages developers like to use and functions to help you efficiently expand more data use cases. Now all these can be executed inside Snowflake using the elastic performance engine.&nbsp; \n \n <strong>Snowpark support starts with Scala API, Java UDFs, and External Functions and expands to Java &amp; Python.</strong></p>", "answers": ["C#", "Java", "C++", "Python", "Scala"]}, "correct_response": ["b", "d", "e"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "Snowpark is a new developer framework for Snowflake. It allows data engineers, data scientists, and data developers to code in their familiar way with their language of choice and execute the pipeline, ML workflow, and data apps faster and more securely in a single platform. \n\nWhich of these following languages does Snowpark support? (Select 3)", "related_lectures": []}, {"_class": "assessment", "id": 58447326, "assessment_type": "multiple-choice", "prompt": {"question": "Search optimization\u00a0is a Database-level property applied to all the tables within the database with supported data types. (True/False)", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "<p><strong>Search optimization is a table-level property and applies to all columns with supported data types.</strong> The search optimization service aims to significantly improve the performance of selective point lookup queries on tables. A point lookup query returns only one or a small number of distinct rows. A user can register one or more tables to the search optimization service.</p>", "answers": ["TRUE", "FALSE"]}, "correct_response": ["b"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "Search optimization\u00a0is a Database-level property applied to all the tables within the database with supported data types. (True/False)", "related_lectures": []}, {"_class": "assessment", "id": 58447328, "assessment_type": "multiple-choice", "prompt": {"question": "The search optimization service speeds only equality searches. (True/False)", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "<p><strong>The search optimization service speeds Equality and IN predicates searches.</strong> </p>", "answers": ["TRUE", "FALSE"]}, "correct_response": ["b"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "The search optimization service speeds only equality searches. (True/False)", "related_lectures": []}, {"_class": "assessment", "id": 58447330, "assessment_type": "multi-select", "prompt": {"question": "<p>Which data types are not supported by the Search Optimization Service? (Select 2)</p>", "relatedLectureIds": "", "feedbacks": ["", "", "", "", "", ""], "explanation": "<p>The search optimization service currently supports <strong>equality predicate and IN list predicate</strong> searches for the following data types:\n\n<strong>Fixed-point numbers (e.g. INTEGER, NUMERIC).\n\nDATE, TIME, and TIMESTAMP.\n\nVARCHAR.\n\nBINARY.</strong>\n\nCurrently, the search optimization service does not support floating point data types, semi-structured data types, or other data types not listed above. </p>", "answers": ["Fixed-point numbers (e.g. INTEGER, NUMERIC)", "DATE, TIME, and TIMESTAMP", "VARCHAR", "BINARY", "Floating-point data types", "Semi-structured data types"]}, "correct_response": ["e", "f"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "Which data types are not supported by the Search Optimization Service? (Select 2)", "related_lectures": []}, {"_class": "assessment", "id": 58447332, "assessment_type": "multi-select", "prompt": {"question": "Which of these are not supported by the Search Optimization Service? (Select all that apply)", "relatedLectureIds": "", "feedbacks": ["", "", "", "", "", ""], "explanation": "<p><strong>None of these are currently supported by the Search Optimization Service. </strong>Additionally, Tables and views protected by row access policies cannot be used with the Search Optimization Search.</p><p><br></p><p>The search optimization service can improve the performance of queries that use:</p><ul><li><p><strong>Equality predicates</strong> (for example, &lt;column_name&gt; = &lt;constant&gt;).</p></li><li><p>Predicates that use IN</p></li></ul>", "answers": ["External Tables", "Materialized Views", "Column Concatenation", "Casts on table columns", "Analytical Expressions", "Columns defined with COLLATE clause"]}, "correct_response": ["a", "b", "c", "d", "e", "f"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "Which of these are not supported by the Search Optimization Service? (Select all that apply)", "related_lectures": []}, {"_class": "assessment", "id": 58447334, "assessment_type": "multi-select", "prompt": {"question": "How can you view the data storage across your entire Snowflake account? (Select 2)", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>Suppose you have been assigned the ACCOUNTADMIN role (i.e., you serve as the top-level administrator for your Snowflake account). In that case, you can use Snowsight or the classic web interface to view data storage across your entire account:&nbsp; </p><ul><li><p>Using Snowsight: Select Admin &gt; Usage &gt; Storage,&nbsp; &nbsp;</p></li><li><p>Using Classic Web Interface: Click on Account &gt; Billing &amp; Usage &gt; Average Storage Used\t</p></li></ul>", "answers": ["Using Snowsight: Select Data &gt; Usage &gt; Storage", "Using Snowsight: Select Admin &gt; Usage &gt; Storage", "Using Classic Web Interface:\u00a0Click on Account &gt; Billing &amp; Usage &gt; Average Storage Used", "Using Classic Web Interface: Click on Account &gt; Resource Monitors &gt; Average Storage Used"]}, "correct_response": ["b", "c"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "How can you view the data storage across your entire Snowflake account? (Select 2)", "related_lectures": []}, {"_class": "assessment", "id": 58447336, "assessment_type": "multi-select", "prompt": {"question": "Which of the following data storage does incur the cost? (Select 3)", "relatedLectureIds": "", "feedbacks": ["", "", "", "", "", ""], "explanation": "<p>Storage is calculated and charged for data regardless of whether it is in the <strong>Active, Time Travel, or Fail-safe state</strong>.</p>", "answers": ["Active data Storage", "Time Travel Storage", "All storage except Fail-Safe storage", "Only Active and Time Travel Storage", "Fail-Safe Storage", "Only Active and Fail-Sage storage"]}, "correct_response": ["a", "b", "e"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "Which of the following data storage does incur the cost? (Select 3)", "related_lectures": []}, {"_class": "assessment", "id": 58447338, "assessment_type": "multi-select", "prompt": {"question": "Which database objects can be shared using the Snowflake Secure Data Sharing feature? (Select all that apply)", "relatedLectureIds": "", "feedbacks": ["", "", "", "", "", ""], "explanation": "<p>Secure Data Sharing enables sharing selected objects in a database in your account with other Snowflake accounts. The following Snowflake database objects can be shared:&nbsp; </p><ul><li><p>Tables&nbsp; </p></li><li><p>External tables&nbsp; </p></li><li><p>Secure views&nbsp; </p></li><li><p>Secure materialized views&nbsp; </p></li><li><p>Secure UDFs&nbsp; </p></li></ul><p>Snowflake enables the sharing of databases through shares created by data providers and \u201cimported\u201d by data consumers.</p>", "answers": ["Tables", "External Tables", "Roles", "Secure Materialized View", "Secure UDFs", "Secure Views"]}, "correct_response": ["a", "b", "d", "e", "f"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "Which database objects can be shared using the Snowflake Secure Data Sharing feature? (Select all that apply)", "related_lectures": []}, {"_class": "assessment", "id": 58447340, "assessment_type": "multiple-choice", "prompt": {"question": "If a warehouse runs for 61 seconds, shuts down, and then restarts and runs for less than 60 seconds, for how much duration will the billing be charged?", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p><strong>It will be billed for 121 seconds (60 + 1 + 60).</strong></p>", "answers": ["60 seconds", "120 seconds", "61 seconds", "121 seconds", "180 seconds"]}, "correct_response": ["d"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "If a warehouse runs for 61 seconds, shuts down, and then restarts and runs for less than 60 seconds, for how much duration will the billing be charged?", "related_lectures": []}, {"_class": "assessment", "id": 58447342, "assessment_type": "multiple-choice", "prompt": {"question": "What sized tables will experience the most benefit from clustering?", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>Generally, <strong>tables in the multi-terabyte (TB) range will experience the most benefit from clustering</strong>, mainly if DML is performed regularly/continually on these tables.</p>", "answers": ["Tables with sizes between the range of 100 MB to 1 GB compressed", "Tables with sizes between the range of 1 GB to 10 GB compressed", "Tables in the multi-terabyte (TB) range", "All sizes of tables"]}, "correct_response": ["c"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "What sized tables will experience the most benefit from clustering?", "related_lectures": []}, {"_class": "assessment", "id": 58447344, "assessment_type": "multiple-choice", "prompt": {"question": "How many maximum columns (or expressions) are recommended for a cluster key?", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>A single clustering key can contain one or more columns or expressions. <strong>Snowflake recommends a maximum of 3 or 4 columns (or expressions) per key for most tables.</strong> Adding more than 3-4 columns tends to increase costs more than benefits.</p>", "answers": ["12 to 16", "7 to 8", "3 to 4", "Higher the number of columns (or expressions) in the key, better will be the performance"]}, "correct_response": ["c"], "section": "", "question_plain": "How many maximum columns (or expressions) are recommended for a cluster key?", "related_lectures": []}, {"_class": "assessment", "id": 58447346, "assessment_type": "multiple-choice", "prompt": {"question": "SQL clause that helps define the clustering key:", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>Example - \n\ncreate or replace table t1 (c1 date, c2 string, c3 number) <strong>cluster by</strong> (c1, c2);\n</p>", "answers": ["CLUSERTING ON ", "CLUSTER ON", "CLUSTERING BY", "CLUSTER BY"]}, "correct_response": ["d"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "SQL clause that helps define the clustering key:", "related_lectures": []}, {"_class": "assessment", "id": 58447348, "assessment_type": "multiple-choice", "prompt": {"question": "<p>John has a SECURITYADMIN role. He created a custom DBA_ROLE.&nbsp; He granted the SYSADMIN role to DBA_ROLE. He created a user, 'Monica'. John then granted DBA_ROLE to Monica. Monica creates a Database Monica_DB. Monica then created a Table T1 in Monica_DB under the PUBLIC schema. What should John do to access Table T1, created by Monica?\t</p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p><strong>It does not matter if John has created the DBA_ROLE. If John wants to access the object created by DBA_ROLE, he needs to grant DBA_ROLE to himself.</strong></p>", "answers": ["USE ROLE dba_role;\nUSE DATABASE monica_db;\nSelect * from t1;", "USE ROLE SECURITYADMIN;\nUSE DATABASE monica_db;\nSelect * from t1;\n", "GRANT ROLE DBA_ROLE TO John;\nUSE DATABASE monica_db;\nSelect * from t1;\n", "GRANT ROLE DBA_ROLE TO John;\nUSE ROLE DBA_ROLE;\nUSE DATABASE monica_db;\nSelect * from t1;"]}, "correct_response": ["d"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "John has a SECURITYADMIN role. He created a custom DBA_ROLE.&nbsp; He granted the SYSADMIN role to DBA_ROLE. He created a user, 'Monica'. John then granted DBA_ROLE to Monica. Monica creates a Database Monica_DB. Monica then created a Table T1 in Monica_DB under the PUBLIC schema. What should John do to access Table T1, created by Monica?", "related_lectures": []}, {"_class": "assessment", "id": 58447350, "assessment_type": "multiple-choice", "prompt": {"question": "Snowflake automatically and transparently maintains materialized views. (True/False)", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "<p><strong>Snowflake automatically and transparently maintains materialized views</strong>. A background service updates the materialized view after changes to the base table. This is more efficient and less error-prone than manually maintaining the equivalent of a materialized view at the application level.</p>", "answers": ["TRUE", "FALSE"]}, "correct_response": ["a"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "Snowflake automatically and transparently maintains materialized views. (True/False)", "related_lectures": []}, {"_class": "assessment", "id": 58447352, "assessment_type": "multiple-choice", "prompt": {"question": "User-managed tasks are recommended when you cannot fully utilize a warehouse because only a few tasks run concurrently or they run to completion quickly (in less than 1 minute). (True / False)\t", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "<p><strong>Serverless Tasks is recommended when you cannot fully utilize a warehouse because too few tasks run concurrently or they run to completion quickly (in less than 1 minute).</strong>\n</p><p>User-managed Tasks is recommended when you can fully utilize a single warehouse by scheduling multiple concurrent tasks to take advantage of available compute resources.</p>", "answers": ["TRUE", "FALSE"]}, "correct_response": ["b"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "User-managed tasks are recommended when you cannot fully utilize a warehouse because only a few tasks run concurrently or they run to completion quickly (in less than 1 minute). (True / False)", "related_lectures": []}, {"_class": "assessment", "id": 58447354, "assessment_type": "multiple-choice", "prompt": {"question": "User-managed Tasks is recommended when you can fully utilize a single warehouse by scheduling multiple concurrent tasks to take advantage of available compute resources. (True /False)", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "<p><strong>User-managed Tasks is recommended when you can fully utilize a single warehouse by scheduling multiple concurrent tasks to take advantage of available compute resources.</strong>\n</p><p>Serverless Tasks is recommended when you cannot fully utilize a warehouse because too few tasks run concurrently or they run to completion quickly (in less than 1 minute).</p>", "answers": ["TRUE", "FALSE"]}, "correct_response": ["a"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "User-managed Tasks is recommended when you can fully utilize a single warehouse by scheduling multiple concurrent tasks to take advantage of available compute resources. (True /False)", "related_lectures": []}, {"_class": "assessment", "id": 58447356, "assessment_type": "multi-select", "prompt": {"question": "In what situations should you consider User-Managed Tasks over Serverless Tasks? (Select 2)", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p><strong>User-managed Tasks is recommended when you can fully utilize a single warehouse by scheduling multiple concurrent tasks to take advantage of available compute resources. Also, recommended when adherence to the schedule interval is less critical.</strong>\n\nServerless Tasks is recommended when you cannot fully utilize a warehouse because too few tasks run concurrently or they run to completion quickly (in less than 1 minute). Also, recommended when adherence to the schedule interval is critical.</p>", "answers": ["Consider when you cannot fully utilize a warehouse because too few tasks run concurrently or they run to completion quickly (in less than 1 minute).", "Consider when you can fully utilize a single warehouse by scheduling multiple concurrent tasks to take advantage of available compute resources.", "Consider when adherence to the schedule interval is less important.", "Consider when adherence to the schedule interval is highly important."]}, "correct_response": ["b", "c"], "section": "Snowflake Data Platform Features and Architecture", "question_plain": "In what situations should you consider User-Managed Tasks over Serverless Tasks? (Select 2)", "related_lectures": []}, {"_class": "assessment", "id": 58447358, "assessment_type": "multiple-choice", "prompt": {"question": "<p>The LIST command returns a list of files that have been staged. Which of these stages supports the LIST command? </p>", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p><strong>The LIST command returns a list of files staged from these specified snowflake stages.</strong></p>", "answers": ["Named internal stage.", "Named external stage.", "Stage for a specified table.", "Stage for the current user.", "All of these"]}, "correct_response": ["e"], "section": "", "question_plain": "The LIST command returns a list of files that have been staged. Which of these stages supports the LIST command?", "related_lectures": []}]}
5053382
~~~
{"count": 105, "next": null, "previous": null, "results": [{"_class": "assessment", "id": 69282560, "assessment_type": "multiple-choice", "prompt": {"question": "A role inherits all the privileges of those higher in the hierarchy. (True / False)", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "A role inherits all the privileges of its underlying roles (those &quot;lower&quot; in the hierarchy). \n\nACOOUNTADMIN inherits privileges from SECURITYADMIN, USERADMIN, SYSADMIN, and PUBLIC.\n\nSECURITYADMIN inherits privileges from USERADMIN and PUBLIC.\n\nUSERADMIN and SYSADMIN inherit privileges from PUBLIC\n\nPUBLIC inherits nothing.", "answers": ["TRUE", "FALSE"]}, "correct_response": ["b"], "section": "Account Access & Security", "question_plain": "A role inherits all the privileges of those higher in the hierarchy. (True / False)", "related_lectures": []}, {"_class": "assessment", "id": 69282562, "assessment_type": "multiple-choice", "prompt": {"question": "A user&#39;s default role is", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p><strong>A user's default role is the role a user gets set to each time the user logs in to Snowflake. </strong>Snowflake uses roles to control the objects (virtual warehouses, databases, tables, etc.) that users can access:&nbsp; </p><p>Snowflake provides a set of predefined roles, as well as a framework for defining a hierarchy of custom roles.&nbsp; &nbsp; &nbsp; All Snowflake users are automatically assigned the predefined PUBLIC role, which enables login to Snowflake and basic object access.&nbsp; &nbsp; &nbsp; </p><p>In addition to the PUBLIC role, each user can be assigned additional roles, with one of these roles designated as their default role. A user\u2019s default role determines the role used in the Snowflake sessions initiated by the user; however, this is only a default. Users can change roles within a session at any time.&nbsp; &nbsp; &nbsp; </p><p>Roles can be assigned at user creation or afterward.</p>", "answers": ["the name used to log in to the Snowflake WebUI.", "always the default PUBLIC role. ", "the role a user gets set to each time the user logs in to Snowflake.", "changed each time the user logs in to Snowflake."]}, "correct_response": ["c"], "section": "Account Access & Security", "question_plain": "A user&#39;s default role is", "related_lectures": []}, {"_class": "assessment", "id": 69282564, "assessment_type": "multi-select", "prompt": {"question": "Which of these security features are supported in Snowflake? (Select all that apply)", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p><strong>Snowflake is a highly secured platform and provides multi-level security like Multi-Factor Authentication (MFA), provision to set up Network policy to block access by unwanted IPs, Single Sign On (SSO), Role-Based Access Control, and Tri Secret Secure, and so on. </strong>Tri-Secret Secure is the combination of a Snowflake-maintained key and a customer-managed key in the cloud provider platform that hosts your Snowflake account to create a composite master key to protect your Snowflake data.</p>", "answers": ["Role-Based Access Control", "Multi-Factor Authentication", "Tri-Secret Secure Encryption", "Network Policy"]}, "correct_response": ["a", "b", "c", "d"], "section": "Account Access & Security", "question_plain": "Which of these security features are supported in Snowflake? (Select all that apply)", "related_lectures": []}, {"_class": "assessment", "id": 69282566, "assessment_type": "multi-select", "prompt": {"question": "<p>What are the security layers that Snowflake takes care of? (Select 4)</p>", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p><strong>Infrastructure Security is managed by the cloud provider. </strong></p>", "answers": ["Access", "Authentication", "Authorization", "Data Protection", "Infrastructure"]}, "correct_response": ["a", "b", "c", "d"], "section": "Account Access & Security", "question_plain": "What are the security layers that Snowflake takes care of? (Select 4)", "related_lectures": []}, {"_class": "assessment", "id": 69282568, "assessment_type": "multiple-choice", "prompt": {"question": "Permissions on database objects such as databases or tables are granted to:", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p><strong>Snowflake supports Role-Based Access control.</strong> Permissions on database objects such as databases or tables are granted to Roles. </p>", "answers": ["Virtual Warehouses", "Roles", "Users", "Schemas"]}, "correct_response": ["b"], "section": "Account Access & Security", "question_plain": "Permissions on database objects such as databases or tables are granted to:", "related_lectures": []}, {"_class": "assessment", "id": 69282570, "assessment_type": "multiple-choice", "prompt": {"question": "Which role is inherited to every other role in the account?", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p><strong>The PUBLIC role is Pseudo-role, which is automatically granted to every user and every role in your account. </strong>\n \nThis role is typically used in cases where explicit access control is not needed, and all users are viewed as equal with regard to their access rights.\t</p>", "answers": ["SECURITYADMIN", "USERADMIN", "PUBLIC", "ACCOUNTADMIN", "SYSADMIN"]}, "correct_response": ["c"], "section": "Account Access & Security", "question_plain": "Which role is inherited to every other role in the account?", "related_lectures": []}, {"_class": "assessment", "id": 69282572, "assessment_type": "multiple-choice", "prompt": {"question": "How can you create a &quot;Super-User&quot; or &quot;Super-Role&quot; in Snowflake who can bypass all the authorization checks?", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p><strong>There is no concept of a \u201csuper-user\u201d or \u201csuper-role\u201d in Snowflake</strong> that can bypass authorization checks. All-access requires appropriate access privileges.&nbsp; </p>", "answers": ["ACCOUNTADMIN role is same as Super-Role", "CREATE ROLE SUPER_ROLE;", "Contact Snowflake personnel to create a Super-Role or Super-User for your account", "There is no concept of SUPER-ROLE or SUPER-USER in Snowflake"]}, "correct_response": ["d"], "section": "Account Access & Security", "question_plain": "How can you create a &quot;Super-User&quot; or &quot;Super-Role&quot; in Snowflake who can bypass all the authorization checks?", "related_lectures": []}, {"_class": "assessment", "id": 69282574, "assessment_type": "multiple-choice", "prompt": {"question": "<p>A user cannot view the result set from a query that another user executed except for the ACCOUNTADMIN role. (True / False)</p>", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "<p><strong>A user cannot view the result set from a query that another user executed.</strong> This behavior is intentional. For security reasons, only the user who executed a query can access the query results.\n\nThis behavior is not connected to the Snowflake access control model for objects. <strong>Even a user with the ACCOUNTADMIN role cannot view the results for a query run by another user.</strong></p>", "answers": ["TRUE", "FALSE"]}, "correct_response": ["b"], "section": "Account Access & Security", "question_plain": "A user cannot view the result set from a query that another user executed except for the ACCOUNTADMIN role. (True / False)", "related_lectures": []}, {"_class": "assessment", "id": 69282576, "assessment_type": "multiple-choice", "prompt": {"question": "Which command will help you to view the current permissions on a Schema?", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>To view the current set of privileges granted on an object, you can execute the <strong>SHOW GRANTS</strong> command. To view the current permissions on a schema, execute the following command: \n\n<strong>SHOW GRANTS ON SCHEMA</strong>&nbsp; &lt;database_name&gt;.&lt;schema_name&gt;;</p>", "answers": ["SHOW ROLES ON SCHEMA &lt;database_name&gt;.&lt;schema_name&gt;;", "SHOW GRANTS OF SCHEMA &lt;database_name&gt;.&lt;schema_name&gt;;", "SHOW GRANTS ON SCHEMA &lt;database_name&gt;.&lt;schema_name&gt;;", "SHOW ALL PREIVILEGE ON SCHEMA  &lt;database_name&gt;.&lt;schema_name&gt;;"]}, "correct_response": ["c"], "section": "Account Access & Security", "question_plain": "Which command will help you to view the current permissions on a Schema?", "related_lectures": []}, {"_class": "assessment", "id": 69282578, "assessment_type": "multi-select", "prompt": {"question": "<p>Federated Authentication is supported by the following:</p><p>(Select all that apply)</p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p><strong>Federated authentication is supported by all of the Snowflake editions.</strong></p>", "answers": ["Standard Edition", "Enterprise Edition", "Business Critical", "VPS"]}, "correct_response": ["a", "b", "c", "d"], "section": "Account Access & Security", "question_plain": "Federated Authentication is supported by the following:(Select all that apply)", "related_lectures": []}, {"_class": "assessment", "id": 69282580, "assessment_type": "multi-select", "prompt": {"question": "<p>Dynamic Data Masking is supported by (Select all that apply)</p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p><strong>Dynamic Data Masking features require Enterprise Edition (or higher).</strong></p>", "answers": ["Standard Edition", "Enterprise Edition", "Business Critical", "VPS"]}, "correct_response": ["b", "c", "d"], "section": "Account Access & Security", "question_plain": "Dynamic Data Masking is supported by (Select all that apply)", "related_lectures": []}, {"_class": "assessment", "id": 69282582, "assessment_type": "multi-select", "prompt": {"question": "<p>Which objects are the securable objects in Snowflake? (Select all that apply)</p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p><strong>All of these are securable objects in Snowflake.&nbsp; &nbsp;A securable Object is an entity to which access can be granted. Unless allowed by a grant, access will be denied.</strong></p>", "answers": ["Database", "Warehouse", "Table", "File Format "]}, "correct_response": ["a", "b", "c", "d"], "section": "Account Access & Security", "question_plain": "Which objects are the securable objects in Snowflake? (Select all that apply)", "related_lectures": []}, {"_class": "assessment", "id": 69282584, "assessment_type": "multiple-choice", "prompt": {"question": "Which type of object key is only used for decryption?", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>Active Key is used for both encryption and decryption.&nbsp; <strong>The retired Key is used for decryption only.</strong>&nbsp; The destroyed Key is no longer used.</p>", "answers": ["Active key", "Retired Key", "Destroyed key", "None of these"]}, "correct_response": ["b"], "section": "Account Access & Security", "question_plain": "Which type of object key is only used for decryption?", "related_lectures": []}, {"_class": "assessment", "id": 69282586, "assessment_type": "multiple-choice", "prompt": {"question": "At what frequency does Snowflake rotate the object keys?", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p><strong>All Snowflake-managed keys are automatically rotated by Snowflake when they are more than 30 days old.</strong> Active keys are retired, and new keys are created. When Snowflake determines the retired key is no longer needed, the key is automatically destroyed. When active, a key is used to encrypt data and is available for usage by the customer. When retired, the key is used solely to decrypt data and is only available for accessing the data.</p>", "answers": ["16 Days", "30 Days", "60 Days", "1 Year"]}, "correct_response": ["b"], "section": "Account Access & Security", "question_plain": "At what frequency does Snowflake rotate the object keys?", "related_lectures": []}, {"_class": "assessment", "id": 69282588, "assessment_type": "multiple-choice", "prompt": {"question": "<p>All files stored in internal stages for data loading and unloading are automatically encrypted using AES-256 strong encryption. (True/False)</p>", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "<p><strong>All files stored in internal stages for data loading and unloading are automatically encrypted using AES-256 strong encryption.</strong></p>", "answers": ["TRUE", "FALSE"]}, "correct_response": ["a"], "section": "Account Access & Security", "question_plain": "All files stored in internal stages for data loading and unloading are automatically encrypted using AES-256 strong encryption. (True/False)", "related_lectures": []}, {"_class": "assessment", "id": 69282590, "assessment_type": "multiple-choice", "prompt": {"question": "Which AWS service is used to create private VPC endpoints that allow direct, secure connectivity between your AWS VPCs and the Snowflake VPC without traversing the public internet?", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p><strong>AWS PrivateLink is an AWS service for creating private VPC endpoints that allow direct, secure connectivity between your AWS VPCs and the Snowflake VPC without traversing the public internet. The connectivity is for AWS VPCs in the same AWS region.</strong></p><p>\nFor External Functions, you can also use AWS PrivateLink with private endpoints.</p><p>\nIn addition, if you have an on-premises environment (e.g. a non-hosted data center), you can choose to use AWS Direct Connect, in conjunction with AWS PrivateLink, to connect all your virtual and physical environments in a single, private network.</p>", "answers": ["AWS Direct Connect", "AWS PrivateVPC", "AWS PrivateLink", "Snowflake PrivateLink"]}, "correct_response": ["c"], "section": "Account Access & Security", "question_plain": "Which AWS service is used to create private VPC endpoints that allow direct, secure connectivity between your AWS VPCs and the Snowflake VPC without traversing the public internet?", "related_lectures": []}, {"_class": "assessment", "id": 69282592, "assessment_type": "multi-select", "prompt": {"question": "<p>Which IdP vendors provide native Snowflake support For federated authentication and SSO?(Select 2)</p>", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p><strong>Okta and Microsoft ADFS </strong>provide native Snowflake support for federated authentication and SSO. </p>", "answers": ["Onelogin", "Okta", "Microsoft ADFS", "Google G Suite", "Microsoft Azure Active Directory"]}, "correct_response": ["b", "c"], "section": "Account Access & Security", "question_plain": "Which IdP vendors provide native Snowflake support For federated authentication and SSO?(Select 2)", "related_lectures": []}, {"_class": "assessment", "id": 69282594, "assessment_type": "multi-select", "prompt": {"question": "Which features of Snowflake provide Column-level security? (Select 2)", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p><strong>Dynamic Data Masking</strong> is a Column-level Security feature that uses masking policies to selectively mask plain-text data in table and view columns at query time.\n</p><p><strong>External Tokenization</strong> enables accounts to tokenize data before loading it into Snowflake and detokenize the data at query runtime. Tokenization is the process of removing sensitive data by replacing it with an undecipherable token. External Tokenization makes use of masking policies with external functions.\n\n</p>", "answers": ["Internal Tokenization", "Dynamic Data Masking", "External Tokenization", "Column Masking"]}, "correct_response": ["b", "c"], "section": "Account Access & Security", "question_plain": "Which features of Snowflake provide Column-level security? (Select 2)", "related_lectures": []}, {"_class": "assessment", "id": 69282596, "assessment_type": "multi-select", "prompt": {"question": "Which of these objects are not replicated? (Select 2)", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p><strong>Temporary Tables, External Tables, Stages, Temporary Stages, Streams, and Tasks do not get replicated.</strong></p>", "answers": ["Permanent Tables", "Transient Tables", "Temporary Tables", "External Tables", "Views"]}, "correct_response": ["c", "d"], "section": "Account Access & Security", "question_plain": "Which of these objects are not replicated? (Select 2)", "related_lectures": []}, {"_class": "assessment", "id": 69282598, "assessment_type": "multiple-choice", "prompt": {"question": "If an account has federated authentication enabled. Can Snowflake admins still maintain user IDs and passwords in Snowflake?", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "<p>With federated authentication enabled on an account, Snowflake still allows maintaining and using Snowflake user credentials (login name and password). In other words:&nbsp; &nbsp; </p><ul><li><p>Account and security administrators can still create users with passwords maintained in Snowflake.&nbsp; &nbsp; </p></li><li><p>Users can still log into Snowflake using their Snowflake credentials.&nbsp; &nbsp;</p></li></ul><p>However, if federated authentication is enabled for an account, Snowflake does not recommend maintaining user passwords in Snowflake. Instead, user passwords should be maintained solely in your IdP.\t&nbsp; &nbsp; </p>", "answers": ["Yes", "No"]}, "correct_response": ["a"], "section": "Account Access & Security", "question_plain": "If an account has federated authentication enabled. Can Snowflake admins still maintain user IDs and passwords in Snowflake?", "related_lectures": []}, {"_class": "assessment", "id": 69282490, "assessment_type": "multiple-choice", "prompt": {"question": "Which of the Snowflake editions provides a federated authorization feature?", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p><strong>All Snowflake Editions (Standard, Enterprise, Business Critical, Virtual Private Snowflake) provide Federated Authentication.</strong></p>", "answers": ["Standard", "Enterprise", "Business Critical", "Virtual Private Snowflake(VPS)", "All of the Snowflake Editions"]}, "correct_response": ["e"], "section": "Account Access & Security", "question_plain": "Which of the Snowflake editions provides a federated authorization feature?", "related_lectures": []}, {"_class": "assessment", "id": 69282492, "assessment_type": "multiple-choice", "prompt": {"question": "Snowflake supports multi-factor authentication (i.e., MFA) to provide increased login security for users connecting to Snowflake. Which role is strongly recommended for using MFA?", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>Snowflake strongly recommends that all users with the <strong>ACCOUNTADMIN</strong> role be required to use MFA.</p>", "answers": ["SYSADMIN", "USERADMIN", "ACCOUNTADMIN", "USERADMIN"]}, "correct_response": ["c"], "section": "Account Access & Security", "question_plain": "Snowflake supports multi-factor authentication (i.e., MFA) to provide increased login security for users connecting to Snowflake. Which role is strongly recommended for using MFA?", "related_lectures": []}, {"_class": "assessment", "id": 69282494, "assessment_type": "multiple-choice", "prompt": {"question": "Which one is not the Snowflake System-Defined role?", "relatedLectureIds": "", "feedbacks": ["", "", "", "", "", ""], "explanation": "<p>The following are the Snowflake System-Defined roles: </p><p>ORGADMIN</p><p>ACCOUTADMIN</p><p>SECURITYADMIN</p><p>USERADMIN</p><p>SYSADMIN</p><p>PUBLIC.&nbsp; </p><p><br></p><p>System-defined roles cannot be dropped. In addition, the privileges granted to these roles by Snowflake cannot be revoked.</p>", "answers": ["ORGADMIN", "ACCOUNTADMIN", "DATABASEADMIN", "SECURITYADMIN", "USERADMIN", "SYSADMIN"]}, "correct_response": ["c"], "section": "Account Access & Security", "question_plain": "Which one is not the Snowflake System-Defined role?", "related_lectures": []}, {"_class": "assessment", "id": 69282496, "assessment_type": "multiple-choice", "prompt": {"question": "<p>Which of these system-defined roles can manage operations at the organizational level?</p>", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p><strong>ORGADMIN role manages operations at the organizational level.</strong> </p><p>More specifically, this role:</p><ul><li><p>Can create accounts in the organization. </p></li><li><p>Can view all accounts in the organization (using SHOW ORGANIZATION ACCOUNTS) and all regions enabled for the organization (using SHOW REGIONS). </p></li><li><p>Can view usage information across the organization.</p></li></ul>", "answers": ["ORGADMIN", "ACCOUNTADMIN", "SECURITYADMIN", "USERADMIN", "SYSADMIN"]}, "correct_response": ["a"], "section": "Account Access & Security", "question_plain": "Which of these system-defined roles can manage operations at the organizational level?", "related_lectures": []}, {"_class": "assessment", "id": 69282498, "assessment_type": "multiple-choice", "prompt": {"question": "Which of these system-defined roles encapsulates the SYSADMIN and SECURITYADMIN roles?", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p><strong>ACCOUNTADMIN role encapsulates the SYSADMIN and SECURITYADMIN system-defined roles.</strong> It is the top-level role in the system and should be granted only to a limited/controlled number of users in your account.</p>", "answers": ["ORGADMIN", "ACCOUNTADMIN", "SECURITYADMIN", "USERADMIN", "SYSADMIN"]}, "correct_response": ["b"], "section": "Account Access & Security", "question_plain": "Which of these system-defined roles encapsulates the SYSADMIN and SECURITYADMIN roles?", "related_lectures": []}, {"_class": "assessment", "id": 69282500, "assessment_type": "multiple-choice", "prompt": {"question": "Which of these roles is granted the MANAGE GRANTS security privilege to be able to modify any grant globally, including revoking it?", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p>SECURITYADMIN role can manage any object grant globally, as well as create, monitor, and manage users and roles. More specifically, this role: </p><ul><li><p>Is granted the MANAGE GRANTS security privilege to be able to modify any grant, including revoking it. </p></li><li><p>Inherits the privileges of the USERADMIN role via the system role hierarchy (i.e. USERADMIN role is granted to SECURITYADMIN).</p></li></ul>", "answers": ["ORGADMIN", "ACCOUNTADMIN", "SECURITYADMIN", "USERADMIN", "SYSADMIN"]}, "correct_response": ["c"], "section": "Account Access & Security", "question_plain": "Which of these roles is granted the MANAGE GRANTS security privilege to be able to modify any grant globally, including revoking it?", "related_lectures": []}, {"_class": "assessment", "id": 69282502, "assessment_type": "multiple-choice", "prompt": {"question": "Which of these roles is dedicated to user and role management only?", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p><strong>USERADMIN role is dedicated to user and role management only.</strong> More specifically, this role: </p><ul><li><p>Is granted the CREATE USER and CREATE ROLE security privileges. </p></li><li><p>Can create users and roles in the account. </p></li></ul><p>This role can also manage users and roles that it owns. Only the role with the OWNERSHIP privilege on an object (i.e. user or role), or a higher role, can modify the object properties.</p>", "answers": ["ORGADMIN", "ACCOUNTADMIN", "SECURITYADMIN", "USERADMIN", "SYSADMIN"]}, "correct_response": ["d"], "section": "Account Access & Security", "question_plain": "Which of these roles is dedicated to user and role management only?", "related_lectures": []}, {"_class": "assessment", "id": 69282504, "assessment_type": "multiple-choice", "prompt": {"question": "Which role has privileges to create warehouses and databases (and other objects) in an account?", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p><strong>SYSADMIN role has privileges to create warehouses and databases (and other objects) in an account.</strong> This role also has the ability to grant privileges on warehouses, databases, and other objects to other roles.</p>", "answers": ["ORGADMIN", "ACCOUNTADMIN", "SECURITYADMIN", "USERADMIN", "SYSADMIN"]}, "correct_response": ["e"], "section": "Account Access & Security", "question_plain": "Which role has privileges to create warehouses and databases (and other objects) in an account?", "related_lectures": []}, {"_class": "assessment", "id": 69282506, "assessment_type": "multiple-choice", "prompt": {"question": "ACCOUNTADMIN role should not be used to create objects in Snowflake?(True/False)", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "<p><strong>The ACOOUNTADMIN role is intended for performing initial setup tasks in the system and managing account-level objects and tasks on a day-to-day basis.</strong> <strong>It should not be used to create objects in your account unless you absolutely need these objects to have the highest level of secure access.</strong></p>", "answers": ["TRUE", "FALSE"]}, "correct_response": ["a"], "section": "Account Access & Security", "question_plain": "ACCOUNTADMIN role should not be used to create objects in Snowflake?(True/False)", "related_lectures": []}, {"_class": "assessment", "id": 69282508, "assessment_type": "multiple-choice", "prompt": {"question": "Readers accounts enable providers to share data with consumers who are not already Snowflake customers without requiring the consumers to become Snowflake Customers. Which role can create the Reader account?", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p><strong>ACCOUNTADMIN role (or a role granted the CREATE ACCOUNT global privilege) only can create the Reader account.</strong></p>", "answers": ["SECURITYADMIN", "USERADMIN", "SYSADMIN", "ACCOUNTADMIN"]}, "correct_response": ["d"], "section": "Account Access & Security", "question_plain": "Readers accounts enable providers to share data with consumers who are not already Snowflake customers without requiring the consumers to become Snowflake Customers. Which role can create the Reader account?", "related_lectures": []}, {"_class": "assessment", "id": 69282510, "assessment_type": "multiple-choice", "prompt": {"question": "<p>ACCOUNTADMIN role cannot view the results for a query run by another user. (True/ False)</p>", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "<p>A user cannot view the result set from a query that another user executed. This behavior is intentional. For security reasons, only the user who executed a query can access the query results. This behavior is not connected to the Snowflake access control model for objects. <strong>Even a user with the ACCOUNTADMIN role cannot view the results for a query run by another user.</strong></p>", "answers": ["TRUE", "FALSE"]}, "correct_response": ["a"], "section": "Account Access & Security", "question_plain": "ACCOUNTADMIN role cannot view the results for a query run by another user. (True/ False)", "related_lectures": []}, {"_class": "assessment", "id": 69282512, "assessment_type": "multi-select", "prompt": {"question": "<p>Which of these roles can configure a network policy? (Select 2)</p>", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p>Only <strong>security administrators (i.e., users with the SECURITYADMIN role) or higher </strong>or a role with the global CREATE NETWORK POLICY privilege can create network policies.</p>", "answers": ["ACCOUNTADMIN", "SYSADMIN", "USERADMIN", "SECURITYADMIN", "PUBLIC"]}, "correct_response": ["a", "d"], "section": "Account Access & Security", "question_plain": "Which of these roles can configure a network policy? (Select 2)", "related_lectures": []}, {"_class": "assessment", "id": 69282514, "assessment_type": "multi-select", "prompt": {"question": "You can create an an account level network policy using _____ (Select all that apply)", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>Only security administrators (i.e., users with the SECURITYADMIN role) or higher or a role with the global CREATE NETWORK POLICY privilege can create network policies <strong>using Snowsight, Classic Web Interface, and SQL.</strong></p>", "answers": ["Snowsight", "Only Snowflake Support can create the Account level Network Policy", "SQL", "Classic Web Interface"]}, "correct_response": ["a", "c", "d"], "section": "Account Access & Security", "question_plain": "You can create an an account level network policy using _____ (Select all that apply)", "related_lectures": []}, {"_class": "assessment", "id": 69282516, "assessment_type": "multiple-choice", "prompt": {"question": "How many network policies can be activated for a user at a time?", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p><strong>Only a single network policy can be activated for each user at a time;</strong> however, different network policies can be activated for different users for granular control. Associating a network policy with a user automatically removes the currently-associated network policy (if any)</p>", "answers": ["99", "31", "1", "16", "100"]}, "correct_response": ["c"], "section": "Account Access & Security", "question_plain": "How many network policies can be activated for a user at a time?", "related_lectures": []}, {"_class": "assessment", "id": 69282518, "assessment_type": "multiple-choice", "prompt": {"question": "<p>You can create a user-level network policy using _____</p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p><strong>You can set a policy at the user level, but this can only be done through the SQL commands. </strong>To activate a network policy for an individual user, set the NETWORK_POLICY parameter for the user using ALTER USER.</p>", "answers": ["Snowsight", "Only Snowflake Support can create the Account level Network Policy", "SQL", "Classic Web Interface"]}, "correct_response": ["c"], "section": "Account Access & Security", "question_plain": "You can create a user-level network policy using _____", "related_lectures": []}, {"_class": "assessment", "id": 69282520, "assessment_type": "multiple-choice", "prompt": {"question": "Which SQL command determines whether a network policy is set on the account or for a specific user?", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p><strong>The SHOW PARAMETERS command determines whether a network policy is set on the account or for a specific user. </strong></p><p><strong>For Account level: </strong>SHOW PARAMETERS LIKE 'network_policy' IN ACCOUNT; </p><p><strong>For User level:</strong> SHOW PARAMETERS LIKE 'network_policy' IN USER &lt;username&gt;;&nbsp; </p><p><strong>Example</strong> - SHOW PARAMETERS LIKE 'network_policy' IN USER john;</p>", "answers": ["SHOW POLICY", "SHOW POLICIES", "SHOW PARAMETER", "SHOW PARAMETERS", "SHOW NETWORK_POLICIES"]}, "correct_response": ["d"], "section": "Account Access & Security", "question_plain": "Which SQL command determines whether a network policy is set on the account or for a specific user?", "related_lectures": []}, {"_class": "assessment", "id": 69282522, "assessment_type": "multi-select", "prompt": {"question": "Network policies allow restricting access to your account based on_____ (Select all that apply)", "relatedLectureIds": "", "feedbacks": ["", "", ""], "explanation": "<p><strong>Network policies allow restricting access to your account based on user IP address. Effectively, a network policy enables you to create an IP allowed list, as well as an IP blocked list, if desired.</strong></p>", "answers": ["User Operating System Type (example - MAC, Windows)", "IP address", "CIDR Notaion based IP ranges"]}, "correct_response": ["b", "c"], "section": "Account Access & Security", "question_plain": "Network policies allow restricting access to your account based on_____ (Select all that apply)", "related_lectures": []}, {"_class": "assessment", "id": 69282524, "assessment_type": "multi-select", "prompt": {"question": "Which are the required parameters for creating a Network Policy? (Select 2)", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p><strong>Policy Name and Allowed IP Addresses are mandatory for creating a Network Policy. </strong>Blocked IP Addresses and Comment Parameters are optional.</p><p>\n<strong>Please Note -</strong> If you provide both Allowed IP Addresses and Blocked IP Addresses, Snowflake applies the Blocked List first.</p>", "answers": ["Policy Name", "Allowed IP Addresses", "Blocked IP Addresses", "Comment"]}, "correct_response": ["a", "b"], "section": "Account Access & Security", "question_plain": "Which are the required parameters for creating a Network Policy? (Select 2)", "related_lectures": []}, {"_class": "assessment", "id": 69282526, "assessment_type": "multiple-choice", "prompt": {"question": "If you create a Network Policy by providing both &#39;Allowed IP Addresses&#39; and &#39;Blocked IP Addresses&#39;, which is applied first by Snowflake while validating the access? ", "answers": ["Allowed IP Addresses", "Blocked IP Addresses"], "explanation": "If you provide both Allowed IP Addresses and Blocked IP Addresses, Snowflake applies the Blocked List first."}, "correct_response": ["b"], "section": "Account Access & Security", "question_plain": "If you create a Network Policy by providing both &#39;Allowed IP Addresses&#39; and &#39;Blocked IP Addresses&#39;, which is applied first by Snowflake while validating the access?", "related_lectures": []}, {"_class": "assessment", "id": 69282528, "assessment_type": "multiple-choice", "prompt": {"question": "What will happen if you add 0.0.0.0/0 to BLOCKED_IP_LIST and your IP address to ALLOWED_IP_LIST of a Network policy?", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "<p>If you provide both Allowed IP Addresses and Blocked IP Addresses, <strong>Snowflake applies the Blocked List first.</strong> <strong>This would block your own access.</strong></p><p>\nAdditionally, in order to block all IP addresses except a select list, you only need to add IP addresses to ALLOWED_IP_LIST. Snowflake automatically blocks all IP addresses not included in the allowed list.</p>", "answers": ["You will be able to access the Snowflake account from your IP address", "You will not be able to access the Snowflake account from your IP address."]}, "correct_response": ["b"], "section": "Account Access & Security", "question_plain": "What will happen if you add 0.0.0.0/0 to BLOCKED_IP_LIST and your IP address to ALLOWED_IP_LIST of a Network policy?", "related_lectures": []}, {"_class": "assessment", "id": 69282530, "assessment_type": "multiple-choice", "prompt": {"question": "<p>Snowflake network policies currently support both Internet Protocol versions 4 and 6 (i.e., IPv4 as well as IPv6). (True/False)</p>", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "<p><strong>Network policies currently support only Internet Protocol version 4 (i.e. IPv4) addresses.</strong></p>", "answers": ["TRUE", "FALSE"]}, "correct_response": ["b"], "section": "Account Access & Security", "question_plain": "Snowflake network policies currently support both Internet Protocol versions 4 and 6 (i.e., IPv4 as well as IPv6). (True/False)", "related_lectures": []}, {"_class": "assessment", "id": 69282532, "assessment_type": "multiple-choice", "prompt": {"question": "What will happen if a policy is assigned to a user who is already signed in?", "relatedLectureIds": "", "feedbacks": ["", "", ""], "explanation": "<p>If a policy is assigned to a user who already signed in, they <strong>can't do anything else until they sign and signed back in again </strong>to make use of the new policy</p>", "answers": ["The user can continue running the SQL queries in the currently opened session. ", "There will be no interruption until the user logoffs and signs in again.", "The user can&#39;t do anything else until signed in and signed back in again."]}, "correct_response": ["c"], "section": "Account Access & Security", "question_plain": "What will happen if a policy is assigned to a user who is already signed in?", "related_lectures": []}, {"_class": "assessment", "id": 69282534, "assessment_type": "multiple-choice", "prompt": {"question": "Which of these is not a valid authentication method supported by Snowflake?", "relatedLectureIds": "", "feedbacks": ["", "", "", "", "", ""], "explanation": "<p>Snowflake supports the following authentication methods:&nbsp; </p><ul><li><p>Username and password</p></li><li><p>MFA</p></li><li><p>SAML</p></li><li><p>other authentication methods such as OAuth, Key-pair, and SCIM.</p></li></ul>", "answers": ["Username and password", "Username and one-time generated pin", "Muti-factor authentication", "Federated Authentication (SAM 2.0)", "Oauth, Key Pair", "SCIM (System for Cross-domain Identity Management specification)"]}, "correct_response": ["b"], "section": "Account Access & Security", "question_plain": "Which of these is not a valid authentication method supported by Snowflake?", "related_lectures": []}, {"_class": "assessment", "id": 69282536, "assessment_type": "multiple-choice", "prompt": {"question": "In a Snowflake federated environment, Snowflake serves as the Identity provider (IdP). (True/False)", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "<p>In a Snowflake federated environment, <strong>Snowflake serves as the Service Provider (SP).</strong> The external, independent entity like Okta serves as the Identify Provider (IdP)</p>", "answers": ["TRUE", "FALSE"]}, "correct_response": ["b"], "section": "Account Access & Security", "question_plain": "In a Snowflake federated environment, Snowflake serves as the Identity provider (IdP). (True/False)", "related_lectures": []}, {"_class": "assessment", "id": 69282538, "assessment_type": "multiple-choice", "prompt": {"question": "If a user is logged in to Snowflake in a federated environment and IdP times out, what does happen to the user&#39;s snowflake session?", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "<p><strong>After a specified period of time (defined by the IdP), a user\u2019s session in the IdP automatically times out, but this does not affect their Snowflake sessions. Any Snowflake sessions that are active at the time remain open and do not require re-authentication. However, to initiate any new Snowflake sessions, the user must log into the IdP again.</strong></p>", "answers": ["The Snowflake web interface is disabled, and the prompt for IdP authentication is displayed.", "It does not affect the user&#39;s Snowflake sessions. However, to initiate any new Snowflake sessions, the user must log into the IdP again."]}, "correct_response": ["b"], "section": "Account Access & Security", "question_plain": "If a user is logged in to Snowflake in a federated environment and IdP times out, what does happen to the user&#39;s snowflake session?", "related_lectures": []}, {"_class": "assessment", "id": 69282540, "assessment_type": "multiple-choice", "prompt": {"question": "In a federated Snowflake environment, can a user still log into Snowflake using their Snowflake credentials?", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "<p><strong>Users can still log into Snowflake using their Snowflake credentials.</strong></p>", "answers": ["Yes", "No"]}, "correct_response": ["a"], "section": "Account Access & Security", "question_plain": "In a federated Snowflake environment, can a user still log into Snowflake using their Snowflake credentials?", "related_lectures": []}, {"_class": "assessment", "id": 69282542, "assessment_type": "multiple-choice", "prompt": {"question": "Is it possible to create a user without a password?", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "<p><strong>Yes, it is possible to create a user in Snowflake without a password. </strong>We cannot use the Snowflake web interface to create users with no passwords or remove passwords from existing users, and <strong>we must use CREATE USER or ALTER USER.</strong> Without a password in Snowflake, a user cannot log in using Snowflake authentication and must use federated authentication instead.</p>", "answers": ["Yes", "No"]}, "correct_response": ["a"], "section": "Account Access & Security", "question_plain": "Is it possible to create a user without a password?", "related_lectures": []}, {"_class": "assessment", "id": 69282544, "assessment_type": "multiple-choice", "prompt": {"question": "If you drop or disable a user in Snowflake in an Okta IdP federated environment, the user can still access Snowflake login through Okta. (True/False)", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "<p><strong>Users who are dropped or disabled in Snowflake are still able to log into their Okta accounts, but they will receive an error message when they attempt to connect to Snowflake. You must recreate or enable the user before they can log in.</strong></p>", "answers": ["TRUE", "FALSE"]}, "correct_response": ["b"], "section": "Account Access & Security", "question_plain": "If you drop or disable a user in Snowflake in an Okta IdP federated environment, the user can still access Snowflake login through Okta. (True/False)", "related_lectures": []}, {"_class": "assessment", "id": 69282546, "assessment_type": "multiple-choice", "prompt": {"question": "If you create a user with MUST_CHANGE_PASSWORD = TRUE in a Snowflake federated environment, will that user be forced to change the password while logging through IdP the first time?", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "<p><strong>The MUST_CHANGE_PASSWORD user property does not apply for federated authentication and should not be used.</strong> In particular, if you choose not to maintain passwords in Snowflake for users, ensure this property is set to FALSE for these users.</p>", "answers": ["Yes", "No"]}, "correct_response": ["b"], "section": "Account Access & Security", "question_plain": "If you create a user with MUST_CHANGE_PASSWORD = TRUE in a Snowflake federated environment, will that user be forced to change the password while logging through IdP the first time?", "related_lectures": []}, {"_class": "assessment", "id": 69282548, "assessment_type": "multi-select", "prompt": {"question": "<p>Snowflake\u2019s approach to access control combines aspects from which of the following models? (Select 2)</p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>Snowflake\u2019s approach to access control combines aspects from both of the following models:&nbsp; &nbsp; &nbsp;</p><p><strong>Discretionary Access Control (DAC):</strong> Each object has an owner, who can in turn grant access to that object.&nbsp; &nbsp; &nbsp; </p><p><strong>Role-based Access Control (RBAC):</strong> Access privileges are assigned to roles, which are in turn assigned to users.</p>", "answers": ["Rule-based access control (RBAC)", "Role-based Access Control (RBAC)", "Discretionary Access Control (DAC)", "Mandatory Access Control (MAC)"]}, "correct_response": ["b", "c"], "section": "Account Access & Security", "question_plain": "Snowflake\u2019s approach to access control combines aspects from which of the following models? (Select 2)", "related_lectures": []}, {"_class": "assessment", "id": 69282550, "assessment_type": "multiple-choice", "prompt": {"question": "A user can be assigned multiple roles. (True / False)", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "<p>Roles are the entities to which privileges on securable objects can be granted and revoked. Roles are assigned to users to allow them to perform actions required for business functions in their organization. <strong>A user can be assigned multiple roles.</strong> It allows users to switch roles (i.e., choose which role is active in the current Snowflake session) to perform different actions using separate sets of privileges.</p>", "answers": ["TRUE", "FALSE"]}, "correct_response": ["a"], "section": "Account Access & Security", "question_plain": "A user can be assigned multiple roles. (True / False)", "related_lectures": []}, {"_class": "assessment", "id": 69282552, "assessment_type": "multi-select", "prompt": {"question": "A row access policy contains an expression that can specify Snowflake database objects (e.g., table or view) and use functions to determine which rows should be visible in a given context. Which of these functions are used in determining row access policy?(Select 2)", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>A row access policy uses <strong>Conditional Expression Functions and Context Functions</strong> to determine which rows should be visible in a given context. Context Functions such as CURRENT_USER(), CURRENT_ROLE(), and CURRENT_ACCOUNT(), which act as dynamic filters and are commonly used with secure views to limit row access in a table.</p>", "answers": ["Conversion Functions", "Context Functions", "Metadata Functions", "Conditional Expression Functions"]}, "correct_response": ["b", "d"], "section": "Account Access & Security", "question_plain": "A row access policy contains an expression that can specify Snowflake database objects (e.g., table or view) and use functions to determine which rows should be visible in a given context. Which of these functions are used in determining row access policy?(Select 2)", "related_lectures": []}, {"_class": "assessment", "id": 69282554, "assessment_type": "multiple-choice", "prompt": {"question": "A DBA_ROLE created a database. Later the DBA_ROLE was dropped. Who will own the database now, which was created by the DBA_ROLE?\t", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p><strong>The role that dropped the DBA_ROLE will own the database. </strong></p>", "answers": ["The database will get dropped too.", "No one will be able to access the database.", "The role that dropped the DBA_ROLE will own the database.", "The DBA_ROLE can&#39;t get dropped as it is the database owner."]}, "correct_response": ["c"], "section": "Account Access & Security", "question_plain": "A DBA_ROLE created a database. Later the DBA_ROLE was dropped. Who will own the database now, which was created by the DBA_ROLE?", "related_lectures": []}, {"_class": "assessment", "id": 69282556, "assessment_type": "multiple-choice", "prompt": {"question": "Snowflake blocks certain IPs by default to ensure that customer is getting the highest level of Network security. (TRUE / FALSE)\t", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "<p><strong>By default, Snowflake allows users to connect to the service from any computer or device IP address.</strong> A security administrator (or higher) can create a network policy to allow or deny access to a single IP address or a list of addresses.</p>", "answers": ["TRUE", "FALSE"]}, "correct_response": ["b"], "section": "Account Access & Security", "question_plain": "Snowflake blocks certain IPs by default to ensure that customer is getting the highest level of Network security. (TRUE / FALSE)", "related_lectures": []}, {"_class": "assessment", "id": 69282558, "assessment_type": "multiple-choice", "prompt": {"question": "What is the best practice after creating a custom role in a Snowflake account?", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>The custom role gets mainly created for specific access to specific objects. <strong>As per best practice, grant ownership to SYSADMIN or a child role under SYSADMIN so that SYSADMIN can control access to the objects.</strong>\t</p>", "answers": ["Grant PUBLIC to the role so all database objects owned by PUBLIC will be available to the new role.\t", "Grant the custom role to the SYSADMIN role so administrators can manage all objects in the account.", "Grant ownership of the role to itself so a member of the role can control access to the role.\t", "Grant the role to the USERADMIN role so users can be added to the role.\t"]}, "correct_response": ["b"], "section": "Account Access & Security", "question_plain": "What is the best practice after creating a custom role in a Snowflake account?", "related_lectures": []}, {"_class": "assessment", "id": 69282600, "assessment_type": "multiple-choice", "prompt": {"question": "Both non-materialized and materialized views can be defined as secure. (True / False)", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "<p><strong>Yes, both non-materialized and materialized views can be defined as secure. </strong></p>", "answers": ["TRUE", "FALSE"]}, "correct_response": ["a"], "section": "Account Access & Security", "question_plain": "Both non-materialized and materialized views can be defined as secure. (True / False)", "related_lectures": []}, {"_class": "assessment", "id": 69282602, "assessment_type": "multi-select", "prompt": {"question": "Choose the true statements about Secure views. (Select 2)", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p><strong>Both non-materialized and materialized views can be defined as secure. Secure views have advantages over standard views, including improved data privacy and data sharing; however, they also have some performance impacts to take into consideration.</strong></p>", "answers": ["Secure views provide improved data privacy and data sharing", "Secure views allow faster access than Standard views", "Only materialized views can be defined as secure", "Only non-materialized views can be defined as secure", "Both non-materialized and materialized views can be defined as secure"]}, "correct_response": ["a", "e"], "section": "Account Access & Security", "question_plain": "Choose the true statements about Secure views. (Select 2)", "related_lectures": []}, {"_class": "assessment", "id": 69282604, "assessment_type": "multiple-choice", "prompt": {"question": "The user access history can be found by querying the ", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>Access History in Snowflake refers to when the user query reads column data and when the SQL statement performs a data write operation, such as INSERT, UPDATE, and DELETE, along with variations of the COPY command, from the source data object to the target data object. <strong>The user access history can be found by querying the Account Usage ACCESS_HISTORY view.</strong></p>", "answers": ["Information Schema ACCESS_HISTORY view", "Account Usage ACCESS_HISTORY view", "Information Schema ACCESS_REPORT view", "Account Usage ACCESS_REPORT view"]}, "correct_response": ["b"], "section": "Account Access & Security", "question_plain": "The user access history can be found by querying the", "related_lectures": []}, {"_class": "assessment", "id": 69282606, "assessment_type": "multiple-choice", "prompt": {"question": "Which privilege is required to enable altering any properties of the resource monitor, such as changing the monthly credit quote?", "relatedLectureIds": "", "feedbacks": ["", "", ""], "explanation": "<p><strong>MODIFY</strong> - Enables altering any properties of a resource monitor, such as changing the monthly credit quota.\n</p><p>MONITOR - Enables viewing a resource monitor.</p>", "answers": ["USAGE", "MODIFY", "MONITOR"]}, "correct_response": ["b"], "section": "Account Access & Security", "question_plain": "Which privilege is required to enable altering any properties of the resource monitor, such as changing the monthly credit quote?", "related_lectures": []}, {"_class": "assessment", "id": 69282608, "assessment_type": "multiple-choice", "prompt": {"question": "Which privilege is required to execute queries using a virtual warehouse?", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>Virtual Warehouse Privileges:&nbsp; <strong>USAGE:</strong> Enables using a virtual warehouse and, as a result, executing queries on the warehouse. If the warehouse is configured to auto-resume when a SQL statement (e.g. query) is submitted to it, the warehouse resumes automatically and executes the statement.</p><p><strong>MODIFY:</strong>&nbsp; Enables altering any properties of a warehouse, including changing its size.&nbsp; &nbsp;Required assigning a warehouse to a resource monitor. Note that only the ACCOUNTADMIN role can assign warehouses to resource monitors.</p><p><strong>MONITOR:</strong> Enables viewing of current and past queries executed on a warehouse as well as usage statistics on that warehouse. \t&nbsp; </p><p><strong>OPERATE:</strong> Enables changing the state of a warehouse (stop, start, suspend, resume). In addition, enables viewing current and past queries executed on a warehouse and aborting any executing queries. \t&nbsp; &nbsp;\t&nbsp; </p><p><strong>OWNERSHIP:</strong> Grants full control over a warehouse. Only a single role can hold this privilege on a specific object at a time.</p>", "answers": ["USAGE", "MODIFY", "MONITOR", "OPERATE"]}, "correct_response": ["a"], "section": "Account Access & Security", "question_plain": "Which privilege is required to execute queries using a virtual warehouse?", "related_lectures": []}, {"_class": "assessment", "id": 69282610, "assessment_type": "multi-select", "prompt": {"question": "<p>The major benefits of defining Clustering keys:&nbsp; (Select 2)</p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p><strong>Defining&nbsp;clustering keys&nbsp;for very large tables (in the multi-terabyte range) helps optimize table maintenance and query performance.</strong> Small tables are not a good candidate for clustering. </p>", "answers": ["To help optimize table maintenance", "To help improve query performance", "To help in faster data sharing", "To help in organizing small tables (&lt;1 GB)"]}, "correct_response": ["a", "b"], "section": "Performance Concepts", "question_plain": "The major benefits of defining Clustering keys:&nbsp; (Select 2)", "related_lectures": []}, {"_class": "assessment", "id": 69282612, "assessment_type": "multiple-choice", "prompt": {"question": "<p>The closer the ratio of scanned micro-partitions and columnar data is to the ratio of actual data selected, the more efficient the pruning performed on the table. (TRUE/FALSE)</p>", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "Snowflake uses columnar scanning of partitions so that an entire partition is not scanned if a query only filters by one column. The closer the ratio of scanned micro-partitions and columnar data is to the ratio of actual data selected, the more efficient is the pruning performed on the table", "answers": ["TRUE", "FALSE"]}, "correct_response": ["a"], "section": "Performance Concepts", "question_plain": "The closer the ratio of scanned micro-partitions and columnar data is to the ratio of actual data selected, the more efficient the pruning performed on the table. (TRUE/FALSE)", "related_lectures": []}, {"_class": "assessment", "id": 69282614, "assessment_type": "multiple-choice", "prompt": {"question": "Snowflake prunes micro-partitions based on a predicate with a subquery, even if the subquery result is constant. (TRUE/FALSE)", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "<p>Please note, not all predicate expressions can be used to prune. <strong>Snowflake does not prune micro-partitions based on a predicate with a subquery, even if the subquery results in a constant.</strong></p>", "answers": ["TRUE", "FALSE"]}, "correct_response": ["b"], "section": "Performance Concepts", "question_plain": "Snowflake prunes micro-partitions based on a predicate with a subquery, even if the subquery result is constant. (TRUE/FALSE)", "related_lectures": []}, {"_class": "assessment", "id": 69282616, "assessment_type": "multiple-choice", "prompt": {"question": "Which of these are kind of Cache in Snowflake?", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>Snowflake has three types of cache. </p><ul><li><p>The metadata cache that lives in the cloud services layer. </p></li></ul><ul><li><p>The data cache/local disk cache that lives on the SSD drives in the virtual warehouses</p></li></ul><ul><li><p>The query result cache. If a result is small, it will be stored in the cloud services layer, but larger results are going to be stored in the storage layer. </p></li></ul>", "answers": ["Metadata Cache", "Data/Local Disk Cache", "Query Result Cache", "All of these"]}, "correct_response": ["d"], "section": "Performance Concepts", "question_plain": "Which of these are kind of Cache in Snowflake?", "related_lectures": []}, {"_class": "assessment", "id": 69282618, "assessment_type": "multi-select", "prompt": {"question": "Which of these SQL Queries can be answered completely by Metadata? (Select 3)", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p><strong>SHOW Commands, MIN, MAX (integers and dates), and COUNT SQL queries take advantage of the Metadata cache and do not require the virtual warehouse, but you still have some cloud service charges.</strong></p>", "answers": ["SHOW Commands", "MIN, MAX (integers and dates)", "COUNT", "AVG", "None of these"]}, "correct_response": ["a", "b", "c"], "section": "Performance Concepts", "question_plain": "Which of these SQL Queries can be answered completely by Metadata? (Select 3)", "related_lectures": []}, {"_class": "assessment", "id": 69282620, "assessment_type": "multiple-choice", "prompt": {"question": "Monica has run a query SELECT * FROM t1; After a couple of hours, John ran the same query. John has the same role as Monica and has the SELECT permissions on table t1. John got the result sooner than Monica. What could be the reason for the faster result?", "answers": ["John&#39;s query resulted from the Metadata cache.", "John&#39;s query resulted from the Query Result cache.", "John&#39;s query resulted from the Local Disk cache.", "John&#39;s query resulted from Remote disk."], "explanation": "It is a typical use case of Query Result Cache. It is stored and managed by the Cloud Services Layer. It is used if the identical query is run and base tables (t1 in this case) have not changed. Query Result Cache doesn&#39;t require Virtual Warehouse and is available for other users in the same role with SELECT permissions on all tables in the query."}, "correct_response": ["b"], "section": "Performance Concepts", "question_plain": "Monica has run a query SELECT * FROM t1; After a couple of hours, John ran the same query. John has the same role as Monica and has the SELECT permissions on table t1. John got the result sooner than Monica. What could be the reason for the faster result?", "related_lectures": []}, {"_class": "assessment", "id": 69282622, "assessment_type": "multiple-choice", "prompt": {"question": "How long do results remain in the Query results cache?", "answers": ["12 hours", "1 hours", "31 hours", "24 hours", "16 hours"], "explanation": " Results are retained for 24 hours in Query Result Cache. Snowflake resets the 24-hour retention period for the result, up to a maximum of 31 days from the date and time that the query was first executed. After 31 days, the result is purged and the next time the query is submitted, a new result is generated and persisted."}, "correct_response": ["d"], "section": "Performance Concepts", "question_plain": "How long do results remain in the Query results cache?", "related_lectures": []}, {"_class": "assessment", "id": 69282624, "assessment_type": "multiple-choice", "prompt": {"question": "Will these queries be considered as same to get the benefit of the Query Result cache?\n\nQuery 1 :  SELECT * FROM t1;\nQuery 2 : select * FROM t1;", "answers": ["YES", "NO"], "explanation": "These queries will not be considered as same to get the benefit of the Query Result cache. First Query has &#39;SELECT&#39; is upper case, and the Second query has &#39;select&#39; in lower case."}, "correct_response": ["b"], "section": "Performance Concepts", "question_plain": "Will these queries be considered as same to get the benefit of the Query Result cache?\n\nQuery 1 :  SELECT * FROM t1;\nQuery 2 : select * FROM t1;", "related_lectures": []}, {"_class": "assessment", "id": 69282626, "assessment_type": "multi-select", "prompt": {"question": "Choose the false statements. (Select 2)", "answers": ["Group and Execute similar queries on the same virtual warehouse to maximize local disk cache reuse, for performance and cost optimization.", "Group and Execute similar queries on the different virtual warehouses to maximize local disk cache reuse, for performance and cost optimization.", "Results are stored in SSD in Virtual Warehouse in case of Local Disk Cache.", "Results are stored in the Cloud Storage layer in the case of Local Disk Cache. ", "If Virtual Warehouse is suspended, then results in Local Disk Cache will be lost"], "explanation": "As a best practice, Group and Execute similar queries on the same virtual warehouse to maximize local disk cache reuse for performance and cost optimization. The results get stored in the SSD of Virtual Warehouse. So, if the Virtual Warehouse gets suspended, then results get lost. "}, "correct_response": ["b", "d"], "section": "Performance Concepts", "question_plain": "Choose the false statements. (Select 2)", "related_lectures": []}, {"_class": "assessment", "id": 69282628, "assessment_type": "multiple-choice", "prompt": {"question": "How can we turn off the query result cache?", "answers": ["Setting the parameter USE_CACHED_INFO to FALSE", "Setting the parameter USE_CACHED_RESULT to FALSE", "Setting the parameter USE_QUERY_CACHED to FALSE", "Query result cache can be turned off. "], "explanation": "We can turn off the query result cache by setting the parameter USE_CACHED_RESULT to FALSE. Though the only reason we would really want to do this is if we are doing performance testing."}, "correct_response": ["b"], "section": "Performance Concepts", "question_plain": "How can we turn off the query result cache?", "related_lectures": []}, {"_class": "assessment", "id": 69282630, "assessment_type": "multiple-choice", "prompt": {"question": "When the Virtual Warehouse data cache gets filled up, in which fashion does the data get flushed out from the data cache?", "answers": ["First In First Out (FIFO)", "Last In Last Out (LILO)", "MOST-RECENTLY USED (MRU)", "LEAST-RECENTLY USED (LRU)"], "explanation": "If the cache does fill up, it is flushed out in a least-recently used fashion."}, "correct_response": ["d"], "section": "Performance Concepts", "question_plain": "When the Virtual Warehouse data cache gets filled up, in which fashion does the data get flushed out from the data cache?", "related_lectures": []}, {"_class": "assessment", "id": 69282632, "assessment_type": "multi-select", "prompt": {"question": "What key insights can we get from the Explain plan in Snowflake? (Select 3)", "answers": ["Partition Pruning", "Join Ordering", "Join Types", "Estimated Query Time", "Exact Query Time"], "explanation": "The key insights that the explain plan gives us in its results output are information on partition pruning, join ordering, and join types.\nThe explain plan is a useful tool for determining the efficiency of your query. It&#39;s a command that compiles your query to figure out all the steps Snowflake would have to work through if it were actually to run the query."}, "correct_response": ["a", "b", "c"], "section": "Performance Concepts", "question_plain": "What key insights can we get from the Explain plan in Snowflake? (Select 3)", "related_lectures": []}, {"_class": "assessment", "id": 69282634, "assessment_type": "multi-select", "prompt": {"question": "Monica ran a SELECT query on a large table t1. The query took longer than expected. She looked into the query profile and found that &#39; Bytes spilled to local storage&#39; and &#39;Bytes spilled to remote storage&#39; are very high. What advice will you give to her to improve the query performance? (Select 3)", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p>When Snowflake warehouse cannot fit an operation in memory, it starts spilling (storing) data first to the local disk of a warehouse node and then to remote storage. In such a case, Snowflake first tries to temporarily store the data on the warehouse's local disk. As this means extra IO operations, any query that requires spilling will take longer than a similar query running on similar data that is capable to fit the operations in memory. Also, if the local disk is insufficient to fit the spilled data, Snowflake further tries to write to the remote cloud storage, which will be shown in the query profile as \"Bytes spilled to remote storage\".&nbsp; </p><p><strong>The spilling can't always be avoided, especially for large batches of data, but it can be decreased by:&nbsp; </strong></p><ul><li><p>Reducing the amount of data processed. For example, by trying to improve partition pruning or projecting only the columns that are needed in the output. </p></li><li><p>Decreasing the number of parallel queries running in the warehouse. </p></li><li><p>Trying to split the processing into several steps (for example, by replacing the CTEs with temporary tables). </p></li><li><p>Using a larger warehouse - effectively means more memory and more local disk space.</p></li></ul>", "answers": ["Using a larger warehouse (effectively increasing the available memory/local disk space for the operation)", "Processing data in smaller batches", "Increasing the number of parallel queries running in the warehouse", "Trying to split the processing into several steps", "Processing data in larger batches"]}, "correct_response": ["a", "b", "d"], "section": "Performance Concepts", "question_plain": "Monica ran a SELECT query on a large table t1. The query took longer than expected. She looked into the query profile and found that &#39; Bytes spilled to local storage&#39; and &#39;Bytes spilled to remote storage&#39; are very high. What advice will you give to her to improve the query performance? (Select 3)", "related_lectures": []}, {"_class": "assessment", "id": 69282636, "assessment_type": "multi-select", "prompt": {"question": "<p>Which of the Snowflake shared view can be used to query the Snowflake Query History? (Select 1)</p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p><strong>QUERY_HISTORY view in ACCOUNT_USAGE</strong> view can be used to query Snowflake query history by various dimensions (time range, session, user, warehouse, etc.) within the last 365 days (1 year).</p>", "answers": ["<p>QUERY_HISTORY_VIEW view in INFORMATION_USAGE </p>", "<p>QUERY_HISTORY_VIEW view in ACCOUNT_USAGE </p>", "<p>QUERY_HISTORY view in ACCOUNT_USAGE </p>", "QUERY_HISTORY view in INFORMATION_SCHEMA"]}, "correct_response": ["c"], "section": "Performance Concepts", "question_plain": "Which of the Snowflake shared view can be used to query the Snowflake Query History? (Select 1)", "related_lectures": []}, {"_class": "assessment", "id": 69282638, "assessment_type": "multiple-choice", "prompt": {"question": "John has a table EMPLOYEE_DATA, and he wants to create another table EMPLOYEE_DATA_OTHER, which should be the same as EMPLOYEE_DATA table with the same data. What is the best option for John?", "answers": ["Create the table with same data with SQL command as follows - \n\nCREATE TABLE EMPLOYEE_DATA_OTHER AS SELECT * FROM EMPLOYEE_DATA;", "Clone the table with same data with SQL command as follows - \n\nCREATE TABLE EMPLOYEE_DATA_OTHER CLONE EMPLOYEE_DATA;", "CREATE SHARE EMPLOYEE_DATA;", "Create the table with LIKE SQL command as follows -\n\n CREATE TABLE EMPLOYEE_DATA_OTHER LIKE EMPLOYEE_DATA;"], "explanation": "The best option is to Clone the table as EMPLOYEE_DATA and EMPLOYEE_DATA_OTHER have the same structure and data. It will help save the storage cost. LIKE command only creates the empty table. CREATE TABLE \u2026 AS SELECT (also referred to as CTAS)\nCreates a new table populated with the data returned by a query but consumes additional storage."}, "correct_response": ["b"], "section": "Performance Concepts", "question_plain": "John has a table EMPLOYEE_DATA, and he wants to create another table EMPLOYEE_DATA_OTHER, which should be the same as EMPLOYEE_DATA table with the same data. What is the best option for John?", "related_lectures": []}, {"_class": "assessment", "id": 69282640, "assessment_type": "multiple-choice", "prompt": {"question": "Snowflake Query history page allows you to view the details of all the queries executed in the last 31 days. (True/False)", "answers": ["TRUE", "FALSE"], "explanation": "Snowflake Query history page allows you to view the details of all the queries executed in the last 14 days. You can query the Query_History view in Snowflake&#39;s Account Usage schema for older queries."}, "correct_response": ["b"], "section": "Performance Concepts", "question_plain": "Snowflake Query history page allows you to view the details of all the queries executed in the last 31 days. (True/False)", "related_lectures": []}, {"_class": "assessment", "id": 69282642, "assessment_type": "multiple-choice", "prompt": {"question": "If you have privileges to view queries executed by another user, the Query Detail page displays the details for the query and the actual query result. (TRUE/FALSE)", "answers": ["TRUE", "FALSE"], "explanation": "If you have privileges to view queries executed by another user, the Query Detail page displays the details for the query, but, for data privacy reasons, the page does not display the actual query result."}, "correct_response": ["b"], "section": "Performance Concepts", "question_plain": "If you have privileges to view queries executed by another user, the Query Detail page displays the details for the query and the actual query result. (TRUE/FALSE)", "related_lectures": []}, {"_class": "assessment", "id": 69282644, "assessment_type": "multiple-choice", "prompt": {"question": "How many servers are available in a large-sized cluster warehouse?", "answers": ["1", "8", "16", "32", "64", "128"], "explanation": "There are eight servers available in a large-sized cluster warehouse."}, "correct_response": ["b"], "section": "Performance Concepts", "question_plain": "How many servers are available in a large-sized cluster warehouse?", "related_lectures": []}, {"_class": "assessment", "id": 69282646, "assessment_type": "multi-select", "prompt": {"question": "There are two modes to set up a multi-cluster warehouse. Select those from the given choices.", "answers": ["Minimized mode", "Maximized mode", "Auto-scaling mode", "Maximum mode", "Minimum mode"], "explanation": "There are two ways to set up a multi-cluster warehouse: in maximized mode, or auto-scaling mode. With maximized mode, you simply set your minimum equal to your maximum, and those values are something greater than one."}, "correct_response": ["b", "c"], "section": "Performance Concepts", "question_plain": "There are two modes to set up a multi-cluster warehouse. Select those from the given choices.", "related_lectures": []}, {"_class": "assessment", "id": 69282648, "assessment_type": "multi-select", "prompt": {"question": "<p>Which of these are types of Scaling policies? (Select 2)</p>", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p>There are two different scaling policies, one is the <strong>Standard</strong> policy, and one is the <strong>Economy</strong> policy.</p>", "answers": ["Maximized", "Standard", "Business", "Economy", "Minimized"]}, "correct_response": ["b", "d"], "section": "Performance Concepts", "question_plain": "Which of these are types of Scaling policies? (Select 2)", "related_lectures": []}, {"_class": "assessment", "id": 69282650, "assessment_type": "multiple-choice", "prompt": {"question": "Suppose you have an auto-scaling mode setup with a Standard policy. In what situation does Snowflake spin up an additional cluster?", "answers": ["Only if the system estimates there\u2019s enough query load to keep the cluster busy for at least 6 minutes.", "The first cluster starts immediately when either a query is queued or the system detects that there\u2019s one more query than the currently-running clusters can execute."], "explanation": "In Standard Scaling policy, the first cluster starts immediately when either a query is queued, or the system detects that there\u2019s one more query than the currently-running clusters can execute.\nEach successive cluster waits to start 20 seconds after the prior one has started. For example, if your warehouse is configured with ten max clusters, it can take 200+ seconds to start all 10 clusters."}, "correct_response": ["b"], "section": "Performance Concepts", "question_plain": "Suppose you have an auto-scaling mode setup with a Standard policy. In what situation does Snowflake spin up an additional cluster?", "related_lectures": []}, {"_class": "assessment", "id": 69282652, "assessment_type": "multiple-choice", "prompt": {"question": "Suppose you have an auto-scaling mode setup with a Economy policy. In what situation does Snowflake spin up an additional cluster?", "answers": ["Only if the system estimates there\u2019s enough query load to keep the cluster busy for at least 6 minutes.", "The first cluster starts immediately when either a query is queued or the system detects that there\u2019s one more query than the currently-running clusters can execute."], "explanation": "In Economy Scaling policy, Snowflake spins up an additional cluster only if the system estimates there\u2019s enough query load to keep the cluster busy for a least 6 minutes"}, "correct_response": ["a"], "section": "Performance Concepts", "question_plain": "Suppose you have an auto-scaling mode setup with a Economy policy. In what situation does Snowflake spin up an additional cluster?", "related_lectures": []}, {"_class": "assessment", "id": 69282654, "assessment_type": "multiple-choice", "prompt": {"question": "Which of these configurations will set up a warehouse in maximized mode?", "answers": ["Minimum Clusters = 1 and Maximum Clusters = 10", "Minimum Clusters = 6 and Maximum Clusters = 6", "Minimum Clusters = 1 and Maximum Clusters = 1", "Minimum Clusters = 9 and Maximum Clusters = 10"], "explanation": "Maximized mode is enabled by specifying the same value for both maximum and minimum number of clusters (note that the specified value must be larger than 1). In this mode, when the warehouse is started, Snowflake starts all the clusters so that maximum resources are available while the warehouse is running. This mode is effective for statically controlling the available compute resources, particularly if you have large numbers of concurrent user sessions and/or queries and the numbers do not fluctuate significantly."}, "correct_response": ["b"], "section": "Performance Concepts", "question_plain": "Which of these configurations will set up a warehouse in maximized mode?", "related_lectures": []}, {"_class": "assessment", "id": 69282656, "assessment_type": "multiple-choice", "prompt": {"question": "Which of these configurations will set up a warehouse in auto-scale mode?", "answers": ["Minimum Clusters = 2 and Maximum Clusters = 6", "Minimum Clusters = 6 and Maximum Clusters = 6"], "explanation": "Auto-scale mode is enabled by specifying different values for maximum and minimum number of clusters. "}, "correct_response": ["a"], "section": "Performance Concepts", "question_plain": "Which of these configurations will set up a warehouse in auto-scale mode?", "related_lectures": []}, {"_class": "assessment", "id": 69282658, "assessment_type": "multiple-choice", "prompt": {"question": "Multi-cluster warehouses are beneficial in improving the performance of slow-running queries or data loading. (True/False)", "answers": ["TRUE", "FALSE"], "explanation": "Multi-cluster warehouses are best utilized for scaling resources to improve concurrency for users/queries. They are not as beneficial for improving the performance of slow-running queries or data loading. For these types of operations, resizing the warehouse provides more benefits."}, "correct_response": ["b"], "section": "Performance Concepts", "question_plain": "Multi-cluster warehouses are beneficial in improving the performance of slow-running queries or data loading. (True/False)", "related_lectures": []}, {"_class": "assessment", "id": 69282660, "assessment_type": "multiple-choice", "prompt": {"question": "What is the minimum billing charge for provisioning compute resources?", "answers": ["1 second", "30 seconds", "60 seconds", "120 seconds"], "explanation": "The minimum billing charge for provisioning compute resources is 1 minute (i.e. 60 seconds). There is no benefit to stopping a warehouse before the first 60-second period is over because the credits have already been billed for that period."}, "correct_response": ["c"], "section": "Performance Concepts", "question_plain": "What is the minimum billing charge for provisioning compute resources?", "related_lectures": []}, {"_class": "assessment", "id": 69282662, "assessment_type": "multiple-choice", "prompt": {"question": "What is the best way to analyze the optimum warehouse size?", "answers": ["Execute queries of widely-varying size and/or complexity on the same warehouse", "Execute relatively homogeneous queries (size, complexity, data sets, etc.) on the same warehouse"], "explanation": "To achieve the best results, try to execute relatively homogeneous queries (size, complexity, data sets, etc.) on the same warehouse; executing queries of widely-varying size and/or complexity on the same warehouse makes it more difficult to analyze warehouse load, which can make it more difficult to select the best size to match the size, composition, and number of queries in your workload."}, "correct_response": ["b"], "section": "Performance Concepts", "question_plain": "What is the best way to analyze the optimum warehouse size?", "related_lectures": []}, {"_class": "assessment", "id": 69282664, "assessment_type": "multiple-choice", "prompt": {"question": "When deciding whether to suspend a warehouse or leave it running, what should you consider?", "answers": ["Consider the trade-off between saving credits by suspending the warehouse versus the operational cost of resuming the warehouse when needed. ", "Consider suspending the warehouse if the warehouse is large and there are no active queries.", "Consider the trade-off between saving credits by suspending the warehouse versus maintaining the cache of data from the previous queries to help with performance."], "explanation": "Consider the trade-off between saving credits by suspending a warehouse versus maintaining the cache of data from previous queries to help with performance."}, "correct_response": ["c"], "section": "Performance Concepts", "question_plain": "When deciding whether to suspend a warehouse or leave it running, what should you consider?", "related_lectures": []}, {"_class": "assessment", "id": 69282666, "assessment_type": "multiple-choice", "prompt": {"question": "What is a key benefit of scaling up a warehouse?", "answers": ["Scaling up improves performance.", "Scaling up improves concurrency."], "explanation": "Resizing a warehouse generally improves query performance, particularly for larger, more complex queries. It can also help reduce the queuing that occurs if a warehouse does not have enough compute resources to process all the queries that are submitted concurrently. Note that warehouse resizing is not intended for handling concurrency issues; instead, use additional warehouses to handle the workload or use a multi-cluster warehouse."}, "correct_response": ["a"], "section": "Performance Concepts", "question_plain": "What is a key benefit of scaling up a warehouse?", "related_lectures": []}, {"_class": "assessment", "id": 69282668, "assessment_type": "multiple-choice", "prompt": {"question": "What is a key benefit of scaling out a warehouse?", "answers": ["Scaling out improves performance.", "Scaling out improves concurrency."], "explanation": "Scaling out is explicitly designed for handling queuing and performance issues related to large numbers of concurrent users and/or queries. "}, "correct_response": ["b"], "section": "Performance Concepts", "question_plain": "What is a key benefit of scaling out a warehouse?", "related_lectures": []}, {"_class": "assessment", "id": 69282670, "assessment_type": "multiple-choice", "prompt": {"question": "What would happen if we suspend the warehouse while it is executing the SQL statement?", "answers": ["All the compute resources of the warehouse will be shut down immediately, and the running statement will be canceled.", "Only idle compute resources of the warehouse will be shut down, allowing any compute resources executing statements to continue until the statement is complete.", "All compute resources of the warehouse will be up until the statement is complete.", "When trying to suspend the warehouse, we will get an error while the same warehouse is executing SQL statements."], "explanation": "When we suspend a warehouse, Snowflake immediately shuts down all idle compute resources for the warehouse. However, it allows any compute resources executing statements to continue until the statements are complete. At this time, the resources are shut down, and the warehouse status changes to \u201cSuspended\u201d. Compute resources waiting to shut down are considered to be in \u201cquiesce\u201d mode."}, "correct_response": ["b"], "section": "Performance Concepts", "question_plain": "What would happen if we suspend the warehouse while it is executing the SQL statement?", "related_lectures": []}, {"_class": "assessment", "id": 69282672, "assessment_type": "multiple-choice", "prompt": {"question": "Suppose we resize a warehouse to a larger size while it is executing SQL statements. In that case, the already running SQL statements will finish faster. (True / False)", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "<p><strong>Resizing a warehouse doesn\u2019t have any impact on statements that are currently being executed</strong> by the warehouse. When resizing to a larger size, the new compute resources, once fully provisioned, are used only to execute statements that are already in the warehouse queue, as well as all future statements submitted to the warehouse.</p>", "answers": ["TRUE", "FALSE"]}, "correct_response": ["b"], "section": "Performance Concepts", "question_plain": "Suppose we resize a warehouse to a larger size while it is executing SQL statements. In that case, the already running SQL statements will finish faster. (True / False)", "related_lectures": []}, {"_class": "assessment", "id": 69282674, "assessment_type": "multiple-choice", "prompt": {"question": "Suppose we resize a warehouse to a smaller size while it is executing SQL statements. There will be no impact on already executing SQL statements. (True / False)", "answers": ["TRUE", "FALSE"], "explanation": "Resizing a warehouse does not impact the statements that the warehouse is executing. When resizing to a smaller size, compute resources are removed from the warehouse only when they are no longer used to execute any current statements."}, "correct_response": ["a"], "section": "Performance Concepts", "question_plain": "Suppose we resize a warehouse to a smaller size while it is executing SQL statements. There will be no impact on already executing SQL statements. (True / False)", "related_lectures": []}, {"_class": "assessment", "id": 69282676, "assessment_type": "multiple-choice", "prompt": {"question": "The suspended warehouse cannot be resized until they resume. (True / False)", "answers": ["TRUE", "FALSE"], "explanation": "The suspended warehouse can be easily resized. Resizing a suspended warehouse does not provision any new compute resources for the warehouse. It simply instructs Snowflake to provision the additional compute resources when the warehouse is next resumed, at which time all the usage and credit rules associated with starting a warehouse apply."}, "correct_response": ["b"], "section": "Performance Concepts", "question_plain": "The suspended warehouse cannot be resized until they resume. (True / False)", "related_lectures": []}, {"_class": "assessment", "id": 69282678, "assessment_type": "multiple-choice", "prompt": {"question": "During Warehouse provisioning, if any of the compute resources fail to provision, then Snowflake kills the entire warehouse provisioning and tries to provision a new warehouse of the same requested size. (True/False)", "answers": ["TRUE", "FALSE"], "explanation": "Snowflake does not begin executing SQL statements submitted to a warehouse until all of the compute resources for the warehouse are successfully provisioned, unless any of the resources fail to provision:\n\nIf any of the compute resources for the warehouse fail to provision during start-up, Snowflake attempts to repair the failed resources.\n\nDuring the repair process, the warehouse starts processing SQL statements once 50% or more of the requested compute resources are successfully provisioned."}, "correct_response": ["b"], "section": "Performance Concepts", "question_plain": "During Warehouse provisioning, if any of the compute resources fail to provision, then Snowflake kills the entire warehouse provisioning and tries to provision a new warehouse of the same requested size. (True/False)", "related_lectures": []}, {"_class": "assessment", "id": 69282680, "assessment_type": "multiple-choice", "prompt": {"question": "The warehouse performance can be evaluated by querying the ", "answers": ["Account Usage LOAD_HISTORY view", "Account Usage QUERY_HISTORY view", "Information Schema QUERY_HISTORY view", "Information Schema LOAD_HISTORY view"], "explanation": "The warehouse performance can be evaluated by querying the Account Usage QUERY_HISTORY view."}, "correct_response": ["b"], "section": "Performance Concepts", "question_plain": "The warehouse performance can be evaluated by querying the", "related_lectures": []}, {"_class": "assessment", "id": 69282682, "assessment_type": "multiple-choice", "prompt": {"question": "Which schema can be used to find out about storage, compute, and objects in a Snowflake account?", "answers": ["RESOURCE_SCHEMA", "SNOWFLAKE_SCHEMA", "USAGE_SCHEMA", "INFORMATION_SCHEMA"], "explanation": "INFORMATION_SCHEMA can be used to find out about storage, compute, and objects in a Snowflake account. Every database that you create on Snowflake has a schema called INFORMATION_SCHEMA that&#39;s automatically created, and inside that schema, you can find views and table functions that provide metadata information about objects in your account."}, "correct_response": ["d"], "section": "Performance Concepts", "question_plain": "Which schema can be used to find out about storage, compute, and objects in a Snowflake account?", "related_lectures": []}, {"_class": "assessment", "id": 69282684, "assessment_type": "multiple-choice", "prompt": {"question": "The BI group is complaining about their queries taking too long to run. Checking the virtual warehouse information shows that the queued time is pretty high. What is the best way to fix this issue?", "answers": ["Provide a virtual warehouse for every user in the group", "Increase the size of the virtual warehouse", "Determine which users have the high priority queries and set the other users", "Set the STATEMENT_QUEUED_TIMEOUT_IN_SECONDS parameter to a low value to cancel those queries if they get in the queue", "Increase the virtual warehouse MAX_CLUSTER_COUNT property"], "explanation": "Queuing can be solved by SCALE-OUT (provision new clusters), i.e., increasing MAX_CLUSTER_COUNT helps in additional cluster provisioning to handle the concurrent workloads.  "}, "correct_response": ["e"], "section": "Performance Concepts", "question_plain": "The BI group is complaining about their queries taking too long to run. Checking the virtual warehouse information shows that the queued time is pretty high. What is the best way to fix this issue?", "related_lectures": []}, {"_class": "assessment", "id": 69282686, "assessment_type": "multi-select", "prompt": {"question": " You have a dashboard that connects to Snowflake via JDBC. The dashboard is refreshed hundreds of times per day. The data is very stable, only changing once or twice per day. The query run by the dashboard user never changes. How will Snowflake manage changing and non-changing data? Mark all true statements. ", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p><strong>Until data has not changed and the query is the same - Snowflake reuses the data from the cache.</strong> Please note,&nbsp; Each time the persisted result for a query is reused, Snowflake resets the 24-hour retention period for the result up to a maximum of 31 days from the date and time that the query was first executed. After 31 days, the result is purged, and the next time the query is submitted, a new result is generated and persisted.\t</p>", "answers": ["Snowflake will show the most up-to-date data each time the dashboard is refreshed.", "<p>Snowflake will spin up a warehouse only if the underlying data has changed.</p>", "<p> Snowflake will compile result cache data from all user results, so no warehouse is needed.</p>", "<p>&nbsp; Snowflake will re-use data from the Results Cache as long as it is still the most up-to-date data available.\t&nbsp; \n </p>"]}, "correct_response": ["a", "b", "d"], "section": "Performance Concepts", "question_plain": "You have a dashboard that connects to Snowflake via JDBC. The dashboard is refreshed hundreds of times per day. The data is very stable, only changing once or twice per day. The query run by the dashboard user never changes. How will Snowflake manage changing and non-changing data? Mark all true statements.", "related_lectures": []}, {"_class": "assessment", "id": 69282688, "assessment_type": "multiple-choice", "prompt": {"question": "David ran a query that took around 30 mins to complete. He referred to the Query profiler and found the &#39;Bytes spilled to local storage&#39; has a big number. What could be the issue?\t", "answers": ["David is using a comparatively larger warehouse.", "David is using a comparatively smaller warehouse. ", "Warehouse size has no impact on Bytes spilling.", "David should contact Snowflake Personnel.  "], "explanation": "If a node has insufficient memory to complete its portion of a query, it will &quot;spill&quot; to local SSD storage. This can negatively impact performance but is sometimes acceptable. If a node has insufficient local SSD storage to complete its portion of a query, it will &quot;spill&quot; to remote cloud storage. This is almost always very bad for performance. The solution, in either case, is to simplify the SQL query or increase the warehouse size."}, "correct_response": ["b"], "section": "Performance Concepts", "question_plain": "David ran a query that took around 30 mins to complete. He referred to the Query profiler and found the &#39;Bytes spilled to local storage&#39; has a big number. What could be the issue?", "related_lectures": []}, {"_class": "assessment", "id": 69282690, "assessment_type": "multi-select", "prompt": {"question": "<p>Materialized views are particularly useful when:</p><p>(Select 3)</p>", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "Materialized views are particularly useful when:\n\n- Query results contain a small number of rows and/or columns relative to the base table (the table on which the view is defined).\n\n- Query results contain results that require significant processing, including:\n\tAnalysis of semi-structured data.\n\tAggregates that take a long time to calculate.\n\n- The query is on an external table (i.e., data sets stored in files in an external stage), which might have a slower performance compared to querying native database tables.\n\n- The view\u2019s base table does not change frequently.", "answers": ["Query results contain a small number of rows and/or columns relative to the base table (the table on which the view is defined).", "Query results contain results that require simple processing.", "Query results contain results that require significant processing.", "The view\u2019s base table changes frequently.", "The view\u2019s base table does not change frequently."]}, "correct_response": ["a", "c", "e"], "section": "Performance Concepts", "question_plain": "Materialized views are particularly useful when:(Select 3)", "related_lectures": []}, {"_class": "assessment", "id": 69282692, "assessment_type": "multiple-choice", "prompt": {"question": "Materialized views can improve the performance of queries that use the same subquery results repeatedly. (True/False)", "answers": ["TRUE", "FALSE"], "explanation": "Materialized views are designed to improve query performance for workloads composed of common, repeated query patterns. However, materializing intermediate results incur additional costs. As such, before creating any materialized views, you should consider whether the costs are offset by the savings from re-using these results frequently enough."}, "correct_response": ["a"], "section": "Performance Concepts", "question_plain": "Materialized views can improve the performance of queries that use the same subquery results repeatedly. (True/False)", "related_lectures": []}, {"_class": "assessment", "id": 69282694, "assessment_type": "multiple-choice", "prompt": {"question": "An account-level resource monitor overrides the resource monitor assignment for individual warehouses. (True/False)", "answers": ["TRUE", "FALSE"], "explanation": "An account-level resource monitor does not override resource monitor assignments for individual warehouses. If either the account resource monitor or the warehouse resource monitor reaches its defined threshold and a suspend action has been defined, the warehouse is suspended."}, "correct_response": ["b"], "section": "Performance Concepts", "question_plain": "An account-level resource monitor overrides the resource monitor assignment for individual warehouses. (True/False)", "related_lectures": []}, {"_class": "assessment", "id": 69282696, "assessment_type": "multiple-choice", "prompt": {"question": "Which privilege is required to enable changing the state of a warehouse (stop, start, suspend, resume)?", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "MODIFY - Enables altering any properties of a warehouse, including changing its size. Required to assign a warehouse to a resource monitor. Note that only the ACCOUNTADMIN role can assign warehouses to resource monitors.\n\nMONITOR - Enables viewing current and past queries executed on a warehouse as well as usage statistics on that warehouse.\n\nOPERATE - Enables changing the state of a warehouse (stop, start, suspend, resume). In addition, enables viewing current and past queries executed on a warehouse and aborting any executing queries.\n\nUSAGE - Enables using a virtual warehouse and, as a result, executing queries on the warehouse. If the warehouse is configured to auto-resume when a SQL statement (e.g. query) is submitted to it, the warehouse resumes automatically and executes the statement.\n\nOWNERSHIP - Grants full control over a warehouse. Only a single role can hold this privilege on a specific object at a time.\n\nALL [ PRIVILEGES ] - Grants all privileges, except OWNERSHIP, on the warehouse.", "answers": ["MODIFY", "MONITOR", "OPERATE", "USAGE"]}, "correct_response": ["c"], "section": "Performance Concepts", "question_plain": "Which privilege is required to enable changing the state of a warehouse (stop, start, suspend, resume)?", "related_lectures": []}, {"_class": "assessment", "id": 69282698, "assessment_type": "multiple-choice", "prompt": {"question": "If you want to create a warehouse that remains in a suspended state initially, which property do you need to set for that warehouse?", "answers": ["AUTO_SUSPEND = 0", " INITIALLY_SUSPENDED = TRUE", "AUTO_RESUME = TRUE", "AUTO_RESUME = FALSE", "AUTO_SUSPEND = TRUE"], "explanation": "INITIALLY_SUSPENDED = TRUE | FALSE  Specifies whether the warehouse is created initially in the \u2018Suspended\u2019 state.\nThe valid values are TRUE and FALSE.\n\n            TRUE: The warehouse is created, but suspended.\n\n            FALSE: The warehouse starts running after it is created.\n\n    Default is  FALSE\n"}, "correct_response": ["b"], "section": "Performance Concepts", "question_plain": "If you want to create a warehouse that remains in a suspended state initially, which property do you need to set for that warehouse?", "related_lectures": []}]}
5053396
~~~
{"count": 90, "next": null, "previous": null, "results": [{"_class": "assessment", "id": 71099274, "assessment_type": "multi-select", "prompt": {"question": "<p>What are the possible values for the VALIDATION_MODE option in the COPY INTO &lt;table&gt; statement?</p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>The VALIDATION_MODE parameter in the COPY INTO &lt;table&gt; command instructs the command to validate the data files instead of loading them into the specified table. This means the COPY command will test the files for errors, but not actually load them. The command will validate the data based on the specified validation option:<br></p><ul><li><p><strong>RETURN_&lt;n&gt;_ROWS</strong> (e.g. RETURN_10_ROWS): Validates the specified number of rows and fails at the first error encountered if any, otherwise the validation continues without error.<br></p></li><li><p><strong>RETURN_ERRORS</strong>: Returns all errors across all specified files, including parsing and conversion errors.<br></p></li><li><p><strong>RETURN_ALL_ERRORS</strong>: Returns all errors across all specified files, including errors that were partially loaded during a previous load with the ON_ERROR option set to CONTINUE.<br><br></p></li></ul><p>The syntax for the VALIDATION_MODE parameter is: VALIDATION_MODE = RETURN_&lt;n&gt;_ROWS | RETURN_ERRORS | RETURN_ALL_ERRORS.<br><br><strong>It is important to note that the option RETURN_ROWS can only be used with the COPY INTO &lt;location&gt; command and not with COPY INTO &lt;table&gt;. </strong>This option is the only one available for the VALIDATION_MODE in COPY INTO &lt;location&gt;.</p>", "answers": ["<p>RETURN_ROWS</p>", "<p>RETURN_&lt;n&gt;_ROWS</p>", "<p>RETURN_ERRORS</p>", "<p>RETURN_ALL_ERRORS</p>"]}, "correct_response": ["b", "c", "d"], "section": "Data Loading and Unloading", "question_plain": "What are the possible values for the VALIDATION_MODE option in the COPY INTO &lt;table&gt; statement?", "related_lectures": []}, {"_class": "assessment", "id": 71099276, "assessment_type": "multiple-choice", "prompt": {"question": "What is the recommended compressed size of data files for optimal bulk data loads?", "answers": ["10-50 MB", "10-50 GB", "100-250 MB", "100-250 GB"], "explanation": "The number of load operations that run in parallel cannot exceed the number of data files to be loaded. To optimize the number of parallel operations for a load, we recommend aiming to produce data files roughly 100-250 MB (or larger) in size compressed. "}, "correct_response": ["c"], "section": "Data Loading and Unloading", "question_plain": "What is the recommended compressed size of data files for optimal bulk data loads?", "related_lectures": []}, {"_class": "assessment", "id": 71099278, "assessment_type": "multiple-choice", "prompt": {"question": "What size limit does VARIANT data type impose on individual rows?", "answers": ["16 GB", "10 GB", "16 MB", "10 MB", "100 MB"], "explanation": "The VARIANT data type imposes a 16 MB size limit on individual rows."}, "correct_response": ["c"], "section": "Data Loading and Unloading", "question_plain": "What size limit does VARIANT data type impose on individual rows?", "related_lectures": []}, {"_class": "assessment", "id": 71099280, "assessment_type": "multiple-choice", "prompt": {"question": "John is trying to load JSON data sets with a huge array containing multiple records. Considering the VARIANT data type imposed size of 16 MB, what do you recommend to John for optimally loading the data?", "answers": ["Separate the documents with line break of commas", "Enable the STRIP_OUTER_ARRAY file format option for the COPY INTO &lt;table&gt; command", "Enable VARIANT_OUTER_ARRAY file format for the COPY INTO &lt;table&gt; command", "No need to remove the outer array structure as Snowflake Intelligent Engine will take care of that"], "explanation": "If the data exceeds 16 MB, enable the STRIP_OUTER_ARRAY file format option for the COPY INTO &lt;table&gt; command to remove the outer array structure and load the records into separate table rows:\n\ncopy into &lt;table&gt;\n  from @~/&lt;file&gt;.json\n  file_format = (type = &#39;JSON&#39; strip_outer_array = true);\n"}, "correct_response": ["b"], "section": "Data Loading and Unloading", "question_plain": "John is trying to load JSON data sets with a huge array containing multiple records. Considering the VARIANT data type imposed size of 16 MB, what do you recommend to John for optimally loading the data?", "related_lectures": []}, {"_class": "assessment", "id": 71099282, "assessment_type": "multiple-choice", "prompt": {"question": "The best use of Snowpipe is to load large volumes of data and incrementally make them available for analysis. (True/False)", "answers": ["TRUE", "FALSE"], "explanation": "Snowpipe is designed to load small volume of data (i.e., micro-batches) and incrementally make them available for analysis."}, "correct_response": ["b"], "section": "Data Loading and Unloading", "question_plain": "The best use of Snowpipe is to load large volumes of data and incrementally make them available for analysis. (True/False)", "related_lectures": []}, {"_class": "assessment", "id": 71099284, "assessment_type": "multiple-choice", "prompt": {"question": "What size of the virtual warehouse needs to be created by the sysadmin while loading using Snowpipe? (Select the best answer)", "answers": ["L Size", "4XL Size", "XS Size", "M Size", "None of these"], "explanation": "Snowpipe uses compute resources provided by Snowflake (i.e. a serverless compute model). These Snowflake-provided resources are automatically resized and scaled up or down as required, and are charged and itemized using per-second billing. Data ingestion is charged based upon the actual workloads. User doesn&#39;t need to create any warehouse as it is taken care by Snowflake."}, "correct_response": ["e"], "section": "Data Loading and Unloading", "question_plain": "What size of the virtual warehouse needs to be created by the sysadmin while loading using Snowpipe? (Select the best answer)", "related_lectures": []}, {"_class": "assessment", "id": 71099286, "assessment_type": "multiple-choice", "prompt": {"question": "Which of the following file format is not supported by Snowflake?", "answers": ["CSV", "AVRO", "ORC", "PARQUET", "JSON", "EDI"], "explanation": "Snowflake supports - CSV, TSV, JSON, AVRO, ORC, PARQUET. Snowflake also supports XML which is a Preview feature as of now. EDI format is not supported by Snowflake. "}, "correct_response": ["f"], "section": "Data Loading and Unloading", "question_plain": "Which of the following file format is not supported by Snowflake?", "related_lectures": []}, {"_class": "assessment", "id": 71099288, "assessment_type": "multiple-choice", "prompt": {"question": "What of the following is the default character set for delimited files (CSV, TSV, etc.)?", "answers": ["UTF-16BE", "UTF-8", "UTF-16", "UTF-32", "UTF-32LE"], "explanation": "UTF-8 is the default character set for delimited files (CSV, TSV, etc.). Snowflake also supports all others in the provided options, but you must explicitly specify the encoding to use for loading."}, "correct_response": ["b"], "section": "Data Loading and Unloading", "question_plain": "What of the following is the default character set for delimited files (CSV, TSV, etc.)?", "related_lectures": []}, {"_class": "assessment", "id": 71099290, "assessment_type": "multiple-choice", "prompt": {"question": "When staging uncompressed files in a Snowflake stage, Snowflake automatically compresses the files unless compression is explicitly disabled. Which of the options is used by Snowflake for compressing the file?", "answers": ["deflate", "bzip2", "Brotli", "gzip", "Zstandard"], "explanation": "When staging uncompressed files in a Snowflake stage, the files are automatically compressed using gzip, unless compression is explicitly disabled."}, "correct_response": ["d"], "section": "Data Loading and Unloading", "question_plain": "When staging uncompressed files in a Snowflake stage, Snowflake automatically compresses the files unless compression is explicitly disabled. Which of the options is used by Snowflake for compressing the file?", "related_lectures": []}, {"_class": "assessment", "id": 71099292, "assessment_type": "multi-select", "prompt": {"question": "Which of these compression methods are supported by Snowflake? (Select all that apply)", "answers": ["gzip", "bzip2", "deflate", "raw_deflate", "Brotli", "Zstandard"], "explanation": "All of these are supported by Snowflake. Snowflake can automatically detect any of these compression methods except Brotli and Zstandard."}, "correct_response": ["a", "b", "c", "d", "e", "f"], "section": "Data Loading and Unloading", "question_plain": "Which of these compression methods are supported by Snowflake? (Select all that apply)", "related_lectures": []}, {"_class": "assessment", "id": 71099392, "assessment_type": "multiple-choice", "prompt": {"question": "VARIANT is used to FLATTEN hierarchical data. (True / False)", "answers": ["TRUE", "FALSE"], "explanation": "VARIANT is a data type that can hold a value of any other data type (including ARRAY and OBJECT). VARIANT is used to build and store hierarchical data. VARIANT is not a function to FLATTEN. \n\nFLATTEN is a table function that is used to produce a lateral view of a VARIANT, OBJECT, or ARRAY column."}, "correct_response": ["b"], "section": "Data Transformation", "question_plain": "VARIANT is used to FLATTEN hierarchical data. (True / False)", "related_lectures": []}, {"_class": "assessment", "id": 71099394, "assessment_type": "multiple-choice", "prompt": {"question": "Which data does not fit into a predefined data model or schema?", "answers": ["Structured-data", "Semi-Structured Data", "Unstructured Data", "All of these"], "explanation": "Unstructured data is information that does not fit into a predefined data model or schema. Typically text-heavy, such as form responses and social media conversations, unstructured data also encompasses images, video, and audio. Industry-specific file types such as VCF (genomics), KDF (semiconductors), or HDF5 (aeronautics) are included in this category."}, "correct_response": ["c"], "section": "Data Transformation", "question_plain": "Which data does not fit into a predefined data model or schema?", "related_lectures": []}, {"_class": "assessment", "id": 71099396, "assessment_type": "multi-select", "prompt": {"question": "Which of these are unstructured data? (Select 2)", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p><strong>Unstructured data is information that does not fit into a predefined data model or schema. Typically text-heavy, such as form responses and social media conversations, unstructured data also encompasses images, video, and audio. Industry-specific file types such as VCF (genomics), KDF (semiconductors), or HDF5 (aeronautics) are included in this category.</strong></p>", "answers": ["JSON", "Relational Data", "Images", "XML", "Videos"]}, "correct_response": ["c", "e"], "section": "Data Transformation", "question_plain": "Which of these are unstructured data? (Select 2)", "related_lectures": []}, {"_class": "assessment", "id": 71099294, "assessment_type": "multi-select", "prompt": {"question": "Which options for selecting staged data files are supported by COPY command in Snowflake? (Select that all apply)", "answers": ["By path (internal stages) / prefix (Amazon S3 bucket)", "Using pattern matching to identify specific files by pattern\n", "Specifying a list of specific files to load"], "explanation": "All of these are supported. These options enable you to copy a fraction of the staged data into Snowflake with a single command. This allows you to execute concurrent COPY statements that match a subset of files, taking advantage of parallel operations."}, "correct_response": ["a", "b", "c"], "section": "Data Loading and Unloading", "question_plain": "Which options for selecting staged data files are supported by COPY command in Snowflake? (Select that all apply)", "related_lectures": []}, {"_class": "assessment", "id": 71099296, "assessment_type": "multiple-choice", "prompt": {"question": "Which is the fastest option for selecting staged data files to load from a stage?", "answers": ["By path (internal stages) / prefix (Amazon S3 bucket)", "Using pattern matching to identify specific files by pattern\n", "Specifying a list of specific files to load"], "explanation": "Of the three options for identifying/specifying data files to load from a stage, providing a discrete list of files is generally the fastest; however, the FILES parameter supports a maximum of 1,000 files, meaning a COPY command executed with the FILES parameter can only load up to 1,000 files.\n\nExample:\n\ncopy into load1 from @%load1/data1/ files=(&#39;test1.csv&#39;, &#39;test2.csv&#39;, &#39;test3.csv&#39;, &#39;test4.csv&#39;)"}, "correct_response": ["c"], "section": "Data Loading and Unloading", "question_plain": "Which is the fastest option for selecting staged data files to load from a stage?", "related_lectures": []}, {"_class": "assessment", "id": 71099298, "assessment_type": "multiple-choice", "prompt": {"question": "Which is generally the slowest option for selecting staged data files to load from a stage?", "answers": ["By path (internal stages) / prefix (Amazon S3 bucket)", "Using pattern matching to identify specific files by pattern\n", "Specifying a list of specific files to load"], "explanation": "Pattern matching using a regular expression is generally the slowest of the three options for identifying/specifying data files to load from a stage; however, this option works well if you exported your files in named order from your external application and want to batch load the files in the same order"}, "correct_response": ["b"], "section": "Data Loading and Unloading", "question_plain": "Which is generally the slowest option for selecting staged data files to load from a stage?", "related_lectures": []}, {"_class": "assessment", "id": 71099300, "assessment_type": "multiple-choice", "prompt": {"question": "Loading into Snowflake from a local file system is a straightforward affair. Which command is used to grab files from the local system, compress them and encrypt them, and then it copies them to Snowflake?", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p><strong>Using the PUT command in SnowSQL.</strong> It grabs the file or files, compresses them, encrypts them, and then copies them up into the stage you chose. Once in the stage, you can use a COPY INTO command to load the data from the stage into Snowflake tables.</p>", "answers": ["GET command", "PUT command", "COPY INTO &lt;table&gt;", "MOVE command"]}, "correct_response": ["b"], "section": "Data Loading and Unloading", "question_plain": "Loading into Snowflake from a local file system is a straightforward affair. Which command is used to grab files from the local system, compress them and encrypt them, and then it copies them to Snowflake?", "related_lectures": []}, {"_class": "assessment", "id": 71099302, "assessment_type": "multiple-choice", "prompt": {"question": "John wants to load data files from an external stage to Snowflake. He has split the large file into smaller 100 - 250 MB data files, and there is a total of 16 smaller data files. What warehouse size would you recommend him to use for loading these data files quickly and cost-effectively?", "answers": ["XS", "S", "M", "L", "XL"], "explanation": "XS sized warehouse can load eight files parallelly. \nS sized warehouse can load sixteen files parallelly. \nM sized warehouse can load thirty-two files parallelly.\nL sized warehouse can load sixty-four files parallelly.\nXL sized warehouse can load one hundred twenty-eight files parallelly and so on. "}, "correct_response": ["b"], "section": "Data Loading and Unloading", "question_plain": "John wants to load data files from an external stage to Snowflake. He has split the large file into smaller 100 - 250 MB data files, and there is a total of 16 smaller data files. What warehouse size would you recommend him to use for loading these data files quickly and cost-effectively?", "related_lectures": []}, {"_class": "assessment", "id": 71099304, "assessment_type": "multiple-choice", "prompt": {"question": "If you recreate a pipe using CREATE OR REPLACE PIPE command.\nWhat does happen to load history if the Snowpipe gets recreated?", "answers": ["Snowflake still keeps load history", "The recreated Pipe still has tracks of the files loaded by the old Pipe", "The pipe can not be recreated", "The load history gets reset to empty"], "explanation": "When you recreate a pipe, if you do CREATE OR REPLACE PIPE, that load history is reset to empty, so Snowflake doesn&#39;t know which files we&#39;ve already loaded."}, "correct_response": ["d"], "section": "Data Loading and Unloading", "question_plain": "If you recreate a pipe using CREATE OR REPLACE PIPE command.\nWhat does happen to load history if the Snowpipe gets recreated?", "related_lectures": []}, {"_class": "assessment", "id": 71099306, "assessment_type": "multi-select", "prompt": {"question": "<p>There are multiple ways you can trigger the loading of files from the stage into Snowpipe. <strong>Select two ways </strong>generally used to trigger the loading with Snowpipe.</p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "Automating Snowpipe using cloud messaging (notification) and Calling Snowpipe REST endpoints are the mostly uses methods for triggering loading with Snowpipe. ", "answers": ["Automating Snowpipe using cloud messaging (notification)", "Calling Snowpipe SOAP endpoints", "By executing START PIPE &lt;pipe_name&gt;", "Calling Snowpipe REST endpoints"]}, "correct_response": ["a", "d"], "section": "Data Loading and Unloading", "question_plain": "There are multiple ways you can trigger the loading of files from the stage into Snowpipe. Select two ways generally used to trigger the loading with Snowpipe.", "related_lectures": []}, {"_class": "assessment", "id": 71099308, "assessment_type": "multiple-choice", "prompt": {"question": "What does OVERWRITE parameter do with INSERT command?", "answers": ["It de-duplicates while inserting and skips the insert if there is an exact similar record in the table.", "It specifies that the target table should be truncated before inserting the values into the table.", "It helps ignore any errors while inserting the values into the table.", "It drops the table, recreates, and inserts the values into the table. "], "explanation": "OVERWRITE specifies that the target table should be truncated before inserting the values into the table. Note that specifying this option does not affect the access control privileges on the table."}, "correct_response": ["b"], "section": "Data Loading and Unloading", "question_plain": "What does OVERWRITE parameter do with INSERT command?", "related_lectures": []}, {"_class": "assessment", "id": 71099310, "assessment_type": "multiple-choice", "prompt": {"question": "John has to create a PIPE that will be triggered for loading by calling the Snowpipe REST endpoints. What parameter does he need to specify in CREATE PIPE statement?", "answers": ["AUTO_INGEST = FALSE", "API_INGEST = TRUE", "AUTO_INGEST = TRUE", "API_INGEST = FALSE"], "explanation": "AUTO_INGEST = TRUE enables automatic data loading. Snowpipe supports loading from external stages (Amazon S3, Google Cloud Storage, or Microsoft Azure).\n\nAUTO_INGEST = FALSE disables automatic data loading. You must make calls to the Snowpipe REST API endpoints to load data files.\n"}, "correct_response": ["a"], "section": "Data Loading and Unloading", "question_plain": "John has to create a PIPE that will be triggered for loading by calling the Snowpipe REST endpoints. What parameter does he need to specify in CREATE PIPE statement?", "related_lectures": []}, {"_class": "assessment", "id": 71099312, "assessment_type": "multi-select", "prompt": {"question": "<p>Which methods can be used to check the status of a COPY INTO command? (Select 3)</p>", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p><strong>The status of COPY INTO command can be checked from the Resource Monitors tab in the Snowflake user interface, as well as querying the INFORMATION_SCHEMA.LOAD_HISTORY and ACCOUNT_USAGE.LOAD_HISTORY view.</strong></p>", "answers": ["Use the resource monitor.", "Write a SQL query against the INFORMATION_SCHEMA.LOAD_HISTORY view.", "Write a SQL query against the ACCOUNT_USAGE.LOAD_HISTORY view.", "Use the Query History tab in the Snowflake user interface.", "<p>Write a SQL query against the ACCOUNT_SCHEMA.LOAD_HISTORY view.</p>"]}, "correct_response": ["b", "c", "d"], "section": "Data Loading and Unloading", "question_plain": "Which methods can be used to check the status of a COPY INTO command? (Select 3)", "related_lectures": []}, {"_class": "assessment", "id": 71099314, "assessment_type": "multiple-choice", "prompt": {"question": "If a file in a stage has the LAST_MODIFIED date older than 64 days and the initial set of data was loaded into the table more than 64 days earlier. In this case, to prevent any data loss, the COPY command loads the file by default. (True / False)", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "<p><strong>The COPY command cannot definitively determine whether a file has been loaded already if the LAST_MODIFIED date is older than 64 days and the initial set of data was loaded into the table more than 64 days earlier (and if the file was loaded into the table, that also occurred more than 64 days earlier). In this case, to prevent accidental reload, the command skips the file by default.</strong></p>", "answers": ["TRUE", "FALSE"]}, "correct_response": ["b"], "section": "Data Loading and Unloading", "question_plain": "If a file in a stage has the LAST_MODIFIED date older than 64 days and the initial set of data was loaded into the table more than 64 days earlier. In this case, to prevent any data loss, the COPY command loads the file by default. (True / False)", "related_lectures": []}, {"_class": "assessment", "id": 71099316, "assessment_type": "multi-select", "prompt": {"question": "Which copyOptions can help load a file with expired metadata (if the LAST_MODIFIED date is older than 64 days and the initial set of data was loaded into the table more than 64 days earlier (and if the file was loaded into the table, that also occurred more than 64 days earlier))? (Select 2)", "relatedLectureIds": "", "feedbacks": ["", "", "", "", "", ""], "explanation": "To load files whose metadata has expired, set the LOAD_UNCERTAIN_FILES copy option to true. The copy option references load metadata, if available, to avoid data duplication, but also attempts to load files with expired load metadata.\n\nAlternatively, set the FORCE option to load all files, ignoring load metadata if it exists. Note that this option reloads files, potentially duplicating data in a table.", "answers": ["LOAD_FILES = TRUE", "LOAD_CERTAIN_FILES = TRUE", "LOAD_UNCERTAIN_FILES = TRUE", "FORCE = FALSE", "FORCE = TRUE", "ON_ERROR = CONTINUE"]}, "correct_response": ["c", "e"], "section": "Data Loading and Unloading", "question_plain": "Which copyOptions can help load a file with expired metadata (if the LAST_MODIFIED date is older than 64 days and the initial set of data was loaded into the table more than 64 days earlier (and if the file was loaded into the table, that also occurred more than 64 days earlier))? (Select 2)", "related_lectures": []}, {"_class": "assessment", "id": 71099318, "assessment_type": "multiple-choice", "prompt": {"question": "David wants to load a JSON file using the COPY INTO &lt;table&gt; command. He found that there are null values in the data for missing values and have no other special meaning. What file format option would you recommend him to use with COPY INTO &lt;table&gt; command to handle the JSON null values?", "answers": ["David should use REPLACE_INVALID_CHARACTERS = TRUE", "David should use STRIP_OUTER_ELEMENT = TRUE", "David should use STRIP_OUTER_ELEMENT = FALSE", "David should use STRIP_NULL_VALUES = TRUE", "David should use STRIP_NULL_VALUES = FALSE"], "explanation": "In a VARIANT column, NULL values are stored as a string containing the word \u201cnull,\u201d not the SQL NULL value. If the \u201cnull\u201d values in your JSON documents indicate missing values and have no other special meaning, you should recommend setting the file format option STRIP_NULL_VALUES to TRUE for the COPY INTO &lt;table&gt; command when loading the JSON files. Retaining the \u201cnull\u201d values often wastes storage and slows query processing."}, "correct_response": ["d"], "section": "Data Loading and Unloading", "question_plain": "David wants to load a JSON file using the COPY INTO &lt;table&gt; command. He found that there are null values in the data for missing values and have no other special meaning. What file format option would you recommend him to use with COPY INTO &lt;table&gt; command to handle the JSON null values?", "related_lectures": []}, {"_class": "assessment", "id": 71099320, "assessment_type": "multiple-choice", "prompt": {"question": "Which copy option is used to delete the file from the Snowflake stage when data from staged files are loaded successfully?", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>Staged files can be deleted from a Snowflake stage (user stage, table stage, or named stage) using the following methods:</p><ol><li><p>Files that were loaded successfully can be deleted from the stage during a load by specifying the PURGE copy option in the COPY INTO &lt;table&gt; command. </p></li><li><p>After the load completes, use the REMOVE command to remove the files in the stage. </p><p><br></p><p>Please note, DELETE or REMOVE are not COPY command options. REMOVE is a different DML command which is used to remove files in the stage. </p></li></ol>", "answers": ["REMOVE = TRUE", "PURGE = TRUE", "DELETE = TRUE", "DEL = TRUE"]}, "correct_response": ["b"], "section": "Data Loading and Unloading", "question_plain": "Which copy option is used to delete the file from the Snowflake stage when data from staged files are loaded successfully?", "related_lectures": []}, {"_class": "assessment", "id": 71099322, "assessment_type": "multiple-choice", "prompt": {"question": "What is the purpose of VALIDATION_MODE in the COPY INTO &lt;table&gt; command?", "answers": ["VALIDATION_MODE is used to validate the load file and load it into the specified table if there is no error.", "VALIDATION_MODE is used to validate the load file for errors instead of loading it into the specified table.", "VALIDATION_MODE is used to validate the load file, skip the errored data and then load it into the specified table."], "explanation": "VALIDATION_MODE instructs the COPY command to validate the data files instead of loading them into the specified table; i.e., the COPY command tests the files for errors but does not load them. The command validates the data to be loaded and returns results based on the validation option specified:\n\nSyntax : VALIDATION_MODE = RETURN_n_ROWS | RETURN_ERRORS | RETURN_ALL_ERRORS\n\nRETURN_n_ROWS (e.g. RETURN_10_ROWS) - Validates the specified number of rows, if no errors are encountered; otherwise, fails at the first error encountered in the rows.\n\nRETURN_ERRORS - Returns all errors (parsing, conversion, etc.) across all files specified in the COPY statement.\n\nRETURN_ALL_ERRORS - Returns all errors across all files specified in the COPY statement, including files with errors that were partially loaded during an earlier load because the ON_ERROR copy option was set to CONTINUE during the load."}, "correct_response": ["b"], "section": "Data Loading and Unloading", "question_plain": "What is the purpose of VALIDATION_MODE in the COPY INTO &lt;table&gt; command?", "related_lectures": []}, {"_class": "assessment", "id": 71099324, "assessment_type": "multiple-choice", "prompt": {"question": "<p>Which compression method does Snowflake use for unloaded data files by default?</p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>By default, all unloaded data files in Snowflake are compressed using the gzip compression method, unless compression is explicitly disabled or one of the other supported compression methods, such as bzip2 or Brotli, is explicitly specified. Gzip is a widely used compression method that provides a balance of high compression and fast decompression speeds, making it a suitable default option in Snowflake.\n </p>", "answers": ["bzip2", "gzip", "Brotli", "Zstandard"]}, "correct_response": ["b"], "section": "Data Loading and Unloading", "question_plain": "Which compression method does Snowflake use for unloaded data files by default?", "related_lectures": []}, {"_class": "assessment", "id": 71099326, "assessment_type": "multiple-choice", "prompt": {"question": "<p>What is the character set used for encoding output files in Snowflake?</p>", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p>In Snowflake, all output files are encoded using the UTF-8 character set. No other character sets are supported. The use of UTF-8 ensures compatibility with a wide range of platforms and applications.</p>", "answers": ["<p>UTF</p>", "UTF-8", "UTF-16", "UTF-32", "<p>Big5</p>"]}, "correct_response": ["b"], "section": "Data Loading and Unloading", "question_plain": "What is the character set used for encoding output files in Snowflake?", "related_lectures": []}, {"_class": "assessment", "id": 71099328, "assessment_type": "multiple-choice", "prompt": {"question": "How can you unload the data from Snowflake using COPY INTO location statements in a Single file?", "answers": ["By specifying copy option SINGLE=TRUE", "By specifying copy option MULTIPLE=FALSE", "By specifying copy option ONE_FILE=TRUE", "By specifying copy option MULTIPLE_FILES=FALSE"], "explanation": "To unload data to a single output file (at the potential cost of decreased performance), specify the SINGLE = true copy option in your statement. You can optionally specify a name for the file in the path."}, "correct_response": ["a"], "section": "Data Loading and Unloading", "question_plain": "How can you unload the data from Snowflake using COPY INTO location statements in a Single file?", "related_lectures": []}, {"_class": "assessment", "id": 71099330, "assessment_type": "multiple-choice", "prompt": {"question": "Which function can be used in combination with COPY command to convert the rows in a relational table to a single VARIANT column and unload the rows into a file?", "answers": ["UNLOAD_CONSTRUCT", "COPY_CONSTRUCT", "VARIANT_CONSTRUCT", "OBJECT_CONSTRUCT"], "explanation": "The OBJECT_CONSTRUCT function can be used in combination with the COPY command to convert the rows in a relational table to a single VARIANT column and unload the rows into a file."}, "correct_response": ["d"], "section": "Data Loading and Unloading", "question_plain": "Which function can be used in combination with COPY command to convert the rows in a relational table to a single VARIANT column and unload the rows into a file?", "related_lectures": []}, {"_class": "assessment", "id": 71099332, "assessment_type": "multiple-choice", "prompt": {"question": "What is the preferred way to distinguish empty strings from NULLs while unloading in CSV files?", "answers": ["Leave string fields unenclosed by setting the FIELD_OPTIONALLY_ENCLOSED_BY option to NONE.", "Enclose strings in quotes by setting the FIELD_OPTIONALLY_ENCLOSED_BY option.", "Set EMPTY_FIELD_AS_NULL to TRUE", "Set EMPTY_FIELD_AS_NULL to FALSE"], "explanation": "An empty string is typically represented by a quoted empty string (e.g. &#39;&#39;) to indicate that the string contains zero characters. The preferred way is to enclose strings in quotes by setting the FIELD_OPTIONALLY_ENCLOSED_BY option, to distinguish empty strings from NULLs in output CSV files."}, "correct_response": ["b"], "section": "Data Loading and Unloading", "question_plain": "What is the preferred way to distinguish empty strings from NULLs while unloading in CSV files?", "related_lectures": []}, {"_class": "assessment", "id": 71099334, "assessment_type": "multi-select", "prompt": {"question": "<p>What all options are available for data transformation while loading data into a table using the COPY command? (Select all that apply)</p>", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p><strong>Snowflake supports transforming data while loading it into a table using the COPY command. Options include:</strong></p><ul><li><p><strong>Column reordering </strong></p></li><li><p><strong>Column omission </strong></p></li><li><p><strong>Casts </strong></p></li><li><p><strong>Truncating text strings that exceed the target column length</strong></p></li></ul>", "answers": ["Column reordering", "Column omission", "Casts", "Truncation of Text Strings", "Join"]}, "correct_response": ["a", "b", "c", "d"], "section": "Data Transformation", "question_plain": "What all options are available for data transformation while loading data into a table using the COPY command? (Select all that apply)", "related_lectures": []}, {"_class": "assessment", "id": 71099336, "assessment_type": "multiple-choice", "prompt": {"question": "When loading data using COPY INTO &lt;table&gt; command, it is a must that the data files have the same number and order of columns as your target table. (True/False)", "answers": ["TRUE", "FALSE"], "explanation": "There is no requirement for your data files to have the same number and ordering of columns as your target table."}, "correct_response": ["b"], "section": "Data Transformation", "question_plain": "When loading data using COPY INTO &lt;table&gt; command, it is a must that the data files have the same number and order of columns as your target table. (True/False)", "related_lectures": []}, {"_class": "assessment", "id": 71099338, "assessment_type": "multi-select", "prompt": {"question": "During data loading using COPY INTO &lt;table&gt; command, if the string exceeds the target column length, what options do you have to truncate the string? (Select 2)", "answers": ["ENFORCE_LENGTH = TRUE ", "ENFORCE_LENGTH = FALSE", "TRUNCATECOLUMNS = TRUE", "TRUNCATECOLUMNS = FALSE"], "explanation": "ENFORCE_LENGTH:  \n- If TRUE, the COPY statement produces an error if a loaded string exceeds the target column length.\n- If FALSE, strings are automatically truncated to the target column length.\n\nTRUNCATECOLUMNS:\n- If TRUE, strings are automatically truncated to the target column length.\n- If FALSE, the COPY statement produces an error if a loaded string exceeds the target column length."}, "correct_response": ["b", "c"], "section": "Data Transformation", "question_plain": "During data loading using COPY INTO &lt;table&gt; command, if the string exceeds the target column length, what options do you have to truncate the string? (Select 2)", "related_lectures": []}, {"_class": "assessment", "id": 71099340, "assessment_type": "multiple-choice", "prompt": {"question": "Which algorithm does Snowflake use to estimate the approximate number of distinct values in a data set?", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p><strong>Snowflake uses HyperLogLog</strong> to estimate the approximate number of distinct values in a data set. HyperLogLog is a state-of-the-art cardinality estimation algorithm, capable of estimating distinct cardinalities of trillions of rows with an average relative error of a few percent.</p>", "answers": ["HyperEstimateLog", "HyperLogLog", "HyerAccumulateLog", "HyperMedianLog", "HyperMeanLog"]}, "correct_response": ["b"], "section": "Data Transformation", "question_plain": "Which algorithm does Snowflake use to estimate the approximate number of distinct values in a data set?", "related_lectures": []}, {"_class": "assessment", "id": 71099342, "assessment_type": "multiple-choice", "prompt": {"question": "When should we use HyperLogLog?", "answers": ["Whenever the input is potentially large, and an approximate result is not acceptable.", "Whenever the input is potentially small, and an approximate result is acceptable.", "Whenever the input is potentially large, and an approximate result is acceptable.", "Whenever the input is potentially small, and an approximate result is not acceptable."], "explanation": "Snowflake recommends using HyperLogLog whenever the input is potentially large, and an approximate result is acceptable. "}, "correct_response": ["c"], "section": "Data Transformation", "question_plain": "When should we use HyperLogLog?", "related_lectures": []}, {"_class": "assessment", "id": 71099344, "assessment_type": "multi-select", "prompt": {"question": "<p>Which of these Sampling methods does Snowflake support? (Select 2)</p>", "relatedLectureIds": "", "feedbacks": ["", "", ""], "explanation": "<p>SAMPLE / TABLESAMPLE returns a subset of rows sampled randomly from the specified table. The following sampling methods are supported:\n\n<strong>Sample a fraction of a table</strong> with a specified probability for including a given row. The number of rows returned depends on the size of the table and the requested probability. A seed can be specified to make the sampling deterministic.&nbsp; </p><p><strong>Sample a fixed, specified number of rows</strong>. The exact number of specified rows is returned unless the table contains fewer rows.\n\nSAMPLE and TABLESAMPLE are synonymous and can be used interchangeably.</p>", "answers": ["Sample a fraction of the table with a specified probability of including a given row", "Sample exact rows of the table with the specified sequence keys", "Sample a fixed, specified number of rows"]}, "correct_response": ["a", "c"], "section": "Data Transformation", "question_plain": "Which of these Sampling methods does Snowflake support? (Select 2)", "related_lectures": []}, {"_class": "assessment", "id": 71099346, "assessment_type": "multiple-choice", "prompt": {"question": "select * from t1 sample row(100);\nWhat would the above query return?", "answers": ["Return an empty sample", "Return an entire table, including all rows in the table", "Return a sample of a table in which each row has a 10% probability of being included in the sample", "samplingMethod is not applied in the query. The query will result in an error."], "explanation": "Return an entire table, including all rows in the table. Sampling method is optional. If no method is applied after sample keyword, the default it takes is BERNOULLI."}, "correct_response": ["b"], "section": "Data Transformation", "question_plain": "select * from t1 sample row(100);\nWhat would the above query return?", "related_lectures": []}, {"_class": "assessment", "id": 71099348, "assessment_type": "multi-select", "prompt": {"question": "Which of these sampling method keywords are used to specify which method to use? (Select 2)", "answers": ["BERNOULLI | ROW", "SYSTEM | ROW", "BERNOULLI | BLOCK", "SYSTEM | BLOCK"], "explanation": "BERNOULLI | ROW and SYSTEM | BLOCK are used to specify the sampling method in SELECT query. \n\nBERNOULLI (or ROW): Includes each row with a &lt;probability&gt; of p/100. Similar to flipping a weighted coin for each row.\n\nSYSTEM (or BLOCK): Includes each block of rows with a &lt;probability&gt; of p/100. Similar to flipping a weighted coin for each block of rows. This method does not support fixed-size sampling.\n\nSampling method is optional. If no method is specified, the default is BERNOULLI.\n\nExample :\n\nselect * from t1 tablesample bernoulli (25); \nThis query will return a sample of a table in which each row has a 25% probability of being included in the sample"}, "correct_response": ["a", "d"], "section": "Data Transformation", "question_plain": "Which of these sampling method keywords are used to specify which method to use? (Select 2)", "related_lectures": []}, {"_class": "assessment", "id": 71099350, "assessment_type": "multiple-choice", "prompt": {"question": "Monica is confused about which sampling method she should use with one the very large tables,, considering better performance. Which sampling method would you recommend from BERNOULLI | ROW and SYSTEM | BLOCK?", "answers": ["SYSTEM | BLOCK", "BERNOULLI | ROW"], "explanation": "SYSTEM | BLOCK sampling is often faster than BERNOULLI | ROW sampling. Also, BERNOULLI | ROW method is good for Smaller Tables and SYSTEM | BLOCK method for Larger Tables."}, "correct_response": ["a"], "section": "Data Transformation", "question_plain": "Monica is confused about which sampling method she should use with one the very large tables,, considering better performance. Which sampling method would you recommend from BERNOULLI | ROW and SYSTEM | BLOCK?", "related_lectures": []}, {"_class": "assessment", "id": 71099352, "assessment_type": "multi-select", "prompt": {"question": "Which of these SQL functions does Snowflake support?", "answers": ["Scalar", "Aggregate", "Window", "System", "Table", "User-Defined"], "explanation": "Snowflake Supports all these SQL functions."}, "correct_response": ["a", "b", "c", "d", "e", "f"], "section": "Data Transformation", "question_plain": "Which of these SQL functions does Snowflake support?", "related_lectures": []}, {"_class": "assessment", "id": 71099354, "assessment_type": "multiple-choice", "prompt": {"question": "Select the type of function that returns one value per invocation (one value per row). ", "answers": ["Aggregate Function", "Scalar Function", "Window Function", "Table Function", "User-Defined Function", "System Function"], "explanation": "A scalar function is a function that returns one value per invocation; in most cases, you can think of this as returning one value per row. This contrasts with Aggregate Functions, which return one value per group of rows. Scalar functions take every row in your table, perform some calculation on that row and give you another value back."}, "correct_response": ["b"], "section": "Data Transformation", "question_plain": "Select the type of function that returns one value per invocation (one value per row).", "related_lectures": []}, {"_class": "assessment", "id": 71099356, "assessment_type": "multiple-choice", "prompt": {"question": "Select the type of function that returns one value per group of rows (for example - AVG, MAX, MIN)", "answers": ["Aggregate Function", "Scalar Function", "Window Function", "Table Function", "User-Defined Function", "System Function"], "explanation": "Aggregate functions operate on values across rows to perform mathematical calculations such as sum, average, counting, minimum/maximum values, standard deviation, and estimation, as well as some non-mathematical operations.\n\nAn aggregate function takes multiple rows (actually, zero, one, or more rows) as input and produces a single output. In contrast, scalar functions take one row as input and produce one row (one value) as output.\n\nAn aggregate function always returns exactly one row, even when the input contains zero rows. Typically, if the input contained zero rows, the output is NULL. However, an aggregate function could return 0, an empty string, or some other value when passed zero rows."}, "correct_response": ["a"], "section": "Data Transformation", "question_plain": "Select the type of function that returns one value per group of rows (for example - AVG, MAX, MIN)", "related_lectures": []}, {"_class": "assessment", "id": 71099358, "assessment_type": "multiple-choice", "prompt": {"question": "Select the type of function that can operate on a subset of rows within the set of input rows.", "answers": ["Aggregate Function", "Scalar Function", "Window Function", "Table Function", "User-Defined Function", "System Function"], "explanation": "A window function is any function that operates over a window of rows.\n"}, "correct_response": ["c"], "section": "Data Transformation", "question_plain": "Select the type of function that can operate on a subset of rows within the set of input rows.", "related_lectures": []}, {"_class": "assessment", "id": 71099360, "assessment_type": "multiple-choice", "prompt": {"question": "Select the type of function that returns multiple rows for each individual input.", "answers": ["Aggregate Function", "Scalar Function", "Window Function", "Table Function", "User-Defined Function", "System Function"], "explanation": "A table function returns a set of rows for each input row. The returned set can contain zero, one, or more rows. Each row can contain one or more columns.\n\nTable functions are sometimes called \u201ctabular functions\u201d."}, "correct_response": ["d"], "section": "Data Transformation", "question_plain": "Select the type of function that returns multiple rows for each individual input.", "related_lectures": []}, {"_class": "assessment", "id": 71099362, "assessment_type": "multiple-choice", "prompt": {"question": "Select the type of function that is used to execute an action in the system or return information about the system.", "answers": ["Aggregate Function", "Scalar Function", "Window Function", "Table Function", "User-Defined Function", "System Function"], "explanation": "System function that is used to execute an action in the system or return information about the system. \n\nSnowflake provides the following types of system functions:\n\nControl functions that allow you to execute actions in the system (e.g. aborting a query).\n\nInformation functions that return information about the system (e.g. calculating the clustering depth of a table).\n\nInformation functions that return information about queries (e.g. information about EXPLAIN plans)."}, "correct_response": ["f"], "section": "Data Transformation", "question_plain": "Select the type of function that is used to execute an action in the system or return information about the system.", "related_lectures": []}, {"_class": "assessment", "id": 71099364, "assessment_type": "multi-select", "prompt": {"question": "<p>Which of the following languages does Snowflake support for writing UDFs (User-Defined Functions)? (Select 4)</p>", "relatedLectureIds": "", "feedbacks": ["", "", "", "", "", ""], "explanation": "<p><strong>User-defined functions (UDFs) let you extend the system to perform operations that are not available through the built-in, system-defined functions provided by Snowflake.</strong> <strong>Snowflake currently supports the following languages for writing UDFs:</strong>\n\n<strong>Java:</strong> A Java UDF lets you use the Java programming language to manipulate data and return either scalar or tabular results.\n\n<strong>JavaScript:</strong> A JavaScript UDF lets you use the JavaScript programming language to manipulate data and return either scalar or tabular results.\n\n<strong>Python:</strong> A Python UDF lets you use the Python programming language to manipulate data and return either scalar or tabular results.\n\n<strong>SQL: </strong>A SQL UDF evaluates an arbitrary SQL expression and returns either scalar or tabular results.</p>", "answers": ["JAVA", "JavaScript", "GO", "SQL", "Python", "C#"]}, "correct_response": ["a", "b", "d", "e"], "section": "Data Transformation", "question_plain": "Which of the following languages does Snowflake support for writing UDFs (User-Defined Functions)? (Select 4)", "related_lectures": []}, {"_class": "assessment", "id": 71099366, "assessment_type": "multiple-choice", "prompt": {"question": "UDF does not support sql DDL / DML? (True/Fales)", "answers": ["TRUE", "FALSE"], "explanation": "UDF does not support sql DDL / DML. That means you can select from a table, but you can&#39;t create or modify tables inside of a UDF."}, "correct_response": ["a"], "section": "Data Transformation", "question_plain": "UDF does not support sql DDL / DML? (True/Fales)", "related_lectures": []}, {"_class": "assessment", "id": 71099368, "assessment_type": "multiple-choice", "prompt": {"question": "Monica wants to share a UDF with other users. She wants to permit other users to use it, but she doesn&#39;t want them to be able to see how it was defined or the underlying logic behind it. What would you recommend to Monica?", "answers": ["Underlying logic can not be hidden with UDF", "Monica should create an unsecure UDF and then block the logic in the sql statement", "Monica should create a secure UDF"], "explanation": "We can create a user-defined function to be unsecure or secure.  A secure user-defined function means if we permit someone else to use this UDF, they will not be able to see how it was defined or the underlying logic behind it."}, "correct_response": ["c"], "section": "Data Transformation", "question_plain": "Monica wants to share a UDF with other users. She wants to permit other users to use it, but she doesn&#39;t want them to be able to see how it was defined or the underlying logic behind it. What would you recommend to Monica?", "related_lectures": []}, {"_class": "assessment", "id": 71099370, "assessment_type": "multiple-choice", "prompt": {"question": "What would you create (UDF or Stored procedure) if you need a function that can be called as part of a SQL statement and must return a value that will be used in the statement?", "answers": ["Stored Procedure", "UDF"], "explanation": "An UDF evaluates to a value, and can be used in contexts in which a general expression can be used (e.g. SELECT my_function() ...).\n\nA stored procedure does not evaluate to a value, and cannot be used in all contexts in which a general expression can be used. For example, you cannot execute SELECT my_stored_procedure()...."}, "correct_response": ["b"], "section": "Data Transformation", "question_plain": "What would you create (UDF or Stored procedure) if you need a function that can be called as part of a SQL statement and must return a value that will be used in the statement?", "related_lectures": []}, {"_class": "assessment", "id": 71099372, "assessment_type": "multiple-choice", "prompt": {"question": "A stored procedure can run both the caller\u2019s and the owner\u2019s rights simultaneously. (TRUE / FALSE)", "answers": ["TRUE", "FALSE"], "explanation": "A stored procedure runs with either the caller\u2019s rights or the owner\u2019s rights. It cannot run with both at the same time.\n\nA caller\u2019s rights stored procedure runs with the privileges of the caller. The primary advantage of a caller\u2019s rights stored procedure is that it can access information about that caller or about the caller\u2019s current session. For example, a caller\u2019s rights stored procedure can read the caller\u2019s session variables and use them in a query.\n\nAn owner\u2019s rights stored procedure runs mostly with the privileges of the stored procedure\u2019s owner. The primary advantage of an owner\u2019s rights stored procedure is that the owner can delegate specific administrative tasks, such as cleaning up old data, to another role without granting that role more general privileges, such as privileges to delete all data from a specific table.\n\nAt the time that the stored procedure is created, the creator specifies whether the procedure runs with owner\u2019s rights or caller\u2019s rights. The default is owner\u2019s rights."}, "correct_response": ["b"], "section": "Data Transformation", "question_plain": "A stored procedure can run both the caller\u2019s and the owner\u2019s rights simultaneously. (TRUE / FALSE)", "related_lectures": []}, {"_class": "assessment", "id": 71099374, "assessment_type": "multiple-choice", "prompt": {"question": "UDF runs with either the caller\u2019s or the owner\u2019s rights. (TRUE / FALSE)", "answers": ["TRUE", "FALSE"], "explanation": "UDF only runs as the function owner. A stored procedure runs with either the caller\u2019s rights or the owner\u2019s rights. It cannot run with both at the same time.\n\nA caller\u2019s rights stored procedure runs with the privileges of the caller. The primary advantage of a caller\u2019s rights stored procedure is that it can access information about that caller or about the caller\u2019s current session. For example, a caller\u2019s rights stored procedure can read the caller\u2019s session variables and use them in a query.\n\nAn owner\u2019s rights stored procedure runs mostly with the privileges of the stored procedure\u2019s owner. The primary advantage of an owner\u2019s rights stored procedure is that the owner can delegate specific administrative tasks, such as cleaning up old data, to another role without granting that role more general privileges, such as privileges to delete all data from a specific table.\n\nAt the time that the stored procedure is created, the creator specifies whether the procedure runs with owner\u2019s rights or caller\u2019s rights. The default is owner\u2019s rights."}, "correct_response": ["b"], "section": "Data Transformation", "question_plain": "UDF runs with either the caller\u2019s or the owner\u2019s rights. (TRUE / FALSE)", "related_lectures": []}, {"_class": "assessment", "id": 71099376, "assessment_type": "multiple-choice", "prompt": {"question": "The VALIDATION_MODE parameter does not support COPY statements that transform data during a load. (True / False)", "answers": ["TRUE", "FALSE"], "explanation": "True.\n\n&quot;VALIDATION_MODE instructs the COPY command to validate the data files instead of loading them into the specified table; i.e., the COPY command tests the files for errors but does not load them. The command validates the data to be loaded and returns results based on the validation option specified:\n\nSyntax : VALIDATION_MODE = RETURN_n_ROWS | RETURN_ERRORS | RETURN_ALL_ERRORS\n\nRETURN_n_ROWS (e.g. RETURN_10_ROWS) - Validates the specified number of rows, if no errors are encountered; otherwise, fails at the first error encountered in the rows.\n\nRETURN_ERRORS - Returns all errors (parsing, conversion, etc.) across all files specified in the COPY statement.\n\nRETURN_ALL_ERRORS - Returns all errors across all files specified in the COPY statement, including files with errors that were partially loaded during an earlier load because the ON_ERROR copy option was set to CONTINUE during the load.&quot;"}, "correct_response": ["a"], "section": "Data Transformation", "question_plain": "The VALIDATION_MODE parameter does not support COPY statements that transform data during a load. (True / False)", "related_lectures": []}, {"_class": "assessment", "id": 71099378, "assessment_type": "multiple-choice", "prompt": {"question": "How does Snowflake store semi-structured data, such as JSON, Avro, Parquet, ORC, and XML?", "answers": ["Stores as VARCHAR data type", "Stores as JSON data type", "Stores as VARIANT data type", "Stores as FLATTEN data type"], "explanation": "Snowflake stores semi-structured data, such as JSON, Avro, Parquet, ORC, and XML, as VARIANT data type. A VARIANT can store a value of any other type, including OBJECT and ARRAY."}, "correct_response": ["c"], "section": "Data Transformation", "question_plain": "How does Snowflake store semi-structured data, such as JSON, Avro, Parquet, ORC, and XML?", "related_lectures": []}, {"_class": "assessment", "id": 71099380, "assessment_type": "multiple-choice", "prompt": {"question": "How can you produce a lateral view of a VARIANT, OBJECT or ARRAY Column?", "answers": ["Using INFER_SCHEMA table function", "Using RESULT_SCAN table function", "Using SPLIT_TO_TABLE table function", "Using FLATTEN table function"], "explanation": "FLATTEN is a table function that produces a lateral view of a VARIANT, OBJECT, or ARRAY column.\n\nINFER_SCHEMA table function is used to detect the file metadata schema in a set of staged data files that contain semi-structured data and retrieves the column definitions.\n\nRESULT SCAN returns the result set of a previous command (within 24 hours of when you executed the query) as if the result was a table.\n\nSPLIT_TO_TABLE table function splits a string (based on a specified delimiter) and flattens the results into rows.\n"}, "correct_response": ["d"], "section": "Data Transformation", "question_plain": "How can you produce a lateral view of a VARIANT, OBJECT or ARRAY Column?", "related_lectures": []}, {"_class": "assessment", "id": 71099382, "assessment_type": "multiple-choice", "prompt": {"question": "While transforming Semi-structure data, If you want expansion for all the sub-elements recursively using FLATTEN function, what argument would you need to set with FLATTEN function?", "answers": ["OUTER =&gt; TRUE ", "RECURSIVE =&gt; TRUE ", "OUTER =&gt; FALSE", "RECURSIVE =&gt; FALSE"], "explanation": "The expansion is performed for all sub-elements recursively by argument RECURSIVE =&gt; TRUE. \n\nOnly the element referenced by PATH is expanded BY RECURSIVE =&gt; FALSE.\n\nThe OUTER argument is used to handle the input rows that cannot be expanded, either because they cannot be accessed in the path or because they have zero fields or entries."}, "correct_response": ["b"], "section": "Data Transformation", "question_plain": "While transforming Semi-structure data, If you want expansion for all the sub-elements recursively using FLATTEN function, what argument would you need to set with FLATTEN function?", "related_lectures": []}, {"_class": "assessment", "id": 71099384, "assessment_type": "multiple-choice", "prompt": {"question": "While transforming Semi-structure data, what argument would you need to set with FLATTEN function to omit the output of the input rows that cannot be expanded, either because they cannot be accessed in the path or because they have zero fields or entries?", "answers": ["OUTER =&gt; TRUE ", "RECURSIVE =&gt; TRUE ", "OUTER =&gt; FALSE", "RECURSIVE =&gt; FALSE", "MODE =&gt; OBJECT"], "explanation": "The OUTER =&gt; FALSE argument with FLATTEN omits the output of the input rows that cannot be expanded, either because they cannot be accessed in the path or because they have zero fields or entries.\n\nThe OUTER =&gt; TRUE argument with FLATTEN generates exactly one row for zero-row expansions (with NULL in the KEY, INDEX, and VALUE columns).\n\nRECURSIVE  is used to instruct if only the element referenced by PATH is expanded or expansion is performed for all sub-elements recursively\n\nMODE Specifies whether only objects, arrays, or both should be flattened."}, "correct_response": ["c"], "section": "Data Transformation", "question_plain": "While transforming Semi-structure data, what argument would you need to set with FLATTEN function to omit the output of the input rows that cannot be expanded, either because they cannot be accessed in the path or because they have zero fields or entries?", "related_lectures": []}, {"_class": "assessment", "id": 71099386, "assessment_type": "multiple-choice", "prompt": {"question": "What value will be return by the following query?\n\nSELECT * FROM TABLE(FLATTEN(input =&gt; parse_json(&#39;[]&#39;), outer =&gt; true)) f;\n\n", "answers": ["0", "[]", "NULL"], "explanation": "The OUTER =&gt; TRUE argument with FLATTEN generates exactly one row for zero-row expansions (with NULL in the KEY, INDEX, and VALUE columns)."}, "correct_response": ["c"], "section": "Data Transformation", "question_plain": "What value will be return by the following query?\n\nSELECT * FROM TABLE(FLATTEN(input =&gt; parse_json(&#39;[]&#39;), outer =&gt; true)) f;", "related_lectures": []}, {"_class": "assessment", "id": 71099388, "assessment_type": "multiple-choice", "prompt": {"question": "What value will be return by the following query?\n\nSELECT * FROM TABLE(FLATTEN(input =&gt; parse_json(&#39;[]&#39;))) f;", "answers": ["0", "[]", "NULL", "nothing will return / output of the input row will be omitted"], "explanation": "If you don\u2019t specify OUTER argument with FLATTEN, it would be defaulted to FALSE. \n\nThe OUTER =&gt; FALSE argument with FLATTEN omits the output of the input rows that cannot be expanded, either because they cannot be accessed in the path or because they have zero fields or entries."}, "correct_response": ["d"], "section": "Data Transformation", "question_plain": "What value will be return by the following query?\n\nSELECT * FROM TABLE(FLATTEN(input =&gt; parse_json(&#39;[]&#39;))) f;", "related_lectures": []}, {"_class": "assessment", "id": 71099390, "assessment_type": "multiple-choice", "prompt": {"question": "What is an &quot;object&quot; in semi-structured data?", "answers": ["Collection of values in an array", "Collection of semi-structure data files", "Collection of key-value pairs"], "explanation": "OBJECT is also called a \u201cdictionary\u201d, \u201chash\u201d, or \u201cmap\u201d in many languages. This contains key-value pairs."}, "correct_response": ["c"], "section": "Data Transformation", "question_plain": "What is an &quot;object&quot; in semi-structured data?", "related_lectures": []}, {"_class": "assessment", "id": 71099398, "assessment_type": "multiple-choice", "prompt": {"question": "Snowflake supports various actions for Unstructured Data. Which one is not supported by Snowflake?", "answers": ["Extract actual data from PDF and load it into Snowflake tables using Snowflake WebUI out of the box option.", "Load file access URLs and other file metadata into Snowflake tables.", "Share file access URLs with collaborators and partners.", "Securely access data files located in cloud storage."], "explanation": "Snowflake supports the following actions for Unstructured data:\n- Securely access data files located in cloud storage.\n- Share file access URLs with collaborators and partners.\n- Load file access URLs and other file metadata into Snowflake tables."}, "correct_response": ["a"], "section": "Data Transformation", "question_plain": "Snowflake supports various actions for Unstructured Data. Which one is not supported by Snowflake?", "related_lectures": []}, {"_class": "assessment", "id": 71099400, "assessment_type": "multiple-choice", "prompt": {"question": "Both external (external cloud storage) and internal (i.e., Snowflake) stages support unstructured data. (True / False)", "answers": ["TRUE", "FALSE"], "explanation": "True, both external (external cloud storage, such as, Amazon S3, Google Cloud Storage, Azure Blob Storage etc.) and internal (i.e. Snowflake) stages support unstructured data."}, "correct_response": ["a"], "section": "Data Transformation", "question_plain": "Both external (external cloud storage) and internal (i.e., Snowflake) stages support unstructured data. (True / False)", "related_lectures": []}, {"_class": "assessment", "id": 71099402, "assessment_type": "multi-select", "prompt": {"question": "Snowflake supports the secured access of unstructured data files in cloud storage. What types of URLs are available to access files in cloud storage? (Select 3)", "answers": ["Unstructured URL", "Scoped URL", "Descoped URL", "File URL", "Signed URL", "Pre-signed URL"], "explanation": "The following types of URLs are available to access files in cloud storage:\n\nScoped URL: Encoded URL that permits temporary access to a staged file without granting privileges to the stage. The URL expires when the persisted query result period ends (i.e., the results cache expires), which is currently 24 hours.\n\nFile URL: URL that identifies the database, schema, stage, and file path to a set of files. A role that has sufficient privileges on the stage can access the files.\n\nPre-signed URL: Simple HTTPS URL used to access a file via a web browser. A file is temporarily accessible to users via this URL using a pre-signed access token. The expiration time for the access token is configurable."}, "correct_response": ["b", "d", "f"], "section": "Data Transformation", "question_plain": "Snowflake supports the secured access of unstructured data files in cloud storage. What types of URLs are available to access files in cloud storage? (Select 3)", "related_lectures": []}, {"_class": "assessment", "id": 71099404, "assessment_type": "multiple-choice", "prompt": {"question": "Which of these SQL functions helps generate the Scoped URL to access the unstructured data file?", "answers": ["BUILD_SCOPED_FILE_URL", "GET_STAGE_LOCATION", "GET_RELATIVE_PATH", "BUILD_STAGE_FILE_URI", "GET_PRESIGNED_URL", "GET_ABSOLUTE_PATH"], "explanation": "BUILD_SCOPED_FILE_URL generates a scoped Snowflake-hosted URL to a staged file using the stage name and relative file path as inputs. A scoped URL is encoded and permits access to a specified file for a limited period of time.\n\nScoped URL: Encoded URL that permits temporary access to a staged file without granting privileges to the stage. The URL expires when the persisted query result period ends (i.e., the results cache expires), which is currently 24 hours.\n"}, "correct_response": ["a"], "section": "Data Transformation", "question_plain": "Which of these SQL functions helps generate the Scoped URL to access the unstructured data file?", "related_lectures": []}, {"_class": "assessment", "id": 71099406, "assessment_type": "multiple-choice", "prompt": {"question": "Which of these functions helps generate the FILE URL to access the unstructured data file?", "answers": ["BUILD_SCOPED_FILE_URL", "GET_STAGE_LOCATION", "GET_RELATIVE_PATH", "BUILD_STAGE_FILE_URI", "GET_PRESIGNED_URL", "GET_ABSOLUTE_PATH"], "explanation": "BUILD_STAGE_FILE_URL generates a Snowflake-hosted file URL to a staged file using the stage name and relative file path as inputs. A file URL permits prolonged access to a specified file. That is, the file URL does not expire.\n\nFile URL: URL that identifies the database, schema, stage, and file path to a set of files. A role that has sufficient privileges on the stage can access the files."}, "correct_response": ["d"], "section": "Data Transformation", "question_plain": "Which of these functions helps generate the FILE URL to access the unstructured data file?", "related_lectures": []}, {"_class": "assessment", "id": 71099408, "assessment_type": "multiple-choice", "prompt": {"question": "Which of these functions helps generate the Pre-signed URL to access the unstructured data file?", "answers": ["BUILD_SCOPED_FILE_URL", "GET_STAGE_LOCATION", "GET_RELATIVE_PATH", "BUILD_STAGE_FILE_URI", "GET_PRESIGNED_URL", "GET_ABSOLUTE_PATH"], "explanation": "GET_PRESIGNED_URL generates the pre-signed URL to a staged file using the stage name and relative file path as inputs.\n\nPre-signed URL: Simple HTTPS URL used to access a file via a web browser. A file is temporarily accessible to users via this URL using a pre-signed access token. The expiration time for the access token is configurable."}, "correct_response": ["e"], "section": "Data Transformation", "question_plain": "Which of these functions helps generate the Pre-signed URL to access the unstructured data file?", "related_lectures": []}, {"_class": "assessment", "id": 71099410, "assessment_type": "multiple-choice", "prompt": {"question": "Which of these SQL functions helps extract the path of a staged file relative to its location in the stage using the stage name and absolute file path in cloud storage as inputs?", "answers": ["BUILD_SCOPED_FILE_URL", "GET_STAGE_LOCATION", "GET_RELATIVE_PATH", "BUILD_STAGE_FILE_URI", "GET_PRESIGNED_URL", "GET_ABSOLUTE_PATH"], "explanation": "GET_RELATIVE_PATH extracts the path of a staged file relative to its location in the stage using the stage name and absolute file path in cloud storage as inputs."}, "correct_response": ["c"], "section": "Data Transformation", "question_plain": "Which of these SQL functions helps extract the path of a staged file relative to its location in the stage using the stage name and absolute file path in cloud storage as inputs?", "related_lectures": []}, {"_class": "assessment", "id": 71099412, "assessment_type": "multiple-choice", "prompt": {"question": "Which of these SQL functions helps returns the absolute path of a staged file using the stage name and path of the file relative to its location in the stage as inputs.?", "answers": ["BUILD_SCOPED_FILE_URL", "GET_STAGE_LOCATION", "GET_RELATIVE_PATH", "BUILD_STAGE_FILE_URI", "GET_PRESIGNED_URL", "GET_ABSOLUTE_PATH"], "explanation": "GET_ABSOLUTE_PATH returns the absolute path of a staged file using the stage name and path of the file relative to its location in the stage as inputs."}, "correct_response": ["f"], "section": "Data Transformation", "question_plain": "Which of these SQL functions helps returns the absolute path of a staged file using the stage name and path of the file relative to its location in the stage as inputs.?", "related_lectures": []}, {"_class": "assessment", "id": 71099414, "assessment_type": "multiple-choice", "prompt": {"question": "Which of these SQL functions helps retrieve the URL for an external or internal named stage using the stage name as the input?", "answers": ["BUILD_SCOPED_FILE_URL", "GET_STAGE_LOCATION", "GET_RELATIVE_PATH", "BUILD_STAGE_FILE_URI", "GET_PRESIGNED_URL", "GET_ABSOLUTE_PATH"], "explanation": "GET_STAGE_LOCATION retrieves the URL for an external or internal named stage using the stage name as the input.\n\n"}, "correct_response": ["b"], "section": "Data Transformation", "question_plain": "Which of these SQL functions helps retrieve the URL for an external or internal named stage using the stage name as the input?", "related_lectures": []}, {"_class": "assessment", "id": 71099416, "assessment_type": "multiple-choice", "prompt": {"question": "A\u00a0Directory table\u00a0is a separate database object that stores a catalog of staged files in cloud storage. (True/False)", "answers": ["TRUE", "FALSE"], "explanation": "\nA Directory table is not a separate database object; it stores a catalog of staged files in cloud storage. Roles with sufficient privileges can query a directory table to retrieve file URLs to access the staged files and other metadata."}, "correct_response": ["b"], "section": "Data Transformation", "question_plain": "A\u00a0Directory table\u00a0is a separate database object that stores a catalog of staged files in cloud storage. (True/False)", "related_lectures": []}, {"_class": "assessment", "id": 71099418, "assessment_type": "multiple-choice", "prompt": {"question": "How can we add a Directory table explicitly to a stage to store a catalog of staged files?", "answers": ["Using CREATE DIRECTORY TABLE command and then add to the stage by ALTER STAGE command", "Using CREATE DIRECTORY TABLES command and then add to the stage by ALTER STAGE command", "Using CREATE STAGE command "], "explanation": "A Directory table is not a separate database object; it stores a catalog of staged files in cloud storage. Roles with sufficient privileges can query a directory table to retrieve file URLs to access the staged files and other metadata. \n\nA directory table can be added explicitly to a stage when the stage is created (using CREATE STAGE) or later (using ALTER STAGE) with supplying directoryTableParams.\n\ndirectoryTableParams (for internal stages) ::=\n  [ DIRECTORY = ( ENABLE = { TRUE | FALSE }\n                  [ REFRESH_ON_CREATE =  { TRUE | FALSE } ] ) ]\n\nENABLE = TRUE | FALSE     Specifies whether to add a directory table to the stage. When the value is TRUE, a directory table is created with the stage."}, "correct_response": ["c"], "section": "Data Transformation", "question_plain": "How can we add a Directory table explicitly to a stage to store a catalog of staged files?", "related_lectures": []}, {"_class": "assessment", "id": 71099420, "assessment_type": "multiple-choice", "prompt": {"question": "How can a directory table metadata be refreshed automatically and efficiently to synchronize the metadata with the latest associated files in the external stage and path?", "answers": ["Using Tasks", "Using Cloud event notification service", "Using Stream", "Using both Tasks and Stream", "It is a manual process and cant be automatically refreshed"], "explanation": "The metadata for a directory table can be refreshed automatically using the event notification service for your cloud storage service. The refresh operation synchronizes the metadata with the latest set of associated files in the external stage and path, i.e.:\n\n        - New files in the path are added to the table metadata.\n\n        - Changes to files in the path are updated in the table metadata.\n\n        - Files no longer in the path are removed from the table metadata.\n"}, "correct_response": ["b"], "section": "Data Transformation", "question_plain": "How can a directory table metadata be refreshed automatically and efficiently to synchronize the metadata with the latest associated files in the external stage and path?", "related_lectures": []}, {"_class": "assessment", "id": 71099422, "assessment_type": "multiple-choice", "prompt": {"question": "The automatic refresh of metadata of the directory table in the cloud storage does not incur any charges to Snowflake Customers. (True/False)", "answers": ["TRUE", "FALSE"], "explanation": "Snowflake customers&#39; charges include an overhead to manage event notifications for automatically refreshing directory table metadata. This overhead increases in relation to the number of files added in cloud storage for customers&#39; stages that include directory tables. Snowflake charges 0.06 credits per 1000 event notifications received."}, "correct_response": ["b"], "section": "Data Transformation", "question_plain": "The automatic refresh of metadata of the directory table in the cloud storage does not incur any charges to Snowflake Customers. (True/False)", "related_lectures": []}, {"_class": "assessment", "id": 71099424, "assessment_type": "multiple-choice", "prompt": {"question": "The Snowflake Information Schema includes table functions you can query to retrieve information about your directory tables. Which table function can be used to query the history of data files registered in the metadata of specified objects and the credits billed for these operations?", "answers": ["DATABASE_REFRESH_HISTORY", "AUTO_REFRESH_REGISTRATION_HISTORY", "STAGE_DIRECTORY_FILE_REGISTRATION_HISTORY", "STAGE_STORAGE_USAGE_HISTORY"], "explanation": "\nAUTO_REFRESH_REGISTRATION_HISTORY table function can be used to query the history of data files registered in the metadata of specified objects and the credits billed for these operations. The table function returns the billing history within a specified date range for your entire Snowflake account. This function returns billing activity within the last 14 days.\n\nPlease note, STAGE_DIRECTORY_FILE_REGISTRATION_HISTORY table function can be used to query information about the metadata history for a directory table, including:\n\n    - Files added or removed automatically as part of a metadata refresh.\n    - Any errors found when refreshing the metadata."}, "correct_response": ["b"], "section": "Data Transformation", "question_plain": "The Snowflake Information Schema includes table functions you can query to retrieve information about your directory tables. Which table function can be used to query the history of data files registered in the metadata of specified objects and the credits billed for these operations?", "related_lectures": []}, {"_class": "assessment", "id": 71099426, "assessment_type": "multiple-choice", "prompt": {"question": "Suppose files downloaded from an internal stage are corrupted. What should be verified with the stage creator to determine why the downloaded file is corrupted?", "answers": ["Verify if ENCRYPTION = (TYPE = &#39;SNOWFLAKE_SSE&#39;) set for the stage", "Verify if ENCRYPTION = (TYPE = &#39;SNOWFLAKE_FULL&#39;) set for the stage"], "explanation": "If files downloaded from an internal stage are corrupted, verify with the stage creator that ENCRYPTION = (TYPE = &#39;SNOWFLAKE_SSE&#39;) is set for the stage."}, "correct_response": ["a"], "section": "Data Transformation", "question_plain": "Suppose files downloaded from an internal stage are corrupted. What should be verified with the stage creator to determine why the downloaded file is corrupted?", "related_lectures": []}, {"_class": "assessment", "id": 71099428, "assessment_type": "multi-select", "prompt": {"question": "<p>What are all operations performed using Snowflake SQL API? (Select 4)</p>", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "The Snowflake SQL API provides operations that we can use to:\n- Submit SQL statements for execution.\n- Check the status of the execution of a statement.\n- Cancel the execution of a statement.\n- Fetch query results concurrently.\n\nCurrently, Snowflake SQL API has limitation for the call command with stored procedures that return a table (stored procedures with the RETURNS TABLE clause).", "answers": ["Submit SQL statements for execution", "Check the status of the execution of a statement", "Calling stored procedures that returns a table", "Cancel the execution of a statement", "Fetch query results concurrently"]}, "correct_response": ["a", "b", "d", "e"], "section": "Data Transformation", "question_plain": "What are all operations performed using Snowflake SQL API? (Select 4)", "related_lectures": []}, {"_class": "assessment", "id": 71099430, "assessment_type": "multi-select", "prompt": {"question": "<p>What authentication methods does Snowflake support for REST API authentication? (Select 2)</p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>Snowflake SQL API supports <strong>Oauth, and Key Pair authentication.</strong></p>", "answers": ["OAuth", "Snowflake Account User ID and Password", "Key Pair Authentication ", "Authentication is not required in case Snowflake SQL API"]}, "correct_response": ["a", "c"], "section": "Data Transformation", "question_plain": "What authentication methods does Snowflake support for REST API authentication? (Select 2)", "related_lectures": []}, {"_class": "assessment", "id": 71099432, "assessment_type": "multiple-choice", "prompt": {"question": "Which command is used to create a security integration to enable an HTTP client that supports OAuth to redirect users to an authorization page and generate access tokens for access to the REST API endpoint?", "answers": ["CREATE OAUTH INTEGRATION", "CREATE INTEGRATION", "CREATE SECURITY INTEGRATION", "CREATE SECURITY API"], "explanation": "CREATE SECURITY INTEGRATION command is used to create a security integration that supports OAuth to redirect users to an authorization page and generate access tokens for access to the REST API endpoint."}, "correct_response": ["c"], "section": "Data Transformation", "question_plain": "Which command is used to create a security integration to enable an HTTP client that supports OAuth to redirect users to an authorization page and generate access tokens for access to the REST API endpoint?", "related_lectures": []}, {"_class": "assessment", "id": 71099434, "assessment_type": "multiple-choice", "prompt": {"question": "An HTTP client that sends a URL (either scoped URL or file URL) to the REST API must be configured to allow redirects. (True/False)", "answers": ["TRUE", "FALSE"], "explanation": "True, An HTTP client that sends a URL (either scoped URL or file URL) to the REST API must be configured to allow redirects."}, "correct_response": ["a"], "section": "Data Transformation", "question_plain": "An HTTP client that sends a URL (either scoped URL or file URL) to the REST API must be configured to allow redirects. (True/False)", "related_lectures": []}, {"_class": "assessment", "id": 71099436, "assessment_type": "multiple-choice", "prompt": {"question": "Only the user who generated the scoped URL can use the URL to access the referenced file. (True/False)", "answers": ["TRUE", "FALSE"], "explanation": "True, only the user who generated the scoped URL can use the URL to access the referenced file. I case of File URL, any role that has sufficient privileges on the stage can access the file."}, "correct_response": ["a"], "section": "Data Transformation", "question_plain": "Only the user who generated the scoped URL can use the URL to access the referenced file. (True/False)", "related_lectures": []}, {"_class": "assessment", "id": 71099438, "assessment_type": "multiple-choice", "prompt": {"question": "Python UDFs and tabular Python UDFs can read and process unstructured data in staged files using SnowflakeFile class. (True/False)", "answers": ["TRUE", "FALSE"], "explanation": "Java UDFs and tabular Java UDFs can read and process unstructured data in staged files using either the SnowflakeFile class or the InputStream class in the UDF code."}, "correct_response": ["b"], "section": "Data Transformation", "question_plain": "Python UDFs and tabular Python UDFs can read and process unstructured data in staged files using SnowflakeFile class. (True/False)", "related_lectures": []}, {"_class": "assessment", "id": 71099440, "assessment_type": "multiple-choice", "prompt": {"question": "Scoped URL is ideal for ", "answers": ["Ideal for custom applications that require access to unstructured data files", "Ideal for use in custom applications, providing unstructured data to other accounts via a share", "Ideal for business intelligence applications or reporting tools that need to display the unstructured file contents", "None of these"], "explanation": "Scoped URL: Encoded URL that permits temporary access to a staged file without granting privileges to the stage. The URL expires when the persisted query result period ends (i.e., the results cache expires), which is currently 24 hours. Ideal for use in custom applications, providing unstructured data to other accounts via a share, or for downloading and ad hoc analysis of unstructured data via Snowsight.\n\nFile URL: URL that identifies the database, schema, stage, and file path to a set of files. A role that has sufficient privileges on the stage can access the files. Ideal for custom applications that require access to unstructured data files.\n\nPre-signed URL: Simple HTTPS URL used to access a file via a web browser. A file is temporarily accessible to users via this URL using a pre-signed access token. The expiration time for the access token is configurable. Ideal for business intelligence applications or reporting tools that need to display the unstructured file contents."}, "correct_response": ["b"], "section": "Data Transformation", "question_plain": "Scoped URL is ideal for", "related_lectures": []}, {"_class": "assessment", "id": 71099442, "assessment_type": "multiple-choice", "prompt": {"question": "File URL is ideal for", "answers": ["Ideal for custom applications that require access to unstructured data files", "Ideal for use in custom applications, providing unstructured data to other accounts via a share", "Ideal for business intelligence applications or reporting tools that need to display the unstructured file contents", "None of these"], "explanation": "Scoped URL: Encoded URL that permits temporary access to a staged file without granting privileges to the stage. The URL expires when the persisted query result period ends (i.e., the results cache expires), which is currently 24 hours. Ideal for use in custom applications, providing unstructured data to other accounts via a share, or for downloading and ad hoc analysis of unstructured data via Snowsight.\n\nFile URL: URL that identifies the database, schema, stage, and file path to a set of files. A role that has sufficient privileges on the stage can access the files. Ideal for custom applications that require access to unstructured data files.\n\nPre-signed URL: Simple HTTPS URL used to access a file via a web browser. A file is temporarily accessible to users via this URL using a pre-signed access token. The expiration time for the access token is configurable. Ideal for business intelligence applications or reporting tools that need to display the unstructured file contents."}, "correct_response": ["a"], "section": "Data Transformation", "question_plain": "File URL is ideal for", "related_lectures": []}, {"_class": "assessment", "id": 71099444, "assessment_type": "multiple-choice", "prompt": {"question": "Pre-Signed URL is ideal for", "answers": ["Ideal for custom applications that require access to unstructured data files", "Ideal for use in custom applications, providing unstructured data to other accounts via a share", "Ideal for business intelligence applications or reporting tools that need to display the unstructured file contents", "None of these"], "explanation": "Scoped URL: Encoded URL that permits temporary access to a staged file without granting privileges to the stage. The URL expires when the persisted query result period ends (i.e., the results cache expires), which is currently 24 hours. Ideal for use in custom applications, providing unstructured data to other accounts via a share, or for downloading and ad hoc analysis of unstructured data via Snowsight.\n\nFile URL: URL that identifies the database, schema, stage, and file path to a set of files. A role that has sufficient privileges on the stage can access the files. Ideal for custom applications that require access to unstructured data files.\n\nPre-signed URL: Simple HTTPS URL used to access a file via a web browser. A file is temporarily accessible to users via this URL using a pre-signed access token. The expiration time for the access token is configurable. Ideal for business intelligence applications or reporting tools that need to display the unstructured file contents."}, "correct_response": ["c"], "section": "Data Transformation", "question_plain": "Pre-Signed URL is ideal for", "related_lectures": []}, {"_class": "assessment", "id": 71099446, "assessment_type": "multiple-choice", "prompt": {"question": "What is the expiration period of a Scoped URL?", "answers": ["The URL expires when the persisted query result period ends", "The URL never expires. It is permanent", "Length of time specified in the expiration_time argument"], "explanation": "The expiration period of Scoped URL: The URL expires when the persisted query result period ends.\nThe expiration period of the File URL: It is permanent.\nThe expiration period of Pre-Signed URL: Length of time specified in the expiration_time argument."}, "correct_response": ["a"], "section": "Data Transformation", "question_plain": "What is the expiration period of a Scoped URL?", "related_lectures": []}, {"_class": "assessment", "id": 71099448, "assessment_type": "multiple-choice", "prompt": {"question": "What is the expiration period of a File URL?", "answers": ["The URL expires when the persisted query result period ends", "It is Permanent", "Length of time specified in the expiration_time argument"], "explanation": "The expiration period of Scoped URL: The URL expires when the persisted query result period ends.\nThe expiration period of the File URL: It is permanent.\nThe expiration period of Pre-Signed URL: Length of time specified in the expiration_time argument."}, "correct_response": ["b"], "section": "Data Transformation", "question_plain": "What is the expiration period of a File URL?", "related_lectures": []}, {"_class": "assessment", "id": 71099450, "assessment_type": "multiple-choice", "prompt": {"question": "What is the expiration period of a Pre-signed URL?", "answers": ["The URL expires when the persisted query result period ends", "It is Permanent", "Length of time specified in the expiration_time argument"], "explanation": "The expiration period of Scoped URL: The URL expires when the persisted query result period ends.\nThe expiration period of the File URL: It is permanent.\nThe expiration period of Pre-Signed URL: Length of time specified in the expiration_time argument."}, "correct_response": ["c"], "section": "Data Transformation", "question_plain": "What is the expiration period of a Pre-signed URL?", "related_lectures": []}, {"_class": "assessment", "id": 71099452, "assessment_type": "multiple-choice", "prompt": {"question": "Snowflake supports _______", "answers": ["SOAP for unstructured data", "REST API for unstructured data", "Both of these", "None of these"], "explanation": "Currently, Snowflake only supports REST API for unstructured data."}, "correct_response": ["b"], "section": "Data Transformation", "question_plain": "Snowflake supports _______", "related_lectures": []}]}
4747086
~~~
{"count": 118, "next": null, "previous": null, "results": [{"_class": "assessment", "id": 70909108, "assessment_type": "multiple-choice", "prompt": {"question": "True or False: The ACCOUNT_USAGE views contain information on objects that have been deleted.", "answers": ["True", "False"], "explanation": "ACCOUNT_USAGE views include information for all dropped objects. Many of these views include a DELETED column showing the dropped object&#39;s information. INFORMATION_SCHEMA does not include dropped objects. Furthermore, because objects can be dropped and recreated with the same name, the account use views include ID columns that display the internal IDs generated and assigned to each object by the system to differentiate amongst object records with the same name.\n  \n  \n https://docs.snowflake.com/en/sql-reference/account-usage#differences-between-account-usage-and-information-schema"}, "correct_response": ["a"], "section": "Account Usage & Monitoring", "question_plain": "True or False: The ACCOUNT_USAGE views contain information on objects that have been deleted.", "related_lectures": []}, {"_class": "assessment", "id": 70909110, "assessment_type": "multiple-choice", "prompt": {"question": "True or False: The data in the views in the ACCOUNT_USAGE schema can have a latency of up to 3 hours.", "answers": ["True", "False"], "explanation": "The ACCOUNT USAGE schema consists of several views that provide usage metrics and metadata information at the account level.\n  \n Data provided by the ACCOUNT_USAGE views is NOT real-time and refreshes typically with a lag of 45 minutes to 3 hours, depending on the view. \n  \n The data in these views are retained for up to 365 days.\n  \n https://docs.snowflake.com/en/sql-reference/account-usage#differences-between-account-usage-and-information-schema"}, "correct_response": ["a"], "section": "Account Usage & Monitoring", "question_plain": "True or False: The data in the views in the ACCOUNT_USAGE schema can have a latency of up to 3 hours.", "related_lectures": []}, {"_class": "assessment", "id": 70909112, "assessment_type": "multiple-choice", "prompt": {"question": "The usage data provided through the INFORMATION SCHEMA has a retention of how many days?", "answers": ["7 days - 6 months", "128 days", "365 days", "Forever"], "explanation": "The data in the INFORMATION_SCHEMA views is retained for a shorter period. Typical data retention in INFORMATION SCHEMA is 14 days but can be seven days for specific views and up to 6 months for usage history views. Thus, these views have retention ranging from 7 days to a maximum of 6 months, depending on the view. So typically, the views in the INFORMATION SCHEMA can be used to find more recent information.\n  \n https://docs.snowflake.com/en/sql-reference/account-usage#differences-between-account-usage-and-information-schema"}, "correct_response": ["a"], "section": "Account Usage & Monitoring", "question_plain": "The usage data provided through the INFORMATION SCHEMA has a retention of how many days?", "related_lectures": []}, {"_class": "assessment", "id": 70909114, "assessment_type": "multiple-choice", "prompt": {"question": "True or False: The functions provided in INFORMATION_SCHEMA can be used to view account-level information.", "answers": ["True", "False"], "explanation": "The INFORMATION_SCHEMA provides data on the objects in the parent database of the INFORMATION_SCHEMA. It also provides data on account-level objects such as roles, warehouses, and databases. \n  \n https://docs.snowflake.com/en/sql-reference/info-schema#information-schema-views-and-table-functions"}, "correct_response": ["a"], "section": "Account Usage & Monitoring", "question_plain": "True or False: The functions provided in INFORMATION_SCHEMA can be used to view account-level information.", "related_lectures": []}, {"_class": "assessment", "id": 70909116, "assessment_type": "multiple-choice", "prompt": {"question": "For how long a query remains visible on the query history page in the Snowsight interface?", "answers": ["14 days", "28 days", "3 months", "60 minutes"], "explanation": "The query history page lets users view the history of executed and currently executing queries. The query history page can show the history of queries executed in the last 14 days.\n  \n  \n https://docs.snowflake.com/en/user-guide/ui-snowsight-activity#query-history"}, "correct_response": ["a"], "section": "Account Usage & Monitoring", "question_plain": "For how long a query remains visible on the query history page in the Snowsight interface?", "related_lectures": []}, {"_class": "assessment", "id": 70909118, "assessment_type": "multiple-choice", "prompt": {"question": "Which of the following can create a new resource monitor?", "answers": ["An account administrator (i.e., a person with the ACCOUNTADMIN role)", "A user who has MONITOR and MODIFY privilege on the resource monitor.", "A system administrator (i.e., a person with the SYSADMIN role).", "Any user of the system"], "explanation": "From a privilege perspective, only Account Administrators (users with ACCOUNTADMIN role) can create new resource monitors. However, account administrators can grant privileges to an existing resource monitor to allow other users to view and modify the resource monitor configuration. The MONITOR and MODIFY privileges on a resource monitor allow other users to view and modify a specific resource monitor.\n  \n https://docs.snowflake.com/en/user-guide/resource-monitors#access-control-privileges-for-resource-monitors"}, "correct_response": ["a"], "section": "Account Usage & Monitoring", "question_plain": "Which of the following can create a new resource monitor?", "related_lectures": []}, {"_class": "assessment", "id": 70909120, "assessment_type": "multiple-choice", "prompt": {"question": "True or False: Snowflake applies new software versions to all Snowflake customers at once?", "answers": ["False", "True"], "explanation": "Snowflake does not instantly deploy a new version to all Snowflake accounts; rather, customer accounts are moved into the new release over time in a phased manner.\n  \n Day 1 (early access): Deployed for Enterprise edition (or higher) accounts that have elected for early access. You can enroll an Enterprise edition (or higher) account for early access by contacting Snowflake support.\n  \n Day 1 or 2 (regular access): Deployment of all Snowflake accounts on the Standard edition. \n  \n Day 2 (last): All remaining Enterprise edition (or higher) accounts are deployed. \n  \n Between an early access deployment and a final deployment, a minimum of 24 hours must pass. This staged release strategy enables Snowflake to identify and address any software issues uncovered during early access.\n  \n https://docs.snowflake.com/en/user-guide/intro-releases"}, "correct_response": ["a"], "section": "Account", "question_plain": "True or False: Snowflake applies new software versions to all Snowflake customers at once?", "related_lectures": []}, {"_class": "assessment", "id": 70909122, "assessment_type": "multiple-choice", "prompt": {"question": "True/False: The storage capacity of your Snowflake-based data warehouse is virtually unlimited because it uses cloud storage as the underlying storage mechanism.", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "Since Snowflake uses cloud-based storage like Amazon S3 or Azure Blob storage, the amount of space available to Snowflake is virtually unlimited.", "answers": ["<p><strong>True</strong></p>", "<p><strong>False</strong></p>"]}, "correct_response": ["a"], "section": "Architecture", "question_plain": "True/False: The storage capacity of your Snowflake-based data warehouse is virtually unlimited because it uses cloud storage as the underlying storage mechanism.", "related_lectures": []}, {"_class": "assessment", "id": 70909124, "assessment_type": "multiple-choice", "prompt": {"question": "Snowflake database is based on the massively parallel shared nothing architecture used by databases like Teradata and Greenplum and data lakes like Hadoop.", "answers": ["No", "Yes"], "explanation": "Snowflake implements a new hybrid architecture that combines the best features of shared-disk and shared-nothing architectures. Snowflake stores data similarly to a shared-disk architecture, i.e., the data is shared. But it also allows for using several compute engines, each with its own memory and processing capabilities.\n  \n https://docs.snowflake.com/en/user-guide/intro-key-concepts#snowflake-architecture"}, "correct_response": ["a"], "section": "Architecture", "question_plain": "Snowflake database is based on the massively parallel shared nothing architecture used by databases like Teradata and Greenplum and data lakes like Hadoop.", "related_lectures": []}, {"_class": "assessment", "id": 70909126, "assessment_type": "multiple-choice", "prompt": {"question": "True/False: The compute and storage can be scaled independently in Snowflake architecture.", "answers": ["True", "False"], "explanation": "True. Snowflake stores data similarly to a shared-disk architecture, i.e., the data is shared. But it also allows for using several compute engines, each with its own memory and processing capabilities. This architecture allows Snowflake to scale compute and storage independently.\n  \n https://docs.snowflake.com/en/user-guide/intro-key-concepts#snowflake-architecture"}, "correct_response": ["a"], "section": "Architecture", "question_plain": "True/False: The compute and storage can be scaled independently in Snowflake architecture.", "related_lectures": []}, {"_class": "assessment", "id": 70909128, "assessment_type": "multiple-choice", "prompt": {"question": "True/False: Snowflake customers can control the format using which Snowflake stores the data for a table.", "answers": ["False", "True"], "explanation": "Snowflake stores data in a proprietary format on cloud object storage, such as AWS S3, Azure Blob Storage, or Google Cloud Storage. Users cannot see the actual files, look at how the data is stored, or access the file directly. Users can not change how Snowflake stores the data behind the scenes."}, "correct_response": ["a"], "section": "Architecture", "question_plain": "True/False: Snowflake customers can control the format using which Snowflake stores the data for a table.", "related_lectures": []}, {"_class": "assessment", "id": 70909130, "assessment_type": "multi-select", "prompt": {"question": "Which of the following statements about micro-partitions is correct? Select all that apply.", "answers": ["Column values may overlap across micro-partitions.", "Micro-partitions are created and added to a table in the order that new data arrives.", "Column values can never overlap between micro-partitions.", "Snowflake uses a row storage format to store columns in each micro-partition."], "explanation": "Because micro-partitions are immutable and new or changed data must be added to a new micro-partition, similar values may not be in the same physical partition. When micro-partitions are added to a table, they are created in the order that the data came in. When more data is added to a table, another micro-partition or possibly many micro-partitions are created to store the new data. Unlike partitioning in many other databases, in Snowflake, values can overlap between different micro-partitions.\n  \n https://docs.snowflake.com/en/user-guide/tables-clustering-micropartitions"}, "correct_response": ["a", "b"], "section": "Architecture", "question_plain": "Which of the following statements about micro-partitions is correct? Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70909132, "assessment_type": "multiple-choice", "prompt": {"question": "True/False: Once created, micro-partitions are immutable and cannot be modified.", "answers": ["True", "False"], "explanation": "Snowflake partitions are immutable, which means they cannot be changed once created.\n  \n https://docs.snowflake.com/en/user-guide/tables-clustering-micropartitions.html"}, "correct_response": ["a"], "section": "Micro partitions", "question_plain": "True/False: Once created, micro-partitions are immutable and cannot be modified.", "related_lectures": []}, {"_class": "assessment", "id": 70909134, "assessment_type": "multiple-choice", "prompt": {"question": "Large tables can have ___________ micro-partitions.", "answers": ["Millions or hundreds of millions", "Tens", "Hundreds"], "explanation": "The number of micro-partitions for a given table depends mainly on the amount of data in that table. For a very large table, the number of micro-partitions can run into millions or hundreds of millions of micro-partitions.\n  \n https://docs.snowflake.com/en/user-guide/tables-clustering-micropartitions"}, "correct_response": ["a"], "section": "Architecture", "question_plain": "Large tables can have ___________ micro-partitions.", "related_lectures": []}, {"_class": "assessment", "id": 70909136, "assessment_type": "multiple-choice", "prompt": {"question": "True/False: If you create more than one virtual warehouse, they will share the memory and CPU resources.", "answers": ["False", "True"], "explanation": "Snowflake stores data in a shared manner, like in shared-disk architecture. But it also allows for using several compute engines, each with its own memory and processing capabilities. The virtual warehouses are independent of each other but access and process the same shared data. \n  \n https://docs.snowflake.com/en/user-guide/intro-key-concepts#snowflake-architecture"}, "correct_response": ["a"], "section": "Architecture", "question_plain": "True/False: If you create more than one virtual warehouse, they will share the memory and CPU resources.", "related_lectures": []}, {"_class": "assessment", "id": 70909138, "assessment_type": "multi-select", "prompt": {"question": "Which of the following statement is true regarding the Query Processing Layer?", "answers": ["The query processing layer is responsible for executing queries.", "The query processing layer can run multiple compute clusters (virtual warehouses) simultaneously.", "The query processing layer is responsible for generating query plans.", "The query processing layer is responsible for optimizing query plans"], "explanation": "The query processing layer is the compute layer through which queries and data processing jobs are executed on the stored data. The compute layer can have multiple clusters for a given Snowflake instance simultaneously. The compute engines in Snowflake are known as virtual warehouses.\n  \n The cloud services layer performs the query plans and optimization.\n  \n https://docs.snowflake.com/en/user-guide/intro-key-concepts"}, "correct_response": ["a", "b"], "section": "Architecture", "question_plain": "Which of the following statement is true regarding the Query Processing Layer?", "related_lectures": []}, {"_class": "assessment", "id": 70909140, "assessment_type": "multiple-choice", "prompt": {"question": "A virtual warehouse was started, used for 45 seconds, and shut down after that. The customer will be charged for how many seconds?", "answers": ["60 seconds", "45 seconds", "315 seconds", "3600 seconds"], "explanation": "Snowflake credits are billed on a per-second usage basis. However, note that a minimum of 60 seconds of billing applies, so if a virtual warehouse were started and shut down within the first 1st minute, a minimum of 60-second credit usage would apply."}, "correct_response": ["a"], "section": "Architecture", "question_plain": "A virtual warehouse was started, used for 45 seconds, and shut down after that. The customer will be charged for how many seconds?", "related_lectures": []}, {"_class": "assessment", "id": 70909142, "assessment_type": "multiple-choice", "prompt": {"question": "What type of virtual warehouse automatically lets you add or remove additional clusters as concurrency and demand change?", "answers": ["Multi-cluster virtual warehouse", "Suspended virtual warehouse", "X-Large virtual warehouse", "Non-virtual warehouse"], "explanation": "Multi-cluster virtual warehouses are utilized when the number of concurrent users exceeds a single virtual warehouse&#39;s capacity. When the concurrent workload for a virtual warehouse reaches the maximum, new queries are queued. Multi-cluster virtual warehouses address this by adding clusters as needed. When the demand drops, the extra clusters are removed.\n  \n https://docs.snowflake.com/en/user-guide/warehouses-considerations#how-are-credits-charged-for-warehouses"}, "correct_response": ["a"], "section": "Elastic Compute", "question_plain": "What type of virtual warehouse automatically lets you add or remove additional clusters as concurrency and demand change?", "related_lectures": []}, {"_class": "assessment", "id": 70909144, "assessment_type": "multiple-choice", "prompt": {"question": "A virtual warehouse is running and executing two queries. The virtual warehouse is resized to a smaller size. What best describes the resize operation?", "answers": ["The resize operation succeeds, but the node removal occurs once the active queries are finished.", "The queries are stopped, and the virtual warehouse is immediately resized to a smaller size.", "The resize operation fails as a virtual warehouse cannot be resized while it is running queries", "The queries are paused while the virtual warehouse is resized to a smaller size."], "explanation": "You can resize a virtual warehouse anytime, even when they are running queries. When resizing to a smaller size, nodes&#39; removal occurs only when all active queries on those nodes have finished.\n  \n https://docs.snowflake.com/en/user-guide/warehouses-tasks#resizing-a-warehouse"}, "correct_response": ["a"], "section": "Architecture", "question_plain": "A virtual warehouse is running and executing two queries. The virtual warehouse is resized to a smaller size. What best describes the resize operation?", "related_lectures": []}, {"_class": "assessment", "id": 70909146, "assessment_type": "multiple-choice", "prompt": {"question": "Which Snowflake layer manages the metadata related to micro-partitions, databases, and tables?", "answers": ["Cloud Services", "Query Processing", "Database Storage", "Client Tools"], "explanation": "The cloud services layer contains and manages a variety of metadata, including details regarding how the data is stored, information on the micro-partitions, metadata regarding the databases and tables in your system, the users, roles and security, and so forth."}, "correct_response": ["a"], "section": "Architecture", "question_plain": "Which Snowflake layer manages the metadata related to micro-partitions, databases, and tables?", "related_lectures": []}, {"_class": "assessment", "id": 70909148, "assessment_type": "multi-select", "prompt": {"question": "Which of the following criteria must be met for Snowflake to reuse the query result cache for a query? Choose all that apply.", "answers": ["The query does not make use of runtime functions.", "The underlying data that contributes to the query results has remained unchanged.", "A new query matches an old query.", "The table micro-partitions have NOT altered as a result of reclustering or consolidation.", "The query makes no use of user-defined or external functions."], "explanation": "All of these are correct. Snowflake uses the query result cache if the following conditions are met. A new query matches an old query, and the underlying data contributing to the query results remains unchanged. The table micro-partitions have not changed as a result of clustering or consolidation. The query makes no use of user-defined, external, or runtime functions. \n Note that queries that use the CURRENT DATE function are eligible for query result caching.\n  \n https://docs.snowflake.com/en/user-guide/querying-persisted-results"}, "correct_response": ["a", "b", "c", "d", "e"], "section": "Architecture", "question_plain": "Which of the following criteria must be met for Snowflake to reuse the query result cache for a query? Choose all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70909150, "assessment_type": "multiple-choice", "prompt": {"question": "Which one of the following correctly represents the storage hierarchy in Snowflake?", "answers": ["Account-&gt;Database-&gt;Schema-&gt;Table", "Database-&gt;Account-&gt;Schema-&gt;Table", "Schema-&gt;Account-&gt;Database-&gt;Table", "Account-&gt;Table-&gt;Database-&gt;Schema"], "explanation": "In Snowflake, the highest level is a Snowflake Account. Customers can have as many accounts as they like. Within an account, you have databases. Each database contains one or more schemas. Schemas contain other Objects. Tables, views, file formats, sequences, UDFs, and stored procedures are all examples of objects available in a schema. An object can be contained in only one schema."}, "correct_response": ["a"], "section": "Snowflake\u2019s catalogue and objects.", "question_plain": "Which one of the following correctly represents the storage hierarchy in Snowflake?", "related_lectures": []}, {"_class": "assessment", "id": 70909152, "assessment_type": "multi-select", "prompt": {"question": "You are unloading data from a multi-gigabyte table to an external stage; which of the following statements regarding the exported file(s) are correct? Select all that apply.", "answers": ["The exported file(s) are compressed.", "Each exported file is 16MB in size.", "The data is exported to multiple files.", "The exported file(s) are NOT compressed.", "The data is exported to a single large file."], "explanation": "When data is unloaded from Snowflake, it is automatically compressed using gzip compression. This is the default behavior; however, you can specify alternate compression methods or turn off compression entirely.\n  \n The unloading process automatically exports to multiple files so that it can take advantage of the parallelism offered by Snowflake. However, if needed, you can set the SINGLE parameter to true to ensure the export goes to a single file.\n  \n The default size of each output file is 16 MB but can be changed using the MAX_FILE_SIZE parameter. The maximum allowed size per file is 5GB if you export data to cloud storage. \n  \n  \n https://docs.snowflake.com/en/user-guide/data-unload-considerations#unloading-to-a-single-file"}, "correct_response": ["a", "b", "c"], "section": "Data Loading and Unloading", "question_plain": "You are unloading data from a multi-gigabyte table to an external stage; which of the following statements regarding the exported file(s) are correct? Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70909154, "assessment_type": "multiple-choice", "prompt": {"question": "True or False: When unloading data, each exported file is 16MB, and this configuration cannot be changed.", "answers": ["False", "True"], "explanation": "The default size of each output file is 16 MB but can be changed using the MAX_FILE_SIZE parameter. The maximum allowed size per file is 5GB if you export data to cloud storage. \n  \n  \n https://docs.snowflake.com/en/user-guide/data-unload-considerations#unloading-to-a-single-file"}, "correct_response": ["a"], "section": "Data Loading and Unloading", "question_plain": "True or False: When unloading data, each exported file is 16MB, and this configuration cannot be changed.", "related_lectures": []}, {"_class": "assessment", "id": 70909156, "assessment_type": "multi-select", "prompt": {"question": "Which of the following statements are true regarding External Tables? Select all that apply.", "answers": ["An external table supports only external stages.", "The data for an external table is stored in cloud storage managed by the customer.", "An external table is another name for transient tables.", "An external table supports internal stages."], "explanation": "An external table is a metadata definition; that is, you register the definition of an external table, but the external table itself doesn&#39;t contain any data. Instead, the table metadata contains column definition, the name of the external stage from where the data for the external table is, and the file format which should be used to read that data. \n  \n The external stage, in turn, points to object storage on the cloud, for example, an AWS bucket or Azure Blob storage, which contains the data for the external table. \n  \n Note that an external table can only point to an external stage. An internal stage cannot be used to create an external table.\n  \n https://docs.snowflake.com/en/user-guide/tables-external-intro"}, "correct_response": ["a", "b"], "section": "Data Loading and Unloading", "question_plain": "Which of the following statements are true regarding External Tables? Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70909158, "assessment_type": "multi-select", "prompt": {"question": "Which of the following statements are true regarding External Tables? Select all that apply.", "answers": ["You can query an external table just like a regular table.", "An external table can be joined with other tables.", "An external table can not be joined with other tables.", "An external table can not be queried."], "explanation": "Snowflake offers an alternative approach for tables called external tables, which permits the creation of tables with data stored in external cloud storage. External tables remove the need for the data to be loaded into Snowflake. In the case of an External table, the definition of the table is still stored in Snowflake metadata and consists of table structure, file locations, filenames, and other attributes. However, the table&#39;s data is saved outside of Snowflake.\n  \n The external table functionality enables you to query external data like a standard table. External tables may be joined to other tables, and views may be created using them.\n  \n https://docs.snowflake.com/en/user-guide/tables-external-intro"}, "correct_response": ["a", "b"], "section": "Data Loading and Unloading", "question_plain": "Which of the following statements are true regarding External Tables? Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70909160, "assessment_type": "multi-select", "prompt": {"question": "Snowflake can load data staged in which of the following?", "answers": ["Internal Stage", "AWS S3", "Google Cloud Storage", "Azure Blob Storage", "Oracle Cloud Storage", "VMWare Storage"], "explanation": "Snowflake supports loading from Internal Stages and External Stages. External Stages can use AWS S3, Azure Blob, and Google Cloud Storage.\n  \n Before data can be processed into a Snowflake table, it is typically first made available in a Snowflake stage. This allows Snowflake access to the data to be loaded into a table. Once the data is available in a stage, the COPY command can be used to copy the data into a table.\n  \n https://docs.snowflake.com/en/user-guide/data-load-overview"}, "correct_response": ["a", "b", "c", "d"], "section": "Data Loading and Unloading", "question_plain": "Snowflake can load data staged in which of the following?", "related_lectures": []}, {"_class": "assessment", "id": 70909162, "assessment_type": "multiple-choice", "prompt": {"question": "True or False: Files already loaded from a stage to a table can be loaded again into a cloned table.", "answers": ["True", "False"], "explanation": "Cloning doesn&#39;t copy the load metadata of a cloned table. Therefore, the load metadata for a cloned table would be empty. Thus, files already loaded for the source table can be loaded again into the cloned table."}, "correct_response": ["a"], "section": "Data Loading and Unloading", "question_plain": "True or False: Files already loaded from a stage to a table can be loaded again into a cloned table.", "related_lectures": []}, {"_class": "assessment", "id": 70909164, "assessment_type": "multi-select", "prompt": {"question": "Which of the following is true regarding data encryption when using PUT to upload data to a Snowflake internal stage? Select two.", "answers": ["Data is encrypted automatically at the client machine before being transmitted to the Snowflake internal stage.", "Data is stored encrypted in the Snowflake internal stage.", "Snowflake&#39;s internal stages do not support encryption.", "The PUT command does not support encryption."], "explanation": "Data is encrypted automatically at the client machine before being transmitted to the Snowflake internal stage. Once the data is in an internal stage, it is stored encrypted.\n This is part of the end-to-end encryption managed by Snowflake.\n  \n https://docs.snowflake.com/en/user-guide/security-encryption-end-to-end"}, "correct_response": ["a", "b"], "section": "Data Loading and Unloading", "question_plain": "Which of the following is true regarding data encryption when using PUT to upload data to a Snowflake internal stage? Select two.", "related_lectures": []}, {"_class": "assessment", "id": 70909166, "assessment_type": "multiple-choice", "prompt": {"question": "Which of the following correctly describe Snowpipe?", "answers": ["Snowpipe is used to load a small volume of data that arrives frequently and continuously.", "Snowpipe is used to load large volumes of data in a batch manner.", "Snowpipe is used for backup and recovery.", "Snowpipe is a security mechanism providing a secure pipe for communication."], "explanation": "Snowflake allows continuous data loading using Snowpipe, a serverless service. Snowpipe enables you to load data in a micro-batch manner, loading small volumes of data on each execution. The micro-batch-based data loading is used when a continuous stream of data, such as transactions or events, must be loaded and made available to enterprises quickly. Snowpipe enables continuous data loading and can load data within a few minutes after it arrives in a stage.\n  \n Snowpipe is serverless and has its own computational capability; therefore, it does not rely on virtual warehouses for processing. Snowflake automatically manages the compute required by a Snowpipe. Snowflake also manages the scaling up and down of a Snowpipe as per the data load requirement. Since a Snowpipe is serverless, its costs are charged separately from virtual warehousing fees.\n  \n  \n https://docs.snowflake.com/en/user-guide/data-load-snowpipe-intro"}, "correct_response": ["a"], "section": "Data Loading and Unloading", "question_plain": "Which of the following correctly describe Snowpipe?", "related_lectures": []}, {"_class": "assessment", "id": 70909168, "assessment_type": "multiple-choice", "prompt": {"question": "True or False: The COPY command in a Snowpipe definition supports the same transformation as provided by the typical COPY command.", "answers": ["True", "False"], "explanation": "Snowpipe uses the COPY command in its definition and can support the same transformations available to the COPY command.\n  \n https://docs.snowflake.com/en/user-guide/data-load-snowpipe-intro#how-does-snowpipe-work"}, "correct_response": ["a"], "section": "Data Loading and Unloading", "question_plain": "True or False: The COPY command in a Snowpipe definition supports the same transformation as provided by the typical COPY command.", "related_lectures": []}, {"_class": "assessment", "id": 70909170, "assessment_type": "multi-select", "prompt": {"question": "Which of the following transformations are NOT supported by the COPY command? Select all that apply.", "answers": ["JOIN", "SUM", "GROUP BY", "Truncate columns"], "explanation": "When loading data into a table using the COPY command, Snowflake allows you to do simple transformations on the data as it is being loaded. During the load process, the COPY command allows for modifying the order of columns, omitting one or more columns, casting data into specified data types, and truncating values.\n  \n While loading the data, complex transformations such as joins, filters, aggregations, and the use of FLATTEN are not supported as they are not essential data transformations. Therefore, joining, filtering, and aggregating the data are supported ONLY after the data has been loaded into a table.\n  \n https://docs.snowflake.com/en/user-guide/data-load-overview#id2"}, "correct_response": ["a", "b", "c"], "section": "Data Loading and Unloading", "question_plain": "Which of the following transformations are NOT supported by the COPY command? Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70909172, "assessment_type": "multiple-choice", "prompt": {"question": "Failsafe is provided as an alternate means to access historical data once the Time Travel retention period has ended.", "answers": ["False", "True"], "explanation": "After the Time Travel period has been completed, the fail-safe storage feature stores data for an additional period of seven days. The fail-safe storage offers additional security against data loss; however, only the Snowflake support team can restore data from the fail-safe storage. Fail-safe cannot be used to access historical data but is used to recover from accidental data loss. \n  \n https://docs.snowflake.com/en/user-guide/data-failsafe"}, "correct_response": ["a"], "section": "Fail-safe", "question_plain": "Failsafe is provided as an alternate means to access historical data once the Time Travel retention period has ended.", "related_lectures": []}, {"_class": "assessment", "id": 70909174, "assessment_type": "multiple-choice", "prompt": {"question": "True/False: It is possible to disable failsafe entirely for a Snowflake account.", "answers": ["False", "True"], "explanation": "Once the Time Travel period ends, Snowflake keeps the data for a further 7-day period as further protection. This fail-safe can not be disabled or configured. You can NOT change it for a Snowflake account, database, schema, or table.\n  \n However, you can use Transient or Temporary tables, which have zero days of fail-safe storage.\n  \n https://docs.snowflake.com/en/user-guide/data-failsafe\n https://docs.snowflake.com/en/user-guide/tables-temp-transient"}, "correct_response": ["a"], "section": "Fail-safe", "question_plain": "True/False: It is possible to disable failsafe entirely for a Snowflake account.", "related_lectures": []}, {"_class": "assessment", "id": 70909176, "assessment_type": "multiple-choice", "prompt": {"question": "As part of a data processing pipeline, you are required to store data in an interim table. The subsequent processes then use the table in the pipeline. The data is deleted and reloaded every time the pipeline is executed. You are required to minimize data storage costs. Which type of table will you create?", "answers": ["Transient", "Temporary", "Permanent", "External"], "explanation": "Based on the requirement, a Transient table is a good option. Transient tables don&#39;t have fail-safe storage and have only up to 1 day of Time Travel. Because the data in this table is deleted and reloaded daily, a transient table provides the best solution. Transient tables are available across sessions, so different processes and sessions can access them. \n  \n https://docs.snowflake.com/en/user-guide/tables-temp-transient"}, "correct_response": ["a"], "section": "Data Protection", "question_plain": "As part of a data processing pipeline, you are required to store data in an interim table. The subsequent processes then use the table in the pipeline. The data is deleted and reloaded every time the pipeline is executed. You are required to minimize data storage costs. Which type of table will you create?", "related_lectures": []}, {"_class": "assessment", "id": 70909178, "assessment_type": "multiple-choice", "prompt": {"question": "<p><strong>True/False: Once the Time Travel retention period has ended for a transient table, historical data for that table can not be recovered by Snowflake support.</strong></p>", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "Transient and temporary tables don&#39;t have fail-safe functionality; therefore, data in such tables goes through zero days of fail-safe storage. Also, Transient and Temporary tables have a maximum of 1 day of Time Travel.\n  \n Therefore, once the Time Travel period for these tables is complete, there is no way to recover historical data.\n  \n https://docs.snowflake.com/en/user-guide/tables-temp-transient", "answers": ["True", "False"]}, "correct_response": ["a"], "section": "Data Protection", "question_plain": "True/False: Once the Time Travel retention period has ended for a transient table, historical data for that table can not be recovered by Snowflake support.", "related_lectures": []}, {"_class": "assessment", "id": 70909184, "assessment_type": "multi-select", "prompt": {"question": "Which object types can be recovered using the UNDROP command after they have been dropped? Select all that apply.", "answers": ["Database", "Schema", "Table", "User", "Role"], "explanation": "The UNDROP functionality applies to tables, schemas, and databases. That means you can restore complete databases or schemas and their child objects.\n  \n https://docs.snowflake.com/en/user-guide/data-time-travel#restoring-objects"}, "correct_response": ["a", "b", "c"], "section": "Time Travel", "question_plain": "Which object types can be recovered using the UNDROP command after they have been dropped? Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70909186, "assessment_type": "multiple-choice", "prompt": {"question": "A data consumer has created a read-only database on a Share object shared by a data provider. The data provider adds an object to the Share. Which of the following statement correctly describe what happens?", "answers": ["The data consumer can see and consume the new object immediately.", "The data consumer needs to run &quot;ALTER SHARE &lt;share_name&gt; REFRESH&quot; to ensure that the added object appears in the read-only database.", "Adding objects to a Share is impossible after a consumer creates a read-only database."], "explanation": "All new objects added to a share object by the data provider automatically become accessible to the consumer\n  \n https://docs.snowflake.com/en/user-guide/data-sharing-intro#what-is-a-share"}, "correct_response": ["a"], "section": "Data Sharing", "question_plain": "A data consumer has created a read-only database on a Share object shared by a data provider. The data provider adds an object to the Share. Which of the following statement correctly describe what happens?", "related_lectures": []}, {"_class": "assessment", "id": 70909188, "assessment_type": "multiple-choice", "prompt": {"question": "True or False: To share data as a provider and consume data as a consumer, you must have two Snowflake accounts, one for sharing data and one for consuming shared data.", "answers": ["False", "True"], "explanation": "The same Snowflake account can share (as a data provider) and consume data (as a data consumer)."}, "correct_response": ["a"], "section": "Data Sharing", "question_plain": "True or False: To share data as a provider and consume data as a consumer, you must have two Snowflake accounts, one for sharing data and one for consuming shared data.", "related_lectures": []}, {"_class": "assessment", "id": 70909190, "assessment_type": "multiple-choice", "prompt": {"question": "A Snowflake share can only have one consumer account added to it.", "answers": ["False", "True"], "explanation": "A Snowflake share can have zero, one, or multiple consumers added to it"}, "correct_response": ["a"], "section": "Data Sharing", "question_plain": "A Snowflake share can only have one consumer account added to it.", "related_lectures": []}, {"_class": "assessment", "id": 70909192, "assessment_type": "multiple-choice", "prompt": {"question": "Assume a share has been granted to a consumer, and the consumer has created a database on the Share. Which of the following correctly describes what occurs if a new object is added to the Share?", "answers": ["The new object becomes accessible to the consumer immediately.", "The consumer is required to re-create a database from the granted Share object.", "Adding objects to a share is impossible once created and granted to a consumer."], "explanation": "Once a share has been granted to a consumer, and the consumer has created a read-only database on the Share, all new objects added to the Share by the data provider automatically become accessible to the consumer as soon as they are added to the Share by the data provider."}, "correct_response": ["a"], "section": "Data Sharing", "question_plain": "Assume a share has been granted to a consumer, and the consumer has created a database on the Share. Which of the following correctly describes what occurs if a new object is added to the Share?", "related_lectures": []}, {"_class": "assessment", "id": 70909194, "assessment_type": "multiple-choice", "prompt": {"question": "You are required to share data from various tables in separate databases. What is the recommended approach to simplify the sharing process?", "answers": ["Create secure views in a single database to consolidate the data from various databases into a new database. Share the new database.", "Clone tables from the separate databases into a new database. Share the new database.", "Copy all data from the various tables into new tables in a new database. Share the new database.", "Create one Share per database."], "explanation": "You may create a secure view if you need to share data from many tables in separate databases. Because several databases cannot be added to a single share, Snowflake suggests creating secure views within a single database and sharing that database.\n  \n https://docs.snowflake.com/en/user-guide/data-sharing-mutiple-db"}, "correct_response": ["a"], "section": "Data Sharing", "question_plain": "You are required to share data from various tables in separate databases. What is the recommended approach to simplify the sharing process?", "related_lectures": []}, {"_class": "assessment", "id": 70909196, "assessment_type": "multiple-choice", "prompt": {"question": "True or False: A reader account can be used to share data with a non-Snowflake user or a non-Snowflake organization.", "answers": ["True", "False"], "explanation": "Sharing data with a non-Snowflake user or organization is possible by creating a reader account. This reader account is created by the data provider solely for sharing purposes.\n https://docs.snowflake.com/en/user-guide/data-sharing-reader-create"}, "correct_response": ["a"], "section": "Data Sharing", "question_plain": "True or False: A reader account can be used to share data with a non-Snowflake user or a non-Snowflake organization.", "related_lectures": []}, {"_class": "assessment", "id": 70909198, "assessment_type": "multi-select", "prompt": {"question": "Which of the following privileges allows a user in a consumer account to create a database from a share? Select two.", "answers": ["ACCOUNTADMIN role", "IMPORT SHARE privileges", "SYSADMIN role", "SECURITY ADMIN role"], "explanation": "A user in a consumer account can create a database from the Share if they have the ACCOUNTADMIN role OR the IMPORT SHARE privileges\n  \n https://docs.snowflake.com/en/user-guide/data-share-consumers"}, "correct_response": ["a", "b"], "section": "Data Sharing", "question_plain": "Which of the following privileges allows a user in a consumer account to create a database from a share? Select two.", "related_lectures": []}, {"_class": "assessment", "id": 70909200, "assessment_type": "multiple-choice", "prompt": {"question": "Which of the following Snowflake edition doesn&#39;t support Snowflake Marketplace?", "answers": ["VPS or Virtual Private Snowflake", "Enterprise", "Business Critical", "Standard"], "explanation": "All Snowflake accounts, except VPS Snowflake accounts, can use the Snowflake Marketplace.\n  \n VPS accounts have isolated metadata and compute and, therefore, can&#39;t use the Snowflake marketplace built on the common cloud services and metadata provided by Snowflake.\n  \n https://other-docs.snowflake.com/en/collaboration/collaboration-marketplace-about.html#about-the-snowflake-marketplace"}, "correct_response": ["a"], "section": "Data Sharing", "question_plain": "Which of the following Snowflake edition doesn&#39;t support Snowflake Marketplace?", "related_lectures": []}, {"_class": "assessment", "id": 70909202, "assessment_type": "multiple-choice", "prompt": {"question": "Through which of the following can users search for and consume third-party datasets?", "answers": ["Snowflake Marketplace", "Secure Data Sharing", "Partner Hub", "Sharing Centre"], "explanation": "Snowflake Marketplace is the place to find and use third-party datasets that different organizations have made available. Users can search and consume third-party data sets using Snowflake Marketplace.\n  \n https://other-docs.snowflake.com/en/collaboration/collaboration-marketplace-about.html"}, "correct_response": ["a"], "section": "Data Sharing", "question_plain": "Through which of the following can users search for and consume third-party datasets?", "related_lectures": []}, {"_class": "assessment", "id": 70909204, "assessment_type": "multiple-choice", "prompt": {"question": "<p><strong>Assume a table with the structure below, which you have already loaded with JSON data.</strong></p><p><strong> </strong></p><p><strong> CREATE TABLE my_json_table (</strong></p><p><strong>&nbsp; json_data VARIANT</strong></p><p><strong> );</strong></p><p><strong> </strong></p><p><strong> The JSON data looks like following</strong></p><p><strong> </strong></p><p><strong> { </strong></p><p><strong>&nbsp; \"data_set\":\"organizations\",</strong></p><p><strong>&nbsp; \"date_extracted\":\"2019-12-10\",</strong></p><p><strong>&nbsp; \"organizations\": [ </strong></p><p><strong>&nbsp; { </strong></p><p><strong>&nbsp; \"Company\": \"Netus Et Malesuada Industries\",</strong></p><p><strong>&nbsp; \"State\": \"VIC\", </strong></p><p><strong>&nbsp; \"OrganisationCode\": \"36783603099\" </strong></p><p><strong>&nbsp; }, </strong></p><p><strong>&nbsp; { </strong></p><p><strong>&nbsp; \"Company\": \"Amet Luctus PC\",</strong></p><p><strong>&nbsp; \"State\": \"NSW\",</strong></p><p><strong>&nbsp; \"OrganisationCode\": \"37908951399\"</strong></p><p><strong>&nbsp; }</strong></p><p><strong>&nbsp; ]</strong></p><p><strong> }</strong></p><p><strong> </strong></p><p><strong> What is the correct way to access the \"date_extracted\" value to be loaded into a relational table?</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", ""], "explanation": "Please see the following link on performing queries on JSON data.\n  \n https://docs.snowflake.com/en/user-guide/semistructured-intro", "answers": ["<p><strong>SELECT </strong></p><p><strong>&nbsp; json_data:date_extracted</strong></p><p><strong> FROM my_json_table;</strong></p>", "<p><strong>SELECT </strong></p><p><strong>&nbsp; extract(date_extracted from json_data)</strong></p><p><strong> FROM my_json_table;</strong></p>", "There is no way to access this data as the data has been loaded into a VARIANT column."]}, "correct_response": ["a"], "section": "Data Loading and Unloading", "question_plain": "Assume a table with the structure below, which you have already loaded with JSON data.  CREATE TABLE my_json_table (&nbsp; json_data VARIANT );  The JSON data looks like following  { &nbsp; \"data_set\":\"organizations\",&nbsp; \"date_extracted\":\"2019-12-10\",&nbsp; \"organizations\": [ &nbsp; { &nbsp; \"Company\": \"Netus Et Malesuada Industries\",&nbsp; \"State\": \"VIC\", &nbsp; \"OrganisationCode\": \"36783603099\" &nbsp; }, &nbsp; { &nbsp; \"Company\": \"Amet Luctus PC\",&nbsp; \"State\": \"NSW\",&nbsp; \"OrganisationCode\": \"37908951399\"&nbsp; }&nbsp; ] }  What is the correct way to access the \"date_extracted\" value to be loaded into a relational table?", "related_lectures": []}, {"_class": "assessment", "id": 70909206, "assessment_type": "multiple-choice", "prompt": {"question": "True or False: Snowflake does not support the loading of semi-structured data.", "answers": ["False", "True"], "explanation": "Snowflake supports loading and processing semi-structured data. Snowflake provides the VARIANT data type, which can store any data and is appropriate for semi-structured data input and querying. SQL may be used to read and navigate JSON data once it has been loaded into a VARIANT column.\n  \n https://docs.snowflake.com/en/user-guide/semistructured-intro"}, "correct_response": ["a"], "section": "Data Loading and Unloading", "question_plain": "True or False: Snowflake does not support the loading of semi-structured data.", "related_lectures": []}, {"_class": "assessment", "id": 70909208, "assessment_type": "multi-select", "prompt": {"question": "Which of the following could be used as a remote service for an external function?", "answers": ["AWS Lambda Function", "Microsoft Azure Function", "Node.js running on an EC2 instance"], "explanation": "All of these are valid examples of how an external function could be implemented.\n  \n https://docs.snowflake.com/en/sql-reference/external-functions-introduction"}, "correct_response": ["a", "b", "c"], "section": "Extending Snowflake Functionality", "question_plain": "Which of the following could be used as a remote service for an external function?", "related_lectures": []}, {"_class": "assessment", "id": 70909210, "assessment_type": "multi-select", "prompt": {"question": "How does a secure UDF differ from a different typical UDF?", "answers": ["Secure UDF does not use specific SQL optimizations.", "Secure UDFs don&#39;t allow unauthorized users to see the UDF definition.", "Secure UDFs can only be executed by administrators.", "Secure UDFs are written in machine language and are compiled into Snowflake&#39;s code."], "explanation": "Specific SQL UDF optimizations may allow data that should be hidden from users to be accessed indirectly via different techniques. Secure UDFs do not use these SQL optimizations, ensuring that users have no access to the underlying data, even indirectly. \n Furthermore, Secure UDFs allow only authorized users to see the definition and information of secure UDFs (i.e., users who are granted the role that owns the UDF).\n  \n https://docs.snowflake.com/en/developer-guide/secure-udf-procedure"}, "correct_response": ["a", "b"], "section": "Extending Snowflake Functionality", "question_plain": "How does a secure UDF differ from a different typical UDF?", "related_lectures": []}, {"_class": "assessment", "id": 70909212, "assessment_type": "multi-select", "prompt": {"question": "Snowpark supports which of the following languages?", "answers": ["Java", "Scala", "Python"], "explanation": "Java, Scala &amp; Python are all supported by Snowpark.\n  \n https://docs.snowflake.com/en/developer-guide/snowpark/index"}, "correct_response": ["a", "b", "c"], "section": "Extending Snowflake Functionality", "question_plain": "Snowpark supports which of the following languages?", "related_lectures": []}, {"_class": "assessment", "id": 70909214, "assessment_type": "multi-select", "prompt": {"question": "A stored procedure can return which type of results?", "answers": ["Single Value", "Tabular Data", "Binary Executables", "Exe files"], "explanation": "A stored procedure can also return a single value or tabular data if desired; however, it is not a requirement that a stored procedure must return a value.\n  \n https://docs.snowflake.com/en/developer-guide/stored-procedures-vs-udfs"}, "correct_response": ["a", "b"], "section": "Extending Snowflake Functionality", "question_plain": "A stored procedure can return which type of results?", "related_lectures": []}, {"_class": "assessment", "id": 70909216, "assessment_type": "multiple-choice", "prompt": {"question": "Which of the following is an appropriate scenario for creating a Stored Procedure?", "answers": ["Execute one or more SQL statements that are assembled dynamically.", "Given two inputs, calculate the MAX of the two values.", "Convert a character column into a numeric column"], "explanation": "Stored procedures are often used to perform recurring administrative activities, e.g., in a particular organization setting up a new user on the system may require creating the user, granting them several roles, creating a private database from them, etc. These steps can easily be placed in a stored procedure, and then the stored procedure can be called whenever there is a requirement to create a new user.\n  \n https://docs.snowflake.com/en/sql-reference/stored-procedures-overview"}, "correct_response": ["a"], "section": "Extending Snowflake Functionality", "question_plain": "Which of the following is an appropriate scenario for creating a Stored Procedure?", "related_lectures": []}, {"_class": "assessment", "id": 70909218, "assessment_type": "multi-select", "prompt": {"question": "Snowflake UDFs can be broadly categorized into which two based on how they return data.", "answers": ["Scalar UDFs", "Table UDFs", "Compiled UDFs", "Interpreted UDFs"], "explanation": "There are broad types of UDF in terms of the kind of result they can return. \n Scalar UDFs return one row for each input row, with each output row containing a single column or value. \n You can also create table UDFs that return zero, one, or several rows for each input, with each result row containing multiple columns. UDTFs are another name for user-defined table functions. \n  \n https://docs.snowflake.com/en/sql-reference/udf-overview#scalar-and-tabular-functions"}, "correct_response": ["a", "b"], "section": "Extending Snowflake Functionality", "question_plain": "Snowflake UDFs can be broadly categorized into which two based on how they return data.", "related_lectures": []}, {"_class": "assessment", "id": 70909220, "assessment_type": "multiple-choice", "prompt": {"question": "True or False. To create Snowflake instances in different regions, you must maintain a separate Snowflake account for each region.", "answers": ["True", "False"], "explanation": "Each Snowflake account is hosted in a particular Snowflake region. To use Snowflake in multiple regions, a Snowflake customer needs to maintain multiple Snowflake accounts, at least one for each region.\n  \n https://docs.snowflake.com/en/user-guide/intro-regions.html"}, "correct_response": ["a"], "section": "Licensing & Features", "question_plain": "True or False. To create Snowflake instances in different regions, you must maintain a separate Snowflake account for each region.", "related_lectures": []}, {"_class": "assessment", "id": 70909222, "assessment_type": "multi-select", "prompt": {"question": "What of the following Snowflake edition allows data clustering to improve query performance?", "answers": ["Standard", "Enterprise", "Business Critical", "Virtual Private Snowflake"], "explanation": "All Snowflake editions support data clustering.\n  \n https://docs.snowflake.com/en/user-guide/intro-editions.html"}, "correct_response": ["a", "b", "c", "d"], "section": "Licensing & Features", "question_plain": "What of the following Snowflake edition allows data clustering to improve query performance?", "related_lectures": []}, {"_class": "assessment", "id": 70909224, "assessment_type": "multi-select", "prompt": {"question": "Which of the following Snowflake editions support database failover and failback between Snowflake accounts, thus providing business continuity and disaster recovery? Select all that apply.", "answers": ["Business Critical", "Virtual Private Snowflake", "Standard", "Enterprise"], "explanation": "Database failover and failback between Snowflake accounts are provided first in the Business Critical edition and are also available in the virtual private Snowflake (VPS) edition.\n  \n https://docs.snowflake.com/en/user-guide/intro-editions.html"}, "correct_response": ["a", "b"], "section": "Licensing & Features", "question_plain": "Which of the following Snowflake editions support database failover and failback between Snowflake accounts, thus providing business continuity and disaster recovery? Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70909226, "assessment_type": "multiple-choice", "prompt": {"question": "What is the minimum Snowflake edition required to browse Snowflake Marketplace?", "answers": ["You don\u2019t need a Snowflake edition to browse the Snowflake marketplace listings", "Standard", "Enterprise", "Business Critical", "Virtual Private Snowflake"], "explanation": "Snowflake Marketplace can be browsed by non-Snowflake users as well, however they need to sign up to a Snowflake edition in order to consume data from the marketplace.\n  \n Data Marketplace is supported in all Snowflake editions; thus, the minimum edition that supports it is the Standard edition. Do note that VPS doesn\u2019t support Data Marketplace.\n  \n https://docs.snowflake.com/en/user-guide/intro-editions.html"}, "correct_response": ["a"], "section": "Licensing & Features", "question_plain": "What is the minimum Snowflake edition required to browse Snowflake Marketplace?", "related_lectures": []}, {"_class": "assessment", "id": 70909228, "assessment_type": "multiple-choice", "prompt": {"question": "What is the minimum Snowflake edition that supports a dedicated metadata store?", "answers": ["Virtual Private Snowflake", "Enterprise", "Business Critical", "Standard"], "explanation": "The VPS edition is meant to provide isolation from other customers; thus, each instance has its own metadata store and compute resources.\n  \n https://docs.snowflake.com/en/user-guide/intro-editions.html"}, "correct_response": ["a"], "section": "Licensing & Features", "question_plain": "What is the minimum Snowflake edition that supports a dedicated metadata store?", "related_lectures": []}, {"_class": "assessment", "id": 70909230, "assessment_type": "multi-select", "prompt": {"question": "Which of the following are Snowflake Data Integration partners? Select all that apply.", "answers": ["Matillion", "Informatica", "IBM DataStage", "Talend", "AbInitio"], "explanation": "All of these are Data Integration partners of Snowflake. Please see https://docs.Snowflake.com/en/user-guide/ecosystem.html"}, "correct_response": ["a", "b", "c", "d", "e"], "section": "Partners", "question_plain": "Which of the following are Snowflake Data Integration partners? Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70909232, "assessment_type": "multi-select", "prompt": {"question": "Which of the following are caching mechanisms in Snowflake? Select all that apply.", "answers": ["Metadata Caching", "Query Result Caching", "Warehouse Caching", "Memory Caching", "Index Caching"], "explanation": "Metadata caching is used for queries that can be fulfilled directly from metadata, e.g., the row count of a table\n \n Query Result Caching is for queries that have been executed already.\n \n Warehouse caching is within the virtual warehouse instance and is usually based on queries that have already been executed."}, "correct_response": ["a", "b", "c"], "section": "Performance Concepts", "question_plain": "Which of the following are caching mechanisms in Snowflake? Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70909234, "assessment_type": "multi-select", "prompt": {"question": "Query Result Cache can be turned off at which levels? Select all that apply.", "answers": ["User", "Session", "Account", "Table"], "explanation": "Query result cache is enabled by default but can be turned off at a session, user, or account level using the USE_CACHED_RESULT parameter.\n  \n https://docs.snowflake.com/en/user-guide/querying-persisted-results"}, "correct_response": ["a", "b", "c"], "section": "Performance Concepts", "question_plain": "Query Result Cache can be turned off at which levels? Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70909236, "assessment_type": "multiple-choice", "prompt": {"question": "<p><strong>A business user is executing a complex query. Another user executed the same query less than 24 hours ago. Assuming that the underlying data for the query hasn't changed, what is the likely way this query will be executed?</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", ""], "explanation": "<p>When Snowflake runs a query, it caches the results of that query for a predetermined amount of time. The stored query results are referred to as the Query Result Cache. The Query Result Cache can be used to fulfill future queries if they are similar to a previously executed query &amp; there have been no changes to the data in the tables being queried.\n&nbsp; \nOnce a result cache is generated for a query stays valid for 24 hours. If another query that reuses the query result cache is executed within that 24-hour window, the result cache expiry is extended for another 24 hours from that point onwards. If the result cache for a query keeps getting used, it will stay valid for up to 31 days. After 31 days, the result cache for a query will be purged regardless of any other condition.\n&nbsp; \n https://docs.snowflake.com/en/user-guide/querying-persisted-results</p>", "answers": ["Snowflake will use the query result cache to fulfill the query because the query has previously been executed.", "Snowflake will return the query results from the metadata cache.", "Snowflake will re-run the query, scanning the underlying tables and re-calculating the query results."]}, "correct_response": ["a"], "section": "Performance Concepts", "question_plain": "A business user is executing a complex query. Another user executed the same query less than 24 hours ago. Assuming that the underlying data for the query hasn't changed, what is the likely way this query will be executed?", "related_lectures": []}, {"_class": "assessment", "id": 70909238, "assessment_type": "multiple-choice", "prompt": {"question": "<p><strong>You are the data modeler at a large retail organization that stores transactional data in a Snowflake table called \"Transactions.\" The daily revenue reports are generated using the \"Transactions\" table, which calculates the revenue for the current day. </strong></p><p><strong>The \"Transactions\" table originally had 500GB of data but has now grown to 5TB. You have noticed that over time the performance of the daily revenue reports has degraded. </strong></p><p><strong>What is the most efficient &amp; cost-effective way of optimizing performance?</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", ""], "explanation": "Clustering a table on a specific column can optimize queries by eliminating unnecessary partitions from the query processing. A table can be re-clustered by defining a clustering key, which effectively redistributes the data into micro-partitions according to the clustering key, ensuring optimal access to queries that predicate or join on the clustered column\n  \n  \n Clustering the table on the transaction date is the most efficient option. The daily report accesses one day at a time and benefits from the partition on the date column.\n  \n https://docs.snowflake.com/en/user-guide/tables-clustering-keys", "answers": ["Cluster the Transactions table on the transaction date column", "Create tables for each year of data, e.g., Transactions_2017, Transactions_2018, and Transactions_2019. Then, insert the relevant data from the Transactions table into these _year tables. Then, change your report to point to the Transactions_2019 table.", "Increase the size of the virtual warehouse executing the daily reports."]}, "correct_response": ["a"], "section": "Performance Concepts", "question_plain": "You are the data modeler at a large retail organization that stores transactional data in a Snowflake table called \"Transactions.\" The daily revenue reports are generated using the \"Transactions\" table, which calculates the revenue for the current day. The \"Transactions\" table originally had 500GB of data but has now grown to 5TB. You have noticed that over time the performance of the daily revenue reports has degraded. What is the most efficient &amp; cost-effective way of optimizing performance?", "related_lectures": []}, {"_class": "assessment", "id": 70909240, "assessment_type": "multiple-choice", "prompt": {"question": "<p><strong>You are the database administrator for a large retailer running Snowflake. There is an event table that contains more than 5TB of data. But it does not have a clustering key defined. You need to define a new cluster key on this table. What is the best method to add the cluster key? </strong></p><p><strong> </strong></p><p><strong> The table structure is below, and the clustering key will be created on event_date.</strong></p><p><strong> </strong></p><p><strong> CREATE TABLE events (</strong></p><p><strong> Event_Date DATE,</strong></p><p><strong> Event_Id integer ,</strong></p><p><strong> Event_PayLoad string,</strong></p><p><strong> Event_Origin_Id integer</strong></p><p><strong> );</strong></p>", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "The easiest way to add a cluster key to an existing table is by running the ALTER statement and using the CLUSTER BY clause to change the clustering key.", "answers": ["<p><strong>Execute ALTER statement on the table to add the clustering key</strong></p><p><strong> </strong></p><p><strong>ALTER TABLE events CLUSTER BY (Event_date);</strong></p>", "<p><strong>Create a new table called events_2 with the same structure as events while adding the clustering key. </strong></p><p><strong>&nbsp; </strong></p><p><strong> CREATE TABLE events2 (</strong></p><p><strong> Event_Date DATE,</strong></p><p><strong> Event_Id integer ,</strong></p><p><strong> Event_PayLoad string,</strong></p><p><strong> Event_Origin_Id integer</strong></p><p><strong> ) CLUSTER BY (Event_Date);</strong></p><p><strong> </strong></p><p><strong> Then insert data from the event table into events2, drop the event table, and rename the events2 to be event.</strong></p>"]}, "correct_response": ["a"], "section": "Performance Concepts", "question_plain": "You are the database administrator for a large retailer running Snowflake. There is an event table that contains more than 5TB of data. But it does not have a clustering key defined. You need to define a new cluster key on this table. What is the best method to add the cluster key?   The table structure is below, and the clustering key will be created on event_date.  CREATE TABLE events ( Event_Date DATE, Event_Id integer , Event_PayLoad string, Event_Origin_Id integer );", "related_lectures": []}, {"_class": "assessment", "id": 70909242, "assessment_type": "multiple-choice", "prompt": {"question": "<p><strong>Which of the following illustration represents the most well-clustered table?</strong>\n&nbsp; \n</p><img src=\"https://img-b.udemycdn.com/redactor/raw/practice_test_question/2023-03-29_20-14-05-269ac8570d4de595162e7881920a66d6.png\"><p><br></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "For a populated table, the clustering depth is the average depth of overlapping micro-partitions for specific columns. The clustering depth starts at 1 (for a well-clustered table) and can be a larger number.\n If the average depth is smaller, the data for the specified columns are better clustered.\n  \n https://docs.snowflake.com/en/user-guide/tables-clustering-micropartitions#label-clustering-depth", "answers": ["1", "2", "3", "4"]}, "correct_response": ["a"], "section": "Performance Concepts", "question_plain": "Which of the following illustration represents the most well-clustered table?\n&nbsp;", "related_lectures": []}, {"_class": "assessment", "id": 70909244, "assessment_type": "multiple-choice", "prompt": {"question": "True or False: When defining a clustering key, you should choose columns that have very high cardinality.", "answers": ["False", "True"], "explanation": "When defining clustering keys, the initial candidate clustering columns are those columns that are frequently used in the WHERE clause or other selective filters. \n  \n Additionally, columns that are used for joining can also be considered.\n  \n Furthermore, the columns&#39; cardinality (number of distinct values) is also important. It is crucial to choose a column with a high enough cardinality to allow effective partition pruning while having a low enough cardinality for Snowflake to group data into micro-partitions efficiently. A column with too few distinct values (e.g., gender) will result in minimal partition pruning. On the other hand, a column that has too many distinct values (e.g., customer id) will result in too much overhead when maintaining the partitions.\n  \n When creating a multi-column cluster key, order the columns from the lowest cardinality to the higher cardinality; otherwise, the effectiveness of clustering will be reduced.\n  \n https://docs.snowflake.com/en/user-guide/tables-clustering-keys"}, "correct_response": ["a"], "section": "Performance Concepts", "question_plain": "True or False: When defining a clustering key, you should choose columns that have very high cardinality.", "related_lectures": []}, {"_class": "assessment", "id": 70909246, "assessment_type": "multiple-choice", "prompt": {"question": "True or False: When defining a clustering key for a large table, consider using columns frequently used in WHERE clauses.", "answers": ["True", "False"], "explanation": "When defining clustering keys, the initial candidate clustering columns are those columns that are frequently used in the WHERE clause or other selective filters. \n  \n Additionally, columns that are used for joining can also be considered.\n  \n Furthermore, the columns&#39; cardinality (number of distinct values) is also important. It is crucial to choose a column with a high enough cardinality to allow effective partition pruning while having a low enough cardinality for Snowflake to group data into micro-partitions efficiently. A column with too few distinct values (e.g., gender) will result in minimal partition pruning. On the other hand, a column that has too many distinct values (e.g., customer id) will result in too much overhead when maintaining the partitions.\n  \n When creating a multi-column cluster key, order the columns from the lowest cardinality to the higher cardinality; otherwise, the effectiveness of clustering will be reduced.\n  \n https://docs.snowflake.com/en/user-guide/tables-clustering-keys"}, "correct_response": ["a"], "section": "Performance Concepts", "question_plain": "True or False: When defining a clustering key for a large table, consider using columns frequently used in WHERE clauses.", "related_lectures": []}, {"_class": "assessment", "id": 70909248, "assessment_type": "multi-select", "prompt": {"question": "Which of the following statements about Materialized Views is correct? Choose all that apply.", "answers": ["Materialized views are used to boost query performance. They pre-compute query results and physically store them", "A materialized view can provide pre-computed answers, enabling some queries to be answered faster.", "A Snowflake service that is invisible to users automatically maintains materialized views in the background."], "explanation": "All these statements are correct. \n  \n A materialized view is a view that pre-computes data based on a SELECT query. The query&#39;s results are pre-computed and physically stored to enhance performance for similar queries that are executed in the future. When the underlying table is updated, the materialized view refreshes automatically, requiring no additional maintenance. Snowflake-managed services perform the update in the background transparent to the user without interfering with the user&#39;s experience.\n  \n https://docs.snowflake.com/en/user-guide/views-materialized"}, "correct_response": ["a", "b", "c"], "section": "Performance Concepts", "question_plain": "Which of the following statements about Materialized Views is correct? Choose all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70909250, "assessment_type": "multiple-choice", "prompt": {"question": "True or False: When there are more queries than a virtual warehouse can handle, the queries start queuing.", "answers": ["True", "False"], "explanation": "When queries are sent to a warehouse, the warehouse allocates the resources required for each query and begins running the queries. If there aren&#39;t enough resources to run all the queries sent to the warehouse, Snowflake queues the extra queries until the resources are available again. Snowflake provides multi-cluster virtual warehouses to overcome this issue.\n  \n https://docs.snowflake.com/en/user-guide/warehouses-multicluster"}, "correct_response": ["a"], "section": "Performance Concepts", "question_plain": "True or False: When there are more queries than a virtual warehouse can handle, the queries start queuing.", "related_lectures": []}, {"_class": "assessment", "id": 70909252, "assessment_type": "multiple-choice", "prompt": {"question": "Which of the following Scaling Policy aims to preserve costs?", "answers": ["Economy", "Standard", "Efficient", "Fast"], "explanation": "The Economy scaling policy attempts to conserve credits over performance and user experience. It doesn&#39;t spin up more virtual warehouses as soon as queuing is observed but instead applies additional criteria to ascertain whether or not to spin up new virtual warehouses.\n  \n With the scaling policy set to Standard, Snowflake prefers to spin up extra virtual warehouses almost as soon as it detects that queries are starting to queue up. The Standard scaling policy aims to prevent or minimize queuing.\n  \n  \n https://docs.snowflake.com/en/user-guide/warehouses-multicluster#setting-the-scaling-policy-for-a-multi-cluster-warehouse"}, "correct_response": ["a"], "section": "Performance Concepts", "question_plain": "Which of the following Scaling Policy aims to preserve costs?", "related_lectures": []}, {"_class": "assessment", "id": 70909254, "assessment_type": "multiple-choice", "prompt": {"question": "Snowflake can eliminate unneeded partitions while executing a query. What is the name given to this optimization technique?", "answers": ["Partition pruning", "Retrieve needed data only (RNDO)", "Predicate optimization", "WHERE clause optimization"], "explanation": "Snowflake stores data in small partitions known as micro-partitions. Data in Snowflake tables is mapped to individual micro-partitions and structured in a columnar manner. Micro-partitions are added to a table in the order in which the data is received. Additional micro-partitions are produced when data is added to a table. Because the column values are scattered across numerous micro-partitions, Snowflake must keep track of what range of data is kept in which micro-partitions for each column. This metadata enables Snowflake to eliminate unnecessary micro-partitions when running queries, boosting performance. This process of eliminating micro-partitions is also known as partition pruning.\n  \n https://docs.snowflake.com/en/user-guide/tables-clustering-micropartitions#query-pruning"}, "correct_response": ["a"], "section": "Performance Concepts", "question_plain": "Snowflake can eliminate unneeded partitions while executing a query. What is the name given to this optimization technique?", "related_lectures": []}, {"_class": "assessment", "id": 70909256, "assessment_type": "multi-select", "prompt": {"question": "Which query profile results indicate that a large table may not be well clustered? Select all that apply.", "answers": ["A significant value for \u2018Partitions Scanned.\u2019", "The value in the \u2018Partitions Total\u2019 equals \u2018Partitions Scanned.\u2019", "The Result node returns many rows.", "There are many JoinFilter nodes."], "explanation": "Partition pruning occurs when the number of Partitions scanned is much smaller than Partitions total.\n  \n If the partitions scanned equal the partition total, the query scanned the complete table. Therefore, no partition pruning happened, and the clustering key should be improved.\n  \n https://docs.snowflake.com/en/user-guide/ui-query-profile"}, "correct_response": ["a", "b"], "section": "Performance Concepts", "question_plain": "Which query profile results indicate that a large table may not be well clustered? Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70909258, "assessment_type": "multiple-choice", "prompt": {"question": "Which of the following best describes \u201cBytes spilled to remote storage\u201d shown in a query profile?", "answers": ["\u201cBytes Spilled to remote storage\u201d indicates that the volume of data could not fit in either the memory or the temporary storage of the virtual warehouse and had to be spilled to temporary cloud storage.", "\u201cBytes spilled to remote storage\u201d indicates the amount of data uploaded using the PUT command.", "\u201cBytes spilled to remote storage\u201d shows that a file from an on-premise system is being loaded.", "\u201cBytes spilled to remote storage\u201d indicates network issues."], "explanation": "Snowflake saves data on the warehouse&#39;s local disk if it can&#39;t fit an operation into memory. Data spilling slows down queries because it requires more IO operations, and disk access is slower than memory access. &quot;Bytes spilled to local storage.&quot; indicates local spillage.\n  \n Snowflake will spill data to remote cloud storage if the local disk becomes full, which is even slower storage than the local disk, making this operation even slower. &quot;Bytes spilled to remote storage&quot; in the query profile indicates remote spillage.\n  \n https://docs.snowflake.com/en/user-guide/ui-query-profile#queries-too-large-to-fit-in-memory"}, "correct_response": ["a"], "section": "Performance Concepts", "question_plain": "Which of the following best describes \u201cBytes spilled to remote storage\u201d shown in a query profile?", "related_lectures": []}, {"_class": "assessment", "id": 70909260, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>Which of the following correctly describes the query profile shown? \n</strong></p><img src=\"https://img-b.udemycdn.com/redactor/raw/practice_test_question/2023-03-29_20-14-45-035dc7037647f6faaecb21fc5e45fab6.png\"><p><strong>\n Select all that apply.</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "When Snowflake runs a query, it caches the results of that query for a predetermined amount of time. The stored query results are referred to as the Query Result Cache. The Query Result Cache can be used to fulfill future queries if they are like a previously executed query &amp; there have been no changes to the data in the tables being queried. \n  \n https://docs.snowflake.com/en/user-guide/querying-persisted-results", "answers": ["The query profile indicates that results produced by a previous query were reused.", "The query profile indicates that an active virtual warehouse was NOT required for this query.", "The query profile indicates that the virtual warehouse cache was used.", "The query profile indicates that the metadata cache was used."]}, "correct_response": ["a", "b"], "section": "Performance Concepts", "question_plain": "Which of the following correctly describes the query profile shown? \n\n Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70909262, "assessment_type": "multiple-choice", "prompt": {"question": "Which of the following scenarios is suitable for scaling up a virtual warehouse to a larger size?", "answers": ["Complex queries are executed on the system and are required to finish faster.", "The system has many concurrent queries", "The system has many concurrent users."], "explanation": "Based on the complexity of the queries and the desired performance, a virtual warehouse can be scaled up or down. In general, increasing the virtual warehouse size improves query speed for CPU-intensive queries.\n  \n  On the other hand, scaling up is ineffective when dealing with a high number of concurrent users or queries. Instead, a multi-cluster virtual warehouse (scaling out) is utilized to accommodate an increased number of users and queries\n  \n https://docs.snowflake.com/en/user-guide/warehouses-considerations"}, "correct_response": ["a"], "section": "Performance Concepts", "question_plain": "Which of the following scenarios is suitable for scaling up a virtual warehouse to a larger size?", "related_lectures": []}, {"_class": "assessment", "id": 70909264, "assessment_type": "multi-select", "prompt": {"question": "Which of the following statement is true regarding key pair authentication in Snowflake? Select all that apply.", "answers": ["Key pair authentication is an alternative to simple username/password authentication.", "Key pair authentication consists of a private key and one or two public keys.", "Key pair authentication enables single sign-on (SSO).", "Key pair authentication requires the user to provide a password."], "explanation": "Snowflake provides an additional layer of security by supporting key pair authentication in addition to the standard username/password login. This approach comprises private and public keys, with the public key allocated to a user and the private key used for authentication. The user provides a public key during authentication. A user can have up to two public keys, which can be rotated at any point in time. Key pair authentication is supported by all SnowSQL and Snowflake drivers and connectors. All Snowflake editions support Key-pair authentication\n  \n https://docs.snowflake.com/en/user-guide/key-pair-auth"}, "correct_response": ["a", "b"], "section": "Security", "question_plain": "Which of the following statement is true regarding key pair authentication in Snowflake? Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70909266, "assessment_type": "multi-select", "prompt": {"question": "Multi-factor authentication can be enabled for which of the following? Select all that apply.", "answers": ["Snowflake WebUI", "SnowSQL", "JDBC", "Snowpipe"], "explanation": "MFA is enabled by default for all Snowflake accounts and is available in all Snowflake editions. All Snowflake client tools, including the web interface, SnowSQL, and the various connectors and drivers, support MFA.\n  \n Snowpipe is a snowflake-managed serverless service. A Snowflake user can not log into it; therefore, it doesn&#39;t require MFA.\n  \n https://docs.snowflake.com/en/user-guide/security-mfa"}, "correct_response": ["a", "b", "c"], "section": "Security", "question_plain": "Multi-factor authentication can be enabled for which of the following? Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70909268, "assessment_type": "multiple-choice", "prompt": {"question": "Which one of the following is supported by Snowflake for the purpose of auto-provisioning users and group membership?", "answers": ["SCIM", "RBAC", "DAC", "ABAC"], "explanation": "Snowflake supports SCIM 2.0 and is compatible with Okta and Azure Active Directory.\n  \n SCIM is an open standard that provides automatic user provisioning and role synchronization based on identity provider information. When a new user is created in the identity provider, the SCIM automatically provisions the user in Snowflake. Additionally, SCIM can sync groups defined in an identity provider with Snowflake roles.\n  \n https://docs.snowflake.com/en/user-guide/scim"}, "correct_response": ["a"], "section": "Security", "question_plain": "Which one of the following is supported by Snowflake for the purpose of auto-provisioning users and group membership?", "related_lectures": []}, {"_class": "assessment", "id": 70909180, "assessment_type": "multi-select", "prompt": {"question": "Which of the following statements are correct regarding Time Travel &amp; fail-safe storage? Select all that apply.", "answers": ["The maximum allowed Time Travel duration for a transient table is 1 day.", "There is no fail-safe storage for a transient table.", "The maximum allowed Time Travel duration for a transient table is 7 days.", "A transient table has 7 days of fail-safe storage."], "explanation": "Transient and temporary tables don&#39;t have fail-safe functionality; therefore, data in such tables goes through zero days of fail-safe storage. Also, Transient and Temporary tables have a maximum of 1 day of Time Travel.\n  \n https://docs.snowflake.com/en/user-guide/tables-temp-transient"}, "correct_response": ["a", "b"], "section": "Time Travel", "question_plain": "Which of the following statements are correct regarding Time Travel &amp; fail-safe storage? Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70909182, "assessment_type": "multi-select", "prompt": {"question": "Which of the following Snowflake Editions support Time Travel? Select all that apply", "answers": ["Standard", "Enterprise", "Business Critical", "Virtual Private Snowflake"], "explanation": "Time Travel is supported in all Snowflake editions.\n  \n https://docs.snowflake.com/en/user-guide/data-time-travel#data-retention-period"}, "correct_response": ["a", "b", "c", "d"], "section": "Time Travel", "question_plain": "Which of the following Snowflake Editions support Time Travel? Select all that apply", "related_lectures": []}, {"_class": "assessment", "id": 70909270, "assessment_type": "multiple-choice", "prompt": {"question": "Dynamic Data Masking provides what sort of security in Snowflake?", "answers": ["Column-level security", "Row-level security", "Object Security", "Database-level security"], "explanation": "Snowflake supports masking policies that may be applied to columns and enforced at the column level to provide column-level security. Column-level security is achieved by dynamic data masking or external Tokenization.\n  \n https://docs.snowflake.com/en/user-guide/security-column"}, "correct_response": ["a"], "section": "Security", "question_plain": "Dynamic Data Masking provides what sort of security in Snowflake?", "related_lectures": []}, {"_class": "assessment", "id": 70909272, "assessment_type": "multi-select", "prompt": {"question": "Which of the following statements accurately describes Snowflake&#39;s encryption for data at rest? Select all that apply.", "answers": ["Every 30 days, Snowflake rotates the keys used for encryption", "Snowflake rekeys encrypted data after 1 year", "Snowflake manages encryption keys by default", "Snowflake uses AES - 128-bit encryption to encrypt data at rest"], "explanation": "By default, Snowflake manages encryption keys automatically, requiring no customer intervention. Snowflake-managed keys are rotated regularly (at 30-day intervals), and an annual rekeying process re-encrypts data with new keys. The data encryption and key management processes are entirely transparent to the users. Snowflake uses AES 256-bit encryption to encrypt data at rest.\n  \n https://docs.snowflake.com/en/user-guide/security-encryption-manage"}, "correct_response": ["a", "b", "c"], "section": "Security", "question_plain": "Which of the following statements accurately describes Snowflake&#39;s encryption for data at rest? Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70909274, "assessment_type": "multiple-choice", "prompt": {"question": "True or False: An ACCOUNTADMIN can see the results of any query executed by any user in a Snowflake system.", "answers": ["False", "True"], "explanation": "You can only view results for queries you have personally executed. For example, as an administrator, If you have permission to view queries run by another user, the Query Detail page displays the query&#39;s details but not the actual query result for data privacy reasons."}, "correct_response": ["a"], "section": "Security", "question_plain": "True or False: An ACCOUNTADMIN can see the results of any query executed by any user in a Snowflake system.", "related_lectures": []}, {"_class": "assessment", "id": 70909276, "assessment_type": "multiple-choice", "prompt": {"question": "True or False: If an IP address is in a network policy&#39;s block list and the allowed list, Snowflake applies the blocked list first.", "answers": ["True", "False"], "explanation": "If both the allowed and blocked IP address lists are populated, Snowflake applies the block list first, followed by the allowed list.\n  \n https://docs.snowflake.com/en/user-guide/network-policies"}, "correct_response": ["a"], "section": "Security", "question_plain": "True or False: If an IP address is in a network policy&#39;s block list and the allowed list, Snowflake applies the blocked list first.", "related_lectures": []}, {"_class": "assessment", "id": 70909278, "assessment_type": "multi-select", "prompt": {"question": "Which of the following statements is true regarding the ACCOUNTADMIN role? Select all that apply.", "answers": ["A user with the ACCOUNTADMIN role can create &amp; manage resource monitors", "ACCOUNTADMIN role has full access rights and is the most powerful account.", "A user with the ACCOUNTADMIN role can NOT view billing information.", "A user with the ACCOUNTADMIN role can NOT create a new reader account."], "explanation": "ACCOUNTADMIN is the account administrator role with full access rights. As the most powerful role in the organization, access to this role should be rigorously managed. This role encapsulates the SECURITYADMIN and SYSADMIN roles, therefore, has all the privileges of SYSADMIN and SECURITYADMIN too.\n  \n https://docs.snowflake.com/en/user-guide/security-access-control-overview#system-defined-roles."}, "correct_response": ["a", "b"], "section": "Security", "question_plain": "Which of the following statements is true regarding the ACCOUNTADMIN role? Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70909280, "assessment_type": "multi-select", "prompt": {"question": "Which of the following statements is true regarding the SYSADMIN role? Select all that apply.", "answers": ["A user with the SYSADMIN role can create a new virtual warehouse.", "A user with the SYSADMIN role can create a new database.", "A user with the SYSADMIN role can create new roles.", "A user with the SYSADMIN role can create new users."], "explanation": "The SYSADMIN role can create and manage most Snowflake objects, including databases, tables, views, virtual warehouses, etc. However, the SYSADMIN role does not have the privileges to create new users or roles.\n  \n https://docs.snowflake.com/en/user-guide/security-access-control-overview#system-defined-roles."}, "correct_response": ["a", "b"], "section": "Security", "question_plain": "Which of the following statements is true regarding the SYSADMIN role? Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70909282, "assessment_type": "multi-select", "prompt": {"question": "Which of the following statement is correct regarding Snowflake billing? Select all that apply.", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "Virtual warehouses in a resumed (active) state contribute to the costs. However, it does not matter if the virtual warehouse is not running a query; if it is resumed, it contributes to the costs.\n https://docs.snowflake.com/en/user-guide/cost-understanding-compute\n  \n Snowflake charges for data storage in database tables, files staged in internal stages, time travel history, and fail-safe storage.\n  \n Snowflake doesn\u2019t charge on how much data a query processed.\n  \n https://docs.snowflake.com/en/user-guide/cost-understanding-overall#how-are-costs-incurred", "answers": ["<p><strong>Snowflake billing is based on the actual used storage.</strong></p>", "If a virtual warehouse is suspended, it does not contribute to the cost.", "Snowflake billing is based on the number of queries executed.", "Snowflake billing is based on the amount of data processed by queries"]}, "correct_response": ["a", "b"], "section": "Cost & Pricing", "question_plain": "Which of the following statement is correct regarding Snowflake billing? Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70909284, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>Snowflake is compliant with which of the following standards? Select all that apply.</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>Snowflake is compliant with the following security and financial standards.</p><p> \u00b7 IRAP Protected</p><p> \u00b7 ITAR</p><p> \u00b7 FedRAMP Moderate</p><p> \u00b7 GxP</p><p> \u00b7 SOC 1 Type II</p><p> \u00b7 SOC 2 Type II</p><p> \u00b7 PCI-DSS</p><p> \u00b7 HITRUST / HIPAA</p><p> \u00b7 ISO/IEC 27001 </p><p>&nbsp; </p><p> https://www.snowflake.com/snowflakes-security-compliance-reports/</p>", "answers": ["FedRAMP", "HIPAA", "PCI-DSS", "IRAP \u2013 Protected"]}, "correct_response": ["a", "b", "c", "d"], "section": "Security", "question_plain": "Snowflake is compliant with which of the following standards? Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70909286, "assessment_type": "multi-select", "prompt": {"question": "Snowflake provides which of the following drivers?", "answers": ["ODBC driver for Snowflake", "JDBC driver for Snowflake", ".NET driver for Snowflake", "Snowflake driver for the Go language", "PHP PDO driver"], "explanation": "All of these are valid examples of drivers provided by Snowflake.\n  \n Snowflake has several drivers and connectors that can be used to connect to your Snowflake instance. These include client tools made by Snowflake, like the web interface and the SnowSQL command-line interface, and drivers and connectors that let different languages and frameworks connect to Snowflake. The following drivers and connectors are currently available\n \u00b7 Snowflake Connector for Python\n \u00b7 Snowflake Connector for Spark\n \u00b7 Snowflake Connector for Kafka\n \u00b7 JDBC driver for Snowflake\n \u00b7 ODBC driver for Snowflake\n \u00b7 .NET driver for Snowflake\n \u00b7 Snowflake driver for the Go language\n \u00b7 Node.js drivers\n PHP PDO drivers"}, "correct_response": ["a", "b", "c", "d", "e"], "section": "Tools & Interfaces", "question_plain": "Snowflake provides which of the following drivers?", "related_lectures": []}, {"_class": "assessment", "id": 70909288, "assessment_type": "multiple-choice", "prompt": {"question": "True or False: In Snowsight (Snowflake web user interface), you can execute only one query at a given time.", "answers": ["False", "True"], "explanation": "Multiple worksheets can be opened in Snowsight, each with a different query. The queries continue to execute even if the worksheets are inactive; thus, multiple queries can be executed simultaneously. \n  \n https://docs.snowflake.com/en/user-guide/ui-snowsight"}, "correct_response": ["a"], "section": "Tools & Interfaces", "question_plain": "True or False: In Snowsight (Snowflake web user interface), you can execute only one query at a given time.", "related_lectures": []}, {"_class": "assessment", "id": 70909290, "assessment_type": "multiple-choice", "prompt": {"question": "Which of the following is a command line tool used to connect to Snowflake?", "answers": ["SnowSQL", "Snowmobile", "Snowpipe", "Snowsight"], "explanation": "Command Line Client (CLI), also known as SnowSQL \u2013 is the method to connect to your Snowflake instance via a command-line interface.\n  \n https://docs.snowflake.com/en/user-guide/snowsql"}, "correct_response": ["a"], "section": "Tools & Interfaces", "question_plain": "Which of the following is a command line tool used to connect to Snowflake?", "related_lectures": []}, {"_class": "assessment", "id": 70909292, "assessment_type": "multi-select", "prompt": {"question": "Which of the following operations can be performed on a cloned table?", "answers": ["DELETE", "SELECT", "DROP", "CLONE"], "explanation": "All these operations can be performed on a cloned table because a cloned table is just like any other table.\n  \n https://docs.snowflake.com/en/user-guide/tables-storage-considerations#label-cloning-tables"}, "correct_response": ["a", "b", "c", "d"], "section": "Cloning", "question_plain": "Which of the following operations can be performed on a cloned table?", "related_lectures": []}, {"_class": "assessment", "id": 70909294, "assessment_type": "multiple-choice", "prompt": {"question": "True or False: After a table has been cloned, any updates to the data in the source table will automatically update the data in the cloned table.", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "Micro-partitions and metadata in the cloud services layer enable rapid and efficient zero-copy cloning because the cloned table&#39;s metadata references the existing micro-partitions.\n The source and cloned items are independent; thus, modifying data in one will not affect the other. For example, the source table can be dropped altogether, which doesn&#39;t affect the cloned table.\n  \n https://docs.snowflake.com/en/user-guide/tables-storage-considerations#label-cloning-tables", "answers": ["False", "<p><strong>True</strong></p>"]}, "correct_response": ["a"], "section": "Cloning", "question_plain": "True or False: After a table has been cloned, any updates to the data in the source table will automatically update the data in the cloned table.", "related_lectures": []}, {"_class": "assessment", "id": 70909296, "assessment_type": "multiple-choice", "prompt": {"question": "Which one of the following objects can NOT be cloned?", "answers": ["Named Internal Stage", "External Stage", "Databases", "Schemas"], "explanation": "Named Internal Stages cannot be cloned. When a database or schema is cloned, any Snowpipe that points to a Named Internal Stage is not cloned. \n Named External Stages can be cloned. Since a table stage is associated with a table, it is automatically cloned when the table is cloned.\n Additionally, external tables cannot be cloned either. Databases, Schema, Tables, etc., can be cloned.\n  \n https://docs.snowflake.com/en/user-guide/object-clone#cloning-and-stages"}, "correct_response": ["a"], "section": "Cloning", "question_plain": "Which one of the following objects can NOT be cloned?", "related_lectures": []}, {"_class": "assessment", "id": 70909298, "assessment_type": "multi-select", "prompt": {"question": "Cloning a schema will clone which of the following. Select all that apply.", "answers": ["The schema itself", "All tables in the schema", "All other cloneable objects in the schema"], "explanation": "When a schema is cloned, all child objects within the schema are cloned.\n  \n https://docs.snowflake.com/en/sql-reference/sql/create-clone#additional-rules-that-apply-to-cloning-objects"}, "correct_response": ["a", "b", "c"], "section": "Cloning", "question_plain": "Cloning a schema will clone which of the following. Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70909300, "assessment_type": "multiple-choice", "prompt": {"question": "How frequently does Snowflake release new software?", "answers": ["Weekly", "Daily", "Monthly", "Yearly", "Fortnightly"], "explanation": ""}, "correct_response": ["a"], "section": "General", "question_plain": "How frequently does Snowflake release new software?", "related_lectures": []}, {"_class": "assessment", "id": 70909302, "assessment_type": "multiple-choice", "prompt": {"question": "<p><strong>Snowflake recommends that any custom roles should be assigned to the pre-defined ____________ role.</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p>Snowflake recommends establishing a hierarchy of custom roles, with the top custom role given to the pre-defined system role SYSADMIN. SYSADMIN can act as the owner of all securable objects in the system and can manage these objects.</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/security-access-control-overview#custom-roles</p>", "answers": ["<p><strong>SYSADMIN</strong></p>", "<p><strong>ACCOUNTADMIN</strong></p>", "<p><strong>USERADMIN</strong></p>", "<p><strong>SECURITYADMIN</strong></p>", "<p><strong>ORGADMIN</strong></p>"]}, "correct_response": ["a"], "section": "Security", "question_plain": "Snowflake recommends that any custom roles should be assigned to the pre-defined ____________ role.", "related_lectures": []}, {"_class": "assessment", "id": 70909304, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>An administrator cloned a table called Customer to a new table called Prospects. The administrator then proceeds to load new data into the Customer table. What can you expect to happen to the Prospects table? </strong></p><p><strong>Select all that apply.</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>The source and cloned items are independent; thus, modifying data in one will not affect the other. For example, the source table can be dropped altogether, which doesn't affect the cloned table.</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/tables-storage-considerations#label-cloning-tables</p>", "answers": ["<p><strong>The new data is loaded successfully into the Customer table only.</strong></p>", "<p><strong>The new data does not show up in the Prospects table.</strong></p>", "<p><strong>The new data is loaded into the Customer table and its clone, the Prospects table.</strong></p>", "<p><strong>The data loading fails as it is impossible to load data into a table that was a source for a cloning operation.</strong></p>"]}, "correct_response": ["a", "b"], "section": "Cloning", "question_plain": "An administrator cloned a table called Customer to a new table called Prospects. The administrator then proceeds to load new data into the Customer table. What can you expect to happen to the Prospects table? Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70909306, "assessment_type": "multiple-choice", "prompt": {"question": "<p><strong>What is the best way for a system administrator to determine the initial size of a new virtual warehouse?</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>Experiment with a defined set of queries against various warehouse sizes (e.g., X-Large, Large, Medium) warehouse sizes to determine the optimal combination for your specific query requirements and workload.</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/warehouses-considerations#selecting-an-initial-warehouse-size</p>", "answers": ["<p><strong>Try different types of queries and warehouse sizes to find the optimum fit for your query needs and workload.</strong></p>", "<p><strong>Choose X-Small virtual warehouse to conserve costs.</strong></p>", "<p><strong>Choose 5X-Large virtual warehouse size to ensure performance.</strong></p>", "<p><strong>Contact Snowflake to get help with determining the right size for your organization.</strong></p>"]}, "correct_response": ["a"], "section": "Performance Concepts", "question_plain": "What is the best way for a system administrator to determine the initial size of a new virtual warehouse?", "related_lectures": []}, {"_class": "assessment", "id": 70909308, "assessment_type": "multiple-choice", "prompt": {"question": "<p><strong>Which role owns a newly created object?</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>Snowflake supports discretionary access control (DAC), which means that the role that created an object owns it and can provide access to other roles to that item.</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/security-access-control-overview</p>", "answers": ["<p><strong>The role that was used by the user while creating the new object.</strong></p>", "<p><strong>SYSADMIN</strong></p>", "<p><strong>ACCOUNTADMIN</strong></p>", "<p><strong>PUBLIC</strong></p>"]}, "correct_response": ["a"], "section": "Security", "question_plain": "Which role owns a newly created object?", "related_lectures": []}, {"_class": "assessment", "id": 70909310, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>Which of the following is correct regarding a directory table?</strong></p><p><strong>Select all that apply.</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>A directory table is not a separate database object but is an implicit object available with a stage. You can enable the directory table for a stage while creating the stage or enable it afterward.</p><p>Since Directory Tables are not separate objects, you cannot provide privileges to them.</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/data-load-dirtables</p>", "answers": ["<p><strong>A directory table is NOT a separate object.</strong></p>", "<p><strong>Privileges can NOT be assigned directly to a directory table.</strong></p>", "<p><strong>A directory table is a separate object.</strong></p>", "<p><strong>Privileges can be assigned to a directory table.</strong></p>"]}, "correct_response": ["a", "b"], "section": "Data Transformation", "question_plain": "Which of the following is correct regarding a directory table?Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70909312, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>Imagine an external stage named FLIGHTS_STAGE. </strong></p><p><strong>Which of the following commands produce the same columns in the result set?</strong></p><p><strong>Select all that apply.</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", ""], "explanation": "<p>The columns in the output obtained from querying a directory table differ from those in the output when listing a stage.</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/data-load-dirtables-manage#output</p><p><br></p><p>https://docs.snowflake.com/en/sql-reference/sql/list#output</p>", "answers": ["<p><strong>SELECT * FROM DIRECTORY(@FLIGHTS_STAGE);</strong></p>", "<p><strong>SELECT * FROM DIRECTORY(@FLIGHTS_STAGE) WHERE SIZE &gt; 1000;</strong></p>", "<p><strong>LIST @FLIGHTS_STAGE;</strong></p>"]}, "correct_response": ["a", "b"], "section": "Data Transformation", "question_plain": "Imagine an external stage named FLIGHTS_STAGE. Which of the following commands produce the same columns in the result set?Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70909314, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>Which of the following is true regarding Directory Tables?</strong></p><p><strong>Select all that apply.</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>Streams can be used with directory tables to easily track which files have been added, removed, or changed. This is done by creating a stream on top of the stage object.</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/data-load-dirtables-manage#streams-on-directory-tables</p>", "answers": ["<p><strong>Streams can be used with directory tables.</strong></p>", "<p><strong>To use a stream with a directory table, you must create the stream on the stage object.</strong></p>", "<p><strong>To use a stream with a directory table, you must create the stream on the directory table object.</strong></p>", "<p><strong>Streams can NOT be used with directory tables.</strong></p>"]}, "correct_response": ["a", "b"], "section": "Data Transformation", "question_plain": "Which of the following is true regarding Directory Tables?Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70909316, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>Which of the following views can be used to view the last 365 days of data loading history for data loaded through Snowpipe?</strong></p><p><br></p><p><strong>Select two answers.</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>The COPY_HISTORY view and the PIPE_USAGE_HISTORY view in the ACCOUNT_USAGE schema provide the history of data loading performed through Snowpipe.</p><p><br></p><p>https://docs.snowflake.com/en/sql-reference/account-usage/pipe_usage_history</p><p><br></p><p>https://docs.snowflake.com/en/sql-reference/account-usage/copy_history</p>", "answers": ["<p><strong>ACCOUNT_USAGE.COPY_HISTORY</strong></p>", "<p><strong>ACCOUNT_USAGE.PIPE_USAGE_HISTORY</strong></p>", "<p><strong>ACCOUNT_USAGE.LOAD_HISTORY</strong></p>", "<p><strong>INFORMATION_SCHEMA.QUERY_HISTORY</strong></p>"]}, "correct_response": ["a", "b"], "section": "Account Usage & Monitoring", "question_plain": "Which of the following views can be used to view the last 365 days of data loading history for data loaded through Snowpipe?Select two answers.", "related_lectures": []}, {"_class": "assessment", "id": 70909318, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>Which of the following is true for the DATABASE_STORAGE_USAGE_HISTORY view in the ACCOUNT_USAGE schema?</strong></p><p><br></p><p><strong>Select four answers.</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", "", "", ""], "explanation": "<p>The DATABASE_STORAGE_USAGE_HISTORY view in the ACCOUNT_USAGE schema shows the number of bytes of database storage used by each database, including information for data that is in Time Travel. The view also separately shows the number of bytes in fail-safe storage. Like other ACCOUNT_USAGE views, the data for the last 365 days is shown; this view can have a latency of up to 3 hours (not real-time) and includes deleted objects.</p><p><br></p><p>https://docs.snowflake.com/en/sql-reference/account-usage/database_storage_usage_history</p>", "answers": ["<p><strong>This view shows the number of bytes of database storage used, including Time Travel storage.</strong></p>", "<p><strong>This view shows the number of bytes of fail-safe storage used.</strong></p>", "<p><strong>This view shows information for all databases, including deleted databases.</strong></p>", "<p><strong>This view contains information for the last 365 days.</strong></p>", "<p><strong>This view contains real-time information.</strong></p>", "<p><strong>This view does not show information for deleted databases.</strong></p>"]}, "correct_response": ["a", "b", "c", "d"], "section": "Account Usage & Monitoring", "question_plain": "Which of the following is true for the DATABASE_STORAGE_USAGE_HISTORY view in the ACCOUNT_USAGE schema?Select four answers.", "related_lectures": []}, {"_class": "assessment", "id": 70909320, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>Snowflake provides which of the following data protection features automatically?</strong></p><p><br></p><p><strong>Select all that apply.</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p>Snowflake provides Time Travel &amp; Fail-Safe. Time Travel enables accessing, retrieving, and recovering past data stored in tables. The time travel can range between one and ninety days.</p><p><br></p><p>Failsafe storage retains data for an additional seven days after the time travel duration has expired. Failsafe adds another layer of protection against data loss; however, only Snowflake support can recover data from failsafe storage.</p>", "answers": ["<p><strong>Time Travel</strong></p>", "<p><strong>Fail-Safe</strong></p>", "<p><strong>Incremental Backups</strong></p>", "<p><strong>Tape Backups</strong></p>", "<p><strong>Backups to on-premises</strong></p>"]}, "correct_response": ["a", "b"], "section": "Cloning", "question_plain": "Snowflake provides which of the following data protection features automatically?Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70909322, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>Consider the following resource monitor configuration.</strong></p><img src=\"https://img-b.udemycdn.com/redactor/raw/practice_test_question/2023-10-01_23-10-49-6538c57653aef552d53d7a9b5d4018b4.png\"><p><strong>Which two of the given virtual warehouses can use a maximum of 5,000 credits?</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p>Resource monitors can track &amp; manage a single virtual warehouse against a defined quota. Resource monitors can be created to track the credit usage of multiple virtual warehouses together.</p><p>Resource Monitors can also be created at the account level, which means that such resource monitors track credit usage at the account level, considering the credit usage of all virtual warehouses.</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/resource-monitors#assignment-of-resource-monitors</p>", "answers": ["<p><strong>Warehouse 4</strong></p>", "<p><strong>Warehouse 5</strong></p>", "<p><strong>Warehouse 1</strong></p>", "<p><strong>Warehouse 2</strong></p>", "<p><strong>Warehouse 3</strong></p>"]}, "correct_response": ["a", "b"], "section": "Account Usage & Monitoring", "question_plain": "Consider the following resource monitor configuration.Which two of the given virtual warehouses can use a maximum of 5,000 credits?", "related_lectures": []}, {"_class": "assessment", "id": 70909324, "assessment_type": "multiple-choice", "prompt": {"question": "<p><strong>Which role must be granted to a Snowflake user to allow them to create new Snowflake accounts?</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p>The ORGADMIN role performs organization-specific tasks like listing all accounts and creating new ones.</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/organizations-gs#enabling-the-orgadmin-role-in-an-account</p>", "answers": ["<p><strong>ORGADMIN</strong></p>", "<p><strong>ACCOUNTADMIN</strong></p>", "<p><strong>SYSADMIN</strong></p>", "<p><strong>SECURITYADMIN</strong></p>", "<p><strong>GLOBALADMIN</strong></p>"]}, "correct_response": ["a"], "section": "Security", "question_plain": "Which role must be granted to a Snowflake user to allow them to create new Snowflake accounts?", "related_lectures": []}, {"_class": "assessment", "id": 70909326, "assessment_type": "multiple-choice", "prompt": {"question": "<p><strong>Which of the following can be used to find the query ID of the 2nd most recent query executed in the current session?</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>The LAST_QUERY_ID function returns the query ID of a specified query in the current session. The function takes a number as the parameter, which specifies the position of the query in the session.</p><p>The parameter can take positive or negative values. A negative value means you are attempting to fetch the most recent query in the session, where</p><p>-1 = most recent query</p><p>-2 = 2nd most recent query</p><p>, and so on. The function defaults to -1, so if no value is provided, it will return the query id of the most recent query.</p><p>A positive number returns the earliest queries in the session. i.e.</p><p>1 = first query</p><p>2 = 2nd query</p><p><br></p><p>https://docs.snowflake.com/en/sql-reference/functions/last_query_id</p>", "answers": ["<p><strong>SELECT LAST_QUERY_ID(-2);</strong></p>", "<p><strong>SELECT LAST_QUERY_ID(-1);</strong></p>", "<p><strong>SELECT LAST_QUERY_ID(1);</strong></p>", "<p><strong>SELECT LAST_QUERY_ID(2);</strong></p>"]}, "correct_response": ["a"], "section": "General", "question_plain": "Which of the following can be used to find the query ID of the 2nd most recent query executed in the current session?", "related_lectures": []}, {"_class": "assessment", "id": 70909328, "assessment_type": "multiple-choice", "prompt": {"question": "<p><strong>The Search Optimization service can be used to improve the performance of which type of queries?</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>The search optimization service can be used to improve the performance of</p><p><br></p><ol><li><p>Point lookup queries - return only one or a few rows using highly selective filters.</p></li><li><p>Substring &amp; RegEx searches \u2013 queries that use LIKE, ILIKE, &amp; RLIKE</p></li><li><p>Queries on fields in VARIANT, OBJECT &amp; ARRAY columns \u2013 using equality conditions, IN, ARRAY_CONTAINS, ARRAY_OVERLAP, Substring &amp; RegEx and NULL check conditions</p></li><li><p>Queries that use specific geospatial functions with GEOGRAPHY values.</p></li></ol><p><br></p><p>https://docs.snowflake.com/en/user-guide/search-optimization-service#understanding-the-search-optimization-service</p>", "answers": ["<p><strong>Selective point lookup queries</strong></p>", "<p><strong>Queries that access a subset of a column in a table</strong></p>", "<p><strong>Any query performed on tables that have greater than 1TB of data</strong></p>", "<p><strong>Queries that access all columns &amp; all rows</strong></p>"]}, "correct_response": ["a"], "section": "Performance Concepts", "question_plain": "The Search Optimization service can be used to improve the performance of which type of queries?", "related_lectures": []}, {"_class": "assessment", "id": 70909330, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>Which of the following are not supported by Search Optimization?</strong></p><p><br></p><p><strong>Select three answers.</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p>Search optimization does not support</p><p><br></p><ul><li><p>External tables.</p></li><li><p>Materialized views.</p></li><li><p>Columns defined with a COLLATE clause.</p></li><li><p>Column concatenation.</p></li><li><p>Analytical expressions.</p></li><li><p>Casts on table columns (except for fixed-point numbers cast to strings).</p></li></ul><p><br></p><p>https://docs.snowflake.com/en/user-guide/search-optimization-service#queries-not-supported-by-the-search-optimization-service</p>", "answers": ["<p><strong>External Tables</strong></p>", "<p><strong>Materialized Views</strong></p>", "<p><strong>Cast on table columns</strong></p>", "<p><strong>Date Columns</strong></p>", "<p><strong>Integer Columns</strong></p>"]}, "correct_response": ["a", "b", "c"], "section": "Performance Concepts", "question_plain": "Which of the following are not supported by Search Optimization?Select three answers.", "related_lectures": []}, {"_class": "assessment", "id": 70909332, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>Which of the following correctly describes materialized views?</strong></p><p><br></p><p><strong>Select two answers.</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", "", "", "", ""], "explanation": "<p>A materialized view is a view that pre-computes data based on a SELECT query. The query's results are pre-computed and physically stored to enhance performance for similar queries that are executed in the future. When the underlying table is updated, the materialized view refreshes automatically, requiring no additional maintenance. Snowflake-managed services perform the update in the background transparent to the user without interfering with the user's experience.</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/views-materialized</p>", "answers": ["<p><strong>Materialized view refreshes are performed automatically.</strong></p>", "<p><strong>Materialized views are created to improve the performance of specific queries.</strong></p>", "<p><strong>Materialized views are created to enable sharing of data.</strong></p>", "<p><strong>Querying a materialized view is typically slower than the base table used in the materialized view.</strong></p>", "<p><strong>Materialized views definition can contain multiple tables and joins.</strong></p>", "<p><strong>Materialized views need to be refreshed manually.</strong></p>", "<p><strong>Materialized views are created to improve the performance of all queries.</strong></p>"]}, "correct_response": ["a", "b"], "section": "Performance Concepts", "question_plain": "Which of the following correctly describes materialized views?Select two answers.", "related_lectures": []}, {"_class": "assessment", "id": 70909334, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>Which of the following can be configured for a user profile in Snowsight?</strong></p><p><br></p><p><strong>Select two answers.</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>Using the profile dialogue in Snowsight, you can enroll in MFA, specify your notification preferences, set your email address, and configure your profile's default role and default warehouse. Other things can also be configured such as name, password, language, etc.</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/ui-snowsight-profile</p>", "answers": ["<p><strong>Default Warehouse</strong></p>", "<p><strong>Default Role</strong></p>", "<p><strong>Default database</strong></p>", "<p><strong>Default schema</strong></p>"]}, "correct_response": ["a", "b"], "section": "Tools & Interfaces", "question_plain": "Which of the following can be configured for a user profile in Snowsight?Select two answers.", "related_lectures": []}, {"_class": "assessment", "id": 70909336, "assessment_type": "multiple-choice", "prompt": {"question": "<p><strong>Which file function allows <em>any </em>user or application access to download unstructured data in a Snowflake stage?</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>A pre-signed URL is a simple HTTPS URL for accessing a file using a web browser. A pre-signed URL is generated using a pre-signed access token. Users can temporarily access a file via a pre-signed URL without authorization. The expiry duration of a pre-signed URL is configurable and can be set to the required duration.</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/unstructured-intro#types-of-urls-available-to-access-files</p>", "answers": ["<p><strong>GET_PRESIGNED_URL</strong></p>", "<p><strong>BUILD_SCOPED_FILE_URL</strong></p>", "<p><strong>BUILD_STAGE_FILE_URL</strong></p>", "<p><strong>GET_DATA_FROM_STAGE</strong></p>"]}, "correct_response": ["a"], "section": "Data Transformation", "question_plain": "Which file function allows any user or application access to download unstructured data in a Snowflake stage?", "related_lectures": []}, {"_class": "assessment", "id": 70909338, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>Which of the following strategies should be used to optimize the performance of a virtual warehouse?</strong></p><p><br></p><p><strong>Select two answers.</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", "", "", ""], "explanation": "<p>The following strategies may be applied to improve the performance of a virtual warehouse.</p><p><br></p><p>1. Reduce queuing</p><p>2. Resolve memory spillage.</p><p>3. Increase warehouse size.</p><p>4. Try query acceleration.</p><p>5. Optimize the warehouse cache.</p><p>6. Limit concurrently running queries.</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/performance-query-warehouse</p>", "answers": ["<p><strong>Increase the virtual warehouse size.</strong></p>", "<p><strong>Reduce queuing.</strong></p>", "<p><strong>Increase the local disk cache size.</strong></p>", "<p><strong>Suspend the virtual warehouse.</strong></p>", "<p><strong>Configure memory spilling parameters to True.</strong></p>", "<p><strong>Configure MAX_CONCURRENCY_LEVEL to a higher number</strong></p>"]}, "correct_response": ["a", "b"], "section": "Performance Concepts", "question_plain": "Which of the following strategies should be used to optimize the performance of a virtual warehouse?Select two answers.", "related_lectures": []}, {"_class": "assessment", "id": 70909340, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>Which of the following statements regarding Snowflake's built-in roles are correct?</strong></p><p><br></p><p><strong>Select two answers.</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>USERADMIN is a role dedicated solely to user and role management. It has the privileges for CREATE USER and CREATE ROLE; therefore, users with this role can create users and roles in the account. USERADMIN can not manage grants, which is the job of SECURITYADMIN role.</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/security-access-control-overview#system-defined-roles</p>", "answers": ["<p><strong>The USERADMIN role separates the management of users and roles from the management of all grants.</strong></p>", "<p><strong>USERADMIN is dedicated to user and role management only.</strong></p>", "<p><strong>USERADMIN is granted to each new user automatically.</strong></p>", "<p><strong>USERADMIN inherits all permissions of SYSADMIN.</strong></p>"]}, "correct_response": ["a", "b"], "section": "Security", "question_plain": "Which of the following statements regarding Snowflake's built-in roles are correct?Select two answers.", "related_lectures": []}, {"_class": "assessment", "id": 70909342, "assessment_type": "multiple-choice", "prompt": {"question": "<p><strong>Which system function can be used to control access to data in a share and allow specific data only to paying customers?</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>SYSTEM$IS_LISTING_PURCHASED system function can be used to control which data is visible to a paid customer and which to a trial customer.</p><p><br></p><p>https://other-docs.snowflake.com/en/collaboration/provider-listings-preparing#preparing-shares-for-a-paid-listing</p>", "answers": ["<p><strong>SYSTEM$IS_LISTING_PURCHASED</strong></p>", "<p><strong>SYSTEM$ALLOWLIST</strong></p>", "<p><strong>SYSTEM$BLOCK_INTERNAL_STAGES_PUBLIC_ACCESS</strong></p>", "<p><strong>SYSTEM$DISABLE_BEHAVIOR_CHANGE_BUNDLE</strong></p>"]}, "correct_response": ["a"], "section": "Data Sharing", "question_plain": "Which system function can be used to control access to data in a share and allow specific data only to paying customers?", "related_lectures": []}]}
4761106
~~~
{"count": 113, "next": null, "previous": null, "results": [{"_class": "assessment", "id": 70866688, "assessment_type": "multi-select", "prompt": {"question": "Which simple transformations can be used while loading data through the COPY command?", "answers": ["Reorder Columns", "Omit Columns", "Truncate", "Cast", "Transpose", "Pivot"], "explanation": "When loading data into a table using the COPY command, Snowflake allows you to do simple transformations on the data as it is being loaded. During the load process, the COPY command allows for modifying the order of columns, omitting one or more columns, casting data into specified data types, and truncating values.\n  \n While loading the data, complex transformations such as joins, filters, aggregations, and the use of FLATTEN are not supported as they are not essential data transformations. Therefore, joining, filtering, and aggregating the data are supported ONLY after the data has been loaded into a table.\n  \n https://docs.snowflake.com/en/user-guide/data-load-overview#id2"}, "correct_response": ["a", "b", "c", "d"], "section": "Data Loading and Unloading", "question_plain": "Which simple transformations can be used while loading data through the COPY command?", "related_lectures": []}, {"_class": "assessment", "id": 70866690, "assessment_type": "multiple-choice", "prompt": {"question": "You are using the Enterprise edition of Snowflake. You inadvertently deleted some crucial data from a permanent table. It has been 92 days since the deletion, and you have just realized your mistake. What should be the best course of action to recover that data?", "answers": ["Contact the Snowflake support team to facilitate the retrieval of this data.", "Use SQL &amp; Time Travel extensions to retrieve the data yourself", "Restore the data from a manual backup into a new table.", "Reload the data from the source files again."], "explanation": "Assuming the table has 90 days of Time Travel, the most straightforward resolution is to contact Snowflake support, which can recover the data from the fail-safe storage. Once the data is in fail-safe storage, only Snowflake support can help retrieve the data. \n  \n Restoring data from a manual backup or reloading from a source file is a cumbersome process and should only be undertaken if even the fail-safe storage does not have the data (i.e., it has been more than 97 (90 for Time Travel &amp; 7 for fail-safe storage) days, and the data is removed from both Time Travel and fail-safe.\n  \n https://docs.snowflake.com/en/user-guide/data-failsafe"}, "correct_response": ["a"], "section": "Fail-safe", "question_plain": "You are using the Enterprise edition of Snowflake. You inadvertently deleted some crucial data from a permanent table. It has been 92 days since the deletion, and you have just realized your mistake. What should be the best course of action to recover that data?", "related_lectures": []}, {"_class": "assessment", "id": 70866692, "assessment_type": "multiple-choice", "prompt": {"question": "True/False: It is possible to disable failsafe for specific databases, schemas, or tables.", "answers": ["False", "True"], "explanation": "Once the Time Travel period ends, Snowflake keeps the data for a further 7-day period as further protection. This fail-safe can not be disabled or configured. You can NOT change it for a Snowflake account, database, schema, or table.\n  \n However, you can use Transient or Temporary tables, which have zero days of fail-safe storage.\n  \n https://docs.snowflake.com/en/user-guide/data-failsafe\n https://docs.snowflake.com/en/user-guide/tables-temp-transient"}, "correct_response": ["a"], "section": "Fail-safe", "question_plain": "True/False: It is possible to disable failsafe for specific databases, schemas, or tables.", "related_lectures": []}, {"_class": "assessment", "id": 70866694, "assessment_type": "multi-select", "prompt": {"question": "Which of the following table types will continue to exist even if the session is closed? Select all that apply.", "answers": ["Transient", "Permanent", "Dual Storage", "Temporary"], "explanation": "Permanent tables exist regardless of the session and are not destroyed when a session is closed.\n Transient tables are not dropped when a session is closed, so they can be accessed from different sessions.\n  \n Temporary tables are local to a session and are dropped as soon as the session is closed. \n  \n https://docs.snowflake.com/en/user-guide/tables-temp-transient"}, "correct_response": ["a", "b"], "section": "Data Protection", "question_plain": "Which of the following table types will continue to exist even if the session is closed? Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70866696, "assessment_type": "multiple-choice", "prompt": {"question": "Which type of short-lived Snowflake tables will continue to exist even if the session is closed?", "answers": ["Transient", "Temporary", "Permanent", "Co-existent"], "explanation": "Transient tables can be used as short-lived tables for ETL work tables and are not dropped when the session is closed.\n  \n https://docs.snowflake.com/en/user-guide/tables-temp-transient"}, "correct_response": ["a"], "section": "Data Protection", "question_plain": "Which type of short-lived Snowflake tables will continue to exist even if the session is closed?", "related_lectures": []}, {"_class": "assessment", "id": 70866698, "assessment_type": "multi-select", "prompt": {"question": "Which Snowflake Editions support up to 90 days of Time Travel? Select all that apply.", "answers": ["Enterprise", "Business Critical", "Virtual Private Snowflake", "Standard"], "explanation": "The enterprise edition and above support Time Travel for up to 90 days.\n  \n https://docs.snowflake.com/en/user-guide/data-time-travel#data-retention-period"}, "correct_response": ["a", "b", "c"], "section": "Time Travel", "question_plain": "Which Snowflake Editions support up to 90 days of Time Travel? Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70866700, "assessment_type": "multiple-choice", "prompt": {"question": "Which of the following actions can be performed by a Snowflake user?", "answers": ["Use SQL to retrieve data in Time Travel.", "Use SQL to retrieve historical data from fail-safe storage.", "Directly access micro-partitions.", "Directly modify micro-partitions."], "explanation": "A Snowflake user may access Time Travel data using the SQL Time Travel extensions. Data stored in fail-safe storage can only be accessed by Snowflake support; a user can not access data in fail-safe storage. A user cannot access or alter micro-partitions directly.\n  \n https://docs.snowflake.com/en/user-guide/data-time-travel#time-travel-sql-extensions"}, "correct_response": ["a"], "section": "Time Travel", "question_plain": "Which of the following actions can be performed by a Snowflake user?", "related_lectures": []}, {"_class": "assessment", "id": 70866702, "assessment_type": "multi-select", "prompt": {"question": "Which of the following is true regarding Time Travel in Snowflake? Select all that apply.", "answers": ["Undrop allows users to restore dropped tables, schemas, and databases.", "Tables, Schemas, and Databases are not immediately deleted physically but instead marked as deleted.", "Undrop can be used to recover data in external stages.", "Undrop can be used to reset a Snowflake account."], "explanation": "Undrop allows users to restore dropped tables, schemas, and databases. When tables, schemas, or databases are dropped in Snowflake, they are not immediately removed from the system and are still recoverable during Time Travel. When a table is dropped, the data is retained on the cloud storage, even though the table is listed as dropped. Snowflake merely sets the table&#39;s state to non-deleted to undrop it. Therefore, undrop can be applied to tables, schemas, and databases.\n  \n https://docs.snowflake.com/en/user-guide/data-time-travel#restoring-objects"}, "correct_response": ["a", "b"], "section": "Time Travel", "question_plain": "Which of the following is true regarding Time Travel in Snowflake? Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70866628, "assessment_type": "multiple-choice", "prompt": {"question": "As an administrator, you are required to find and list all tables with a size greater than 1 TB. You must also include tables created and deleted in the last month. Which one of the following options should you use?", "answers": ["Query the views in the ACCOUNT_USAGE schema", "Use the table functions provided in the INFORMATION_SCHEMA schema", "Go through the logs for COPY command to identify which tables were loaded with large volumes of data", "Use Snowsight to show this information"], "explanation": "ACCOUNT_USAGE views include information for all dropped objects. Many of these views include a DELETED column showing the dropped object&#39;s information. INFORMATION_SCHEMA does not include dropped objects.\n  \n https://docs.snowflake.com/en/sql-reference/account-usage#differences-between-account-usage-and-information-schema"}, "correct_response": ["a"], "section": "Account Usage & Monitoring", "question_plain": "As an administrator, you are required to find and list all tables with a size greater than 1 TB. You must also include tables created and deleted in the last month. Which one of the following options should you use?", "related_lectures": []}, {"_class": "assessment", "id": 70866630, "assessment_type": "multiple-choice", "prompt": {"question": "True or False: Using the views in the ACCOUNT_USAGE schema, you can access the history of usage that occurred 5 minutes ago.", "answers": ["False", "True"], "explanation": "The ACCOUNT USAGE schema consists of several views that provide usage metrics and metadata information at the account level.\n  \n Data provided by the ACCOUNT_USAGE views is NOT real-time and refreshes typically with a lag of 45 minutes to 3 hours, depending on the view. \n  \n The data in these views are retained for up to 365 days.\n  \n https://docs.snowflake.com/en/sql-reference/account-usage#differences-between-account-usage-and-information-schema"}, "correct_response": ["a"], "section": "Account Usage & Monitoring", "question_plain": "True or False: Using the views in the ACCOUNT_USAGE schema, you can access the history of usage that occurred 5 minutes ago.", "related_lectures": []}, {"_class": "assessment", "id": 70866632, "assessment_type": "multiple-choice", "prompt": {"question": "How many days of historical data can you access through the views in the INFORMATION_SCHEMA schema?", "answers": ["7 days - 6 months", "7 days", "1 day", "365 days"], "explanation": "The data in the INFORMATION_SCHEMA views is retained for a shorter period. Typical data retention in INFORMATION SCHEMA is 14 days but can be seven days for specific views and up to 6 months for usage history views. Thus, these views have retention ranging from 7 days to a maximum of 6 months, depending on the view. So typically, the views in the INFORMATION SCHEMA can be used to find more recent information.\n  \n https://docs.snowflake.com/en/sql-reference/account-usage#differences-between-account-usage-and-information-schema"}, "correct_response": ["a"], "section": "Account Usage & Monitoring", "question_plain": "How many days of historical data can you access through the views in the INFORMATION_SCHEMA schema?", "related_lectures": []}, {"_class": "assessment", "id": 70866634, "assessment_type": "multiple-choice", "prompt": {"question": "Using the INFORMATION_SCHEMA you can view information on account-level objects such as roles, warehouses, and databases.", "answers": ["True", "False"], "explanation": "The INFORMATION_SCHEMA provides data on the objects in the parent database of the INFORMATION_SCHEMA. It also provides data on account-level objects such as roles, warehouses, and databases.\n  \n https://docs.snowflake.com/en/sql-reference/info-schema#information-schema-views-and-table-functions"}, "correct_response": ["a"], "section": "Account Usage & Monitoring", "question_plain": "Using the INFORMATION_SCHEMA you can view information on account-level objects such as roles, warehouses, and databases.", "related_lectures": []}, {"_class": "assessment", "id": 70866636, "assessment_type": "multi-select", "prompt": {"question": "You need to see the history of all queries executed in the last 60 minutes. Which of the following method should you use?", "answers": ["Use the QUERY_HISTORY table function in the INFORMATION schema", "View the historical queries using the query history page", "Use the QUERY_HISTORY view in the ACCOUNT_USAGE schema", "Request Snowflake support to provide query history"], "explanation": "The QUERY_HISTORY table function in the INFORMATION schema provides up-to-date information without latency. \n  \n The QUERY_HISTORY view in ACCOUNT_USAGE schema can have 3 hours of latency, so it will not be suitable for viewing the last 60 minutes of query history.\n  \n The query history page can also be used to view the history of executed queries with-in the last 14 days."}, "correct_response": ["a", "b"], "section": "Account Usage & Monitoring", "question_plain": "You need to see the history of all queries executed in the last 60 minutes. Which of the following method should you use?", "related_lectures": []}, {"_class": "assessment", "id": 70866638, "assessment_type": "multiple-choice", "prompt": {"question": "True or False: Resource monitors can manage a single virtual warehouse, a collection of virtual warehouses, or the entire Snowflake account.", "answers": ["True", "False"], "explanation": "Resource monitors can track &amp; manage a single virtual warehouse against a defined quota. Resource monitors can be created to track the credit usage of multiple virtual warehouses together.\n Resource Monitors can also be created at the account level, which means that such resource monitors track credit usage at the account level, considering the credit usage of all virtual warehouses.\n  \n https://docs.snowflake.com/en/user-guide/resource-monitors#assignment-of-resource-monitors"}, "correct_response": ["a"], "section": "Account Usage & Monitoring", "question_plain": "True or False: Resource monitors can manage a single virtual warehouse, a collection of virtual warehouses, or the entire Snowflake account.", "related_lectures": []}, {"_class": "assessment", "id": 70866640, "assessment_type": "multi-select", "prompt": {"question": "During a weekly release cycle, which of the following accounts may be updated on the first day of release?", "answers": ["Only those Enterprise edition accounts which have opted into early access", "Standard edition accounts", "All Enterprise edition accounts", "All business critical edition accounts"], "explanation": "Snowflake does not instantly deploy a new version to all Snowflake accounts; rather, customer accounts are moved into the new release over time in a phased manner.\n  \n Day 1 (early access): Deployed for Enterprise edition (or higher) accounts that have elected for early access. You can enroll an Enterprise edition (or higher) account for early access by contacting Snowflake support.\n  \n Day 1 or 2 (regular access): Deployment of all Snowflake accounts on the Standard edition. \n  \n Day 2 (last): All remaining Enterprise edition (or higher) accounts are deployed. \n  \n Between an early access deployment and a final deployment, a minimum of 24 hours must pass. This staged release strategy enables Snowflake to identify and address any software issues uncovered during early access.\n  \n https://docs.snowflake.com/en/user-guide/intro-releases"}, "correct_response": ["a", "b"], "section": "Account", "question_plain": "During a weekly release cycle, which of the following accounts may be updated on the first day of release?", "related_lectures": []}, {"_class": "assessment", "id": 70866642, "assessment_type": "multi-select", "prompt": {"question": "Please select the 3 key layers which are part of the Snowflake Architecture.", "answers": ["Database Storage", "Cloud Services", "Query Processing", "Docker Containers", "Azure VMs"], "explanation": "Snowflake architecture has three distinct layers:\n Database Storage - Cheap cloud storage on AWS, Azure, or Google Cloud\n Query Processing - Primarily composed of virtual warehouses\n Cloud Services - The brain of the whole operation\n  \n https://docs.snowflake.com/en/user-guide/intro-key-concepts#snowflake-architecture"}, "correct_response": ["a", "b", "c"], "section": "Architecture", "question_plain": "Please select the 3 key layers which are part of the Snowflake Architecture.", "related_lectures": []}, {"_class": "assessment", "id": 70866644, "assessment_type": "multiple-choice", "prompt": {"question": "Snowflake database is based on the traditional shared disk architecture used by RDBMS like MySQL and Postgres.", "answers": ["No", "Yes"], "explanation": "Snowflake implements a new hybrid architecture that combines the best features of shared-disk and shared-nothing architectures. Snowflake stores data similarly to a shared-disk architecture, i.e., the data is shared, i.e., the data is shared. But it also allows for using several compute engines, each with its own memory and processing capabilities.\n  \n https://docs.snowflake.com/en/user-guide/intro-key-concepts#snowflake-architecture"}, "correct_response": ["a"], "section": "Architecture", "question_plain": "Snowflake database is based on the traditional shared disk architecture used by RDBMS like MySQL and Postgres.", "related_lectures": []}, {"_class": "assessment", "id": 70866646, "assessment_type": "multiple-choice", "prompt": {"question": "Can micro-partition overlap in their range of values?", "answers": ["Yes", "No"], "explanation": "Because micro-partitions are immutable and any data modifications or new data must require a new micro-partition, similar values are not guaranteed to be in the same physical partition, and partition values can also overlap.\n  \n https://docs.snowflake.com/en/user-guide/tables-clustering-micropartitions"}, "correct_response": ["a"], "section": "Architecture", "question_plain": "Can micro-partition overlap in their range of values?", "related_lectures": []}, {"_class": "assessment", "id": 70866648, "assessment_type": "multiple-choice", "prompt": {"question": "Which of the following statement is true regarding how Snowflake stores its data?", "answers": ["Snowflake uses its own proprietary columnar format to store table data.", "Snowflake stores table data as simple comma-separated files in cloud-based storage.", "Snowflake uses the Parquet file format to store the table data."], "explanation": "Snowflake stores data in a proprietary format on cloud object storage, such as AWS S3, Azure Blob Storage, or Google Cloud Storage. \n Snowflake stores columns in a columnar manner. The columnar format enables Snowflake to optimize queries by retrieving only the referenced columns."}, "correct_response": ["a"], "section": "Architecture", "question_plain": "Which of the following statement is true regarding how Snowflake stores its data?", "related_lectures": []}, {"_class": "assessment", "id": 70866650, "assessment_type": "multiple-choice", "prompt": {"question": "True/False: Data in micro-partitions is stored with compression.", "answers": ["True", "False"], "explanation": "Data in Snowflake tables is automatically organized into partitions, known as micro-partition. Each micro-partition generally contains 50MB to 500 MB of uncompressed data. However, the stored size is smaller as Snowflake data is always stored with compression. Within each micro-partition, the data is stored in a columnar format.\n  \n https://docs.snowflake.com/en/user-guide/tables-clustering-micropartitions.html"}, "correct_response": ["a"], "section": "Micro partitions", "question_plain": "True/False: Data in micro-partitions is stored with compression.", "related_lectures": []}, {"_class": "assessment", "id": 70866652, "assessment_type": "multiple-choice", "prompt": {"question": "How are the columns stored in a Snowflake micro-partition?", "answers": ["Independently - each column is stored on its own, also known as columnar storage.", "Combined - columns for a given row are stored together, also known as row storage."], "explanation": "Snowflake stores columns in a columnar manner within each micro-partition. A columnar format enables Snowflake to optimize queries by retrieving only the referenced columns. In addition to micro-partition compression, each column in a micro-partition is compressed independently. Snowflake chooses the optimum compression algorithm for each column.\n  \n https://docs.snowflake.com/en/user-guide/tables-clustering-micropartitions.html"}, "correct_response": ["a"], "section": "Architecture", "question_plain": "How are the columns stored in a Snowflake micro-partition?", "related_lectures": []}, {"_class": "assessment", "id": 70866654, "assessment_type": "multiple-choice", "prompt": {"question": "What is the number of nodes in a 6X-Large virtual warehouse?", "answers": ["512", "256", "128", "64"], "explanation": "6X-Large, the largest cluster configuration (at the moment), has 512 nodes. The easy way to calculate is from the Large size, which has 8 nodes. 6X-Large means Large doubled in size 6 times. i.e. 8 nodes * (2*2*2*2*2*2) = 512\n  \n https://docs.snowflake.com/en/user-guide/warehouses-overview"}, "correct_response": ["a"], "section": "Architecture", "question_plain": "What is the number of nodes in a 6X-Large virtual warehouse?", "related_lectures": []}, {"_class": "assessment", "id": 70866656, "assessment_type": "multiple-choice", "prompt": {"question": "True/False: If you have multiple virtual warehouses in your Snowflake system, they will access the same shared data.", "answers": ["True", "False"], "explanation": "Snowflake stores data in a shared manner, like in shared-disk architecture. But it also allows for using several compute engines, each with its own memory and processing capabilities. The virtual warehouses are independent of each other but access and process the same shared data. \n  \n https://docs.snowflake.com/en/user-guide/intro-key-concepts#snowflake-architecture"}, "correct_response": ["a"], "section": "Architecture", "question_plain": "True/False: If you have multiple virtual warehouses in your Snowflake system, they will access the same shared data.", "related_lectures": []}, {"_class": "assessment", "id": 70866658, "assessment_type": "multiple-choice", "prompt": {"question": "True/False: Once a virtual warehouse has been created, its size cannot be changed.", "answers": ["False", "True"], "explanation": "You can resize a virtual warehouse at any time, even when they are running.\n  \n https://docs.snowflake.com/en/user-guide/warehouses-tasks"}, "correct_response": ["a"], "section": "Architecture", "question_plain": "True/False: Once a virtual warehouse has been created, its size cannot be changed.", "related_lectures": []}, {"_class": "assessment", "id": 70866660, "assessment_type": "multiple-choice", "prompt": {"question": "A virtual warehouse was started and then stopped after 35 seconds. How much time would be considered to calculate the number of Snowflake credits used?", "answers": ["60 seconds", "35 seconds", "0 seconds", "35 seconds if a query was run; otherwise, 0 seconds"], "explanation": "Snowflake credits are billed per second; however, a minimum of 60 seconds of billing applies. If a virtual warehouse were provisioned, resumed, suspended, or deleted within the first 60 seconds, a minimum of 60 seconds of credit usage would apply. Whether or not a warehouse is running a query doesn&#39;t matter; if the virtual warehouse is running, it is consuming credits."}, "correct_response": ["a"], "section": "Architecture", "question_plain": "A virtual warehouse was started and then stopped after 35 seconds. How much time would be considered to calculate the number of Snowflake credits used?", "related_lectures": []}, {"_class": "assessment", "id": 70866662, "assessment_type": "multi-select", "prompt": {"question": "What is meant by scaling down a virtual warehouse in Snowflake? Select all that apply.", "answers": ["Typically a virtual warehouse is scaled down as a response to decreased query complexity.", "Scaling down means resizing the virtual warehouse to a smaller size.", "Nodes are de-provisioned when a virtual warehouse is scaled down.", "Scaling down means increasing the size of a virtual warehouse to accommodate more complex workloads"], "explanation": "Scaling down a virtual warehouse is typically done in reaction to reduced query complexity, where a smaller virtual warehouse can still perform queries efficiently and on time. Keeping a larger virtual warehouse when a smaller virtual warehouse can perform queries efficiently and fast wastes resources and costs money. In such cases, scaling down the virtual warehouse is an option. Nodes are removed from a virtual warehouse when scaling down. Nodes are removed only when they are no longer executing a query.\n  \n https://docs.snowflake.com/en/user-guide/warehouses-considerations#scaling-up-vs-scaling-out"}, "correct_response": ["a", "b", "c"], "section": "Architecture", "question_plain": "What is meant by scaling down a virtual warehouse in Snowflake? Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70866664, "assessment_type": "multiple-choice", "prompt": {"question": "A virtual warehouse is running. Can it be resized?", "answers": ["Yes", "No"], "explanation": "You can resize a virtual warehouse at any time, even when they are running. When a virtual warehouse is resized, Snowflake adds or removes nodes according to the new size. The removal of nodes takes place only when all active queries on those nodes have finished.\n  \n https://docs.snowflake.com/en/user-guide/warehouses-tasks#resizing-a-warehouse"}, "correct_response": ["a"], "section": "Architecture", "question_plain": "A virtual warehouse is running. Can it be resized?", "related_lectures": []}, {"_class": "assessment", "id": 70866666, "assessment_type": "multiple-choice", "prompt": {"question": "The cloud services layer in Snowflake provides which one of the following?", "answers": ["Metadata Management", "Query execution", "Data Storage"], "explanation": "The cloud services layer contains and manages a variety of metadata, including details regarding how the data is stored, information on the micro-partitions, metadata regarding the databases and tables in your system, the users, roles and security, and so forth. \n Query execution is performed by the query processing layer (not cloud services)."}, "correct_response": ["a"], "section": "Architecture", "question_plain": "The cloud services layer in Snowflake provides which one of the following?", "related_lectures": []}, {"_class": "assessment", "id": 70866668, "assessment_type": "multi-select", "prompt": {"question": "Which of the following are examples of caches in Snowflake?", "answers": ["Query Result Cache", "Metadata Cache", "Virtual Warehouse Cache", "Memory Cache", "High-Speed Cache"], "explanation": "Statistics are kept in the metadata cache for each table, micro-partition, and column. The metadata cache can return results if the query merely counts rows or finds a column&#39;s minimum or maximum value. \n  \n Snowflake can use the query result cache to return the results if the query has previously been executed and the data hasn&#39;t changed.\n  \n Each virtual warehouse also has its own cache, constructed over time by moving micro-partitions from cloud storage to SSD storage. Similar queries run on a virtual warehouse may already have some data in the cache, which improves query performance.\n  \n https://docs.snowflake.com/en/user-guide/querying-persisted-results"}, "correct_response": ["a", "b", "c"], "section": "Architecture", "question_plain": "Which of the following are examples of caches in Snowflake?", "related_lectures": []}, {"_class": "assessment", "id": 70866670, "assessment_type": "multiple-choice", "prompt": {"question": "True or False: When exporting data using the COPY command, the exported file(s) are automatically compressed.", "answers": ["True", "False"], "explanation": "When data is unloaded from Snowflake, it is automatically compressed using gzip compression. This is the default behavior; however, you can specify alternate compression methods or turn off compression entirely.\n  \n The unloading process automatically exports to multiple files so that it can take advantage of the parallelism offered by Snowflake. However, if needed, you can set the SINGLE parameter to true to ensure the export goes to a single file.\n  \n The default size of each output file is 16 MB but can be changed using the MAX_FILE_SIZE parameter. The maximum allowed size per file is 5GB if you export data to cloud storage. \n  \n  \n https://docs.snowflake.com/en/user-guide/data-unload-considerations#unloading-to-a-single-file"}, "correct_response": ["a"], "section": "Data Loading and Unloading", "question_plain": "True or False: When exporting data using the COPY command, the exported file(s) are automatically compressed.", "related_lectures": []}, {"_class": "assessment", "id": 70866672, "assessment_type": "multiple-choice", "prompt": {"question": "When loading data through COPY command, it is required that your table and the file from where the data is being loaded should have the same number of columns.", "answers": ["False", "True"], "explanation": "The order &amp; the number of columns in the file and the table can differ. In this case, a SELECT statement can be used to select only the required columns from the stage.\n  \n When loading data into a table using the COPY command, Snowflake allows you to do simple transformations on the data as it is being loaded by using a SELECT statement. During the load process, the COPY command allows for modifying the order of columns, omitting one or more columns, and casting data into specified data types. It is also possible to truncate data using the COPY command if it is larger than the desired column width. \n  \n  \n https://docs.snowflake.com/en/user-guide/data-load-overview#simple-transformations-during-a-load"}, "correct_response": ["a"], "section": "Data Loading and Unloading", "question_plain": "When loading data through COPY command, it is required that your table and the file from where the data is being loaded should have the same number of columns.", "related_lectures": []}, {"_class": "assessment", "id": 70866674, "assessment_type": "multiple-choice", "prompt": {"question": "An external table can only be created using an external stage.", "answers": ["True", "False"], "explanation": "An external table is a metadata definition; that is, you register the definition of an external table, but the external table itself doesn&#39;t contain any data. The table metadata contains column definition, the name of the external stage from where the data for the external table is, and the file format which should be used to read that data. \n  \n The external stage, in turn, points to object storage on the cloud, for example, an AWS bucket or Azure Blob storage, which contains the data for the external table. \n  \n Note that an external table can only point to an external stage. An internal stage cannot be used to create an external table.\n  \n https://docs.snowflake.com/en/user-guide/tables-external-intro"}, "correct_response": ["a"], "section": "Data Loading and Unloading", "question_plain": "An external table can only be created using an external stage.", "related_lectures": []}, {"_class": "assessment", "id": 70866676, "assessment_type": "multi-select", "prompt": {"question": "Which of the following statements are true regarding External Tables? Select all that apply.", "answers": ["Views can be created on top of an external table.", "An external table allows querying of data in cloud storage without requiring it to be loaded into Snowflake first.", "External tables don&#39;t support views.", "External tables can not be joined with other Snowflake tables."], "explanation": "Snowflake offers an alternative approach for tables called external tables, which permits the creation of tables with data stored in external cloud storage. External tables remove the need for the data to be loaded into Snowflake. In the case of an External table, the definition of the table is still stored in Snowflake metadata and consists of table structure, file locations, filenames, and other attributes. However, the table&#39;s data is saved outside of Snowflake.\n  \n The external table functionality enables you to query external data like a standard table. For example, external tables may be joined to other tables, and views may be created using them.\n  \n https://docs.snowflake.com/en/user-guide/tables-external-intro"}, "correct_response": ["a", "b"], "section": "Data Loading and Unloading", "question_plain": "Which of the following statements are true regarding External Tables? Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70866678, "assessment_type": "multiple-choice", "prompt": {"question": "For data loading and transformation, the approach recommended by Snowflake is?", "answers": ["ELT (Extract, Load, Transform)", "ETL (Extract, Transform, Load)"], "explanation": "The ELT approach utilizes the processing power of Snowflake to transform the data after it has been loaded."}, "correct_response": ["a"], "section": "Data Loading and Unloading", "question_plain": "For data loading and transformation, the approach recommended by Snowflake is?", "related_lectures": []}, {"_class": "assessment", "id": 70866680, "assessment_type": "multi-select", "prompt": {"question": "Which of the following is true regarding data loading in Snowflake?", "answers": ["Snowflake does not ensure that files are loaded in the order they arrived.", "Snowflake maintains load metadata to track processed files.", "Snowflake does not maintain any load metadata for tracking processed files.", "Snowflake guarantees that files are loaded in the order they arrived."], "explanation": "Each time data is loaded, metadata is created, called load metadata. The load metadata stores a variety of information, such as the name of every file that was loaded into that table and the time stamp corresponding to the time that a file was loaded. By utilizing this load metadata, Snowflake ensures that it will not reprocess a previously loaded file. \n  \n Snowflake doesn&#39;t ensure that the files are loaded in the order they arrived.\n  \n https://docs.snowflake.com/en/user-guide/data-load-considerations-load"}, "correct_response": ["a", "b"], "section": "Data Loading and Unloading", "question_plain": "Which of the following is true regarding data loading in Snowflake?", "related_lectures": []}, {"_class": "assessment", "id": 70866682, "assessment_type": "multiple-choice", "prompt": {"question": "What is the PUT command used for?", "answers": ["Transfer data into a Snowflake internal stage.", "Transfer data into a Snowflake external stage.", "Transfer data from cloud object storage to on-premise storage", "Transfer data from on-premise storage to cloud object storage"], "explanation": "The PUT command uploads data from an on-premises system to an internal stage.\n  \n The GET command is used to download data from an internal stage to an on-premises system.\n  \n To download or upload data to an external stage, cloud provider utilities or other tools are used to interact with data in the cloud storage pointed to by the external stage.\n  \n  \n https://docs.snowflake.com/en/user-guide/data-unload-overview#bulk-unloading-process"}, "correct_response": ["a"], "section": "Data Loading and Unloading", "question_plain": "What is the PUT command used for?", "related_lectures": []}, {"_class": "assessment", "id": 70866684, "assessment_type": "multi-select", "prompt": {"question": "Snowpipe can load data directly from which of the following? Select all that apply.", "answers": ["External Stage", "Internal Stage", "On-premises system", "Snowflake tables"], "explanation": "Snowpipe can load data from an external stage as well as an internal stage. When using an external stage, you can use the cloud platform notifications to trigger your Snowpipe. The cloud platform notifications can be configured to trigger an event as soon as a new file is detected in the cloud storage bucket. Additional configuration links the event to your Snowpipe, so every time new files arrive, the Snowpipe is automatically triggered into action. When triggered, the Snowpipe runs the COPY command from its definition and loads newly received data into the target table.\n  \n The alternate mechanism is through a REST API call, which requires you to write a program that can trigger the Snowpipe as needed by calling Snowpipe-specific REST APIs. Using REST APIs, you control when you want to trigger the Snowpipe, either on a scheduled or ad-hoc basis.\n Note that when using internal stages with Snowpipe, you must trigger a Snowpipe via the REST API. There is no provision for a trigger based invocation of Snowpipe when using the internal stage as a source.\n  \n Note: A snowpipe can not check an S3 bucket directly for a file, and it must be triggered by a notification or a REST API call.\n  \n https://docs.snowflake.com/en/user-guide/data-load-snowpipe-intro"}, "correct_response": ["a", "b"], "section": "Data Loading and Unloading", "question_plain": "Snowpipe can load data directly from which of the following? Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70866686, "assessment_type": "multiple-choice", "prompt": {"question": "Snowpipe can reload a file with the same name if it has been modified.", "answers": ["False", "True"], "explanation": "The load metadata stores a variety of information, such as the name of every file that was loaded into that table and the time stamp corresponding to the time that a file was loaded. By utilizing this load metadata, Snowflake ensures that it will not reprocess a file already loaded.\n  \n https://docs.snowflake.com/en/user-guide/data-load-snowpipe-ts#unable-to-reload-modified-data-modified-data-loaded-unintentionally"}, "correct_response": ["a"], "section": "Data Loading and Unloading", "question_plain": "Snowpipe can reload a file with the same name if it has been modified.", "related_lectures": []}, {"_class": "assessment", "id": 70866704, "assessment_type": "multiple-choice", "prompt": {"question": "True or False: Any Snowflake account can act as a data provider or consumer; therefore, any Snowflake account can share or consume data.", "answers": ["True", "False"], "explanation": "Correct. Any Snowflake account can share data and simultaneously consume data from another provider. Therefore, a Snowflake can act as a data provider and consumer.\n  \n Virtual Private Snowflake (VPS) accounts are an exception because VPS accounts have isolated metadata and compute and therefore don&#39;t have sharing capabilities."}, "correct_response": ["a"], "section": "Data Sharing", "question_plain": "True or False: Any Snowflake account can act as a data provider or consumer; therefore, any Snowflake account can share or consume data.", "related_lectures": []}, {"_class": "assessment", "id": 70866706, "assessment_type": "multiple-choice", "prompt": {"question": "True or False: Snowflake recommends creating a secure view to share data from several tables in different databases.", "answers": ["True", "False"], "explanation": "You can create secure views if you need to share data from many tables in different databases. Since you can&#39;t add more than one database to a single share, Snowflake recommends creating secure views in a single database.\n  \n https://docs.snowflake.com/en/user-guide/data-sharing-mutiple-db"}, "correct_response": ["a"], "section": "Data Sharing", "question_plain": "True or False: Snowflake recommends creating a secure view to share data from several tables in different databases.", "related_lectures": []}, {"_class": "assessment", "id": 70866708, "assessment_type": "multi-select", "prompt": {"question": "Which of the following objects may be shared via direct data sharing?", "answers": ["Tables", "Secure Views", "Secure Materialized Views", "Accounts", "Users"], "explanation": "Direct data sharing enables sharing of the following types of objects:\n Tables, External tables, Secure views, Secure materialized views, Secure UDFs.\n  \n https://docs.snowflake.com/en/user-guide/data-sharing-intro"}, "correct_response": ["a", "b", "c"], "section": "Data Sharing", "question_plain": "Which of the following objects may be shared via direct data sharing?", "related_lectures": []}, {"_class": "assessment", "id": 70866710, "assessment_type": "multiple-choice", "prompt": {"question": "True or False: A consumer of a shared database can add new tables or views to the shared database.", "answers": ["False", "True"], "explanation": "Shared objects are read-only for the consumer and cannot be modified by the consumer. A database created on Share contains the tables and other objects that the data provider added, but the consumer cannot add additional objects."}, "correct_response": ["a"], "section": "Data Sharing", "question_plain": "True or False: A consumer of a shared database can add new tables or views to the shared database.", "related_lectures": []}, {"_class": "assessment", "id": 70866712, "assessment_type": "multiple-choice", "prompt": {"question": "A reader account can consume data from sources other than the producer that created the reader account.", "answers": ["False", "True"], "explanation": "A reader account cannot consume data from any data provider other than the data provider that created and owns the reader account.\n  \n https://docs.snowflake.com/en/user-guide/data-sharing-reader-create#what-is-restricted-allowed-in-a-reader-account"}, "correct_response": ["a"], "section": "Data Sharing", "question_plain": "A reader account can consume data from sources other than the producer that created the reader account.", "related_lectures": []}, {"_class": "assessment", "id": 70866714, "assessment_type": "multiple-choice", "prompt": {"question": "Which statement is true regarding costs when a Snowflake account shares data with a non-Snowflake user or a non-Snowflake organization?", "answers": ["The data provider is charged for the compute charges for queries the data consumer runs.", "The data consumer is charged for the compute charges for queries they run.", "Both the data provider and the data consumer are charged for the compute costs."], "explanation": "Sharing data with a non-Snowflake user or organization is possible by creating a reader account. This reader account is created by the data provider solely for sharing purposes. Since the data provider creates and administers the reader account, all the reader account&#39;s compute expenses are invoiced to the provider account. Therefore, the reader account&#39;s use of the virtual warehouse compute is added to the provider account compute charges.\n  \n https://docs.snowflake.com/en/user-guide/data-sharing-reader-create#overview"}, "correct_response": ["a"], "section": "Data Sharing", "question_plain": "Which statement is true regarding costs when a Snowflake account shares data with a non-Snowflake user or a non-Snowflake organization?", "related_lectures": []}, {"_class": "assessment", "id": 70866716, "assessment_type": "multiple-choice", "prompt": {"question": "To create a SHARE, what is the minimum required role?", "answers": ["ACCOUNTADMIN", "SECURITYADMIN", "SYSADMIN"], "explanation": "By default, ACCOUNTADMIN is the only role with the privileges required to create &amp; manage a share because managing Share is an account-level activity.\n \n Alternatively, using the ACCOUNTADMIN role, you can grant the privileges to manage shares to other roles.\n  \n https://docs.snowflake.com/en/user-guide/data-sharing-gs"}, "correct_response": ["a"], "section": "Data Sharing", "question_plain": "To create a SHARE, what is the minimum required role?", "related_lectures": []}, {"_class": "assessment", "id": 70866718, "assessment_type": "multiple-choice", "prompt": {"question": "Which of the following roles can import a dataset from Snowflake Marketplace?", "answers": ["ACCOUNTADMIN", "SYSADMIN", "SECURITYADMIN", "SHAREADMIN"], "explanation": "Although any user or role can explore the Snowflake Marketplace, you need a user with the ACCOUNTADMIN privilege or the IMPORT SHARE privilege for consuming data. For simplicity, we suggest you utilize a user with the ACCOUNTADMIN privilege."}, "correct_response": ["a"], "section": "Data Sharing", "question_plain": "Which of the following roles can import a dataset from Snowflake Marketplace?", "related_lectures": []}, {"_class": "assessment", "id": 70866720, "assessment_type": "multiple-choice", "prompt": {"question": "True or False: Using the Snowflake Marketplace, customers can search for and utilize publicly accessible third-party datasets made available by different organizations.", "answers": ["True", "False"], "explanation": "The Snowflake Marketplace is an online marketplace where you can purchase and sell datasets. You may import data from outside your company into your Snowflake instance and utilize it to enrich your data via the Snowflake Marketplace.\n  \n https://other-docs.snowflake.com/en/collaboration/collaboration-marketplace-about.html"}, "correct_response": ["a"], "section": "Data Sharing", "question_plain": "True or False: Using the Snowflake Marketplace, customers can search for and utilize publicly accessible third-party datasets made available by different organizations.", "related_lectures": []}, {"_class": "assessment", "id": 70866722, "assessment_type": "multiple-choice", "prompt": {"question": "<p><strong>When processing semi-structured data into structured (i.e., a table), what is the correct way to cast a column into a data type? </strong></p><p><strong> </strong></p><p><strong> Assume the target column name is CustomerName, and the data type is String.</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", ""], "explanation": "<p>&lt;json_column_name&gt;:&lt;intended_column_name&gt;:&lt;datatype&gt; is the correct way to cast when processing semi-structured data in a VARIANT column.</p><p>Thus \"SELECT col1:CustomerName::String\" is the correct answer&nbsp; &nbsp; &nbsp;</p><p>https://docs.snowflake.com/en/user-guide/semistructured-&nbsp; considerations#casting-key-values</p>", "answers": ["SELECT col1:CustomerName::String", "SELECT col1 AS CustomerName WITH DATATYPE AS String", "SELECT CAST(col1:CustomerName AS String)"]}, "correct_response": ["a"], "section": "Data Loading and Unloading", "question_plain": "When processing semi-structured data into structured (i.e., a table), what is the correct way to cast a column into a data type?   Assume the target column name is CustomerName, and the data type is String.", "related_lectures": []}, {"_class": "assessment", "id": 70866724, "assessment_type": "multiple-choice", "prompt": {"question": "You are required to store JSON data in a Snowflake table. Which data type will you use?", "answers": ["VARIANT", "STRING", "VARCHAR", "VARBINARY"], "explanation": "Snowflake supports loading and processing semi-structured data. Snowflake provides the VARIANT data type, which can store any data and is appropriate for semi-structured data input and querying. SQL may be used to read and navigate JSON data once it has been loaded into a VARIANT column.\n  \n https://docs.snowflake.com/en/user-guide/semistructured-intro"}, "correct_response": ["a"], "section": "Data Loading and Unloading", "question_plain": "You are required to store JSON data in a Snowflake table. Which data type will you use?", "related_lectures": []}, {"_class": "assessment", "id": 70866726, "assessment_type": "multiple-choice", "prompt": {"question": "An external function&#39;s code executes in which location?", "answers": ["Outside of Snowflake", "In virtual warehouse memory", "In a sandbox in Snowflake", "In the cloud services layer"], "explanation": "An external function, unlike other UDFs, does not include its own code; instead, it invokes code that is stored and run outside of Snowflake.\n  \n For an external function, the only thing that is kept inside Snowflake is information that Snowflake uses to invoke the remote service that contains the code.\n  \n https://docs.snowflake.com/en/sql-reference/external-functions-introduction"}, "correct_response": ["a"], "section": "Extending Snowflake Functionality", "question_plain": "An external function&#39;s code executes in which location?", "related_lectures": []}, {"_class": "assessment", "id": 70866728, "assessment_type": "multi-select", "prompt": {"question": "Which of the following requirements can be fulfilled by only a secure UDF? Select all that apply.", "answers": ["There is a requirement to protect data by limiting some table columns from the result set.", "There is a requirement to protect data by limiting a subset of rows from the result set.", "There is a requirement to simplify complex SQL so that users don&#39;t have to re-code the same logic repeatedly."], "explanation": "SQL UDFs should be created as secure if their purpose is to protect data, such as views that limit the rows returned to the user or the columns. \n  \n https://docs.snowflake.com/en/developer-guide/secure-udf-procedure"}, "correct_response": ["a", "b"], "section": "Extending Snowflake Functionality", "question_plain": "Which of the following requirements can be fulfilled by only a secure UDF? Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70866730, "assessment_type": "multi-select", "prompt": {"question": "Which of the following statements are true regarding Snowpark?", "answers": ["When using Snowpark, Snowflake operations are performed lazily.", "Functions defined in Snowpark can be pushed down to the server (Snowflake) for execution.", "When using Snowpark, Snowflake operations are performed immediately on the client side.", "Snowpark uses the Hadoop query engine for execution."], "explanation": "Snowpark automatically converts the data-processing programming constructs to SQL and pushes it down to Snowflake for execution.\n This approach results in parallel execution of the data-specific code since the execution can take advantage of the Snowflake scale. It also uses lazy execution, which means that a programmer may perform several operations on a data frame, but it is only after they perform an execute operation that the code is converted to SQL and executed. \n  \n https://docs.snowflake.com/en/developer-guide/snowpark/index"}, "correct_response": ["a", "b"], "section": "Extending Snowflake Functionality", "question_plain": "Which of the following statements are true regarding Snowpark?", "related_lectures": []}, {"_class": "assessment", "id": 70866732, "assessment_type": "multiple-choice", "prompt": {"question": "Under which condition a stored procedure will execute under the privileges of the person calling the stored procedure?", "answers": ["The stored procedure has been configured to run under the caller&#39;s rights.", "The stored procedure has been configured to run under the owner&#39;s rights.", "The stored procedure doesn&#39;t perform any DML operations.", "The stored procedure has a single SQL statement in its definition"], "explanation": "A stored procedure can be called with either the caller&#39;s rights or the owner&#39;s rights. \n A stored procedure configured to run with callers&#39; rights executes under the permissions of the calling user. \n A stored procedure configured to run with the owner&#39;s rights executes under the privileges of the role that created and owns the stored procedure."}, "correct_response": ["a"], "section": "Extending Snowflake Functionality", "question_plain": "Under which condition a stored procedure will execute under the privileges of the person calling the stored procedure?", "related_lectures": []}, {"_class": "assessment", "id": 70866734, "assessment_type": "multi-select", "prompt": {"question": "Stored Procedures provide which of the following functionality?", "answers": ["Conditional Logic", "Loops", "Execute SQL statements", "Query cloud services layer", "Access the internal memory of a virtual warehouse"], "explanation": "Stored procedures let you use if-else logic, looping, and other features that SQL does not typically provide. With stored procedures, you can assemble dynamic SQL statements on the fly and execute them as well. \n  \n https://docs.snowflake.com/en/sql-reference/stored-procedures-overview"}, "correct_response": ["a", "b", "c"], "section": "Extending Snowflake Functionality", "question_plain": "Stored Procedures provide which of the following functionality?", "related_lectures": []}, {"_class": "assessment", "id": 70866736, "assessment_type": "multiple-choice", "prompt": {"question": "True or False: Snowflake is available to be installed on-premises servers.", "answers": ["False", "True"], "explanation": "False. Snowflake is engineered for the cloud and is available only on AWS, Azure &amp; GCP."}, "correct_response": ["a"], "section": "Licensing & Features", "question_plain": "True or False: Snowflake is available to be installed on-premises servers.", "related_lectures": []}, {"_class": "assessment", "id": 70866738, "assessment_type": "multiple-choice", "prompt": {"question": "To create an external table, what minimum Snowflake edition is required?", "answers": ["Standard", "Enterprise", "Business Critical", "Virtual Private Snowflake"], "explanation": "All Snowflake editions support external tables; thus, the minimum edition that supports it is the Standard edition.\n  \n  \n https://docs.snowflake.com/en/user-guide/intro-editions.html"}, "correct_response": ["a"], "section": "Licensing & Features", "question_plain": "To create an external table, what minimum Snowflake edition is required?", "related_lectures": []}, {"_class": "assessment", "id": 70866740, "assessment_type": "multiple-choice", "prompt": {"question": "What is the minimum Snowflake edition that supports Database replication between Snowflake accounts (within an organization)?", "answers": ["Standard", "Enterprise", "Business Critical", "Virtual Private Snowflake"], "explanation": "Database replication is supported in all Snowflake editions; thus, the minimum edition that supports it is the Standard edition.\n  \n  \n https://docs.snowflake.com/en/user-guide/intro-editions.html"}, "correct_response": ["a"], "section": "Licensing & Features", "question_plain": "What is the minimum Snowflake edition that supports Database replication between Snowflake accounts (within an organization)?", "related_lectures": []}, {"_class": "assessment", "id": 70866742, "assessment_type": "multiple-choice", "prompt": {"question": "What is the minimum Snowflake edition that supports multi-cluster virtual warehouses?", "answers": ["Enterprise", "Standard", "Business Critical", "Virtual Private Snowflake"], "explanation": "The Enterprise edition has several additional capabilities not provided in the Standard edition. These include multi-cluster virtual warehouses, column-level masking, row access policies, materialized views, and search optimization.\n  \n  \n https://docs.snowflake.com/en/user-guide/intro-editions.html"}, "correct_response": ["a"], "section": "Licensing & Features", "question_plain": "What is the minimum Snowflake edition that supports multi-cluster virtual warehouses?", "related_lectures": []}, {"_class": "assessment", "id": 70866744, "assessment_type": "multiple-choice", "prompt": {"question": "What is the minimum Snowflake edition that supports dedicated compute resources?", "answers": ["Virtual Private Snowflake", "Enterprise", "Business Critical", "Standard"], "explanation": "The VPS edition is meant to provide isolation from other customers; thus, each instance has its own metadata store and compute resources.\n  \n https://docs.snowflake.com/en/user-guide/intro-editions.html"}, "correct_response": ["a"], "section": "Licensing & Features", "question_plain": "What is the minimum Snowflake edition that supports dedicated compute resources?", "related_lectures": []}, {"_class": "assessment", "id": 70866746, "assessment_type": "multi-select", "prompt": {"question": "Which of the following are Snowflake Business Intelligence partners? Select all that apply.", "answers": ["PowerBI", "Looker", "MicroStrategy", "Tableau", "Oracle"], "explanation": "All of these are Business Intelligence partners of Snowflake. Please see https://docs.Snowflake.com/en/user-guide/ecosystem.html"}, "correct_response": ["a", "b", "c", "d", "e"], "section": "Partners", "question_plain": "Which of the following are Snowflake Business Intelligence partners? Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70866748, "assessment_type": "multi-select", "prompt": {"question": "When processing queries, what types of caches might be used by Snowflake? Select all that apply.", "answers": ["Metadata Cache", "Query Result Cache", "Warehouse Cache", "Memory Cache", "Cloud Cache"], "explanation": "To improve query performance, Snowflake employs a variety of caching techniques. \n When a new query is submitted for execution, Snowflake can immediately provide the query results using either the metadata cache or the query result cache. \n  \n Each virtual warehouse has its own cache, which it constructs over time while executing queries, copying relevant micro-partitions from the cloud storage to the local SSD storage."}, "correct_response": ["a", "b", "c"], "section": "Performance Concepts", "question_plain": "When processing queries, what types of caches might be used by Snowflake? Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70866750, "assessment_type": "multiple-choice", "prompt": {"question": "The query result cache is purged after 24 hours unless which of the following condition is true?", "answers": ["Another query is executed within 24 hours that reuses the query result cache.", "The value for the query result cache purge parameter is set to a different number than 24."], "explanation": "The query result cache for a query has an initial validity period of twenty-four hours. The cache is purged if a new query doesn&#39;t reuse the previously generated cache within 24 hours. If a new query uses the result cache, the validity period for the query result cache is reset to another 24 hours. It is now valid for another 24 hours from when it was reused. This extension of the first query result cache can continue for up to a maximum of 31 days from the point in time when a query result cache was initially produced. After 31 days, the query result cache for a query is purged altogether. \n  \n https://docs.snowflake.com/en/user-guide/querying-persisted-results"}, "correct_response": ["a"], "section": "Performance Concepts", "question_plain": "The query result cache is purged after 24 hours unless which of the following condition is true?", "related_lectures": []}, {"_class": "assessment", "id": 70866752, "assessment_type": "multiple-choice", "prompt": {"question": "True or False. A virtual warehouse cache or the local disk cache is private to the virtual warehouse and can not be shared with other virtual warehouses.", "answers": ["True", "False"], "explanation": "Every time a virtual warehouse accesses data from a table, it caches that data locally. This data cache can improve the performance of subsequent queries if those queries can reuse the data in the cache instead of reading from the table in the cloud storage. \n  \n The warehouse cache is local to a virtual warehouse and can not be shared with other virtual warehouses. \n  \n  \n https://docs.snowflake.com/en/user-guide/warehouses-considerations#how-does-warehouse-caching-impact-queries"}, "correct_response": ["a"], "section": "Performance Concepts", "question_plain": "True or False. A virtual warehouse cache or the local disk cache is private to the virtual warehouse and can not be shared with other virtual warehouses.", "related_lectures": []}, {"_class": "assessment", "id": 70866754, "assessment_type": "multiple-choice", "prompt": {"question": "Automatic Clustering Service is responsible for what activity in Snowflake?", "answers": ["Redistributing data in micro-partitions according to the clustering key.", "Starting and stopping virtual warehouse clusters.", "Managing multi-cluster virtual warehouses.", "Managing synchronization of shared data."], "explanation": "For tables with a clustering key defined, Automatic Clustering, a Snowflake service, manages the re-clustering as needed, distributing data according to the clustering key. Snowflake internally maintains the clustered tables and any resource requirements with Automatic Clustering. Automatic Clustering only adjusts those micro-partitions which benefit from the re-clustering process.\n  \n https://docs.snowflake.com/en/user-guide/tables-auto-reclustering"}, "correct_response": ["a"], "section": "Performance Concepts", "question_plain": "Automatic Clustering Service is responsible for what activity in Snowflake?", "related_lectures": []}, {"_class": "assessment", "id": 70866756, "assessment_type": "multi-select", "prompt": {"question": "What are some general indicators that a clustering key is required on a table? Select all that apply.", "answers": ["The query performance has slowed down over time.", "The size of the table is multi-terabytes.", "The table has a large number of columns."], "explanation": "The following indicators can help determine if a clustering key may be needed.\n  \n \u00b7 The table has large volumes of data (e.g., multiple terabytes)\n \u00b7 Queries on the table are running slower than expected.\n \u00b7 Query performance has gotten worse over time.\n \u00b7 The table has a large clustering depth"}, "correct_response": ["a", "b"], "section": "Performance Concepts", "question_plain": "What are some general indicators that a clustering key is required on a table? Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70866758, "assessment_type": "multiple-choice", "prompt": {"question": "<p><strong>Which of the following illustration represents the most well-clustered table?</strong>&nbsp; &nbsp;</p><p><img src=\"https://img-b.udemycdn.com/redactor/raw/practice_test_question/2023-03-29_20-22-14-7320ec6d16d8ee626bdc5e05de3753f3.png\"></p><p><br></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "For a populated table, the clustering depth is the average depth of overlapping micro-partitions for specific columns. The clustering depth starts at 1 (for a well-clustered table) and can be a larger number.\n If the average depth is smaller, the data for the specified columns are better clustered.\n  \n https://docs.snowflake.com/en/user-guide/tables-clustering-micropartitions#label-clustering-depth", "answers": ["3", "1", "2", "<p>4</p>"]}, "correct_response": ["d"], "section": "Performance Concepts", "question_plain": "Which of the following illustration represents the most well-clustered table?&nbsp; &nbsp;", "related_lectures": []}, {"_class": "assessment", "id": 70866760, "assessment_type": "multiple-choice", "prompt": {"question": "True or False: When defining a clustering key, you should choose columns that have very low cardinality.", "answers": ["False", "True"], "explanation": "When defining clustering keys, the initial candidate clustering columns are those columns that are frequently used in the WHERE clause or other selective filters. \n  \n Additionally, columns that are used for joining can also be considered.\n  \n Furthermore, the columns&#39; cardinality (number of distinct values) is also important. It is crucial to choose a column with a high enough cardinality to allow effective partition pruning while having a low enough cardinality for Snowflake to group data into micro-partitions efficiently. A column with too few distinct values (e.g., gender) will result in minimal partition pruning. On the other hand, a column that has too many distinct values (e.g., customer id) will result in too much overhead when maintaining the partitions.\n  \n When creating a multi-column cluster key, order the columns from the lowest cardinality to the higher cardinality; otherwise, the effectiveness of clustering will be reduced.\n  \n https://docs.snowflake.com/en/user-guide/tables-clustering-keys"}, "correct_response": ["a"], "section": "Performance Concepts", "question_plain": "True or False: When defining a clustering key, you should choose columns that have very low cardinality.", "related_lectures": []}, {"_class": "assessment", "id": 70866762, "assessment_type": "multiple-choice", "prompt": {"question": "True or False: When defining a clustering key for a large table, consider using columns that are used frequently in join statements.", "answers": ["True", "False"], "explanation": "When defining clustering keys, the initial candidate clustering columns are those columns that are frequently used in the WHERE clause or other selective filters. \n  \n Additionally, columns that are used for joining can also be considered.\n  \n Furthermore, the columns&#39; cardinality (number of distinct values) is also important. It is crucial to choose a column with a high enough cardinality to allow effective partition pruning while having a low enough cardinality for Snowflake to group data into micro-partitions efficiently. A column with too few distinct values (e.g., gender) will result in minimal partition pruning. On the other hand, a column that has too many distinct values (e.g., customer id) will result in too much overhead when maintaining the partitions.\n  \n When creating a multi-column cluster key, order the columns from the lowest cardinality to the higher cardinality; otherwise, the effectiveness of clustering will be reduced.\n  \n https://docs.snowflake.com/en/user-guide/tables-clustering-keys"}, "correct_response": ["a"], "section": "Performance Concepts", "question_plain": "True or False: When defining a clustering key for a large table, consider using columns that are used frequently in join statements.", "related_lectures": []}, {"_class": "assessment", "id": 70866764, "assessment_type": "multiple-choice", "prompt": {"question": "A multi-cluster virtual warehouse will dynamically start or stop virtual warehouses in which scaling mode?", "answers": ["Auto Scale", "Maximized", "Scale on Demand", "Scale Fast"], "explanation": "Auto-Scaling mode is enabled by selecting different values for the multi-minimum clusters and maximum warehouse count. As a result, Snowflake starts and stops warehouses dynamically based on the workload needs. When a multi-cluster virtual warehouse using auto-scaling mode starts, the number of active virtual warehouses equals the minimum warehouse count. Snowflake spins up more warehouses according to the need, up to the maximum warehouse count. Snowflake shuts down virtual warehouses as the demand lowers until the number equals the minimum warehouse count.\n  \n https://docs.snowflake.com/en/user-guide/warehouses-multicluster#maximized-vs-auto-scale"}, "correct_response": ["a"], "section": "Performance Concepts", "question_plain": "A multi-cluster virtual warehouse will dynamically start or stop virtual warehouses in which scaling mode?", "related_lectures": []}, {"_class": "assessment", "id": 70866766, "assessment_type": "multiple-choice", "prompt": {"question": "Consider the following scenario. Queries are running on a multi-cluster virtual warehouse of size Large, and the scaling policy is set to Economy. The warehouse is currently executing the maximum number of queries that it can accommodate. What happens when an additional query is run?", "answers": ["The multi-cluster virtual warehouse only adds a new virtual warehouse if the system determines there is enough work to keep it busy for at least 6 minutes.", "The size of the virtual warehouse is scaled up to X-Large.", "An additional virtual warehouse of size Large is added almost immediately to the cluster and runs the additional query.", "The size of the virtual warehouse is scaled up to X-Large."], "explanation": "When the scaling policy is set to Economy, it permits queuing to continue for some time before scaling up, conserving costs at the expense of performance. New virtual warehouses are spun up only if the system determines that the new warehouse has sufficient query burden to keep it busy for at least 6 minutes. \n  \n When scaling down, the system conducts 5 to 6 successive checks to determine whether the workload can be reallocated to other warehouses without the need to spin up another warehouse again. If the criteria are met, the virtual warehouse is scaled-down. These checks are carried out at one-minute intervals.\n  \n https://docs.snowflake.com/en/user-guide/warehouses-multicluster#setting-the-scaling-policy-for-a-multi-cluster-warehouse"}, "correct_response": ["a"], "section": "Performance Concepts", "question_plain": "Consider the following scenario. Queries are running on a multi-cluster virtual warehouse of size Large, and the scaling policy is set to Economy. The warehouse is currently executing the maximum number of queries that it can accommodate. What happens when an additional query is run?", "related_lectures": []}, {"_class": "assessment", "id": 70866768, "assessment_type": "multiple-choice", "prompt": {"question": "Which of the following Scaling Policies prioritizes performance over cost?", "answers": ["Standard", "Economy", "Efficient", "Fast"], "explanation": "With the scaling policy set to Standard, Snowflake prefers to spin up extra virtual warehouses almost as soon as it detects that queries are starting to queue up. The Standard scaling policy aims to prevent or minimize queuing.\n  \n The Economy scaling policy attempts to conserve credits over performance and user experience. It doesn&#39;t spin up more virtual warehouses as soon as queuing is observed but instead applies additional criteria to ascertain whether or not to spin up new virtual warehouses.\n  \n https://docs.snowflake.com/en/user-guide/warehouses-multicluster#setting-the-scaling-policy-for-a-multi-cluster-warehouse"}, "correct_response": ["a"], "section": "Performance Concepts", "question_plain": "Which of the following Scaling Policies prioritizes performance over cost?", "related_lectures": []}, {"_class": "assessment", "id": 70866770, "assessment_type": "multiple-choice", "prompt": {"question": "What is the term used when Snowflake eliminates some partitions from the scanning process while executing a query?", "answers": ["Partition Pruning", "Partition Indexing", "Table Scan", "In Memory Operations"], "explanation": "The metadata in Snowflake allows the Snowflake query engine to eliminate partitions to optimize query execution. For example, if the query specifies a WHERE condition, partitions NOT containing the value matching that condition will NOT be scanned.\n  \n https://docs.snowflake.com/en/user-guide/tables-clustering-micropartitions#query-pruning"}, "correct_response": ["a"], "section": "Performance Concepts", "question_plain": "What is the term used when Snowflake eliminates some partitions from the scanning process while executing a query?", "related_lectures": []}, {"_class": "assessment", "id": 70866772, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>Consider the following snippet from the query profile of a finished query.&nbsp; &nbsp; &nbsp;</strong></p><img src=\"https://img-b.udemycdn.com/redactor/raw/practice_test_question/2023-03-29_20-20-21-9814f45dbfdd8e916eb3fc0e641b7005.png\"><p>\n&nbsp; \n<strong> Which of the following accurately describes the highlighted statistics?</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "Partition pruning occurs when the number of Partitions scanned is much smaller than Partitions total.\n  \n Snowflake saves data on the warehouse&#39;s local disk and sometimes remote cloud storage if it can&#39;t fit an operation into memory. Data spilling slows down queries because it requires more IO operations, and disk access is slower than memory access.\n  \n https://docs.snowflake.com/en/user-guide/ui-query-profile", "answers": ["The query profile indicates effective partition pruning.", "The query profile indicates that the virtual warehouse used is too small for the query.", "The query profile indicates that the virtual warehouse cache was used.", "The query profile indicates ineffective partition pruning."]}, "correct_response": ["a", "b", "c"], "section": "Performance Concepts", "question_plain": "Consider the following snippet from the query profile of a finished query.&nbsp; &nbsp; &nbsp;\n&nbsp; \n Which of the following accurately describes the highlighted statistics?", "related_lectures": []}, {"_class": "assessment", "id": 70866774, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>Consider the following snippet from the query profile of a finished query. </strong>\n&nbsp; \n</p><img src=\"https://img-b.udemycdn.com/redactor/raw/practice_test_question/2023-03-29_20-20-56-763deb51e6d146b28b5383c067b2f8d2.png\"><p>\n&nbsp; \n<strong> Which of the following accurately describes the highlighted statistics? </strong></p><p><strong>Select all that apply.</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "Snowflake saves data on the warehouse&#39;s local disk if it can&#39;t fit an operation into memory. Data spilling slows down queries because it requires more IO operations, and disk access is slower than memory access. &quot;Bytes spilled to local storage.&quot; indicates local spillage.\n  \n Snowflake will spill data to remote cloud storage if the local disk becomes full, which is even slower storage than the local disk, making this operation even slower. &quot;Bytes spilled to remote storage&quot; in the query profile indicates remote spillage.\n  \n If the partitions scanned equal the partition total, the query scanned the complete table. Therefore, no partition pruning happened, and the clustering key should be improved.\n  \n  \n https://docs.snowflake.com/en/user-guide/ui-query-profile#queries-too-large-to-fit-in-memory", "answers": ["The query profile indicates that the query is too large to fit in the virtual warehouse memory.", "The query profile indicates ineffective partition pruning.", "The query profile indicates that the metadata cache was used.", "The query profile indicates that the query result cache was used."]}, "correct_response": ["a", "b"], "section": "Performance Concepts", "question_plain": "Consider the following snippet from the query profile of a finished query. \n&nbsp; \n\n&nbsp; \n Which of the following accurately describes the highlighted statistics? Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70866776, "assessment_type": "multi-select", "prompt": {"question": "Which of the following statements correctly describe Search Optimization in Snowflake? Select all that apply.", "answers": ["The search optimization service in Snowflake is similar to the secondary index concept in typical databases.", "The search optimization service can significantly enhance the performance of some lookup and analytical queries that use many predicates for filtering.", "The search optimization service is like materialized view functionality."], "explanation": "The search optimization service can significantly enhance the performance of some lookup and analytical queries that use many predicates for filtering.\n The search optimization service uses a persistent data structure as an optimized search access path to speed up point lookups.\n  \n When you enable search optimization for a table, the maintenance service creates the search access path and populates it with the data required for lookups. Depending on the size of the table, the process of populating the search optimization data can take some time. The search optimization service performs this update in the background, so it does not interfere with other actions on the table. \n  \n https://docs.snowflake.com/en/user-guide/search-optimization-service"}, "correct_response": ["a", "b"], "section": "Performance Concepts", "question_plain": "Which of the following statements correctly describe Search Optimization in Snowflake? Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70866778, "assessment_type": "multiple-choice", "prompt": {"question": "For which of the following scenarios scaling up a virtual warehouse is a good option?", "answers": ["The virtual warehouse is executing complex queries and processing large volumes of data.", "There are more active concurrent queries than the current virtual warehouse can handle.", "A query is accessing more than 5 tables.", "The query is accessing an external table."], "explanation": "Based on the complexity of the queries and the desired performance, a virtual warehouse can be scaled up or down. In general, increasing the virtual warehouse size improves query speed for CPU-intensive queries.\n  \n  On the other hand, scaling up is ineffective when dealing with a high number of concurrent users or queries. A multi-cluster virtual warehouse (scaling out) accommodates an increased number of concurrent users and queries.\n  \n https://docs.snowflake.com/en/user-guide/warehouses-considerations"}, "correct_response": ["a"], "section": "Performance Concepts", "question_plain": "For which of the following scenarios scaling up a virtual warehouse is a good option?", "related_lectures": []}, {"_class": "assessment", "id": 70866780, "assessment_type": "multiple-choice", "prompt": {"question": "The key pair authentication mechanism consists of which of the following? Select one.", "answers": ["A private key and public key, with the public key allocated to a user and the private key used for authentication.", "A 2nd factor of authentication provided through a mobile app.", "A 2nd factor of authentication provided through a paired blue tooth device.", "A physical key that provides a code every 90 seconds."], "explanation": "Snowflake provides an additional layer of security by supporting key pair authentication in addition to the standard username/password login. This approach comprises private and public keys, with the public key allocated to a user and the private key used for authentication. The user provides a public key during authentication. A user can have up to two public keys, which can be rotated at any point in time. Key pair authentication is supported by all SnowSQL and Snowflake drivers and connectors. All Snowflake editions support Key-pair authentication\n  \n https://docs.snowflake.com/en/user-guide/key-pair-auth"}, "correct_response": ["a"], "section": "Security", "question_plain": "The key pair authentication mechanism consists of which of the following? Select one.", "related_lectures": []}, {"_class": "assessment", "id": 70866782, "assessment_type": "multiple-choice", "prompt": {"question": "True or False: When a new user is created, the user is automatically enrolled in multi-factor authentication (MFA).", "answers": ["False", "True"], "explanation": "Multi-factor authentication (MFA) is enabled by default for all Snowflake accounts, and any Snowflake user can enroll themselves in MFA through the Snowflake web interface. Although multi-factor is enabled for all accounts and all users, new users are not automatically enrolled in MFA. Instead, a user must initiate and complete the MFA enrolment process themselves. \n  \n https://docs.snowflake.com/en/user-guide/security-mfa"}, "correct_response": ["a"], "section": "Security", "question_plain": "True or False: When a new user is created, the user is automatically enrolled in multi-factor authentication (MFA).", "related_lectures": []}, {"_class": "assessment", "id": 70866784, "assessment_type": "multiple-choice", "prompt": {"question": "True or False: Snowflake supports SCIM 2.0 and is compatible with Okta and Azure Active Directory.", "answers": ["True", "False"], "explanation": "Snowflake supports SCIM 2.0 and is compatible with Okta and Azure Active Directory.\n  \n SCIM is an open standard that provides automatic user provisioning and role synchronization based on identity provider information. When a new user is created in the identity provider, the SCIM automatically provisions the user in Snowflake. Additionally, SCIM can sync groups defined in an identity provider with Snowflake roles.\n  \n https://docs.snowflake.com/en/user-guide/scim"}, "correct_response": ["a"], "section": "Security", "question_plain": "True or False: Snowflake supports SCIM 2.0 and is compatible with Okta and Azure Active Directory.", "related_lectures": []}, {"_class": "assessment", "id": 70866786, "assessment_type": "multiple-choice", "prompt": {"question": "External Tokenization provides what sort of security in Snowflake?", "answers": ["Column-level security", "Row-level security", "Object Security", "Database-level security"], "explanation": "Snowflake supports masking policies that may be applied to columns and enforced at the column level to provide column-level security. Column-level security is achieved by dynamic data masking or external Tokenization.\n  \n https://docs.snowflake.com/en/user-guide/security-column"}, "correct_response": ["a"], "section": "Security", "question_plain": "External Tokenization provides what sort of security in Snowflake?", "related_lectures": []}, {"_class": "assessment", "id": 70866788, "assessment_type": "multiple-choice", "prompt": {"question": "True or False: Snowflake stores all data at rest unencrypted unless configured by the customer.", "answers": ["False", "True"], "explanation": "In Snowflake, all data at rest is encrypted using AES 256-bit encryption.\n  \n https://docs.snowflake.com/en/user-guide/security-encryption-manage"}, "correct_response": ["a"], "section": "Security", "question_plain": "True or False: Snowflake stores all data at rest unencrypted unless configured by the customer.", "related_lectures": []}, {"_class": "assessment", "id": 70866790, "assessment_type": "multiple-choice", "prompt": {"question": "True or False: Snowflake encrypts all data in transit end to end using TLS 1.2.", "answers": ["True", "False"], "explanation": "Snowflake encrypts all data in transit using Transport Layer Security (TLS) 1.2. This applies to all Snowflake connections, including those made through the Snowflake Web interface, JDBC, ODBC, and the Python connector.\n  \n https://docs.snowflake.com/en/user-guide/security-encryption-end-to-end"}, "correct_response": ["a"], "section": "Security", "question_plain": "True or False: Snowflake encrypts all data in transit end to end using TLS 1.2.", "related_lectures": []}, {"_class": "assessment", "id": 70866792, "assessment_type": "multiple-choice", "prompt": {"question": "Which of the following is the most powerful role in a Snowflake account?", "answers": ["ACCOUNTADMIN", "SECURITYADMIN", "PUBLIC", "SYSADMIN"], "explanation": "ACCOUNTADMIN is the most powerful role in a Snowflake account. Access to the ACCOUNTADMIN role should be managed carefully. Any user with the ACCOUNTADMIN role should have MFA enabled to ensure it is not easy to compromise their account. \n  \n https://docs.snowflake.com/en/user-guide/security-access-control-overview#system-defined-roles."}, "correct_response": ["a"], "section": "Security", "question_plain": "Which of the following is the most powerful role in a Snowflake account?", "related_lectures": []}, {"_class": "assessment", "id": 70866794, "assessment_type": "multiple-choice", "prompt": {"question": "The privileges provided by the SYSADMIN &amp; SECURITYADMIN role are automatically contained in the ACCOUNTADMIN role since the ACCOUNTADMIN role sits at the top of the role hierarchy.", "answers": ["True", "False"], "explanation": "ACCOUNTADMIN is the most powerful role in a Snowflake account. Due to the role hierarchy and privileges inheritance, the ACCOUNTADMIN inherits all the privileges that SECURITYADMIN &amp; USERAMDIN has.\n  \n https://docs.snowflake.com/en/user-guide/security-access-control-overview#system-defined-roles."}, "correct_response": ["a"], "section": "Security", "question_plain": "The privileges provided by the SYSADMIN &amp; SECURITYADMIN role are automatically contained in the ACCOUNTADMIN role since the ACCOUNTADMIN role sits at the top of the role hierarchy.", "related_lectures": []}, {"_class": "assessment", "id": 70866796, "assessment_type": "multi-select", "prompt": {"question": "Which of the following statements is true regarding the USERADMIN role? Select all that apply.", "answers": ["A user with the USERADMIN role can create new users.", "A user with the USERADMIN role can create new roles.", "A user with the USERADMIN role can manage object grants.", "A user with the USERADMIN role can manage the whole account."], "explanation": "The USERADMIN role allows you to create USERS and ROLES for your organization. USERADMIN role doesn&#39;t allow managing object grants or managing the account. \n  \n https://docs.snowflake.com/en/user-guide/security-access-control-overview#system-defined-roles."}, "correct_response": ["a", "b"], "section": "Security", "question_plain": "Which of the following statements is true regarding the USERADMIN role? Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70866798, "assessment_type": "multi-select", "prompt": {"question": "The compute cost for a virtual warehouse is determined based on which of the following. Select all that apply.", "answers": ["The size of the virtual warehouse.", "The duration for which the virtual warehouse was running.", "The number of queries executed by the virtual warehouse.", "The number of users serviced by the virtual warehouse."], "explanation": "Virtual warehouses in a resumed (active) state contribute to the costs. The cost incurred is directly proportional to the size of the virtual warehouse. For example, a larger virtual warehouse running for the same time as a smaller virtual warehouse will cost more.\n  \n The number of queries and users does not impact the virtual warehouse cost. (However, in the case of a multicluster virtual warehouse, a higher user/query concurrency might spin up additional virtual warehouses that add to the costs).\n  \n  \n https://docs.snowflake.com/en/user-guide/cost-understanding-compute"}, "correct_response": ["a", "b"], "section": "Cost & Pricing", "question_plain": "The compute cost for a virtual warehouse is determined based on which of the following. Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70866800, "assessment_type": "multiple-choice", "prompt": {"question": "True or False: Snowflake provides connectors and drivers for various languages and frameworks.", "answers": ["True", "False"], "explanation": "Snowflake has several drivers and connectors that can be used to connect to your Snowflake instance. These include client tools made by Snowflake, like the web interface and the SnowSQL command-line interface, and drivers and connectors that let different languages and frameworks connect to Snowflake."}, "correct_response": ["a"], "section": "Tools & Interfaces", "question_plain": "True or False: Snowflake provides connectors and drivers for various languages and frameworks.", "related_lectures": []}, {"_class": "assessment", "id": 70866802, "assessment_type": "multiple-choice", "prompt": {"question": "Which of the following is a web-based interface to Snowflake?", "answers": ["Snowsight", "SnowCD", "Snowpipe", "SnowSQL"], "explanation": "Snowsight is a modern and lightweight web interface using new technologies and is a primary method of interacting with your Snowflake instance. \n  \n https://docs.snowflake.com/en/user-guide/snowsql"}, "correct_response": ["a"], "section": "Tools & Interfaces", "question_plain": "Which of the following is a web-based interface to Snowflake?", "related_lectures": []}, {"_class": "assessment", "id": 70866804, "assessment_type": "multi-select", "prompt": {"question": "SnowSQL is available for which of the following operating systems?", "answers": ["Windows", "Linux", "macOS", "Android"], "explanation": "SnowSQL connects to Snowflake through the command line and executes SQL queries on your Snowflake instance. SnowSQL is available for Linux, Windows, and Mac OS.\n  \n https://docs.snowflake.com/en/user-guide/snowsql"}, "correct_response": ["a", "b", "c"], "section": "Tools & Interfaces", "question_plain": "SnowSQL is available for which of the following operating systems?", "related_lectures": []}, {"_class": "assessment", "id": 70866806, "assessment_type": "multiple-choice", "prompt": {"question": "<p><strong>True/False:When a table is cloned, a snapshot of the source table's data is taken and represents the state of the source data. The cloned table is based on the snapshot of the data at the time of cloning.</strong></p>", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "Cloning is a metadata operation in which no actual copying of the data occurs. A snapshot of the data in the object being cloned is captured and made available in the cloned object. The cloned table&#39;s metadata references the existing micro-partitions at the time of the snapshot.\n  \n https://docs.snowflake.com/en/user-guide/tables-storage-considerations#label-cloning-tables", "answers": ["True", "False"]}, "correct_response": ["a"], "section": "Cloning", "question_plain": "True/False:When a table is cloned, a snapshot of the source table's data is taken and represents the state of the source data. The cloned table is based on the snapshot of the data at the time of cloning.", "related_lectures": []}, {"_class": "assessment", "id": 70866808, "assessment_type": "multiple-choice", "prompt": {"question": "True or False: The data is physically copied into new micro-partitions during a clone operation.", "answers": ["False", "True"], "explanation": "The zero-copy cloning capability of Snowflake enables users to create clones of tables, schemas, and databases without physically copying the data. Cloning does not require additional storage space, and because cloning does not physically replicate data, it is far faster than the physical copying of data. Micro-partitions and metadata enable rapid and efficient zero-copy cloning because the cloned table&#39;s metadata references the existing micro-partitions.\n  \n https://docs.snowflake.com/en/user-guide/tables-storage-considerations#label-cloning-tables"}, "correct_response": ["a"], "section": "Cloning", "question_plain": "True or False: The data is physically copied into new micro-partitions during a clone operation.", "related_lectures": []}, {"_class": "assessment", "id": 70866810, "assessment_type": "multi-select", "prompt": {"question": "When a database or a schema is cloned, which of the following statements are valid for stages in that database?", "answers": ["External stages are cloned.", "Table stages are cloned", "Named internal stages are NOT cloned", "External stages are NOT cloned", "Named internal stages are cloned"], "explanation": "Named Internal Stages cannot be cloned. When a database or schema is cloned, any Snowpipe that points to a Named Internal Stage is not cloned. \n Named External Stages can be cloned. Since a table stage is associated with a table, it is automatically cloned when the table is cloned.\n  \n https://docs.snowflake.com/en/user-guide/object-clone"}, "correct_response": ["a", "b", "c"], "section": "Cloning", "question_plain": "When a database or a schema is cloned, which of the following statements are valid for stages in that database?", "related_lectures": []}, {"_class": "assessment", "id": 70866812, "assessment_type": "multi-select", "prompt": {"question": "When a database is cloned, which objects inherit the corresponding source privileges?\n Select all that apply.", "answers": ["Schemas contained in the database.", "Tables contained in the database.", "Views contained in the database.", "The cloned database itself."], "explanation": "A cloned object does not inherit any privileges from its source object; for instance, a cloned table does not inherit any privileges from its source table. However, if a database or schema is cloned, privileges are inherited by the child objects.\n  \n https://docs.snowflake.com/en/user-guide/object-clone#access-control-privileges-for-cloned-objects"}, "correct_response": ["a", "b", "c"], "section": "Cloning", "question_plain": "When a database is cloned, which objects inherit the corresponding source privileges?\n Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70866814, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>Creating a materialized view will prove beneficial for which of the following scenarios? Select all that apply.</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>Materialized views can be helpful if a query or slight variation is executed frequently.</p><p>The executed queries are complex and take time and resources; a materialized view can pre-compute the results and speed up the processing.</p><p><br></p><p>Materialized views can be created on an external table to improve performance. These materialized views must either be refreshed manually or through a notification system.</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/views-materialized</p>", "answers": ["<p><strong>Different business users execute frequent and similar complex queries accessing the same table.</strong></p>", "<p><strong>Speeding up queries that access a subset of data from an external table is required.</strong></p>", "<p><strong>There is a requirement to return different rows to different users based on their roles.</strong></p>", "<p><strong>There is a requirement to speed up the data ingestion processes.</strong></p>"]}, "correct_response": ["a", "b"], "section": "Performance Concepts", "question_plain": "Creating a materialized view will prove beneficial for which of the following scenarios? Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70866816, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>Consider the CUSTOMER table in the SNOWFLAKE_SAMPLE_DATA.TPCH_SF1 schema. Which of the following queries do NOT require an active virtual warehouse? Select all that apply.</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p>Statistics are kept in the metadata cache in the cloud services layer for each table, micro-partition, and column. The metadata cache can return results if the query simply counts the number of rows.</p><p><br></p><p>Similarly, the cloud services layer can provide table definitions (i.e., DESCRIBE) and a list of tables in a schema (i.e., SHOW TABLES LIKE).</p><p><br></p><p>Metadata cache or cloud services operations do not require an active virtual warehouse.</p>", "answers": ["<p><strong>SELECT COUNT(*) FROM SNOWFLAKE_SAMPLE_DATA.TPCH_SF1.CUSTOMER;</strong></p>", "<p><strong>USE SNOWFLAKE_SAMPLE_DATA.TPCH_SF1;</strong></p><p><strong>SHOW TABLES LIKE '%CUSTOMER%';</strong></p>", "<p><strong>DESCRIBE TABLE SNOWFLAKE_SAMPLE_DATA.TPCH_SF1.CUSTOMER;</strong></p>", "<p><strong>SELECT C_MKTSEGMENT,SUM(C_ACCTBAL) FROM SNOWFLAKE_SAMPLE_DATA.TPCH_SF1.CUSTOMER GROUP BY C_MKTSEGMENT;</strong></p>", "<p><strong>SELECT * FROM SNOWFLAKE_SAMPLE_DATA.TPCH_SF1.CUSTOMER</strong></p>"]}, "correct_response": ["a", "b", "c"], "section": "Architecture", "question_plain": "Consider the CUSTOMER table in the SNOWFLAKE_SAMPLE_DATA.TPCH_SF1 schema. Which of the following queries do NOT require an active virtual warehouse? Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70866818, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>Which of the following correctly describes the behaviour when a Temporary table is attempted to be cloned?</strong></p><p><br></p><p><strong>Select two answers.</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>Temporary tables can NOT be cloned to a permanent table.</p><p>Doing so will typically show the following error \u201cTemp table cannot be cloned to a permanent table; clone to a transient table instead.\u201d</p><p>However, a temporary table may be cloned to a transient table or another temporary table.</p>", "answers": ["<p><strong>Temporary tables can be cloned to transient tables.</strong></p>", "<p><strong>Temporary tables can be cloned to temporary tables.</strong></p>", "<p><strong>Temporary tables can be cloned to permanent tables.</strong></p>", "<p><strong>Temporary tables can be cloned to external tables.</strong></p>"]}, "correct_response": ["a", "b"], "section": "Cloning", "question_plain": "Which of the following correctly describes the behaviour when a Temporary table is attempted to be cloned?Select two answers.", "related_lectures": []}, {"_class": "assessment", "id": 70866820, "assessment_type": "multiple-choice", "prompt": {"question": "<p><strong>You are an account administrator tasked with creating a trial account with one of Snowflake's data integration partners. What should you do to create this trial account?</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>Partner Connect makes it easy to set up trial accounts with some of Snowflake's business partners and link them to Snowflake. This feature makes testing out different third-party tools and services easy.</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/ecosystem-partner-connect</p>", "answers": ["<p><strong>Use Partner Connect to initiate the trial.</strong></p>", "<p><strong>Go to the partner's website to download and install the trial account.</strong></p>", "<p><strong>Raise a support ticket with Snowflake.</strong></p>", "<p><strong>Raise a support ticket with the partner.</strong></p>"]}, "correct_response": ["a"], "section": "Partners", "question_plain": "You are an account administrator tasked with creating a trial account with one of Snowflake's data integration partners. What should you do to create this trial account?", "related_lectures": []}, {"_class": "assessment", "id": 70866822, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>A Snowflake system administrator is creating a new virtual warehouse for loading eight files of size 1GB each. The virtual warehouse will be dedicated to loading data on a daily basis. How should they configure the virtual warehouse? </strong></p><p><strong>Select all that apply.</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p>Unless you are loading a large number of files in parallel, a larger virtual warehouse size will not provide any benefits. A Small or X-Small virtual warehouse should suffice for small, infrequently loaded files.</p><p><br></p><p>Configuring the virtual warehouse to auto-suspend and auto-resume in this scenario is helpful as it will conserve credits once the data loading is complete.</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/data-load-considerations-plan</p>", "answers": ["<p><strong>Choose X-Small or Small as the size for the virtual warehouse</strong></p>", "<p><strong>Configure the virtual warehouse to auto-suspend &amp; auto-resume.</strong></p>", "<p><strong>Create a multi-cluster virtual warehouse.</strong></p>", "<p><strong>Contact Snowflake to get help with determining the right size for your organization.</strong></p>", "<p><strong>Choose 5X-large as the size for the virtual warehouse.</strong></p>"]}, "correct_response": ["a", "b"], "section": "Performance Concepts", "question_plain": "A Snowflake system administrator is creating a new virtual warehouse for loading eight files of size 1GB each. The virtual warehouse will be dedicated to loading data on a daily basis. How should they configure the virtual warehouse? Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70866824, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>Which of the following two layers are replicated by Snowflake to ensure high availability?</strong></p><p><strong>Select all that apply.</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p>Snowflake automatically replicates the cloud services layer &amp; the storage layer across three availability zones. The storage layer, which uses cloud providers' blob stores, is replicated synchronously across multiple disk devices and at least three availability zones, transparent to the users.</p><p><br></p><p>Similarly, the cloud services layer, primarily composed of the metadata storage system, is deployed, and replicated across 3 availability zones.</p><p><br></p><p>The compute layer, i.e., the virtual warehouses, is not replicated, although Snowflake can spin up compute instances in a different availability zone if required.</p><p><br></p><p>https://developers.snowflake.com/wp-content/uploads/2021/06/Snowflake-High-Availability-for-Data-Apps-Whitepaper.pdf</p>", "answers": ["<p><strong>Cloud Services Layer</strong></p>", "<p><strong>Storage Layer</strong></p>", "<p><strong>Compute Layer</strong></p>", "<p><strong>On-Premises storage</strong></p>", "<p><strong>Partner Layer</strong></p>"]}, "correct_response": ["a", "b"], "section": "Architecture", "question_plain": "Which of the following two layers are replicated by Snowflake to ensure high availability?Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70866826, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>ACCOUNTADMIN inherits the privileges of which of the following roles?</strong></p><p><strong>Select all that apply.</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>Due to the role hierarchy and privileges inheritance, the ACCOUNTADMIN has all the privileges that SECURITYADMIN, USERAMDIN, and SYSADMIN have.</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/security-access-control-overview#system-defined-roles.</p>", "answers": ["<p><strong>SYSADMIN</strong></p>", "<p><strong>SECURITYADMIN</strong></p>", "<p><strong>ORGADMIN</strong></p>", "<p><strong>SUPERADMIN</strong></p>"]}, "correct_response": ["a", "b"], "section": "Security", "question_plain": "ACCOUNTADMIN inherits the privileges of which of the following roles?Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70866828, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>Which of the following contributes towards the storage costs in Snowflake?</strong></p><p><strong>Select all that apply.</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p>Data stored in permanent tables counts towards the storage costs.</p><p>Data stored in temporary &amp; transient tables also contribute towards the storage costs until they are dropped or data is cleared.</p><p><br></p><p>Data in Fail-safe storage &amp; Time Travel storage also contribute to the storage costs.</p><p><br>Transient and temporary tables, however, do not contribute towards Fail-safe storage costs and have a maximum of 1-day Time Travel costs.</p><p><br></p><p>Caching is NOT considered for determining storage costs.</p><p>The query result cache &amp; metadata cache are part of the cloud services layer.</p><p><br></p><p>The warehouse cache (local disk cache) is part of a virtual warehouse and does NOT contribute to storage costs.</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/cost-understanding-overall</p>", "answers": ["<p><strong>Time Travel Storage</strong></p>", "<p><strong>Fail-Safe Storage</strong></p>", "<p><strong>Permanent Table Storage</strong></p>", "<p><strong>Cached Results</strong></p>", "<p><strong>Metadata</strong></p>"]}, "correct_response": ["a", "b", "c"], "section": "Cost & Pricing", "question_plain": "Which of the following contributes towards the storage costs in Snowflake?Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70866830, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>Which of the following is correct regarding a directory table?</strong></p><p><strong>Select all that apply.</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>Directory tables store and present a catalog of files available in an internal or external stage. You can query the directory table associated with a stage to get a list of file URLs that can be used to access the files in the stage object. The query returns the Snowflake-hosted file URL to each file in the stage. The directory table provides other metadata as well.</p><p><br></p><p>Directory tables do not physically store data; therefore, they do not act like ordinary tables, which can be clustered.</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/data-load-dirtables</p>", "answers": ["<p><strong>A directory table provides a catalog of files staged in a Stage object.</strong></p>", "<p><strong>You can query a directory table to obtain File URLs for each file in a Stage.</strong></p>", "<p><strong>Directory tables store CSV data in a VARIANT column.</strong></p>", "<p><strong>Clustering keys can be defined on directory tables.</strong></p>"]}, "correct_response": ["a", "b"], "section": "Data Transformation", "question_plain": "Which of the following is correct regarding a directory table?Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70866832, "assessment_type": "multiple-choice", "prompt": {"question": "<p><strong>True or False: Querying a directory table provides a File URL for each file in the corresponding stage. The URL is valid for 90 days.</strong></p>", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "<p>The File URL provided by a directory table is a long-term URL and doesn't expire.</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/data-load-dirtables-intro#what-are-directory-tables</p>", "answers": ["<p><strong>False</strong></p><p><br></p>", "<p><strong>True</strong></p>"]}, "correct_response": ["a"], "section": "Data Transformation", "question_plain": "True or False: Querying a directory table provides a File URL for each file in the corresponding stage. The URL is valid for 90 days.", "related_lectures": []}, {"_class": "assessment", "id": 70866834, "assessment_type": "multiple-choice", "prompt": {"question": "<p><strong>Which of the following URL types enables access to a file without requiring authorization?</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", ""], "explanation": "<p>A pre-signed URL is a simple HTTPS URL for accessing a file using a web browser. A pre-signed URL is generated using a pre-signed access token. Users can temporarily access a file via a pre-signed URL without authorization. The expiry duration of a pre-signed URL is configurable and can be set to the required duration.</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/unstructured-intro#types-of-urls-available-to-access-files</p>", "answers": ["<p><strong>Pre-signed URL</strong></p>", "<p><strong>Scoped URL</strong></p>", "<p><strong>File URL</strong></p>"]}, "correct_response": ["a"], "section": "Data Transformation", "question_plain": "Which of the following URL types enables access to a file without requiring authorization?", "related_lectures": []}, {"_class": "assessment", "id": 70866836, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>Which of the following views can be used to view the last 365 days of loading history for data loaded through the COPY command?</strong></p><p><br></p><p><strong>Select two answers.</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>The COPY_HISTORY view and the LOAD_HISTORY view in the ACCOUNT_USAGE schema provide the history of data loading performed through the COPY command.</p><p><br></p><p>https://docs.snowflake.com/en/sql-reference/account-usage/load_history</p><p><br></p><p>https://docs.snowflake.com/en/sql-reference/account-usage/copy_history</p>", "answers": ["<p><strong>ACCOUNT_USAGE.COPY_HISTORY</strong></p>", "<p><strong>ACCOUNT_USAGE.LOAD_HISTORY</strong></p>", "<p><strong>INFORMATION_SCHEMA.QUERY_HISTORY</strong></p>", "<p><strong>ACCOUNT_USAGE.PIPE_USAGE_HISTORY</strong></p>"]}, "correct_response": ["a", "b"], "section": "Account Usage & Monitoring", "question_plain": "Which of the following views can be used to view the last 365 days of loading history for data loaded through the COPY command?Select two answers.", "related_lectures": []}, {"_class": "assessment", "id": 70866838, "assessment_type": "multiple-choice", "prompt": {"question": "<p><strong>Which of the following ACCOUNT_USAGE view can be used to view the storage consumed by a database?</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>The DATABASE_STORAGE_USAGE_HISTORY view in the ACCOUNT_USAGE schema shows the number of bytes of database storage used by each database.</p><p>https://docs.snowflake.com/en/sql-reference/account-usage/database_storage_usage_history</p><p><br></p><p>The DATABASES view provides information on each database but doesn't show the size consumed.</p><p>https://docs.snowflake.com/en/sql-reference/account-usage/databases</p>", "answers": ["<p><strong>ACCOUNT_USAGE. DATABASE_STORAGE_USAGE_HISTORY</strong></p>", "<p><strong>ACCOUNT_USAGE.DATABASES</strong></p>", "<p><strong>ACCOUNT_USAGE.TAGS</strong></p>", "<p><strong>ACCOUNT_USAGE.SESSIONS</strong></p>"]}, "correct_response": ["a"], "section": "Account Usage & Monitoring", "question_plain": "Which of the following ACCOUNT_USAGE view can be used to view the storage consumed by a database?", "related_lectures": []}, {"_class": "assessment", "id": 70866840, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>Which type of queries will see a performance improvement from Search Optimization?</strong></p><p><br></p><p><strong>Select two answers.</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>The search optimization service can be used to improve the performance of point lookup queries that return only one or a few rows, using highly selective filters using equality predicates or IN predicates.</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/search-optimization-service#understanding-the-search-optimization-service</p>", "answers": ["<p><strong>Queries that use equality predicate</strong></p>", "<p><strong>Queries that use IN predicate</strong></p>", "<p><strong>Queries that read the entire table</strong></p>", "<p><strong>Queries that use windowing functions</strong></p>"]}, "correct_response": ["a", "b"], "section": "Performance Concepts", "question_plain": "Which type of queries will see a performance improvement from Search Optimization?Select two answers.", "related_lectures": []}, {"_class": "assessment", "id": 70866842, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>A materialized view will be beneficial for which of the following scenarios?</strong></p><p><br></p><p><strong>Select all that apply.</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p>Materialized views can be helpful if a query or slight variation is executed frequently.</p><p>The executed queries are complex and take time and resources; a materialized view can pre-compute the results and speed up the processing.</p><p><br></p><p>The query result is consistent and does not change frequently. This indicates that the data underlying the query doesn\u2019t change too frequently. If it did change frequently, then the resources &amp; compute required to keep the materialized view up-to-date will outweigh the benefit the view provides.</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/views-materialized</p>", "answers": ["<p><strong>The query consumes a large number of compute credits on each execution.</strong></p>", "<p><strong>The data processed by the query does not change often.</strong></p>", "<p><strong>The data in the base table is updated frequently.</strong></p>", "<p><strong>The query cost is very low.</strong></p>", "<p><strong>The query consumes a negligible number of compute credits on each execution.</strong></p>"]}, "correct_response": ["a", "b"], "section": "Performance Concepts", "question_plain": "A materialized view will be beneficial for which of the following scenarios?Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70866844, "assessment_type": "multiple-choice", "prompt": {"question": "<p><strong>What is required to alter the property MINS_TO_BYPASS_NETWORK_POLICY for a user?</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>Only Snowflake support can set the value for the MINS_TO_BYPASS_NETWORK_POLICY property for a user.</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/network-policies#bypassing-a-network-policy</p>", "answers": ["<p><strong>Contact Snowflake Support</strong></p>", "<p><strong>Use USERADMIN role</strong></p>", "<p><strong>Use SYSADMIN role</strong></p>", "<p><strong>Use SECURITYADMIN role</strong></p>"]}, "correct_response": ["a"], "section": "Security", "question_plain": "What is required to alter the property MINS_TO_BYPASS_NETWORK_POLICY for a user?", "related_lectures": []}, {"_class": "assessment", "id": 70866846, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>Which of the following actions can be performed by an ORGADMIN?</strong></p><p><br></p><p><strong>Select two.</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>The ORGADMIN role performs organization-specific tasks like listing all accounts and creating new ones. ORGADMIN can also delete accounts if required.</p><p><br></p><p>However, they can not see the data inside an account; e.g., they can NOT select or change data from a table.</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/organizations#orgadmin-role</p><p>https://docs.snowflake.com/en/user-guide/organizations-manage-accounts-delete</p>", "answers": ["<p><strong>Create a new account for an organization.</strong></p>", "<p><strong>View usage information for all accounts under the organization.</strong></p>", "<p><strong>Select data in any tables in any account.</strong></p>", "<p><strong>Update data in any table in any account.</strong></p>"]}, "correct_response": ["a", "b"], "section": "Security", "question_plain": "Which of the following actions can be performed by an ORGADMIN?Select two.", "related_lectures": []}, {"_class": "assessment", "id": 70866848, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>Which information is displayed in the Statistics box in the Query Profile?</strong></p><p><br></p><p><strong>Select two answers.</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>Please see the link for details.</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/ui-query-profile#statistics</p>", "answers": ["<p><strong>Partition pruning</strong></p>", "<p><strong>Percentage of data read from the local disk cache</strong></p>", "<p><strong>Most expensive nodes</strong></p>", "<p><strong>Operator tree</strong></p>"]}, "correct_response": ["a", "b"], "section": "Performance Concepts", "question_plain": "Which information is displayed in the Statistics box in the Query Profile?Select two answers.", "related_lectures": []}, {"_class": "assessment", "id": 70866850, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>Which of the following can be chosen when creating a new Snowflake account?</strong></p><p><br></p><p><strong>Select two.</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", "", "", ""], "explanation": "<p>Using the CREATE ACCOUNT statement, you can specify the account name, the Snowflake edition, the region (which contains the cloud platform information), the region group, and details about the administrative account, including name, password, email, etc.</p><p><br></p><p>https://docs.snowflake.com/en/sql-reference/sql/create-account</p>", "answers": ["<p><strong>Snowflake Edition</strong></p>", "<p><strong>Region</strong></p>", "<p><strong>Payment Information</strong></p>", "<p><strong>Organization Name</strong></p>", "<p><strong>Account Locator</strong></p>", "<p><strong>Account Locator URL</strong></p>"]}, "correct_response": ["a", "b"], "section": "Performance Concepts", "question_plain": "Which of the following can be chosen when creating a new Snowflake account?Select two.", "related_lectures": []}, {"_class": "assessment", "id": 70866852, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>Which of the following will help reduce query queuing on a virtual warehouse?</strong></p><p><br></p><p><strong>Select two answers.</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p>Queuing can be reduced in a variety of ways.</p><p>1) Consider creating additional virtual warehouses and distributing the query workload if using a standard virtual warehouse.</p><p>2) Convert a standard virtual warehouse to a multi-cluster virtual warehouse</p><p>3) If already using a multi-cluster virtual warehouse, increase the maximum cluster size.</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/performance-query-warehouse-queue#options-for-reducing-queues</p>", "answers": ["<p><strong>Change the virtual warehouse to a multi-cluster virtual warehouse.</strong></p>", "<p><strong>If already using a multi-cluster virtual warehouse, increase the maximum number of clusters.</strong></p>", "<p><strong>Suspend the warehouse often so that its memory is cleared.</strong></p>", "<p><strong>Enable Auto Resume.</strong></p>", "<p><strong>Increase the size of the virtual warehouse.</strong></p>"]}, "correct_response": ["a", "b"], "section": "Performance Concepts", "question_plain": "Which of the following will help reduce query queuing on a virtual warehouse?Select two answers.", "related_lectures": []}]}
4763076
~~~
{"count": 124, "next": null, "previous": null, "results": [{"_class": "assessment", "id": 70942310, "assessment_type": "multiple-choice", "prompt": {"question": "As an administrator, you are required to find all users that logged in to the system during the past 15 minutes. Which of the following options should you use?", "answers": ["Use the table functions provided in the INFORMATION_SCHEMA schema", "Use the views in the ACCOUNT_USAGE schema", "Analyze the system logs to find out who logged in", "Use cloud provider logs to ascertain the users that recently logged in"], "explanation": "Because there is a requirement to see the logins from the last 15 minutes, you must use the INFORMATION_SCHEMA, since it contains near real-time information.\n  \n https://docs.snowflake.com/en/sql-reference/account-usage#differences-between-account-usage-and-information-schema"}, "correct_response": ["a"], "section": "Account Usage & Monitoring", "question_plain": "As an administrator, you are required to find all users that logged in to the system during the past 15 minutes. Which of the following options should you use?", "related_lectures": []}, {"_class": "assessment", "id": 70942312, "assessment_type": "multiple-choice", "prompt": {"question": "What is the range of latency of data in the ACCOUNT_USAGE schema?", "answers": ["45 mins to 3 hours", "No latency", "5 - 10 mins", "5 - 10 days"], "explanation": "The ACCOUNT USAGE schema consists of several views that provide usage metrics and metadata information at the account level.\n  \n Data provided by the ACCOUNT_USAGE views is NOT real-time and refreshes typically with a lag of 45 minutes to 3 hours, depending on the view. \n  \n The data in these views are retained for up to 365 days.\n  \n https://docs.snowflake.com/en/sql-reference/account-usage#differences-between-account-usage-and-information-schema"}, "correct_response": ["a"], "section": "Account Usage & Monitoring", "question_plain": "What is the range of latency of data in the ACCOUNT_USAGE schema?", "related_lectures": []}, {"_class": "assessment", "id": 70942314, "assessment_type": "multiple-choice", "prompt": {"question": "True or False: The data in the views in the INFORMATION_SCHEMA can have a latency of up to 3 hours.", "answers": ["False", "True"], "explanation": "The data provided via the INFORMATION_SCHEMA views is real-time, and there is no latency in the information provided. So, if you are asked which schema should be used if there is a requirement to view real-time data, then the views in INFORMATION SCHEMA should be used as they contain real-time information. \n  \n https://docs.snowflake.com/en/sql-reference/account-usage#differences-between-account-usage-and-information-schema"}, "correct_response": ["a"], "section": "Account Usage & Monitoring", "question_plain": "True or False: The data in the views in the INFORMATION_SCHEMA can have a latency of up to 3 hours.", "related_lectures": []}, {"_class": "assessment", "id": 70942316, "assessment_type": "multiple-choice", "prompt": {"question": "As the security administrator for your organization&#39;s Snowflake instance, you are required to continuously track a list of all users who logged into the system in the last 60 minutes. Which one of the following methods can you use?", "answers": ["Use the table function INFORMATION_SCHEMA.LOGIN_HISTORY ()", "Query the view SNOWFLAKE.ACCOUNT_USAGE.LOGIN_HISTORY", "Use the table function INFORMATION_SCHEMA.LOGIN_HISTORY_BY_USER()", "Ask Snowflake support to provide these details."], "explanation": "The views in ACCOUNT_USAGE schema can have up to 3 hours of latency. Since the requirement is to continuously track the login history for the last 60 minutes, you will require near real-time information, which is available through the INFORMATION_SCHEMA table functions. In this case, the INFORMATION_SCHEMA.LOGIN_HISTORY() function will fulfill the requirements. \n  \n Note: INFORMATION_SCHEMA.LOGIN_HISTORY_BY_USER() is unsuitable because it only provides information for a single user.\n  \n https://docs.snowflake.com/en/sql-reference/account-usage#differences-between-account-usage-and-information-schema"}, "correct_response": ["a"], "section": "Account Usage & Monitoring", "question_plain": "As the security administrator for your organization&#39;s Snowflake instance, you are required to continuously track a list of all users who logged into the system in the last 60 minutes. Which one of the following methods can you use?", "related_lectures": []}, {"_class": "assessment", "id": 70942318, "assessment_type": "multiple-choice", "prompt": {"question": "You are required to see the query history for a date seven months ago. Which of the following methods will provide you with the query history for seven months ago?", "answers": ["Use the QUERY_HISTORY view in the ACCOUNT_USAGE schema", "View the historical queries using the query history page", "Use the QUERY_HISTORY table function in the INFORMATION schema", "Request Snowflake support to provide query history"], "explanation": "The views in the ACCOUNT_USAGE schema provide up to 365 days of history for various information. The history of queries from 7 months ago can only be retrieved using the QUERY_HISTORY view in the ACCOUNT_USAGE schema. \n  \n The QUERY HISTORY table function in the INFORMATION schema can only provide seven days of history.\n  \n The query history page can only show the history of executed queries within the last 14 days.\n  \n https://docs.snowflake.com/en/sql-reference/account-usage#differences-between-account-usage-and-information-schema"}, "correct_response": ["a"], "section": "Account Usage & Monitoring", "question_plain": "You are required to see the query history for a date seven months ago. Which of the following methods will provide you with the query history for seven months ago?", "related_lectures": []}, {"_class": "assessment", "id": 70942320, "assessment_type": "multi-select", "prompt": {"question": "Which of the following can be tracked and managed by a resource monitor?", "answers": ["A single virtual warehouse", "A group of virtual warehouses", "The whole account", "A single Snowpipe"], "explanation": "Resource monitors can track &amp; manage a single virtual warehouse or multiple virtual warehouses together.\n Resource Monitors can also be created at the account level, which means that such resource monitors track credit usage at the account level, considering the credit usage of all virtual warehouses.\n Resource Monitors can not manage costs for Snowpipe or other serverless functions.\n  \n https://docs.snowflake.com/en/user-guide/resource-monitors#assignment-of-resource-monitors"}, "correct_response": ["a", "b", "c"], "section": "Account Usage & Monitoring", "question_plain": "Which of the following can be tracked and managed by a resource monitor?", "related_lectures": []}, {"_class": "assessment", "id": 70942322, "assessment_type": "multi-select", "prompt": {"question": "During a weekly release cycle, which of the following accounts may be updated on the second day of release?", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "Snowflake does not instantly deploy a new version to all Snowflake accounts; rather, customer accounts are moved into the new release over time in a phased manner.\n  \n Day 1 (early access): Deployed for Enterprise edition (or higher) accounts that have elected for early access. You can enroll an Enterprise edition (or higher) account for early access by contacting Snowflake support.\n  \n Day 1 or 2 (regular access): Deployment of all Snowflake accounts on the Standard edition. \n  \n Day 2 (last): All remaining Enterprise edition (or higher) accounts are deployed. \n  \n Between an early access deployment and a final deployment, a minimum of 24 hours must pass. This staged release strategy enables Snowflake to identify and address any software issues uncovered during early access.\n  \n https://docs.snowflake.com/en/user-guide/intro-releases", "answers": ["All enterprise edition (and above) accounts that have not opted into early access", "All standard edition accounts", "Only those Enterprise edition accounts which have opted into early access", "<p><strong>Only business critical edition accounts</strong></p>"]}, "correct_response": ["a", "b"], "section": "Account", "question_plain": "During a weekly release cycle, which of the following accounts may be updated on the second day of release?", "related_lectures": []}, {"_class": "assessment", "id": 70942324, "assessment_type": "multi-select", "prompt": {"question": "Which of the following are the key layers in Snowflake architecture? Select all that apply.", "answers": ["Database Storage", "Query Processing", "Cloud Services", "Authentication Services", "Global Services"], "explanation": "Snowflake architecture has three distinct layers:\n Database Storage - Cheap cloud storage on AWS, Azure, or Google Cloud\n Query Processing - Primarily composed of virtual warehouses\n Cloud Services - The brain of the whole operation\n  \n https://docs.snowflake.com/en/user-guide/intro-key-concepts#snowflake-architecture"}, "correct_response": ["a", "b", "c"], "section": "Architecture", "question_plain": "Which of the following are the key layers in Snowflake architecture? Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70942326, "assessment_type": "multiple-choice", "prompt": {"question": "Which of the following statement correctly describes Snowflake architecture?", "answers": ["Multi-cluster Shared Data architecture", "Shared nothing architecture", "Shared disk architecture"], "explanation": "Snowflake implements a new hybrid architecture that combines the best features of shared-disk and shared-nothing architectures. Snowflake stores data similarly to a shared-disk architecture, i.e., the data is shared. But it also allows for using several compute engines, each with its own memory and processing capabilities.\n  \n https://docs.snowflake.com/en/user-guide/intro-key-concepts#snowflake-architecture"}, "correct_response": ["a"], "section": "Architecture", "question_plain": "Which of the following statement correctly describes Snowflake architecture?", "related_lectures": []}, {"_class": "assessment", "id": 70942328, "assessment_type": "multi-select", "prompt": {"question": "Which of the following statements are true regarding how Snowflake stores table data? Select all that apply.", "answers": ["Data is stored in columnar format", "Data is stored in micro-partitions", "Data is automatically compressed", "Data is stored as CSV", "Data is stored as Parquet"], "explanation": "Data in Snowflake tables is automatically organized into partitions, known as micro-partition. Each micro-partition generally contains 50MB to 500 MB of uncompressed data. However, the stored size is smaller as Snowflake data is always stored with compression. Within each micro-partition, the data is stored in a columnar format.\n  \n https://docs.snowflake.com/en/user-guide/tables-clustering-micropartitions"}, "correct_response": ["a", "b", "c"], "section": "Architecture", "question_plain": "Which of the following statements are true regarding how Snowflake stores table data? Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70942330, "assessment_type": "multi-select", "prompt": {"question": "The Database Storage layer in Snowflake architecture can be on which of the following? Select all that apply.", "answers": ["AWS S3", "Azure Blob Storage", "Google Cloud Storage", "On-Premise NAS", "Hybrid Cloud"], "explanation": "Snowflake&#39;s shared storage layer resides on low-cost object cloud storage. Snowflake currently supports AWS S3 storage, Azure Blob Storage, and Google Cloud Storage for data storage."}, "correct_response": ["a", "b", "c"], "section": "Architecture", "question_plain": "The Database Storage layer in Snowflake architecture can be on which of the following? Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70942332, "assessment_type": "multiple-choice", "prompt": {"question": "Each micro-partition generally contains ________ of uncompressed data.", "answers": ["50MB to 500MB", "5MB to 10MB", "1GB to 10GB", "1024KB to 2048KB"], "explanation": "Micro-partitions are small and typically store 50 MB to 500 MB of uncompressed data. \n  \n https://docs.snowflake.com/en/user-guide/tables-clustering-micropartitions.html"}, "correct_response": ["a"], "section": "Architecture", "question_plain": "Each micro-partition generally contains ________ of uncompressed data.", "related_lectures": []}, {"_class": "assessment", "id": 70942334, "assessment_type": "multiple-choice", "prompt": {"question": "True/False: Snowflake automatically determines the most efficient algorithm to compress columns in a micro-partition.", "answers": ["True", "False"], "explanation": "Snowflake stores columns in a columnar manner within each micro-partition. A columnar format enables Snowflake to optimize queries by retrieving only the referenced columns. In addition to micro-partition compression, each column in a micro-partition is compressed independently. Snowflake chooses the optimum compression algorithm for each column.\n  \n https://docs.snowflake.com/en/user-guide/tables-clustering-micropartitions.html"}, "correct_response": ["a"], "section": "Architecture", "question_plain": "True/False: Snowflake automatically determines the most efficient algorithm to compress columns in a micro-partition.", "related_lectures": []}, {"_class": "assessment", "id": 70942336, "assessment_type": "multi-select", "prompt": {"question": "A virtual warehouse provides which of the following resources? Select all that apply.", "answers": ["CPU", "Memory", "Temporary Local Storage", "Shared Storage"], "explanation": "A virtual warehouse provides CPU, memory, and temporary storage resources to process queries and run data load jobs. Each node in a virtual warehouse computes cluster has its own memory, computing resources, and local cache stored on a solid-state disk.\n  \n https://docs.snowflake.com/en/user-guide/warehouses-overview"}, "correct_response": ["a", "b", "c"], "section": "Architecture", "question_plain": "A virtual warehouse provides which of the following resources? Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70942464, "assessment_type": "multiple-choice", "prompt": {"question": "Your security administrator has created Row Access Policies on a table. What type of security has the administrator implemented?", "answers": ["Row Level Security", "Column Level Security", "Dynamic Data Masking", "Row Elimination"], "explanation": "Row-level security is implemented by creating row access policies, which include conditions and functions that govern which rows are returned during query execution.\n  \n https://docs.snowflake.com/en/user-guide/security-row-intro"}, "correct_response": ["a"], "section": "Security", "question_plain": "Your security administrator has created Row Access Policies on a table. What type of security has the administrator implemented?", "related_lectures": []}, {"_class": "assessment", "id": 70942338, "assessment_type": "multiple-choice", "prompt": {"question": "The Query Processing Layer can run multiple compute clusters (virtual warehouses) simultaneously. Which statement is true regarding how the compute clusters access data?", "answers": ["Each virtual warehouse accesses the same shared data.", "Each virtual warehouse gets a complete copy of all data.", "Each virtual warehouse gets a portion of the data."], "explanation": "Snowflake stores data similarly to a shared-disk architecture, i.e., the data is shared. But it also allows for using several compute engines on the same shared data, each with its own memory and processing capabilities.\n  \n https://docs.snowflake.com/en/user-guide/intro-key-concepts#snowflake-architecture"}, "correct_response": ["a"], "section": "Architecture", "question_plain": "The Query Processing Layer can run multiple compute clusters (virtual warehouses) simultaneously. Which statement is true regarding how the compute clusters access data?", "related_lectures": []}, {"_class": "assessment", "id": 70942340, "assessment_type": "multiple-choice", "prompt": {"question": "True/False: If you use a specific virtual warehouse to load data into a table, you must use the same virtual warehouse to query that data.", "answers": ["False", "True"], "explanation": "You can use any virtual warehouse to access the data.\n  \n Snowflake stores data in a shared manner, like in shared-disk architecture. But it also allows for using several compute engines, each with its own memory and processing capabilities. The virtual warehouses are independent of each other but access and process the same shared data. \n  \n https://docs.snowflake.com/en/user-guide/intro-key-concepts#snowflake-architecture"}, "correct_response": ["a"], "section": "Architecture", "question_plain": "True/False: If you use a specific virtual warehouse to load data into a table, you must use the same virtual warehouse to query that data.", "related_lectures": []}, {"_class": "assessment", "id": 70942342, "assessment_type": "multiple-choice", "prompt": {"question": "True/False: Credits used by a Medium virtual warehouse running for 2 hours is equal to 4 hours of Small virtual warehouse usage.", "answers": ["True", "False"], "explanation": "Virtual warehouses&#39; compute time is paid for using snowflake credits. The quantity of Snowflake credits used is determined by the size of the virtual warehouse and the length of time they are in a running state. When the size of a virtual warehouse is increased, the number of credits used in an hour also increases.\n  \n An X-Small (1-node) virtual warehouse consumes 1 credit for an hour of use. \n  \n Since the credit usage per hour doubles for each increase in size, a Small virtual warehouse (consisting of 2 nodes) running for 4 hours consumes 8 snowflake credits. Similarly, a Medium virtual warehouse consumes 8 snowflake credits within 2 hours because it consists of 4 nodes and is consuming credits at twice the rate of a Small virtual warehouse."}, "correct_response": ["a"], "section": "Architecture", "question_plain": "True/False: Credits used by a Medium virtual warehouse running for 2 hours is equal to 4 hours of Small virtual warehouse usage.", "related_lectures": []}, {"_class": "assessment", "id": 70942344, "assessment_type": "multiple-choice", "prompt": {"question": "True/False: When a virtual warehouse is suspended, It does not go into a suspended state until all ongoing queries that use that virtual warehouse are finished.", "answers": ["True", "False"], "explanation": "When a virtual warehouse is requested to be suspended, it does not enter a suspended state until all active queries using that virtual warehouse have been completed.\n  \n Note that when a resource monitor performs a &quot;suspend immediately&quot; on a virtual warehouse after a credit limit has been reached, the virtual warehouse is suspended immediately, stopping all running queries. \n  \n https://docs.snowflake.com/en/user-guide/warehouses-tasks"}, "correct_response": ["a"], "section": "Architecture", "question_plain": "True/False: When a virtual warehouse is suspended, It does not go into a suspended state until all ongoing queries that use that virtual warehouse are finished.", "related_lectures": []}, {"_class": "assessment", "id": 70942346, "assessment_type": "multiple-choice", "prompt": {"question": "A virtual warehouse is in a suspended state. Can it be resized?", "answers": ["Yes", "No"], "explanation": "You can resize a virtual warehouse at any time, even when they are running. When a virtual warehouse is resized, Snowflake adds or removes nodes according to the new size. The removal of nodes takes place only when all active queries on those nodes have finished.\n  \n https://docs.snowflake.com/en/user-guide/warehouses-tasks#resizing-a-warehouse"}, "correct_response": ["a"], "section": "Architecture", "question_plain": "A virtual warehouse is in a suspended state. Can it be resized?", "related_lectures": []}, {"_class": "assessment", "id": 70942348, "assessment_type": "multi-select", "prompt": {"question": "Which of the following functions does the Cloud Services Layer perform? Select all that apply", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "The cloud services layer is responsible for query planning and optimization. Virtual warehouses perform the query processing, but once a result set has been created, it is stored in the query result cache, which is part of the cloud services layer.\n  \n ttps://docs.snowflake.com/en/user-guide/intro-key-concepts#cloud-services", "answers": ["Query Planning", "Query Optimization", "<p><strong>Query Result Caching</strong></p>", "Query Processing"]}, "correct_response": ["a", "b", "c"], "section": "Architecture", "question_plain": "Which of the following functions does the Cloud Services Layer perform? Select all that apply", "related_lectures": []}, {"_class": "assessment", "id": 70942350, "assessment_type": "multi-select", "prompt": {"question": "Which of the following caches are stored in the cloud services layer? Select all that apply.", "answers": ["Query Result Cache", "Metadata Cache", "Virtual Warehouse Cache", "JDBC Cache", "Web Cache"], "explanation": "The cloud services layer stores the Query Result Cache and Metadata Cache. \n  \n The virtual warehouse cache is stored locally in a virtual warehouse. \n  \n https://docs.snowflake.com/en/user-guide/querying-persisted-results"}, "correct_response": ["a", "b"], "section": "Architecture", "question_plain": "Which of the following caches are stored in the cloud services layer? Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70942352, "assessment_type": "multi-select", "prompt": {"question": "The COPY command allows the following options for selecting files for loading data from a stage.\n \n Select all that apply.", "answers": ["Load specific files by providing exact file names.", "Load all files in a specific path.", "Load files that match a pattern."], "explanation": "All of these options are correct. You can load by providing exact file names, load all files from a specific path, or load files that match a pattern.\n \n \n https://docs.snowflake.com/en/user-guide/data-load-considerations-load#options-for-selecting-staged-data-files"}, "correct_response": ["a", "b", "c"], "section": "Data Loading and Unloading", "question_plain": "The COPY command allows the following options for selecting files for loading data from a stage.\n \n Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70942354, "assessment_type": "multiple-choice", "prompt": {"question": "True or False: The COPY command exports to a single file by default.", "answers": ["False", "True"], "explanation": "The unloading process automatically exports to multiple files so that it can take advantage of the parallelism offered by Snowflake. However, if needed, you can set the SINGLE parameter to true to ensure the export goes to a single file.\n  \n The default size of each output file is 16 MB but can be changed using the MAX_FILE_SIZE parameter. The maximum allowed size per file is 5GB if you export data to cloud storage. \n  \n  \n https://docs.snowflake.com/en/user-guide/data-unload-considerations#unloading-to-a-single-file"}, "correct_response": ["a"], "section": "Data Loading and Unloading", "question_plain": "True or False: The COPY command exports to a single file by default.", "related_lectures": []}, {"_class": "assessment", "id": 70942356, "assessment_type": "multi-select", "prompt": {"question": "External tables are a good solution for which of the following is true? Select all that apply.", "answers": ["Data is already in a data lake on a cloud platform (e.g., S3, Azure Blob Storage)", "The data is not accessed frequently.", "Typically only a subset of data is accessed.", "Data is in binary format and can not be loaded into Snowflake."], "explanation": "Organizations with established data lakes and significant amounts of data in cloud object storage will find external tables helpful. When data is accessed infrequently, or only a portion of the data has to be queried, external tables can expose data from data lakes in a cost-effective manner. However, storing the data in a typical Snowflake table may be more economical if all of the data is viewed or if access is made often.\n  \n https://docs.snowflake.com/en/user-guide/tables-external-intro"}, "correct_response": ["a", "b", "c"], "section": "Data Loading and Unloading", "question_plain": "External tables are a good solution for which of the following is true? Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70942358, "assessment_type": "multi-select", "prompt": {"question": "Which of the following are true regarding External tables?", "answers": ["Queries can be run on an external table just like any other table", "An external table and a standard Snowflake table can be joined", "An external table and a standard Snowflake table can NOT be joined", "An external table points to an internal stage"], "explanation": "Snowflake provides external tables that enable the creation of tables with data stored in external cloud storage. The definition and metadata of an external table contain information on file locations, filenames, and other attributes. The definition also includes the external stage from which the data for an external table will come. External tables allow you to query an external table in the same manner as a typical table. External tables may be joined to other tables, and views can be created on external tables.\n  \n https://docs.snowflake.com/en/user-guide/tables-external-intro"}, "correct_response": ["a", "b"], "section": "Data Loading and Unloading", "question_plain": "Which of the following are true regarding External tables?", "related_lectures": []}, {"_class": "assessment", "id": 70942360, "assessment_type": "multiple-choice", "prompt": {"question": "Which command can be used to download data from an internal stage to an on-premises system?", "answers": ["GET", "PUT", "COPY", "VALIDATE"], "explanation": "The GET command is used to download data from an internal stage to an on-premises system.\n  \n The PUT command uploads data from an on-premises system to an internal stage.\n  \n To download or upload data to an external stage, cloud provider utilities or other tools are used to interact with data in the cloud storage pointed to by the external stage.\n  \n  \n https://docs.snowflake.com/en/user-guide/data-unload-overview#bulk-unloading-process"}, "correct_response": ["a"], "section": "Data Loading and Unloading", "question_plain": "Which command can be used to download data from an internal stage to an on-premises system?", "related_lectures": []}, {"_class": "assessment", "id": 70942362, "assessment_type": "multiple-choice", "prompt": {"question": "True or False: When a file has been loaded into a table, Snowflake marks that file as loaded in the metadata so that the file does not get processed again.", "answers": ["True", "False"], "explanation": "The load metadata stores a variety of information, such as the name of every file that was loaded into that table and the time stamp corresponding to the time that a file was loaded. By utilizing this load metadata, Snowflake ensures that it will not reprocess a previously loaded file.\n  \n The load metadata expires after 64 days. Snowflake skips over any older files for which the load status is undetermined.\n  \n https://docs.snowflake.com/en/user-guide/data-load-considerations-load#load-metadata"}, "correct_response": ["a"], "section": "Data Loading and Unloading", "question_plain": "True or False: When a file has been loaded into a table, Snowflake marks that file as loaded in the metadata so that the file does not get processed again.", "related_lectures": []}, {"_class": "assessment", "id": 70942364, "assessment_type": "multi-select", "prompt": {"question": "You can upload data into which of the following stages using the PUT command? Select all that apply.", "answers": ["Named Internal Stage", "User Stage", "Table Stage", "External Stage"], "explanation": "The PUT command uploads data from an on-premises system to an internal stage (including named internal stages, table stages &amp; user stages).\n  \n The GET command is used to download data from an internal stage to an on-premises system.\n  \n To download or upload data to an external stage, cloud provider utilities or other tools are used to interact with data in the cloud storage pointed to by the external stage.\n  \n  \n https://docs.snowflake.com/en/user-guide/data-unload-overview#bulk-unloading-process"}, "correct_response": ["a", "b", "c"], "section": "Data Loading and Unloading", "question_plain": "You can upload data into which of the following stages using the PUT command? Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70942366, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>You are a telecom company's data engineer who uses Snowflake as a data warehouse. The company requires all network signaling data to be loaded into a table in near real-time. The network signaling data already lands into an S3 bucket every 1 minute. What is the course of action that you should take? </strong></p><p><strong> Select three options; each option forms part of the answer.</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "Snowpipe can load data from an external stage as well as an internal stage. When using an external stage, you can use the cloud platform notifications to trigger your Snowpipe. The cloud platform notifications can be configured to trigger an event as soon as a new file is detected in the cloud storage bucket. Additional configuration links the event to your Snowpipe, so every time new files arrive, the Snowpipe is automatically triggered into action. When triggered, the Snowpipe runs the COPY command from its definition and loads newly received data into the target table.\n  \n The alternate mechanism is through a REST API call, which requires you to write a program that can trigger the Snowpipe as needed by calling Snowpipe-specific REST APIs. Using REST APIs, you control when you want to trigger the Snowpipe, either on a scheduled or ad-hoc basis.\n Note that when using internal stages with Snowpipe, you must trigger a Snowpipe via the REST API. There is no provision for a trigger best invocation of Snowpipe when using the internal stage as a source.\n  \n Note: A snowpipe can not check an S3 bucket directly for a file, and it must be triggered by a notification or a REST API call.\n  \n https://docs.snowflake.com/en/user-guide/data-load-snowpipe-intro", "answers": ["Create a Snowpipe that loads data from an external stage.", "Create an external stage on top of the S3 bucket where the near real-time data lands.", "Configure notification event on the S3 bucket, which triggers the Snowpipe.", "Configure the Snowpipe to check for new files in the S3 bucket continuously.", "Execute RUN Snowpipe to start the snowpipe"]}, "correct_response": ["a", "b", "c"], "section": "Data Loading and Unloading", "question_plain": "You are a telecom company's data engineer who uses Snowflake as a data warehouse. The company requires all network signaling data to be loaded into a table in near real-time. The network signaling data already lands into an S3 bucket every 1 minute. What is the course of action that you should take?  Select three options; each option forms part of the answer.", "related_lectures": []}, {"_class": "assessment", "id": 70942368, "assessment_type": "multi-select", "prompt": {"question": "Basic Transformations during the COPY process are supported by which of the following stage types?", "answers": ["External Stage", "Named Internal Stage", "Table Stage"], "explanation": "The table stages do not allow basic transformations during the COPY process; thus, basic transformations may only be performed while loading data from external stages, named internal stages or user stages.\n  \n  \n https://docs.snowflake.com/en/user-guide/data-load-local-file-system-create-stage#table-stages"}, "correct_response": ["a", "b"], "section": "Data Loading and Unloading", "question_plain": "Basic Transformations during the COPY process are supported by which of the following stage types?", "related_lectures": []}, {"_class": "assessment", "id": 70942370, "assessment_type": "multi-select", "prompt": {"question": "Which of the following statements correctly describes fail-safe in Snowflake? Select all that apply.", "answers": ["The fail-safe protection is in addition to the protection provided by Time Travel.", "Failsafe ensures that historical data is protected in the event of a catastrophic failure.", "Failsafe provides up to 7 days of historical data protection for permanent tables.", "Failsafe is the same as Time Travel.", "Failsafe provides up to 90 days of historical data protection for permanent tables."], "explanation": "In addition to protection provided by Time Travel, data that has been modified also goes through a failsafe period. Failsafe storage is intended to provide an extra layer of protection against data loss caused by human error. Once the Time Travel period ends, Snowflake keeps the data for a further 7-day period as further protection. When data is in failsafe storage, ordinary users cannot access it; only Snowflake support employees can access and recover it if the customer requests it.\n  \n https://docs.snowflake.com/en/user-guide/data-failsafe"}, "correct_response": ["a", "b", "c"], "section": "Fail-safe", "question_plain": "Which of the following statements correctly describes fail-safe in Snowflake? Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70942372, "assessment_type": "multiple-choice", "prompt": {"question": "Snowflake stores data in fail-safe storage for Transient tables for how long?", "answers": ["0 days", "7 days", "14 days", "1 day"], "explanation": "Snowflake has transient and temporary tables that don&#39;t provide fail-safe capabilities; hence, data in such tables have 0 days of fail-safe storage.\n  \n https://docs.snowflake.com/en/user-guide/tables-temp-transient"}, "correct_response": ["a"], "section": "Fail-safe", "question_plain": "Snowflake stores data in fail-safe storage for Transient tables for how long?", "related_lectures": []}, {"_class": "assessment", "id": 70942374, "assessment_type": "multiple-choice", "prompt": {"question": "Which type of Snowflake tables will cease to exist once the session is closed?", "answers": ["Temporary", "Transient", "Permanent", "Clustered"], "explanation": "Temporary tables are local to a session and are dropped as soon as the session is closed.\n  \n https://docs.snowflake.com/en/user-guide/tables-temp-transient"}, "correct_response": ["a"], "section": "Data Protection", "question_plain": "Which type of Snowflake tables will cease to exist once the session is closed?", "related_lectures": []}, {"_class": "assessment", "id": 70942376, "assessment_type": "multiple-choice", "prompt": {"question": "True or False: Data in Time Travel and fail-safe storage is stored free of charge by Snowflake.", "answers": ["False", "True"], "explanation": "Snowflake charges for Time Travel and failsafe data storage. The cost of maintaining data for Time Travel and fail-safe is calculated every 24 hours based on the number of days it is maintained and the time since it was last modified.\n  \n https://docs.snowflake.com/en/user-guide/data-cdp-storage-costs"}, "correct_response": ["a"], "section": "Time Travel", "question_plain": "True or False: Data in Time Travel and fail-safe storage is stored free of charge by Snowflake.", "related_lectures": []}, {"_class": "assessment", "id": 70942378, "assessment_type": "multiple-choice", "prompt": {"question": "What is the maximum period for which Time Travel is permitted for Transient tables?", "answers": ["1 day", "7 days", "14 days", "21 days"], "explanation": "Transient and Temporary tables in Snowflake support Time Travel for up to 1 day, irrespective of the Snowflake edition used.\n  \n https://docs.snowflake.com/en/user-guide/tables-temp-transient"}, "correct_response": ["a"], "section": "Time Travel", "question_plain": "What is the maximum period for which Time Travel is permitted for Transient tables?", "related_lectures": []}, {"_class": "assessment", "id": 70942380, "assessment_type": "multi-select", "prompt": {"question": "You execute a time travel query on a table but get the following error. &quot;Time travel data is not available for the table. The requested time is either beyond the allowed time travel period or before the object creation time.&quot; What could this error indicate? Select all that apply.", "answers": ["You have provided a value for TIMESTAMP in the BEFORE clause that is outside of that table&#39;s Time Travel retention period.", "You have provided a value for OFFSET in the AT clause that is outside of the Time Travel retention period of that table.", "You have provided a query id for STATEMENT in the BEFORE clause that is outside of that table&#39;s Time Travel retention period.", "Your role is not authorized to use Time Travel.", "The table is being loaded; therefore, Time Travel is unavailable."], "explanation": "A time travel query will fail, and an error will be returned if the TIMESTAMP, OFFSET, or STATEMENT supplied in the AT | BEFORE clause is outside of the Time Travel retention period for the table.\n The same error is thrown if the time travel query attempts to access the table data before it was created.\n  \n https://docs.snowflake.com/en/user-guide/data-time-travel#querying-historical-data"}, "correct_response": ["a", "b", "c"], "section": "Time Travel", "question_plain": "You execute a time travel query on a table but get the following error. &quot;Time travel data is not available for the table. The requested time is either beyond the allowed time travel period or before the object creation time.&quot; What could this error indicate? Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70942382, "assessment_type": "multiple-choice", "prompt": {"question": "Which of the following is true regarding Time Travel in Snowflake?", "answers": ["Undrop allows users to restore dropped tables, schemas, and databases.", "Undrop allows users to recover dropped accounts and roles.", "The undrop feature allows Snowflake to reconstruct data packets dropped during communication.", "Undrop enables Snowflake to keep a stable client connection open even with a bad network link."], "explanation": "Undrop allows users to restore dropped tables, schemas, and databases. When tables, schemas, or databases are dropped in Snowflake, they are not immediately removed from the system and are still recoverable during Time Travel. When a table is dropped, the data is retained on the cloud storage, even though the table is listed as dropped. Snowflake merely sets the table&#39;s state to non-deleted to undrop it. Therefore, undrop can be applied to tables, schemas, and databases.\n https://docs.snowflake.com/en/user-guide/data-time-travel#restoring-objects"}, "correct_response": ["a"], "section": "Time Travel", "question_plain": "Which of the following is true regarding Time Travel in Snowflake?", "related_lectures": []}, {"_class": "assessment", "id": 70942384, "assessment_type": "multi-select", "prompt": {"question": "Which of the following occurs when a Snowflake account shares a table with another Snowflake account? Select all that apply.", "answers": ["No actual data is copied or transferred between accounts.", "Sharing is managed through the Snowflake metadata services layer.", "Data is copied to the target Snowflake account.", "The target Snowflake account is charged for shared data storage."], "explanation": "In Snowflake sharing, no data is copied. Instead, it is just the metadata that enables the sharing of data. Since no data is copied, the target Snowflake account (the consumer) is NOT charged for any storage.\n \n https://docs.Snowflake.net/manuals/user-guide/data-sharing-intro.html#how-does-secure-data-sharing-work"}, "correct_response": ["a", "b"], "section": "Data Sharing", "question_plain": "Which of the following occurs when a Snowflake account shares a table with another Snowflake account? Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70942386, "assessment_type": "multi-select", "prompt": {"question": "Which statements correctly describe the contents of a Snowflake share object? Select all that apply.", "answers": ["A share object contains privileges that grant access to a database &amp; a schema from which objects are being shared.", "A share object contains privileges that grant access to the shared objects, i.e., tables, secure views, etc., that are being shared.", "A share object contains the consumer account(s) with which the database &amp; the objects are to be shared.", "A share object contains the virtual warehouse that will be used to execute queries on the shared objects."], "explanation": "A share acts as a container for objects that need to be shared and specifies the consumer accounts. \n A share contains USAGE privileges on the database &amp; the schema to be shared, privileges on the tables, secure views which will be shared, and the consumer account(s) to which the Share will be available.\n \n A virtual warehouse is not part of a share. If a Snowflake customer consumes a share, they will use their own virtual warehouse. If a non-Snowflake customer is consuming the Share, they will use the data provider compute through a data provider-created virtual warehouse (which would have been separately configured)"}, "correct_response": ["a", "b", "c"], "section": "Data Sharing", "question_plain": "Which statements correctly describe the contents of a Snowflake share object? Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70942388, "assessment_type": "multi-select", "prompt": {"question": "Which of the following objects may be shared via direct data sharing?", "answers": ["Tables", "External Tables", "Secure UDFs", "Virtual Warehouses", "Resource Monitors"], "explanation": "Direct data sharing enables sharing of the following types of objects:\n Tables, External tables, Secure views, Secure materialized views, Secure UDFs.\n  \n https://docs.snowflake.com/en/user-guide/data-sharing-intro"}, "correct_response": ["a", "b", "c"], "section": "Data Sharing", "question_plain": "Which of the following objects may be shared via direct data sharing?", "related_lectures": []}, {"_class": "assessment", "id": 70942390, "assessment_type": "multi-select", "prompt": {"question": "Which statements are true regarding costs when a Snowflake account shares data with another Snowflake account? Select all that apply.", "answers": ["The data consumer is charged for the compute charges for queries they run.", "The data consumer is NOT charged for any storage costs associated with the shared data.", "The data provider is charged for the compute charges for queries the data consumer runs.", "Both the data provider and the data consumer are charged for the storage costs."], "explanation": "Since the provider account stores and pays for the data storage, the data consumer doesn&#39;t have to pay anything extra for storage. However, the data consumer pays for the compute used to run queries on shared data. When queries are run on shared data, the compute of the data consumer is used"}, "correct_response": ["a", "b"], "section": "Data Sharing", "question_plain": "Which statements are true regarding costs when a Snowflake account shares data with another Snowflake account? Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70942392, "assessment_type": "multiple-choice", "prompt": {"question": "When sharing with a non-Snowflake user, the reader account belongs to which account?", "answers": ["The data provider", "The data consumer", "Neither the data provider nor the data consumer", "Both the data provider &amp; the data consumer"], "explanation": "A reader account is created by the data provider and owned by the data provider. The data provider bears the compute costs incurred in a reader account.\n  \n https://docs.snowflake.com/en/user-guide/data-sharing-reader-create#who-provides-support-for-a-reader-account"}, "correct_response": ["a"], "section": "Data Sharing", "question_plain": "When sharing with a non-Snowflake user, the reader account belongs to which account?", "related_lectures": []}, {"_class": "assessment", "id": 70942394, "assessment_type": "multiple-choice", "prompt": {"question": "Which of the following statement is true when sharing data with an organization that does not have a Snowflake account?", "answers": ["A reader account must be created for sharing data with a non-Snowflake", "A child account must be created for sharing data with a non-Snowflake customer", "An account inheritance hierarchy must be created to share data with a non-Snowflake customer."], "explanation": "Sharing with a non-Snowflake user requires the creation of a reader account. The reader account provides the non-Snowflake user with a Snowflake account through which they can consume the shared data. The data providers own the reader account, and all costs (including query costs) are charged to the data provider.\n  \n https://docs.snowflake.com/en/user-guide/data-sharing-reader-create"}, "correct_response": ["a"], "section": "Data Sharing", "question_plain": "Which of the following statement is true when sharing data with an organization that does not have a Snowflake account?", "related_lectures": []}, {"_class": "assessment", "id": 70942396, "assessment_type": "multiple-choice", "prompt": {"question": "True or False: A database is created from a share by the consuming account; the access to this database is configurable using Snowflake&#39;s role-based access control.", "answers": ["True", "False"], "explanation": "Correct. Role-based access control (RBAC), typically used for securing objects in a Snowflake account, also applies to consumer accounts and can control access to databases created on shared objects.\n  \n https://docs.snowflake.com/en/user-guide/data-share-consumers"}, "correct_response": ["a"], "section": "Data Sharing", "question_plain": "True or False: A database is created from a share by the consuming account; the access to this database is configurable using Snowflake&#39;s role-based access control.", "related_lectures": []}, {"_class": "assessment", "id": 70942398, "assessment_type": "multi-select", "prompt": {"question": "Which of the following roles can import a dataset from Snowflake Marketplace? Select all that apply.", "answers": ["ACCOUNTADMIN", "A role that has IMPORT SHARE privileges", "ORGADMIN", "SYSADMIN"], "explanation": "Although any user or role can explore the Snowflake Marketplace, you will need a user with the ACCOUNTADMIN privilege or the IMPORT SHARE privilege for consuming data. For simplicity, we suggest you utilize a user with the ACCOUNTADMIN privilege."}, "correct_response": ["a", "b"], "section": "Data Sharing", "question_plain": "Which of the following roles can import a dataset from Snowflake Marketplace? Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70942400, "assessment_type": "multiple-choice", "prompt": {"question": "Which of the following correctly describes Data Exchange?", "answers": ["Data Exchange is your own private hub for sharing data with a small group of people or organizations you invite.", "Data Exchange is another name for One Drive storage which can be used to share Snowflake data", "Data Exchange is a mechanism to email data extracts from a Snowflake table securely.", "Data Exchange transfers data from on-premise to a Snowflake cloud storage using the COPY command."], "explanation": "Data Exchange is your own private hub for sharing data with a small group of people or organizations who have been invited to join. The owner of the Data Exchange account is in charge of inviting members and specifying whether they can share, consume, or do both.\n  \n https://docs.snowflake.com/en/user-guide/data-exchange"}, "correct_response": ["a"], "section": "Data Sharing", "question_plain": "Which of the following correctly describes Data Exchange?", "related_lectures": []}, {"_class": "assessment", "id": 70942402, "assessment_type": "multiple-choice", "prompt": {"question": "True or False. The variant data type can hold up to 16MB of data per row.", "answers": ["True", "False"], "explanation": "A single row of a VARIANT column can hold up to 16MB of data. If your JSON is larger then that, you will need to think of alternate techniques, such as splitting the JSON into multiple rows. \n  \n  \n https://docs.snowflake.com/en/sql-reference/data-types-semistructured#variant\n  \n https://docs.snowflake.com/en/user-guide/semistructured-intro#loading-semi-structured-data"}, "correct_response": ["a"], "section": "Data Loading and Unloading", "question_plain": "True or False. The variant data type can hold up to 16MB of data per row.", "related_lectures": []}, {"_class": "assessment", "id": 70942404, "assessment_type": "multiple-choice", "prompt": {"question": "You are a developer for a retail organization running a Snowflake data warehouse. You need to upload JSON-based data into a table. What approach should you take?", "relatedLectureIds": "", "feedbacks": ["", "", ""], "explanation": "Snowflake supports several semi-structured data formats and JSON, Avro, ORC, Parquet, and XML.\n  \n Snowflake provides the VARIANT data type, which can store any data and is appropriate for semi-structured data input and querying. SQL may be used to read and navigate JSON data once it has been loaded into a VARIANT column.\n  \n https://docs.snowflake.com/en/user-guide/semistructured-intro#loading-semi-structured-data", "answers": ["<p><strong>Use Snowflake provided functions to process JSON data while loading it into the table.</strong></p>", "Write a program using a programming language of your choice (Python, Java, etc.) to process the JSON file into a CSV structure. Then, load the CSV file into the table using the COPY command.", "Ask the source system to send you a CSV rather than a JSON file, as Snowflake does not support JSON."]}, "correct_response": ["a"], "section": "Data Loading and Unloading", "question_plain": "You are a developer for a retail organization running a Snowflake data warehouse. You need to upload JSON-based data into a table. What approach should you take?", "related_lectures": []}, {"_class": "assessment", "id": 70942406, "assessment_type": "multiple-choice", "prompt": {"question": "An external function&#39;s code is stored in which location?", "answers": ["Outside of Snowflake", "In a table", "In a code repository in the cloud services layer", "In the Snowflake metadata"], "explanation": "An external function, unlike other UDFs, does not include its own code; instead, it invokes code that is stored and run outside of Snowflake. For an external function, the only thing that is kept inside Snowflake is information that Snowflake uses to invoke the remote service that contains the code. \n  \n https://docs.snowflake.com/en/sql-reference/external-functions-introduction"}, "correct_response": ["a"], "section": "Extending Snowflake Functionality", "question_plain": "An external function&#39;s code is stored in which location?", "related_lectures": []}, {"_class": "assessment", "id": 70942408, "assessment_type": "multi-select", "prompt": {"question": "Which of the following are valid sections in a Snowflake Scripting code?", "answers": ["BEGIN", "END", "DECLARE", "EXCEPTION", "NOTIFY", "PARALLEL"], "explanation": "A typical Snowflake Scripting block will have a DECLARE section where variables and cursors may be declared. \n The BEGIN &amp; END enclose the actual logic of the script and may optionally contain the EXCEPTION section, where you handle any exceptions.\n  \n https://docs.snowflake.com/en/developer-guide/snowflake-scripting/index"}, "correct_response": ["a", "b", "c", "d"], "section": "Extending Snowflake Functionality", "question_plain": "Which of the following are valid sections in a Snowflake Scripting code?", "related_lectures": []}, {"_class": "assessment", "id": 70942410, "assessment_type": "multi-select", "prompt": {"question": "Which of the following statements best describe Snowpark? Select all that apply.", "answers": ["Snowpark is a library created by Snowflake that provides APIs for accessing and processing data in applications written in a programming language other than SQL.", "Snowpark automatically converts the data-processing programming constructs to SQL and pushes them down to Snowflake for execution.", "Snowpark does not rely on the Snowflake SQL execution engine.", "Snowflake provides APIS that allows programmers to access the internals of the Snowflake cloud services layer."], "explanation": "Snowpark is a library created by Snowflake that provides APIs for accessing and processing data in applications written in a programming language other than SQL. Snowpark allows programmers to utilize common programming languages such as Java, Scala, and Python to construct apps that handle data using standard programming structures. \n  \n Snowpark automatically converts the data-processing programming constructs to SQL and sends them to Snowflake for execution. \n  \n https://docs.snowflake.com/en/developer-guide/snowpark/index"}, "correct_response": ["a", "b"], "section": "Extending Snowflake Functionality", "question_plain": "Which of the following statements best describe Snowpark? Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70942412, "assessment_type": "multiple-choice", "prompt": {"question": "Under which condition a stored procedure will execute under the privileges of the role that created the stored procedure?", "answers": ["The stored procedure has been configured to run under the owner&#39;s rights.", "The stored procedure has been configured to run under the caller&#39;s rights.", "The stored procedure performs account-level modifications.", "The stored procedure changes the system security settings."], "explanation": "A stored procedure can be called with either the caller&#39;s rights or the owner&#39;s rights. \n A stored procedure configured to run with callers&#39; rights executes under the permissions of the calling user. \n A stored procedure configured to run with the owner&#39;s rights executes under the privileges of the role that created and owns the stored procedure. \n  \n https://docs.snowflake.com/en/sql-reference/stored-procedures-rights"}, "correct_response": ["a"], "section": "Extending Snowflake Functionality", "question_plain": "Under which condition a stored procedure will execute under the privileges of the role that created the stored procedure?", "related_lectures": []}, {"_class": "assessment", "id": 70942414, "assessment_type": "multi-select", "prompt": {"question": "Which of the following is true regarding stored procedures?", "answers": ["A newly created stored procedure defaults to run under the owner&#39;s privileges.", "A stored procedure can be altered to configure if it runs under owner&#39;s rights or caller&#39;s rights.", "A newly created stored procedure defaults to run under the caller&#39;s privileges.", "Once created, a stored procedure can not be altered to configure if it runs under owner&#39;s rights or caller&#39;s rights."], "explanation": "You can specify if a stored procedure runs under the caller&#39;s or owner&#39;s rights when creating the stored procedure. \n It defaults to the owner&#39;s right if nothing is specified.\n  It is possible to change this configuration later by altering the stored procedure.\n  \n  \n https://docs.snowflake.com/en/sql-reference/stored-procedures-rights"}, "correct_response": ["a", "b"], "section": "Extending Snowflake Functionality", "question_plain": "Which of the following is true regarding stored procedures?", "related_lectures": []}, {"_class": "assessment", "id": 70942416, "assessment_type": "multi-select", "prompt": {"question": "Which of the following are the four available Snowflake editions? Select all that apply.", "answers": ["Standard", "Enterprise", "Business Critical", "Virtual Private Snowflake", "Government", "On-Premise"], "explanation": "Snowflake provides 4 editions. Standard, Enterprise, Business Critical, and Virtual Private Snowflake (VPS).\n  \n https://docs.snowflake.com/en/user-guide/intro-editions.html"}, "correct_response": ["a", "b", "c", "d"], "section": "Licensing & Features", "question_plain": "Which of the following are the four available Snowflake editions? Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70942418, "assessment_type": "multiple-choice", "prompt": {"question": "What is the minimum Snowflake edition which supports multi-factor authentication (MFA)?", "answers": ["Standard", "Enterprise", "Business Critical", "Virtual Private Snowflake"], "explanation": "All Snowflake editions support MFA; thus, the minimum edition that supports it is the Standard edition.\n  \n  \n https://docs.snowflake.com/en/user-guide/intro-editions.html"}, "correct_response": ["a"], "section": "Licensing & Features", "question_plain": "What is the minimum Snowflake edition which supports multi-factor authentication (MFA)?", "related_lectures": []}, {"_class": "assessment", "id": 70942420, "assessment_type": "multiple-choice", "prompt": {"question": "What is the minimum Snowflake edition required for securely sharing data across regions and cloud platforms (via replication)?", "answers": ["Standard", "Enterprise", "Business Critical", "Virtual Private Snowflake"], "explanation": "Database sharing across regions and clouds (via replication) is supported in all Snowflake editions; thus, the minimum edition that supports it is the Standard edition.\n  \n https://docs.snowflake.com/en/user-guide/intro-editions.html"}, "correct_response": ["a"], "section": "Licensing & Features", "question_plain": "What is the minimum Snowflake edition required for securely sharing data across regions and cloud platforms (via replication)?", "related_lectures": []}, {"_class": "assessment", "id": 70942422, "assessment_type": "multiple-choice", "prompt": {"question": "What is the minimum Snowflake edition that supports Column Level Masking?", "answers": ["Enterprise", "Business Critical", "Standard", "Virtual Private Snowflake"], "explanation": "The Enterprise edition has several additional capabilities not provided in the Standard edition. These include multi-cluster virtual warehouses, column-level masking, row access policies, materialized views, and search optimization.\n  \n  \n https://docs.snowflake.com/en/user-guide/intro-editions.html"}, "correct_response": ["a"], "section": "Licensing & Features", "question_plain": "What is the minimum Snowflake edition that supports Column Level Masking?", "related_lectures": []}, {"_class": "assessment", "id": 70942424, "assessment_type": "multiple-choice", "prompt": {"question": "To create an external UDF, what is the minimum Snowflake edition required?", "answers": ["Standard", "Enterprise", "Business Critical", "Virtual Private Snowflake"], "explanation": "UDFs and external functions are foundational features supported by all Snowflake editions.\n  \n  \n https://docs.snowflake.com/en/user-guide/intro-editions.html"}, "correct_response": ["a"], "section": "Licensing & Features", "question_plain": "To create an external UDF, what is the minimum Snowflake edition required?", "related_lectures": []}, {"_class": "assessment", "id": 70942426, "assessment_type": "multi-select", "prompt": {"question": "Which of the following operations can be fulfilled without needing an active virtual warehouse? Select all that apply.", "answers": ["Count the number of rows in a table", "Find the maximum value of a numeric column", "Find the average of a numeric column", "Find the total of a numeric column"], "explanation": "Snowflake stores information about micro-partitions in the metadata. It stores the range of column values in its metadata, which includes the maximum and minimum values for each column in each micro-partition. Snowflake also stores the count of distinct values for each column in the metadata and certain other information to optimize a query. \n  \n Because this information is stored in the metadata cache, Snowflake does not have to read the data from the tables for specific queries; instead, it may retrieve the information it needs directly from the metadata. These queries include things like count queries and queries containing functions like MIN or MAX. The metadata cache will not be used if you execute MIN or MAX on a column containing only characters."}, "correct_response": ["a", "b"], "section": "Performance Concepts", "question_plain": "Which of the following operations can be fulfilled without needing an active virtual warehouse? Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70942428, "assessment_type": "multiple-choice", "prompt": {"question": "What is the maximum period for a query result cache to be retained?", "answers": ["31 days", "24 hours"], "explanation": "The query result cache for a query has an initial validity period of twenty-four hours. The cache is purged if a new query doesn&#39;t reuse the previously generated cache within 24 hours. If a new query uses the result cache, the validity period for the query result cache is reset to another 24 hours. It is now valid for another 24 hours from when it was reused. This extension of the first query result cache can continue for up to a maximum of 31 days from the point in time when a query result cache was initially produced. After 31 days, the query result cache for a query is purged altogether. \n  \n https://docs.snowflake.com/en/user-guide/querying-persisted-results"}, "correct_response": ["a"], "section": "Performance Concepts", "question_plain": "What is the maximum period for a query result cache to be retained?", "related_lectures": []}, {"_class": "assessment", "id": 70942430, "assessment_type": "multiple-choice", "prompt": {"question": "True or False. The local disk cache is purged when a virtual warehouse is suspended.", "answers": ["True", "False"], "explanation": "Every time a virtual warehouse accesses data from a table, it caches that data locally. This data cache can improve the performance of subsequent queries if those queries can reuse the data in the cache instead of reading from the table in the cloud storage. Reading from a local cache is a much more efficient operation than reading data from the cloud storage; therefore, it improves performance for queries that can take advantage of it. \n  \n  \n The warehouse cache is purged if the virtual warehouse is suspended. When the virtual house is resumed, the warehouse cache is rebuilt over time as queries are processed.\n  \n  \n https://docs.snowflake.com/en/user-guide/warehouses-considerations#how-does-warehouse-caching-impact-queries"}, "correct_response": ["a"], "section": "Performance Concepts", "question_plain": "True or False. The local disk cache is purged when a virtual warehouse is suspended.", "related_lectures": []}, {"_class": "assessment", "id": 70942432, "assessment_type": "multi-select", "prompt": {"question": "Which of the following correctly describes Automatic Clustering? Select all that apply.", "answers": ["Automatic Clustering is a serverless service.", "Automatic Clustering redistributes data in micro-partitions based on the clustering key.", "Automatic Clustering requires an active virtual warehouse to be running.", "Automatic Clustering can be turned off at the account level."], "explanation": "For tables with a clustering key defined, Automatic Clustering, a Snowflake service, manages the re-clustering as needed, distributing data according to the clustering key. Snowflake internally maintains the clustered tables and any resource requirements with Automatic Clustering. Automatic Clustering only adjusts those micro-partitions which benefit from the re-clustering process.\n  \n https://docs.snowflake.com/en/user-guide/tables-auto-reclustering"}, "correct_response": ["a", "b"], "section": "Performance Concepts", "question_plain": "Which of the following correctly describes Automatic Clustering? Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70942434, "assessment_type": "multiple-choice", "prompt": {"question": "True or False: When a clustering key is changed for a table, there may be a serverless cost associated with it.", "answers": ["True", "False"], "explanation": "For tables with a clustering key defined, Automatic Clustering, a Snowflake service, re-clusters the micro-partitions as needed, distributing data according to the clustering key to achieve appropriate partition pruning. Snowflake internally maintains the clustered tables and any resource requirements with Automatic Clustering. Automatic Clustering only adjusts those micro-partitions which benefit from the re-clustering process. Automatic Clustering does not need a virtual warehouse but uses Snowflake-managed CPU, RAM, etc. Therefore, it has a cost attached, which should appear under serverless costs. Clustering a table uses credits like any other data modification (DML) action in Snowflake. Re-clustering also adds extra storage when data is physically redistributed and new micro-partitions are created. The original micro-partitions are kept for Time Travel and Fail-safe purposes, resulting in increased storage.\n  \n https://docs.snowflake.com/en/user-guide/tables-auto-reclustering#credit-usage-and-warehouses-for-automatic-clustering"}, "correct_response": ["a"], "section": "Performance Concepts", "question_plain": "True or False: When a clustering key is changed for a table, there may be a serverless cost associated with it.", "related_lectures": []}, {"_class": "assessment", "id": 70942436, "assessment_type": "multiple-choice", "prompt": {"question": "<p><strong>Which of the following illustration represents the least well-clustered table?</strong>\n</p><img src=\"https://img-b.udemycdn.com/redactor/raw/practice_test_question/2023-03-29_20-26-35-a87bc235a7fbf223a63983791d0101e3.png\"><p><br></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "For a populated table, the clustering depth is the average depth of overlapping micro-partitions for specific columns. The clustering depth starts at 1 (for a well-clustered table) and can be a larger number.\n If the average depth is smaller, the data for the specified columns are better clustered.\n  \n https://docs.snowflake.com/en/user-guide/tables-clustering-micropartitions#label-clustering-depth", "answers": ["4", "1", "2", "3"]}, "correct_response": ["a"], "section": "Performance Concepts", "question_plain": "Which of the following illustration represents the least well-clustered table?", "related_lectures": []}, {"_class": "assessment", "id": 70942438, "assessment_type": "multiple-choice", "prompt": {"question": "When creating a clustering key with multiple columns, in what order should the columns be specified in the CLUSTER BY clause?", "answers": ["Lowest cardinality to highest cardinality.", "Highest cardinality to lowest cardinality.", "The order does not matter.", "Alphabetical order.", "Reverse alphabetical order."], "explanation": "When defining clustering keys, the initial candidate clustering columns are those columns that are frequently used in the WHERE clause or other selective filters. \n  \n Additionally, columns that are used for joining can also be considered.\n  \n Furthermore, the columns&#39; cardinality (number of distinct values) is also important. It is crucial to choose a column with a high enough cardinality to allow effective partition pruning while having a low enough cardinality for Snowflake to group data into micro-partitions efficiently. A column with too few distinct values (e.g., gender) will result in minimal partition pruning. On the other hand, a column that has too many distinct values (e.g., customer id) will result in too much overhead when maintaining the partitions.\n  \n When creating a multi-column cluster key, order the columns from the lowest cardinality to the higher cardinality; otherwise, the effectiveness of clustering will be reduced.\n  \n https://docs.snowflake.com/en/user-guide/tables-clustering-keys"}, "correct_response": ["a"], "section": "Performance Concepts", "question_plain": "When creating a clustering key with multiple columns, in what order should the columns be specified in the CLUSTER BY clause?", "related_lectures": []}, {"_class": "assessment", "id": 70942440, "assessment_type": "multi-select", "prompt": {"question": "What are some of the ways to improve performance in Snowflake? Select all that apply", "answers": ["Clustering Keys", "Dedicated Virtual Warehouse", "Multi-cluster Virtual Warehouse", "Query Result Caching", "Secondary Indices"], "explanation": "Snowflake&#39;s unique architecture and the underlying micro-partitions storage technology mean it is not required to perform much query tuning in most situations. There are, however, several performance improvement approaches that are available and are used to increase Snowflake&#39;s overall performance. \n  \n These include\n  \n \u00b7 Internal caching mechanisms that operate transparently in the background to increase performance.\n \u00b7 Scaling up or increasing the capacity of a virtual warehouse to allow for more processing power to be available for complex queries\n \u00b7 Horizontal scaling by increasing the capacity by using a multi-cluster virtual warehouse to handle a large number of concurrent users and concurrent queries\n \u00b7 Automatic static and dynamic partition pruning can reduce unneeded partitions while processing a query.\n \u00b7 It is possible to accomplish better partition pruning by redistributing data in micro-partitions using clustering keys.\n \u00b7 Pre-computing results of complex, regularly executed queries by using materialized views.\n \u00b7 Using Search Optimization services to improve the performance of specific types of lookup queries"}, "correct_response": ["a", "b", "c", "d"], "section": "Performance Concepts", "question_plain": "What are some of the ways to improve performance in Snowflake? Select all that apply", "related_lectures": []}, {"_class": "assessment", "id": 70942442, "assessment_type": "multiple-choice", "prompt": {"question": "<p><strong>You are the Data warehouse administrator at a large bank running the Enterprise edition of Snowflake as their data warehouse solution. You have noticed that every month's end, the number of queries executed on Snowflake by the finance department increases many times. </strong></p><p><strong>Although the finance department has a large (L) virtual warehouse, user queries must wait (queue) while the previous queries complete. </strong></p><p><strong>What is the best course of action to improve the user experience during month-ends while minimizing costs?</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "Multi-cluster virtual warehouses are frequently used in scenarios where the number of concurrent queries exceeds the capacity of a single virtual warehouse. When a virtual warehouse&#39;s concurrent workload exceeds its maximum capacity, additional queries are placed in the queue. Multi-cluster virtual warehouses dynamically add additional clusters based on demand to solve the queueing issue. When demand decreases, the additional clusters are decommissioned. This process is also known as scaling out or auto-scaling.\n  \n https://docs.snowflake.com/en/user-guide/warehouses-multicluster", "answers": ["Configure the finance virtual warehouse to be a multi-clustered virtual warehouse. The multi-cluster virtual warehouse will auto-spawn (and auto shutdown) additional virtual warehouses as the demand increases and decreases.", "Permanently increase the size of the virtual warehouse dedicated to finance to XL. This will ensure increased performance throughout the month and not just at the month-end.", "Disable finance users during the month-end processing so that the load on the system decreases.", "<p><strong>Increase the size of the virtual warehouse dedicated to finance from L to XL during the month-end processing. This increase will double the processing power of the virtual warehouse and will result in queries finishing faster. </strong></p><p><strong>In addition, reduce the size of the virtual warehouse after the month-end period is complete.</strong></p>"]}, "correct_response": ["a"], "section": "Performance Concepts", "question_plain": "You are the Data warehouse administrator at a large bank running the Enterprise edition of Snowflake as their data warehouse solution. You have noticed that every month's end, the number of queries executed on Snowflake by the finance department increases many times. Although the finance department has a large (L) virtual warehouse, user queries must wait (queue) while the previous queries complete. What is the best course of action to improve the user experience during month-ends while minimizing costs?", "related_lectures": []}, {"_class": "assessment", "id": 70942444, "assessment_type": "multiple-choice", "prompt": {"question": "Consider the following scenario. Queries are running on a multi-cluster virtual warehouse of size Large, and the scaling policy is set to Standard. The warehouse is currently executing the maximum number of queries that it can accommodate. What happens when an additional query is run?", "answers": ["An additional virtual warehouse of size Large is added almost immediately to the cluster and runs the additional query.", "The size of the virtual warehouse is scaled up to 4X-Large.", "The multi-cluster virtual warehouse only adds a new virtual warehouse if the system determines there is enough work to keep it busy for at least 6 minutes."], "explanation": "When the scaling policy is set to Standard (also the default), Snowflake attempts to reduce queuing by launching additional warehouses soon after queuing is detected. As soon as queries start queuing or there are more queries than the present set of virtual warehouses can handle, the first additional warehouse is spun up immediately. Additional warehouses may be spun up if the volume of requests is causing queuing to continue. Additional warehouses are started 20 seconds after the preceding warehouse has started. \n  \n Once the workload starts diminishing, the system does 2-3 consecutive checks to assess whether the workload can be reallocated to other warehouses without the need to spin up another warehouse again. If the criteria are met, the virtual warehouse is scaled-down. The scale-down checks are carried out at one-minute intervals.\n  \n https://docs.snowflake.com/en/user-guide/warehouses-multicluster#setting-the-scaling-policy-for-a-multi-cluster-warehouse"}, "correct_response": ["a"], "section": "Performance Concepts", "question_plain": "Consider the following scenario. Queries are running on a multi-cluster virtual warehouse of size Large, and the scaling policy is set to Standard. The warehouse is currently executing the maximum number of queries that it can accommodate. What happens when an additional query is run?", "related_lectures": []}, {"_class": "assessment", "id": 70942446, "assessment_type": "multi-select", "prompt": {"question": "A multi-clustered virtual warehouse is configured in Auto Scaling mode. Which of the following Scaling Policies does it support? Select two options.", "answers": ["Standard", "Economy", "Efficient", "Fast"], "explanation": "With the scaling policy set to Standard, Snowflake prefers to spin up extra virtual warehouses almost as soon as it detects that queries are starting to queue up. The Standard scaling policy aims to prevent or minimize queuing.\n  \n The Economy scaling policy attempts to conserve credits over performance and user experience. It doesn&#39;t spin up more virtual warehouses as soon as queuing is observed but instead applies additional criteria to ascertain whether or not to spin up new virtual warehouses.\n  \n The scaling policies are applied only when a virtual warehouse is running in the auto-scale mode because all clusters are automatically started anyway in a maximized manner, and a scaling policy does not have much use. \n  \n https://docs.snowflake.com/en/user-guide/warehouses-multicluster#setting-the-scaling-policy-for-a-multi-cluster-warehouse"}, "correct_response": ["a", "b"], "section": "Performance Concepts", "question_plain": "A multi-clustered virtual warehouse is configured in Auto Scaling mode. Which of the following Scaling Policies does it support? Select two options.", "related_lectures": []}, {"_class": "assessment", "id": 70942448, "assessment_type": "multi-select", "prompt": {"question": "A query executed in Snowflake took a long duration to complete. The Query Profile shows that the \u201cBytes spilled to local storage\u201d was a large number. How can the query performance be improved? Select all that apply.", "answers": ["Increase the size of the virtual warehouse so that more data can fit in the memory.", "Rewrite the query more optimally so that the partition pruning occurs and the query needs to process less data.", "Restart the virtual warehouse to clear the local disk cache.", "Run the query on a multi-cluster virtual warehouse."], "explanation": "One of the ways to avoid spilling is to use a larger warehouse, which will increase the overall available RAM, local storage, and parallelism and might be able to fit the query in memory.\n Another way to optimize a query that spills a lot of data is to limit the number of rows that must be processed. Sometimes this may be achievable by rewriting the query more optimally. \n Clustering a large table can also help since it allows Snowflake to read only the necessary subset of the data, thus reducing the memory requirement. \n  \n https://docs.snowflake.com/en/user-guide/ui-query-profile#queries-too-large-to-fit-in-memory"}, "correct_response": ["a", "b"], "section": "Performance Concepts", "question_plain": "A query executed in Snowflake took a long duration to complete. The Query Profile shows that the \u201cBytes spilled to local storage\u201d was a large number. How can the query performance be improved? Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70942450, "assessment_type": "multiple-choice", "prompt": {"question": "<p><strong>Consider the following snippet from the query profile of a finished query. </strong>\n</p><img src=\"https://img-b.udemycdn.com/redactor/raw/practice_test_question/2023-03-29_20-27-29-bc36291419e3665f0a273c0c4a808217.png\"><p>\n<strong> Which of the following accurately describes the highlighted statistics?</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "Partition pruning occurs when the number of Partitions scanned is much smaller than Partitions total.\n  \n If the partitions scanned equal the partition total, the query scanned the complete table. Therefore, no partition pruning happened, and the clustering key should be improved.\n  \n https://docs.snowflake.com/en/user-guide/ui-query-profile", "answers": ["The query profile indicates ineffective partition pruning.", "The query profile indicates extremely effective partition pruning.", "The query profile indicates that the virtual warehouse used is too small for the query.", "The query profile indicates that the metadata cache was used."]}, "correct_response": ["a"], "section": "Performance Concepts", "question_plain": "Consider the following snippet from the query profile of a finished query. \n\n Which of the following accurately describes the highlighted statistics?", "related_lectures": []}, {"_class": "assessment", "id": 70942452, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>Consider the query profile for a specific step in a query. </strong>&nbsp; &nbsp;</p><img src=\"https://img-b.udemycdn.com/redactor/raw/practice_test_question/2023-03-29_20-28-09-a6e1ef53f51044f9661489dd4195473a.png\"><p>\n&nbsp; \n<strong> Which of the following accurately describes the highlighted statistics? Select all that apply.</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "Snowflake saves data on the warehouse&#39;s local disk if it can&#39;t fit an operation into memory. Data spilling slows down queries because it requires more IO operations, and disk access is slower than memory access. &quot;Bytes spilled to local storage.&quot; indicates local spillage.\n  \n Snowflake will spill data to remote cloud storage if the local disk becomes full, which is even slower storage than the local disk, making this operation even slower. &quot;Bytes spilled to remote storage&quot; in the query profile indicates remote spillage.\n  \n One of the ways to avoid spilling is to use a larger warehouse, which will increase the overall available RAM, local storage, and parallelism and might be able to fit the query in memory.\n  \n https://docs.snowflake.com/en/user-guide/ui-query-profile#queries-too-large-to-fit-in-memory", "answers": ["The query profile indicates that the step is too significant to fit in the virtual warehouse memory.", "A larger virtual warehouse size will likely reduce local and remote spilling.", "The query profile indicates effective partition pruning.", "The query profile indicates that the metadata cache was used."]}, "correct_response": ["a", "b"], "section": "Performance Concepts", "question_plain": "Consider the query profile for a specific step in a query. &nbsp; &nbsp;\n&nbsp; \n Which of the following accurately describes the highlighted statistics? Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70942454, "assessment_type": "multi-select", "prompt": {"question": "Which of the following statements correctly describe Search Optimization in Snowflake? Select all that apply.", "relatedLectureIds": "", "feedbacks": ["", "", ""], "explanation": "The search optimization service can significantly enhance the performance of some lookup and analytical queries that use many predicates for filtering.\n The search optimization service uses a persistent data structure as an optimized search access path to speed up point lookups.\n  \n When the data in the table is changed (for example, by loading new data sets or performing their DML operations), the maintenance service updates the search access path to reflect the changes.\n  \n The search optimization configuration on a table and the maintenance service are transparent to the users.\n  \n https://docs.snowflake.com/en/user-guide/search-optimization-service", "answers": ["<p><strong>The search optimization configuration on a table and its maintenance service are transparent to the users.</strong></p>", "The search optimization service uses a persistent data structure", "The search optimization service doesn&#39;t use a persistent data structure."]}, "correct_response": ["a", "b"], "section": "Performance Concepts", "question_plain": "Which of the following statements correctly describe Search Optimization in Snowflake? Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70942456, "assessment_type": "multiple-choice", "prompt": {"question": "You are the solution architect for a large retail company running a Snowflake data warehouse. Your Snowflake implementation has just gone live with a single virtual warehouse used by users across the organization. One of your heaviest users is the Finance department, which has a large number of users and executes a large number of queries. The finance department has complained that the queries take a long time to execute. What is the best immediate action you should take to improve their experience?", "answers": ["Introduce a dedicated virtual warehouse instance for the finance department and size it according to their needs. Set the new virtual warehouse to auto-suspend and auto-resume.", "Increase the size of your single virtual warehouse to the maximum size available so that queries for all users (not just finance) execute faster.", "Limit the number of queries that the finance department can execute."], "explanation": "By using dedicated virtual warehouses, you can isolate the workload for a specific user group. In this case, dedicating a virtual warehouse for the finance users will ensure that they get maximum and dedicated performance."}, "correct_response": ["a"], "section": "Performance Concepts", "question_plain": "You are the solution architect for a large retail company running a Snowflake data warehouse. Your Snowflake implementation has just gone live with a single virtual warehouse used by users across the organization. One of your heaviest users is the Finance department, which has a large number of users and executes a large number of queries. The finance department has complained that the queries take a long time to execute. What is the best immediate action you should take to improve their experience?", "related_lectures": []}, {"_class": "assessment", "id": 70942458, "assessment_type": "multi-select", "prompt": {"question": "Which of the following statements is true for Snowflake&#39;s key pair authentication? Select all that apply", "answers": ["If desired, the keys can be rotated.", "A user may have up to two public keys allocated to them.", "It requires inputting your Snowflake username and password for every login attempt", "Key-pair authentication is supported only by the Business-Critical edition"], "explanation": "Snowflake provides an additional layer of security by supporting key pair authentication in addition to the standard username/password login. This approach comprises private and public keys, with the public key allocated to a user and the private key used for authentication. The user provides a public key during authentication. A user can have up to two public keys, which can be rotated at any point in time. Key pair authentication is supported by all SnowSQL and Snowflake drivers and connectors. All Snowflake editions support Key-pair authentication\n  \n https://docs.snowflake.com/en/user-guide/key-pair-auth"}, "correct_response": ["a", "b"], "section": "Security", "question_plain": "Which of the following statements is true for Snowflake&#39;s key pair authentication? Select all that apply", "related_lectures": []}, {"_class": "assessment", "id": 70942460, "assessment_type": "multiple-choice", "prompt": {"question": "True or False: An ACCOUNTADMIN or SECURITYADMIN can disable a user&#39;s MFA and allow the user to re-enroll in MFA if required.", "answers": ["True", "False"], "explanation": "Multi-factor authentication (MFA) is enabled by default for all Snowflake accounts, and any Snowflake user can enroll themselves in MFA through the Snowflake web interface. An administrator can disable a user&#39;s MFA enrolment; in this case, the user must re-enroll to access the MFA features and functionality.\n  \n An administrator with the SECURITYADMIN or above role can disable MFA for a user. \n  \n https://docs.snowflake.com/en/user-guide/security-mfa"}, "correct_response": ["a"], "section": "Security", "question_plain": "True or False: An ACCOUNTADMIN or SECURITYADMIN can disable a user&#39;s MFA and allow the user to re-enroll in MFA if required.", "related_lectures": []}, {"_class": "assessment", "id": 70942462, "assessment_type": "multi-select", "prompt": {"question": "Which of the following statements best describe Snowflake&#39;s federated authentication? Select all that apply", "answers": ["Snowflake has native support for Okta and ADFS.", "Once authenticated with an external identity provider, a user is not required to submit their Snowflake username &amp; password individually.", "Snowflake is compatible with the majority of SAML 2.0 identity providers.", "After being authorized by an external identity source, users must enter their Snowflake username and password."], "explanation": "Snowflake supports federated authentication, allowing for single sign-on (SSO). Users authenticate using a SAML 2.0-compliant external identity provider (IdP). After IdP authentication, users can access Snowflake without logging in. Snowflake natively supports the majority of SAML 2.0 compliant identity providers, including Okta, ADFS, OneLogin, and Ping Identity PingOne.\n  \n https://docs.snowflake.com/en/user-guide/admin-security-fed-auth"}, "correct_response": ["a", "b", "c"], "section": "Security", "question_plain": "Which of the following statements best describe Snowflake&#39;s federated authentication? Select all that apply", "related_lectures": []}, {"_class": "assessment", "id": 70942466, "assessment_type": "multiple-choice", "prompt": {"question": "In Snowflake, all data at rest is encrypted using which encryption method?", "answers": ["AES 256-bit encryption", "AES 128-bit encryption", "MD5", "SHA"], "explanation": "In Snowflake, all data at rest is encrypted using AES 256-bit encryption.\n  \n https://docs.snowflake.com/en/user-guide/security-encryption-manage"}, "correct_response": ["a"], "section": "Security", "question_plain": "In Snowflake, all data at rest is encrypted using which encryption method?", "related_lectures": []}, {"_class": "assessment", "id": 70942468, "assessment_type": "multi-select", "prompt": {"question": "Snowflake performs encryption in transit using TLS 1.2. Snowflake can do encryption in transit for which of the following tools? Select all that apply.", "answers": ["SnowSQL", "Snowflake Web UI", "JDBC Connector", "ODBC Connector"], "explanation": "Snowflake encrypts all data in transit using Transport Layer Security (TLS) 1.2. This applies to all Snowflake connections, including those made through the Snowflake Web interface, JDBC, ODBC, and the Python connector.\n  \n https://docs.snowflake.com/en/user-guide/security-encryption-end-to-end"}, "correct_response": ["a", "b", "c", "d"], "section": "Security", "question_plain": "Snowflake performs encryption in transit using TLS 1.2. Snowflake can do encryption in transit for which of the following tools? Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70942470, "assessment_type": "multi-select", "prompt": {"question": "Which of the following roles are available out of the box in Snowflake?", "answers": ["USERADMIN", "ACCOUNTADMIN", "SECURITYADMIN", "ROOT"], "explanation": "Built-in Snowflake roles include ORGADMIN, ACCOUNTADMIN, USERADMIN, SECURITYADMIN, SYSADMIN, and PUBLIC.\n  \n https://docs.snowflake.com/en/user-guide/security-access-control-overview#system-defined-roles"}, "correct_response": ["a", "b", "c"], "section": "Security", "question_plain": "Which of the following roles are available out of the box in Snowflake?", "related_lectures": []}, {"_class": "assessment", "id": 70942472, "assessment_type": "multi-select", "prompt": {"question": "Which of the following statements best describe Snowflake&#39;s access control mechanism? Select all that apply.", "answers": ["Roles can be granted to other roles.", "Roles can be granted to other users.", "Privileges can be granted on securable objects.", "Roles can NOT be granted to other roles."], "explanation": "Objects or entities that can be granted privileges are called securable objects. Each securable object can be assigned a set of rights. Privileges can only be granted to roles; they cannot be granted directly to individual users. Therefore, it is possible to grant roles to other users or other roles. \n  \n https://docs.snowflake.com/en/user-guide/security-access-control-overview"}, "correct_response": ["a", "b", "c"], "section": "Security", "question_plain": "Which of the following statements best describe Snowflake&#39;s access control mechanism? Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70942474, "assessment_type": "multi-select", "prompt": {"question": "Which of the following roles can create &amp; manage users? Select all that apply", "answers": ["SECURITYADMIN", "ACCOUNTADMIN", "USERADMIN", "SYSADMIN"], "explanation": "The USERADMIN role is typically meant for creating and managing users. However, the privileges of the USERADMIN role are inherited by SECURITYADMIN and ACCOUNTADMIN; therefore, they also get the privileges to create users. ACCOUNTADMIN is the most powerful role anyway and can do anything in a Snowflake account.\n  \n https://docs.snowflake.com/en/user-guide/security-access-control-overview#system-defined-roles."}, "correct_response": ["a", "b", "c"], "section": "Security", "question_plain": "Which of the following roles can create &amp; manage users? Select all that apply", "related_lectures": []}, {"_class": "assessment", "id": 70942476, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>Which of the following contributes toward the costs of a Snowflake system?</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>Virtual warehouses in a resumed (active) state contribute to the costs. However, it does not matter if the virtual warehouse is not running a query; if it is resumed, it contributes to the costs.</p><p> https://docs.snowflake.com/en/user-guide/cost-understanding-compute</p><p>Snowflake charges for data storage in database tables, files staged in internal stages, time travel history, and fail-safe storage.</p><p>https://docs.snowflake.com/en/user-guide/cost-understanding-data-storage</p>", "answers": ["Active virtual warehouses.", "The amount of storage used.", "Number of tables", "Number of Users"]}, "correct_response": ["a", "b"], "section": "Cost & Pricing", "question_plain": "Which of the following contributes toward the costs of a Snowflake system?", "related_lectures": []}, {"_class": "assessment", "id": 70942478, "assessment_type": "multi-select", "prompt": {"question": "Snowflake provides which of the following connectors?", "answers": ["Snowflake Connector for Python", "Snowflake Connector for Spark", "Snowflake Connector for Kafka", "Snowflake Connector for Assembly", "Snowflake Connector for Cobol"], "explanation": "Snowflake has several drivers and connectors that can be used to connect to your Snowflake instance. These include client tools made by Snowflake, like the web interface and the SnowSQL command-line interface, and drivers and connectors that let different languages and frameworks connect to Snowflake. The following drivers and connectors are currently available\n \u00b7 Snowflake Connector for Python\n \u00b7 Snowflake Connector for Spark\n \u00b7 Snowflake Connector for Kafka\n \u00b7 JDBC driver for Snowflake\n \u00b7 ODBC driver for Snowflake\n \u00b7 .NET driver for Snowflake\n \u00b7 Snowflake driver for the Go language\n \u00b7 Node.js drivers\n PHP PDO drivers"}, "correct_response": ["a", "b", "c"], "section": "Tools & Interfaces", "question_plain": "Snowflake provides which of the following connectors?", "related_lectures": []}, {"_class": "assessment", "id": 70942480, "assessment_type": "multiple-choice", "prompt": {"question": "Which of the following statements best describes Snowsight?", "answers": ["A web-based interface to connect to your Snowflake instance.", "A command-line interface to connect to your Snowflake instance.", "A mobile app to connect to your Snowflake instance.", "A lightweight desktop application with a user interface to administer your Snowflake instance."], "explanation": "Snowsight is a modern and lightweight web interface using new technologies and is a primary method of interacting with your Snowflake instance.\n  \n https://docs.snowflake.com/en/user-guide/ui-snowsight"}, "correct_response": ["a"], "section": "Tools & Interfaces", "question_plain": "Which of the following statements best describes Snowsight?", "related_lectures": []}, {"_class": "assessment", "id": 70942482, "assessment_type": "multiple-choice", "prompt": {"question": "Which of the following statements best describes SnowSQL?", "answers": ["A command-line interface to connect to your Snowflake instance", "A web-based interface to connect to your Snowflake instance.", "A mobile app that can be used to connect to your Snowflake instance.", "A lightweight desktop application with a user interface to administer your Snowflake instance."], "explanation": "SnowSQL connects to Snowflake through the command line and executes SQL queries on your Snowflake instance. SnowSQL is available for Linux, Windows, and Mac OS.\n  \n https://docs.snowflake.com/en/user-guide/snowsql"}, "correct_response": ["a"], "section": "Tools & Interfaces", "question_plain": "Which of the following statements best describes SnowSQL?", "related_lectures": []}, {"_class": "assessment", "id": 70942484, "assessment_type": "multiple-choice", "prompt": {"question": "Which of the following layer facilitates the cloning of tables?", "answers": ["Cloud Services Layer", "Query Processing Layer", "Cloning Management Layer", "Sharing Management Layer"], "explanation": "Cloning is achieved through metadata operation performed in the cloud services layer. Data is not physically copied, nor are new micro-partitions created\u2014instead, the cloned table points to the micro-partitions of the source table.\n  \n https://docs.snowflake.com/en/user-guide/tables-storage-considerations#label-cloning-tables"}, "correct_response": ["a"], "section": "Cloning", "question_plain": "Which of the following layer facilitates the cloning of tables?", "related_lectures": []}, {"_class": "assessment", "id": 70942486, "assessment_type": "multi-select", "prompt": {"question": "A cloned object does not contribute towards the overall storage unless which of the following conditions are met?", "answers": ["Data is changed in the source table.", "Data is changed in the cloned table.", "The CREATE_COPY parameter is set to true while cloning data.", "The cloned object is too big."], "explanation": "When tables, schemas, or databases are cloned, the cloned item does not contribute to total storage until data manipulation language (DML) operations are performed on the source or target, which modify or delete existing data or add additional data.\n  \n https://docs.snowflake.com/en/user-guide/tables-storage-considerations#label-cloning-tables"}, "correct_response": ["a", "b"], "section": "Cloning", "question_plain": "A cloned object does not contribute towards the overall storage unless which of the following conditions are met?", "related_lectures": []}, {"_class": "assessment", "id": 70942488, "assessment_type": "multi-select", "prompt": {"question": "Which of the following objects can be cloned? Select all that apply.", "answers": ["Database", "Schema", "Table", "Task", "Virtual Warehouse", "Share"], "explanation": "Virtual warehouses &amp; Share objects cannot be cloned.\n \n Tables, Schemas &amp; Databases can be cloned.\n Other objects that can be cloned include Stages, File Formats, Tasks, Sequences, and Streams.\n  \n https://docs.snowflake.com/en/user-guide/object-clone"}, "correct_response": ["a", "b", "c", "d"], "section": "Cloning", "question_plain": "Which of the following objects can be cloned? Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70942490, "assessment_type": "multiple-choice", "prompt": {"question": "True or False: If a database or a schema Is cloned, the child object privileges are automatically copied.", "answers": ["True", "False"], "explanation": "A cloned object does not inherit any privileges from its source object; for instance, a cloned table does not inherit any privileges from its source table. However, if a database or schema is cloned, privileges are inherited by the child objects.\n  \n https://docs.snowflake.com/en/user-guide/object-clone#access-control-privileges-for-cloned-objects"}, "correct_response": ["a"], "section": "Cloning", "question_plain": "True or False: If a database or a schema Is cloned, the child object privileges are automatically copied.", "related_lectures": []}, {"_class": "assessment", "id": 70942492, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>A materialized view contributes to which of the following costs?</strong></p><p><br></p><p><strong>Select all that apply.</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>Each materialized view stores query results, which contributes to the storage use.</p><p><br></p><p>Snowflake also performs automatic background maintenance on materialized views to prevent them from getting out-of-date. When a base table is modified, all materialized views created on that table are updated by a background service utilizing Snowflake compute resource (serverless from the customer\u2019s point of view).</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/views-materialized#materialized-views-cost</p>", "answers": ["<p><strong>Storage Costs</strong></p>", "<p><strong>Serverless Costs</strong></p>", "<p><strong>Virtual Warehouse Costs</strong></p>", "<p><strong>Replication costs</strong></p>"]}, "correct_response": ["a", "b"], "section": "Cost & Pricing", "question_plain": "A materialized view contributes to which of the following costs?Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70942494, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>Which of the following actions can NOT be performed by a consumer account on a shared database?</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", "", "", ""], "explanation": "<p>Consumer accounts can only access and query data but cannot add, modify, or create database objects to a shared database.</p><p><br></p><p>Consumer accounts cannot clone a shared database, its schemas, or any of its tables.</p><p>Consumer accounts cannot use Time Travel on the shared data.</p><p>Consumer accounts cannot further share a shared database.</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/data-share-consumers#general-limitations-for-shared-databases</p>", "answers": ["<p><strong>Clone a table from the shared database.</strong></p>", "<p><strong>Clone the shared database.</strong></p>", "<p><strong>Use Time Travel on shared tables.</strong></p>", "<p><strong>Modify data in a shared table.</strong></p>", "<p><strong>Join data from a shared table with another table.</strong></p>", "<p><strong>Query data in a shared table.</strong></p>"]}, "correct_response": ["a", "b", "c", "d"], "section": "Data Sharing", "question_plain": "Which of the following actions can NOT be performed by a consumer account on a shared database?", "related_lectures": []}, {"_class": "assessment", "id": 70942496, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>Under which circumstances will the query result cache fulfill the query result? Select all that apply</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p>The underlying data and micro-partitions must not change, and the query should be syntactically identical for the query result cache to be used. The cache must have been generated (or last used) less than 24 hours ago.<br><br>https://docs.snowflake.com/en/user-guide/querying-persisted-results</p>", "answers": ["<p><strong>The micro-partitions for the tables in the query have not changed.</strong></p>", "<p><strong>The role executing the query has the necessary privileges on the tables used in the query.</strong></p>", "<p><strong>The query matches a previously executed query for which cached results are still available.</strong></p>", "<p><strong>The query is executed by the same user who generated the result cache for a previous query.</strong></p>", "<p><strong>New micro-partitions have been added to one of the tables used in the query.</strong></p>"]}, "correct_response": ["a", "b", "c"], "section": "Performance Concepts", "question_plain": "Under which circumstances will the query result cache fulfill the query result? Select all that apply", "related_lectures": []}, {"_class": "assessment", "id": 70942498, "assessment_type": "multiple-choice", "prompt": {"question": "<p><strong>What type of partners are Matillion, Informatica, IBM DataStage, Talend, and AbInitio within the Snowflake partner ecosystem?</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>All of these are Data Integration partners of Snowflake. Please see https://docs.Snowflake.com/en/user-guide/ecosystem.html</p>", "answers": ["<p><strong>Data Integration</strong></p>", "<p><strong>Business Intelligence</strong></p>", "<p><strong>Machine Learning &amp; Data Science</strong></p>", "<p><br></p><p><strong>Security, Governance &amp; Observability</strong></p>"]}, "correct_response": ["a"], "section": "Partners", "question_plain": "What type of partners are Matillion, Informatica, IBM DataStage, Talend, and AbInitio within the Snowflake partner ecosystem?", "related_lectures": []}, {"_class": "assessment", "id": 70942500, "assessment_type": "multiple-choice", "prompt": {"question": "<p><strong>What is the minimum required role to create a trial account through Partner Connect?</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p>Only users with the ACCOUNTADMIN role and a verified email address in Snowflake can access Partner Connect.</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/ecosystem-partner-connect#connecting-with-a-snowflake-partner</p>", "answers": ["<p><strong>ACCOUNTADMIN</strong></p>", "<p><strong>SECURITYADMIN</strong></p>", "<p><strong>ORGADMIN</strong></p>", "<p><strong>SYSADMIN</strong></p>", "<p><strong>PUBLIC</strong></p>"]}, "correct_response": ["a"], "section": "Partners", "question_plain": "What is the minimum required role to create a trial account through Partner Connect?", "related_lectures": []}, {"_class": "assessment", "id": 70942502, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>After a virtual warehouse has been suspended by a resource monitor, which of the following will allow the virtual warehouse to be resumed?</strong></p><p><br></p><p><strong>Select all that apply.</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p>If a monitor has a Suspend or Suspend Immediately action, and its used credits hit the threshold for the action, any warehouses assigned to the monitor are put on hold and can't be used again until one of the following happens:</p><p>\u2022 The next interval starts as per the monitor configuration. A monitor credit limit is applicable within a defined time interval (days, months, etc.)</p><p>\u2022 The credit quota for the monitor is increased.</p><p>\u2022 The credit threshold needed to suspend is increased.</p><p>\u2022 The virtual warehouse is removed from the monitor configuration (does not apply to account-level monitors)</p><p>\u2022 The monitor is dropped altogether.</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/resource-monitors</p>", "answers": ["<p><strong>The monitor's credit quota is increased.</strong></p><p><br></p><p><br></p><p><br></p><p><br></p>", "<p><strong>The credit threshold for the suspend action is increased.</strong></p>", "<p><strong>The next interval for the resource monitor starts.</strong></p>", "<p><strong>An account administrator resumes the virtual warehouse.</strong></p>", "<p><strong>The virtual warehouse is resumed using SnowSQL.</strong></p>"]}, "correct_response": ["a", "b", "c"], "section": "Account Usage & Monitoring", "question_plain": "After a virtual warehouse has been suspended by a resource monitor, which of the following will allow the virtual warehouse to be resumed?Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70942504, "assessment_type": "multiple-choice", "prompt": {"question": "<p><strong>Which of the following statements correctly describes natural clustering in Snowflake?</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>Typically, in data warehouses, data arrives and gets loaded daily. Without an explicit clustering key, Snowflake will cluster the data based on the order in which it was inserted into a table. Often natural clustering is good enough for large transactional tables with data arriving based on a date, such as an order table, in which rows often have an order date.</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/tables-clustering-micropartitions</p>", "answers": ["<p><strong>Snowflake clusters data in the order it was loaded into a table.</strong></p>", "<p><strong>Snowflake can determine the best clustering key based on the natural keys defined for the table.</strong></p>", "<p><strong>Natural clustering is the name of the service that maintains micro-partitions.</strong></p>", "<p><strong>Natural clustering is the process of defining explicit clustering keys.</strong></p>"]}, "correct_response": ["a"], "section": "Architecture", "question_plain": "Which of the following statements correctly describes natural clustering in Snowflake?", "related_lectures": []}, {"_class": "assessment", "id": 70942506, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>Which of the following statements are true regarding Snowflake virtual warehouse's high availability?</strong></p><p><strong>Select all that apply.</strong></p><p><br></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>Snowflake automatically &amp; transparently replaces failed compute instances within a virtual warehouse. This occurs without disruption to any queries.</p><p><br></p><p>The compute layer, i.e., the virtual warehouses, is not replicated. The virtual warehouses do not permanently store data and thus don\u2019t require replication.</p><p><br></p><p>Snowflake typically runs each virtual warehouse in a single availability zone. However, in case of an availability zone failure, Snowflake\u2019s cloud services layer can re-provision impacted warehouses in a different availability zone.</p><p><br></p><p>https://developers.snowflake.com/wp-content/uploads/2021/06/Snowflake-High-Availability-for-Data-Apps-Whitepaper.pdf</p>", "answers": ["<p><strong>Snowflake can provision Virtual Warehouses in a different availability zone if required.</strong></p>", "<p><strong>Snowflake will automatically replace failed compute instances within a virtual warehouse without causing disruptions.</strong></p>", "<p><strong>Snowflake replicates virtual warehouses across three availability zones.</strong></p>", "<p><strong>A failed virtual warehouse will result in corrupted data in tables.</strong></p>"]}, "correct_response": ["a", "b"], "section": "Architecture", "question_plain": "Which of the following statements are true regarding Snowflake virtual warehouse's high availability?Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70942508, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>Which of the following statements are true regarding the storage hierarchy in Snowflake?</strong></p><p><strong>Select all that apply.</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p>In Snowflake, the highest level is a Snowflake Account. Customers can have as many accounts as they like. Within an account, you have databases. Each database contains one or more schemas. Schemas contain other Objects. Tables, views, file formats, sequences, UDFs, and stored procedures are all examples of objects available in a schema. An object can be contained in only one schema.</p>", "answers": ["<p><strong>Tables are stored within Schemas.</strong></p>", "<p><strong>Schemas are stored within Databases.</strong></p>", "<p><strong>Databases are stored within Accounts.</strong></p>", "<p><strong>Databases are stored in Virtual Warehouses.</strong></p>", "<p><strong>Virtual Warehouses are stored in Databases.</strong></p>"]}, "correct_response": ["a", "b", "c"], "section": "Snowflake\u2019s catalog and objects", "question_plain": "Which of the following statements are true regarding the storage hierarchy in Snowflake?Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70942510, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>Which of the following statements regarding built-in roles' privileges in Snowflake are true?</strong></p><p><strong>Select all that apply.</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>Due to the role hierarchy and privileges inheritance, the ACCOUNTADMIN has all the privileges that lower roles have. Therefore, It can delete and modify objects created by lower roles.</p><p><br></p><p>Similarly, SECURITYADMIN is a higher role than USERADMIN and can drop a user created by the USERADMIN.</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/security-access-control-overview#system-defined-roles.</p>", "answers": ["<p><strong>ACCOUNTADMIN can delete objects created by a SYSADMIN</strong></p>", "<p><strong>SECURITYADMIN can drop USERS created by a USERADMIN</strong></p>", "<p><strong>ACCOUNTADMIN can modify a ROLE created by the SECURITYADMIN</strong></p>", "<p><strong>The PUBLIC role can delete objects created by SYSADMIN</strong></p>"]}, "correct_response": ["a", "b", "c"], "section": "Security", "question_plain": "Which of the following statements regarding built-in roles' privileges in Snowflake are true?Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70942512, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>Which of the following terms refers to the same layer in Snowflake architecture? Select all that apply.</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p>Query Processing Layer, Virtual Warehouses, Computer Layer, Compute Nodes, and Compute Clusters may be interchangeably used to refer to \"a layer providing query processing capability.\"</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/intro-key-concepts#query-processing</p>", "answers": ["<p><strong>Computer Layer</strong></p>", "<p><strong>Virtual Warehouses</strong></p>", "<p><strong>Query Processing Layer</strong></p>", "<p><strong>Cloud Layer</strong></p>", "<p><strong>Storage Layer</strong></p>"]}, "correct_response": ["a", "b", "c"], "section": "Architecture", "question_plain": "Which of the following terms refers to the same layer in Snowflake architecture? Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70942514, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>Which of the following terms may be used to describe Snowflake?</strong></p><p><strong>Select all that apply.</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", "", "", ""], "explanation": "<p>Snowflake has been designed for the cloud and has been designed from scratch.</p><p><br></p><p>Snowflake stores data similarly to a shared-disk architecture, i.e., the data is shared (disk isn't shared). It also allows for the use of several compute engines.</p><p><br></p><p>It provides Native SQL support and stores data in a hybrid columnar format.</p>", "answers": ["<p><strong>Native SQL support</strong></p>", "<p><strong>Hybrid Columnar Storage</strong></p>", "<p><strong>Shared Data</strong></p>", "<p><strong>Built from scratch, specifically designed for execution on cloud platforms.</strong></p>", "<p><strong>Shared Disk</strong></p>", "<p><strong>Shared Compute</strong></p>"]}, "correct_response": ["a", "b", "c", "d"], "section": "Architecture", "question_plain": "Which of the following terms may be used to describe Snowflake?Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70942516, "assessment_type": "multiple-choice", "prompt": {"question": "<p><strong>True or False: A directory table can be enabled while creating a Stage object or enabled afterward.</strong></p><p><br></p>", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "<p>A directory table is not a separate database object but is an implicit object available with a stage. You can enable the directory table for a stage while creating the stage or enable it afterward.</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/data-load-dirtables</p>", "answers": ["<p><strong>True</strong></p><p><br></p>", "<p><strong>False</strong></p>"]}, "correct_response": ["a"], "section": "Data Transformation", "question_plain": "True or False: A directory table can be enabled while creating a Stage object or enabled afterward.", "related_lectures": []}, {"_class": "assessment", "id": 70942518, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>You are required to regularly refresh the metadata for a directory table for an external stage. Which of the following methods can you use?</strong></p><p><strong>Select all that apply.</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>A directory table's metadata can be manually refreshed.</p><p>ALTER STAGE &lt;stage-name&gt; REFRESH;</p><p><br></p><p>In the case of an external stage, a directory table's metadata can also be automatically refreshed using cloud provider event notification services</p><p>AUTO_REFRESH = true</p><p>configuration for cloud provider notification.</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/data-load-dirtables-intro#automatically-refreshing-directory-table-metadata</p>", "answers": ["<p><strong>Run ALTER STAGE &lt;stage-name&gt; REFRESH; periodically to manually refresh the metadata.</strong></p>", "<p><strong>Configure even notifications on the cloud platform and set the stage to auto-refresh.</strong></p>", "<p><strong>Request Snowflake support to refresh the stage periodically.</strong></p>", "<p><strong>Configure a Resource Monitor to refresh the stage periodically.</strong></p>"]}, "correct_response": ["a", "b"], "section": "Data Transformation", "question_plain": "You are required to regularly refresh the metadata for a directory table for an external stage. Which of the following methods can you use?Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70942520, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>Which of the following statements are true regarding URL expiry?</strong></p><p><strong>Select all that apply.</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>A file URL is a permanent Snowflake-hosted URL to a staged file. File URLs don't expire.</p><p><br></p><p>A scoped URL is a temporary and encoded URL that allows temporary access to a staged file without requiring any privileges on the stage. A scoped URL expires after 24 hours.</p><p><br></p><p>A pre-signed URL is a simple HTTPS URL for accessing a file using a web browser. The expiry duration of a pre-signed URL is configurable and can be set to the required duration.</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/unstructured-intro#types-of-urls-available-to-access-files</p>", "answers": ["<p><strong>File URLs never expire.</strong></p>", "<p><strong>Scoped URLs expire after 24 hours.</strong></p>", "<p><strong>Scoped URLs don't expire.</strong></p>", "<p><strong>File URLs expire after 24 hours.</strong></p>"]}, "correct_response": ["a", "b"], "section": "Data Transformation", "question_plain": "Which of the following statements are true regarding URL expiry?Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70942524, "assessment_type": "multiple-choice", "prompt": {"question": "<p><strong>Which of the following ACCOUNT_USAGE view can be used to view credit usage by hour?</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>The METERING_HISTORY provides the credit usage data at an hourly level. The view provides the start and end times during which credit usage occurred. It also provides a breakup of the information according to the service that contributed to the credit usage, such as Virtual Warehouse compute usage, Snowpipe, Automatic Clustering, etc.</p><p><br></p><p><br></p><p>https://docs.snowflake.com/en/sql-reference/account-usage/metering_history</p>", "answers": ["<p><strong>METERING_HISTORY</strong></p>", "<p><strong>METERING_DAILY_HISTORY</strong></p>", "<p><strong>WAREHOUSE_LOAD_HISTORY</strong></p>", "<p><strong>WAREHOUSE_EVENTS_HISTORY</strong></p>"]}, "correct_response": ["a"], "section": "Account Usage & Monitoring", "question_plain": "Which of the following ACCOUNT_USAGE view can be used to view credit usage by hour?", "related_lectures": []}, {"_class": "assessment", "id": 70942526, "assessment_type": "multiple-choice", "prompt": {"question": "<p><strong>Which of the following ACCOUNT_USAGE view can be used to view privileges granted to roles?</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>The GRANTS_TO_ROLES view can be used to view information about access privileges granted to a role. This view also contains historical information (up to 365 days), so privileges that have been granted and revoked in the last 365 days will also be shown.</p><p><br></p><p>https://docs.snowflake.com/en/sql-reference/account-usage/grants_to_users</p>", "answers": ["<p><strong>GRANTS_TO_ROLES</strong></p>", "<p><strong>GRANTS_TO_USERS</strong></p>", "<p><strong>OBJECT_DEPENDENCIES</strong></p>", "<p><strong>ACCESS_HISTORY</strong></p>"]}, "correct_response": ["a"], "section": "Account Usage & Monitoring", "question_plain": "Which of the following ACCOUNT_USAGE view can be used to view privileges granted to roles?", "related_lectures": []}, {"_class": "assessment", "id": 70942528, "assessment_type": "multiple-choice", "prompt": {"question": "<p><strong>Consider the following resource monitor configuration.</strong></p><img src=\"https://img-b.udemycdn.com/redactor/raw/practice_test_question/2023-10-01_23-12-03-8c34d9d45859dac480de314435cb10f1.png\"><p><strong>What is the maximum credit that Warehouse 1 can use?</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p>Resource monitors can track &amp; manage a single virtual warehouse against a defined quota. Resource monitors can be created to track the credit usage of multiple virtual warehouses together.</p><p>Resource Monitors can also be created at the account level, which means that such resource monitors track credit usage at the account level, considering the credit usage of all virtual warehouses.</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/resource-monitors#assignment-of-resource-monitors</p>", "answers": ["<p><strong>500</strong></p>", "<p><strong>2000</strong></p>", "<p><strong>5000</strong></p>", "<p><strong>2500</strong></p>", "<p><strong>1000</strong></p>"]}, "correct_response": ["a"], "section": "Account Usage & Monitoring", "question_plain": "Consider the following resource monitor configuration.What is the maximum credit that Warehouse 1 can use?", "related_lectures": []}, {"_class": "assessment", "id": 70942530, "assessment_type": "multiple-choice", "prompt": {"question": "<p><strong>Consider a database with the name MARKETING. The database has a table called CUSTOMER in the PUBLIC schema. The table has <em>10,000</em> rows.</strong></p><p><br></p><p><strong>You create a temporary table with the same name, i.e., CUSTOMER, in the PUBLIC schema of the MARKETING database. This temporary table has <em>no </em>data.</strong></p><p><br></p><p><strong>Which of the following statements correctly describes the behavior for SELECT queries (in the same session) accessing the CUSTOMER table?</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>Like permanent and transient tables, temporary tables belong to a database &amp; schema. However, because they are limited to a session, the naming uniqueness constraints do not apply to them. Therefore, creating a temporary table with the same name as an existing table is possible. This can result in some potential conflicts and unexpected behavior.</p><p><br></p><p>If a temporary table is created in a schema with the same name as a permanent (or transient) table, the temporary table effectively hides the permanent table in that session. Queries and other operations during the session will affect only the temporary table.</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/tables-temp-transient#potential-naming-conflicts-with-other-table-types</p>", "answers": ["<p><strong>Executing \"SELECT * FROM MARKETING.PUBLIC.CUSTOMER;\" query returns zero rows.</strong></p>", "<p><strong>Executing \"SELECT * FROM MARKETING.PUBLIC.CUSTOMER;\" query fails with a duplicate error.</strong></p>", "<p><strong>Executing \"SELECT * FROM MARKETING.PUBLIC.CUSTOMER;\" query returns 10,000 rows.</strong></p>", "<p><strong>Executing \"SELECT * FROM MARKETING.PUBLIC.CUSTOMER;\" query fails with an unknown object error.</strong></p>"]}, "correct_response": ["a"], "section": "Snowflake\u2019s catalog and objects", "question_plain": "Consider a database with the name MARKETING. The database has a table called CUSTOMER in the PUBLIC schema. The table has 10,000 rows.You create a temporary table with the same name, i.e., CUSTOMER, in the PUBLIC schema of the MARKETING database. This temporary table has no data.Which of the following statements correctly describes the behavior for SELECT queries (in the same session) accessing the CUSTOMER table?", "related_lectures": []}, {"_class": "assessment", "id": 70942532, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>Which of the following correctly describes the behavior of a materialized view when columns are changed or dropped from the base table?</strong></p><p><br></p><p><strong>Select two answers.</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p>When columns are changed or dropped from a base table with a materialized view on top, the change is not propagated to the materialized view. The materialized view is suspended and can NOT be resumed. It must be re-created with the corrected definition that reflects the changed/dropped columns.</p><p><br></p><p><br></p><p>https://docs.snowflake.com/en/user-guide/views-materialized#changing-or-dropping-columns-in-the-base-table</p>", "answers": ["<p><strong>You must re-create the materialized view if you want to use it again.</strong></p>", "<p><strong>The materialized view is suspended.</strong></p>", "<p><strong>You must resume the materialized view if you want to use it again.</strong></p>", "<p><strong>The materialized view is NOT suspended.</strong></p>", "<p><strong>The changed and dropped columns are automatically propagated to the materialized view.</strong></p>"]}, "correct_response": ["a", "b"], "section": "Performance Concepts", "question_plain": "Which of the following correctly describes the behavior of a materialized view when columns are changed or dropped from the base table?Select two answers.", "related_lectures": []}, {"_class": "assessment", "id": 70942534, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>Which of the following correctly describes the behavior of a materialized view when new columns are added to the base table?</strong></p><p><br></p><p><strong>Select two answers.</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p>When new columns are added to a base table with a materialized view on top, the new columns are NOT propagated automatically to the materialized view. Even in a scenario where a SELECT * statement might be used in a materialized view; the new columns are NOT propagated because the columns of a materialized view are defined when the materialized view is defined.</p><p><br></p><p>Also, the materialized view is NOT suspended, so it can continue to be used.</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/views-materialized#adding-columns-to-the-base-table</p>", "answers": ["<p><strong>The new columns are NOT propagated to the materialized view automatically.</strong></p>", "<p><strong>The materialized view is NOT suspended.</strong></p>", "<p><strong>You must resume the materialized view if you want to use it again.</strong></p>", "<p><strong>The materialized view is suspended.</strong></p>", "<p><strong>The new columns are automatically propagated to the materialized view.</strong></p>"]}, "correct_response": ["a", "b"], "section": "Performance Concepts", "question_plain": "Which of the following correctly describes the behavior of a materialized view when new columns are added to the base table?Select two answers.", "related_lectures": []}, {"_class": "assessment", "id": 70942536, "assessment_type": "multiple-choice", "prompt": {"question": "<p><strong>Which of the following allows users to control how the data for a table is organized in micro-partitions?</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>For tables with a clustering key defined, Automatic Clustering, a Snowflake service, manages the re-clustering as needed, distributing data according to the clustering key. Snowflake internally maintains the clustered tables and any resource requirements with Automatic Clustering. Automatic Clustering only adjusts those micro-partitions that benefit from the re-clustering process.</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/tables-auto-reclustering</p>", "answers": ["<p><strong>Automatic Clustering</strong></p>", "<p><strong>Materialized Views</strong></p>", "<p><strong>Search Optimization</strong></p>", "<p><strong>Partition Pruning</strong></p>"]}, "correct_response": ["a"], "section": "Performance Concepts", "question_plain": "Which of the following allows users to control how the data for a table is organized in micro-partitions?", "related_lectures": []}, {"_class": "assessment", "id": 70942538, "assessment_type": "multiple-choice", "prompt": {"question": "<p><strong>Which of the following can improve the performance of point lookup queries?</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p>The search optimization service can be used to improve the performance of point lookup queries that return only one or a few rows and use highly selective filters using equality predicates or IN predicates.</p><p><br></p><p><br></p><p>https://docs.snowflake.com/en/user-guide/search-optimization-service#understanding-the-search-optimization-service</p>", "answers": ["<p><strong>Search Optimization</strong></p>", "<p><strong>Automatic Clustering</strong></p>", "<p><strong>External Tables</strong></p>", "<p><strong>Materialized Views</strong></p>", "<p><strong>Secure Views</strong></p>"]}, "correct_response": ["a"], "section": "Performance Concepts", "question_plain": "Which of the following can improve the performance of point lookup queries?", "related_lectures": []}, {"_class": "assessment", "id": 70942540, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>Which of the following factors drive the costs associated with materialized view maintenance?</strong></p><p><strong>Select two answers.</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>The costs of keeping data in materialized views are impacted by</p><p><br></p><p>1) The number of materialized views created for each base table.</p><p>2) The extent of data changes occurring in these materialized views when changes are made to the base table.</p><p>3) The number of these materialized views with a clustering key is defined.</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/views-materialized#label-materialized-views-maintenance-billing</p>", "answers": ["<p><strong>How frequently does the data in the base table change.</strong></p>", "<p><strong>Whether or not a clustering key is defined on the materialized view.</strong></p>", "<p><strong>How frequently is the materialized view queried.</strong></p>", "<p><strong>How frequently is the base table queried.</strong></p>"]}, "correct_response": ["a", "b"], "section": "Performance Concepts", "question_plain": "Which of the following factors drive the costs associated with materialized view maintenance?Select two answers.", "related_lectures": []}, {"_class": "assessment", "id": 70942542, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>Which of the following correctly describes the behaviour when a Transient table is attempted to be cloned?</strong></p><p><br></p><p><strong>Select two answers.</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>Transient tables can NOT be cloned to a permanent table.</p><p>Doing so will typically show the following error \u201cTransient object cannot be cloned to a permanent object.\u201d</p><p><br></p><p>However, a transient table may be cloned to a transient table or another temporary table.</p>", "answers": ["<p><strong>Transient tables can be cloned to transient tables.</strong></p>", "<p><strong>Transient tables can be cloned to temporary tables.</strong></p>", "<p><strong>Transient tables can be cloned to permanent tables.</strong></p>", "<p><strong>Transient tables can be cloned to external tables.</strong></p>"]}, "correct_response": ["a", "b"], "section": "Cloning", "question_plain": "Which of the following correctly describes the behaviour when a Transient table is attempted to be cloned?Select two answers.", "related_lectures": []}, {"_class": "assessment", "id": 70942544, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>What S3 permissions are required when unloading data from Snowflake to an AWS 3 location?</strong></p><p><br></p><p><strong>Select two answers.</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>Snowflake requires s3:DeleteObject &amp; s3:PutObject permissions on the target S3 bucket.</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/data-unload-s3#configuring-an-s3-bucket-for-unloading-data</p>", "answers": ["<p><strong>s3:DeleteObject</strong></p>", "<p><strong>s3:PutObject</strong></p>", "<p><strong>s3:ListBucket</strong></p>", "<p><strong>s3:GetObject</strong></p>"]}, "correct_response": ["a", "b"], "section": "Data Loading and Unloading", "question_plain": "What S3 permissions are required when unloading data from Snowflake to an AWS 3 location?Select two answers.", "related_lectures": []}, {"_class": "assessment", "id": 70942546, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>Columns with which data types can be used as clustering keys?</strong></p><p><br></p><p><strong>Select two.</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p>Clustering keys can be of any data type except GEOGRAPHY, VARIANT, OBJECT, or ARRAY</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/tables-clustering-keys#defining-a-clustering-key-for-a-table</p>", "answers": ["<p><strong>GEOMETRY</strong></p>", "<p><strong>BINARY</strong></p>", "<p><strong>GEOGRAPHY</strong></p>", "<p><strong>OBJECT</strong></p>", "<p><strong>VARIANT</strong></p>"]}, "correct_response": ["a", "b"], "section": "Performance Concepts", "question_plain": "Columns with which data types can be used as clustering keys?Select two.", "related_lectures": []}, {"_class": "assessment", "id": 70942548, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>Which of the following statistics indicate if partitioning pruning has occurred?</strong></p><p><br></p><p><strong>Select two.</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p>Partition pruning occurs when the number of Partitions scanned is much smaller than Partitions total.</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/ui-query-profile</p>", "answers": ["<p><strong>Partitions total</strong></p>", "<p><strong>Partitions scanned</strong></p>", "<p><strong>Bytes Scanned</strong></p>", "<p><strong>Bytes Written</strong></p>", "<p><strong>Total Bytes</strong></p>"]}, "correct_response": ["a", "b"], "section": "Performance Concepts", "question_plain": "Which of the following statistics indicate if partitioning pruning has occurred?Select two.", "related_lectures": []}, {"_class": "assessment", "id": 70942550, "assessment_type": "multiple-choice", "prompt": {"question": "<p><strong>Which of the following operations can be performed on an object provided by an inbound share?</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p>Shared objects are read-only for the consumer and cannot be modified by the consumer. A read-only database created on Share contains the tables and other objects that the data provider added, but the consumer cannot add additional objects. The consumer cannot UPDATE, DELETE data, ALTER, or DROP any objects.</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/data-sharing-intro</p>", "answers": ["<p><strong>SELECT</strong></p>", "<p><strong>DELETE</strong></p>", "<p><strong>DROP</strong></p>", "<p><strong>UPDATE</strong></p>", "<p><strong>ALTER</strong></p>"]}, "correct_response": ["a"], "section": "Data Sharing", "question_plain": "Which of the following operations can be performed on an object provided by an inbound share?", "related_lectures": []}, {"_class": "assessment", "id": 70942552, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>Which of the following Snowflake objects do not contribute towards storage costs?</strong></p><p><br></p><p><strong>Select two.</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p>Views &amp; Secure view do not use any storage. Both of these objects consist of an SQL statement, which is executed at runtime.</p><p><br></p><p>Materialized view persists the results of the SQL in its definition and, therefore, uses storage.</p><p><br></p><p>Both temporary and transient tables use storage.</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/views-introduction</p>", "answers": ["<p><strong>Secure View</strong></p>", "<p><strong>View</strong></p>", "<p><strong>Materialized View</strong></p>", "<p><strong>Temporary Table</strong></p>", "<p><strong>Transient Tables</strong></p>"]}, "correct_response": ["a", "b"], "section": "Snowflake\u2019s catalog and objects", "question_plain": "Which of the following Snowflake objects do not contribute towards storage costs?Select two.", "related_lectures": []}, {"_class": "assessment", "id": 70942554, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>In Snowflake, which of the following types of URLs can be used to access unstructured data?</strong></p><p><br></p><p><strong>Select all that apply.</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p>The three types of URLs that can be used to access unstructured data in cloud storage are Scoped URLs, File URLs, and Pre-signed URLs</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/unstructured-intro#types-of-urls-available-to-access-files</p>", "answers": ["<p><strong>Scoped URL</strong></p>", "<p><strong>File URL</strong></p>", "<p><strong>Pre-signed URL</strong></p>", "<p><strong>Samba URL</strong></p>", "<p><strong>Network Share Path</strong></p>"]}, "correct_response": ["a", "b", "c"], "section": "Data Transformation", "question_plain": "In Snowflake, which of the following types of URLs can be used to access unstructured data?Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70942556, "assessment_type": "multiple-choice", "prompt": {"question": "<p><strong>What are the implications if the number of concurrent users on a virtual warehouse is increased?</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>Concurrent queries share warehouse resources; thus, a high number of concurrent queries means each query gets fewer resources and will likely perform worse.</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/performance-query-warehouse-max-concurrency</p>", "answers": ["<p><strong>Decreased performance for large, complex queries</strong></p>", "<p><strong>Improved performance for all queries</strong></p>", "<p><strong>Improved performance for small, point lookup queries</strong></p>", "<p><strong>Improved performance for large, complex queries</strong></p>"]}, "correct_response": ["a"], "section": "Performance Concepts", "question_plain": "What are the implications if the number of concurrent users on a virtual warehouse is increased?", "related_lectures": []}, {"_class": "assessment", "id": 70942812, "assessment_type": "multiple-choice", "prompt": {"question": "<p><strong>A multi-cluster virtual warehouse of size X-Large has 1 cluster running for 1 hour. Due to query demands, it scales out (adds another cluster) and then runs the two clusters for another house. What is the total number of credits consumed by the multi-cluster virtual warehouse?</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>1 cluster of X-Large multi-cluster virtual warehouse running for 1 hour = 16 credits</p><p>2 clusters of X-Large multi-cluster virtual warehouse running for 1 hour = 16 credits * 2 = 32</p><p>Total = 48</p>", "answers": ["<p><strong>48</strong></p>", "<p><strong>16</strong></p>", "<p><strong>32</strong></p>", "<p><strong>64</strong></p>"]}, "correct_response": ["a"], "section": "Performance Concepts", "question_plain": "A multi-cluster virtual warehouse of size X-Large has 1 cluster running for 1 hour. Due to query demands, it scales out (adds another cluster) and then runs the two clusters for another house. What is the total number of credits consumed by the multi-cluster virtual warehouse?", "related_lectures": []}]}
4762416
~~~
{"count": 122, "next": null, "previous": null, "results": [{"_class": "assessment", "id": 70909930, "assessment_type": "multiple-choice", "prompt": {"question": "True or False: The INFORMATION_SCHEMA contains information on objects that have been deleted.", "answers": ["False", "True"], "explanation": "INFORMATION SCHEMA does NOT include information for any dropped objects. However, if the information on deleted objects is required, you must query the ACCOUNT_USAGE views.\n  \n https://docs.snowflake.com/en/sql-reference/account-usage#differences-between-account-usage-and-information-schema"}, "correct_response": ["a"], "section": "Account Usage & Monitoring", "question_plain": "True or False: The INFORMATION_SCHEMA contains information on objects that have been deleted.", "related_lectures": []}, {"_class": "assessment", "id": 70909932, "assessment_type": "multiple-choice", "prompt": {"question": "True or False: The data in the views in the ACCOUNT_USAGE schema is real-time.", "answers": ["False", "True"], "explanation": "The ACCOUNT USAGE schema consists of several views that provide usage metrics and metadata information at the account level.\n  \n Data provided by the ACCOUNT_USAGE views is NOT real-time and refreshes typically with a lag of 45 minutes to 3 hours, depending on the view. \n  \n The data in these views are retained for up to 365 days.\n  \n https://docs.snowflake.com/en/sql-reference/account-usage#differences-between-account-usage-and-information-schema"}, "correct_response": ["a"], "section": "Account Usage & Monitoring", "question_plain": "True or False: The data in the views in the ACCOUNT_USAGE schema is real-time.", "related_lectures": []}, {"_class": "assessment", "id": 70909934, "assessment_type": "multiple-choice", "prompt": {"question": "True or False: Using the views in the INFORMATION_SCHEMA, you can access the history of usage that occurred 5 minutes ago.", "answers": ["True", "False"], "explanation": "The data provided via the INFORMATION_SCHEMA views is real-time, and there is no latency in the information provided. So, if you are asked which schema should be used if there is a requirement to view real-time data, then the views in INFORMATION SCHEMA should be used as they contain real-time information.\n  \n https://docs.snowflake.com/en/sql-reference/account-usage#differences-between-account-usage-and-information-schema"}, "correct_response": ["a"], "section": "Account Usage & Monitoring", "question_plain": "True or False: Using the views in the INFORMATION_SCHEMA, you can access the history of usage that occurred 5 minutes ago.", "related_lectures": []}, {"_class": "assessment", "id": 70909936, "assessment_type": "multiple-choice", "prompt": {"question": "As part of a security incident investigation, you need to extract the history of who logged into Snowflake during the past 1 year. Which one of the following methods should you use?", "answers": ["Query the view SNOWFLAKE.ACCOUNT_USAGE.LOGIN_HISTORY", "Use the table function INFORMATION_SCHEMA.LOGIN_HISTORY_BY_USER()", "Use the table function INFORMATION_SCHEMA.LOGIN_HISTORY ()", "Ask Snowflake support to provide these details."], "explanation": "The views in ACCOUNT_USAGE schema provide up to 365 days of history. Therefore they are useful for scenarios where data for a long historical duration is required. The LOGIN_HISTORY view in the ACCOUNT_USAGE schema will therefore fulfill the requirement. \n Note: The ACCOUNT_USAGE views are not real-time and may have up to 3 hours of latency."}, "correct_response": ["a"], "section": "Account Usage & Monitoring", "question_plain": "As part of a security incident investigation, you need to extract the history of who logged into Snowflake during the past 1 year. Which one of the following methods should you use?", "related_lectures": []}, {"_class": "assessment", "id": 70909938, "assessment_type": "multiple-choice", "prompt": {"question": "True or False: A resource monitor can track cloud services costs associated with a virtual warehouse but can not stop cloud services costs from occurring.", "answers": ["True", "False"], "explanation": "A resource monitor can not control the costs of cloud services. A warehouse-level resource monitor can monitor credit usage by Cloud Services, but the resource monitor can not suspend the cloud services.\n  \n https://docs.snowflake.com/en/user-guide/resource-monitors#assignment-of-resource-monitors"}, "correct_response": ["a"], "section": "Account Usage & Monitoring", "question_plain": "True or False: A resource monitor can track cloud services costs associated with a virtual warehouse but can not stop cloud services costs from occurring.", "related_lectures": []}, {"_class": "assessment", "id": 70909940, "assessment_type": "multi-select", "prompt": {"question": "A resource monitor can NOT control the cost of which of the following? Select all that apply.", "answers": ["Cloud Services costs", "Serverless compute", "A virtual warehouse created by a user"], "explanation": "Resource monitors cannot control the credit usage of serverless features such as Snowpipe, Automatic Reclustering, and Materialized View maintenance. So, resource monitors can only manage virtual warehouses created by the customer, and their resource monitors can only suspend virtual warehouses operated by the user. Any Snowflake-managed compute resource, such as Snowpipe, Serverless tasks, etc., can not be tracked or managed by resource monitors.\n  \n In addition, a Resource Monitor can not control the costs of cloud services. A warehouse-level resource monitor can monitor credit usage by Cloud Services, but the resource monitor can not suspend the cloud services.\n  \n https://docs.snowflake.com/en/user-guide/resource-monitors#assignment-of-resource-monitors"}, "correct_response": ["a", "b"], "section": "Account Usage & Monitoring", "question_plain": "A resource monitor can NOT control the cost of which of the following? Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70909942, "assessment_type": "multiple-choice", "prompt": {"question": "Snowflake deploys new releases at what interval?", "answers": ["Weekly", "Monthly", "Fortnightly", "Daily"], "explanation": "Snowflake releases new software weekly. The updates are done behind the scenes, so there is no downtime or disruption. To ensure that the customer always has the most up-to-date version of the software, the automatic releases can include bug fixes, new features, and other changes.\n  \n https://docs.snowflake.com/en/user-guide/intro-releases"}, "correct_response": ["a"], "section": "Account", "question_plain": "Snowflake deploys new releases at what interval?", "related_lectures": []}, {"_class": "assessment", "id": 70909944, "assessment_type": "multiple-choice", "prompt": {"question": "Which of the following is not an architecture layer in Snowflake?", "answers": ["Virtual Machine", "Database Storage", "Cloud Services", "Virtual Warehouse"], "explanation": "Snowflake architecture has three distinct layers:\n Database Storage - Cheap cloud storage on AWS, Azure, or Google Cloud\n Query Processing - Primarily composed of virtual warehouses\n Cloud Services - The brain of the whole operation\n  \n https://docs.snowflake.com/en/user-guide/intro-key-concepts#snowflake-architecture"}, "correct_response": ["a"], "section": "Architecture", "question_plain": "Which of the following is not an architecture layer in Snowflake?", "related_lectures": []}, {"_class": "assessment", "id": 70909946, "assessment_type": "multiple-choice", "prompt": {"question": "Which of the statement correctly describes Snowflake architecture?", "answers": ["Shared storage and multiple compute engines", "Shared storage &amp; shared compute engine", "Distributed storage and multiple compute engines"], "explanation": "Snowflake implements a new hybrid architecture that combines the best features of shared-disk and shared-nothing architectures. Snowflake stores data similarly to a shared-disk architecture, i.e., the data is shared. But it also allows for using several compute engines, each with its own memory and processing capabilities.\n  \n https://docs.snowflake.com/en/user-guide/intro-key-concepts#snowflake-architecture"}, "correct_response": ["a"], "section": "Architecture", "question_plain": "Which of the statement correctly describes Snowflake architecture?", "related_lectures": []}, {"_class": "assessment", "id": 70909948, "assessment_type": "multiple-choice", "prompt": {"question": "True/False: Snowflake creates new micro-partitions using the order of the data in which it is inserted.", "answers": ["True", "False"], "explanation": "Micro partitions are added to a table in the order of how the data arrived in the table, so if new data is added to a table, new micro-partition(s) will be created to accommodate that data. \n  \n Snowflake partitions are immutable; they can not be changed once created. Therefore, any update to existing data or loading new data into a table will create new micro-partitions. The micro-partitions are created and populated with data in the order of how the data arrived.\n  \n https://docs.snowflake.com/en/user-guide/tables-clustering-micropartitions"}, "correct_response": ["a"], "section": "Architecture", "question_plain": "True/False: Snowflake creates new micro-partitions using the order of the data in which it is inserted.", "related_lectures": []}, {"_class": "assessment", "id": 70909950, "assessment_type": "multiple-choice", "prompt": {"question": "True/False: Snowflake automatically clusters data as it is inserted into a table.", "answers": ["True", "False"], "explanation": "Snowflake automatically clusters the data as it is inserted into a table.\n  \n https://docs.snowflake.com/en/user-guide/tables-clustering-micropartitions#what-is-data-clustering"}, "correct_response": ["a"], "section": "Architecture", "question_plain": "True/False: Snowflake automatically clusters data as it is inserted into a table.", "related_lectures": []}, {"_class": "assessment", "id": 70909952, "assessment_type": "multiple-choice", "prompt": {"question": "Micro-partitions are small in size and (before compression) are generally of size ___________.", "answers": ["50-500 MB", "500MB-1GB", "10-50MB"], "explanation": "Micro-partitions are small and typically store 50 MB to 500 MB of uncompressed data. \n  \n https://docs.snowflake.com/en/user-guide/tables-clustering-micropartitions.html"}, "correct_response": ["a"], "section": "Architecture", "question_plain": "Micro-partitions are small in size and (before compression) are generally of size ___________.", "related_lectures": []}, {"_class": "assessment", "id": 70909954, "assessment_type": "multi-select", "prompt": {"question": "What type of metadata is maintained for each micro-partition? Select all that apply.", "answers": ["Range of column values", "Maximum &amp; minimum of each column", "Count of distinct values for each column", "Mean, median &amp; mode of each column"], "explanation": "Snowflake stores the range of column values in its metadata: the maximum and the minimum value for each column in each micro-partition. Snowflake can intelligently decide which partitions to read when processing a query using this metadata. Additionally, Snowflake stores the count of distinct values for each column in each partition in the metadata and certain other information to assist in query optimization.\n  \n https://docs.snowflake.com/en/user-guide/tables-clustering-micropartitions"}, "correct_response": ["a", "b", "c"], "section": "Architecture", "question_plain": "What type of metadata is maintained for each micro-partition? Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70909956, "assessment_type": "multiple-choice", "prompt": {"question": "What is the number of nodes in a Medium virtual warehouse?", "answers": ["4", "256", "3", "6"], "explanation": "An X-Small virtual warehouse consists of a single node, the smallest possible configuration for a Snowflake virtual warehouse. A Small virtual warehouse consists of two nodes, and a Medium virtual warehouse is composed of four nodes. As the cluster size grows, the number of nodes in that cluster multiplies.\n  \n https://docs.snowflake.com/en/user-guide/warehouses-overview"}, "correct_response": ["a"], "section": "Architecture", "question_plain": "What is the number of nodes in a Medium virtual warehouse?", "related_lectures": []}, {"_class": "assessment", "id": 70909958, "assessment_type": "multiple-choice", "prompt": {"question": "Query processing in Snowflake is performed by compute engines called ________________.", "answers": ["Virtual Warehouses", "Compute Nodes", "Hadoop Clusters", "Spark Machines"], "explanation": "The compute engines in Snowflake are known as virtual warehouses.\n  \n https://docs.snowflake.com/en/user-guide/warehouses-overview"}, "correct_response": ["a"], "section": "Architecture", "question_plain": "Query processing in Snowflake is performed by compute engines called ________________.", "related_lectures": []}, {"_class": "assessment", "id": 70909960, "assessment_type": "multiple-choice", "prompt": {"question": "True/False: Snowflake credits are billed on a per-second basis.", "answers": ["True", "False"], "explanation": "Snowflake credits are billed on a per-second usage basis, which means if a virtual warehouse ran for 1 minute 45 seconds, you would be charged for 105 seconds (60 + 45). However, a minimum of 60 seconds of billing applies, so if a virtual warehouse were started and shut down within the first 1st minute, a minimum of 60-second credit usage would apply."}, "correct_response": ["a"], "section": "Architecture", "question_plain": "True/False: Snowflake credits are billed on a per-second basis.", "related_lectures": []}, {"_class": "assessment", "id": 70909962, "assessment_type": "multi-select", "prompt": {"question": "Which statements best describe scaling up a virtual warehouse in Snowflake? Select all that apply.", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "It is possible to resize a virtual warehouse to suit changing workloads. Assume a customer began with a small virtual warehouse which may no longer be sufficient to meet increased query complexity. Scaling up the virtual warehouse can accommodate the increasing work complexity. When a virtual warehouse is scaled up, more nodes are added to the compute cluster.\n  \n https://docs.snowflake.com/en/user-guide/warehouses-tasks", "answers": ["Generally, scaling up is performed to accommodate more complex workloads.", "When scaling up, the size of the virtual warehouse is increased to a larger size.", "<p>Additional compute resources are added to a virtual warehouse when scaling up.</p>", "<p><strong>Scaling up means <em>decreasing </em>the size of a virtual warehouse due to improved query processing efficiency.</strong></p>"]}, "correct_response": ["a", "b", "c"], "section": "Architecture", "question_plain": "Which statements best describe scaling up a virtual warehouse in Snowflake? Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70909964, "assessment_type": "multi-select", "prompt": {"question": "A virtual warehouse is in a running state and is executing a complex query. The administrator increases the size of the virtual warehouse. What best describes the impact on the running query and any future queries? Select all that apply.", "answers": ["There is no impact on the running query.", "Only future queries can take advantage of the increased size.", "The current query immediately utilizes the additional nodes available after the resize operation.", "The existing running queries are stopped and re-submitted after the virtual warehouse is resized."], "explanation": "When a virtual warehouse is resized, any currently executing queries are not impacted\u2014only new queries are affected by the new size.\n  \n https://docs.snowflake.com/en/user-guide/warehouses-tasks#resizing-a-warehouse"}, "correct_response": ["a", "b"], "section": "Architecture", "question_plain": "A virtual warehouse is in a running state and is executing a complex query. The administrator increases the size of the virtual warehouse. What best describes the impact on the running query and any future queries? Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70909966, "assessment_type": "multiple-choice", "prompt": {"question": "True/False: As the size of the virtual warehouse increases, the amount of Snowflake credit consumed per second increases.", "answers": ["True", "False"], "explanation": "The number of Snowflake credits consumed depends on the size of the virtual warehouse, the duration while it is in a running state, and how many virtual warehouses you have created. As the size of a virtual warehouse increases, the number of credits consumed per hour or second also increases.\n  \n https://docs.snowflake.com/en/user-guide/warehouses-considerations#how-are-credits-charged-for-warehouses"}, "correct_response": ["a"], "section": "Architecture", "question_plain": "True/False: As the size of the virtual warehouse increases, the amount of Snowflake credit consumed per second increases.", "related_lectures": []}, {"_class": "assessment", "id": 70909968, "assessment_type": "multiple-choice", "prompt": {"question": "Which of the following layers is responsible for query optimization and dispatching?", "answers": ["Cloud Services", "Query Processing", "Database Storage", "Client Optimization Library"], "explanation": "The cloud services layer is responsible for query planning and optimization. \n The actual query processing is performed by virtual warehouses."}, "correct_response": ["a"], "section": "Architecture", "question_plain": "Which of the following layers is responsible for query optimization and dispatching?", "related_lectures": []}, {"_class": "assessment", "id": 70909970, "assessment_type": "multi-select", "prompt": {"question": "Which of the following statements about Query Result Cache are correct? Choose all that apply.", "answers": ["The query result cache is used if an identical query is run within 24 hours of the original query.", "The maximum number of days a query result cache can be retained is 31.", "If a query result cache is not reused within 24 hours, it is purged.", "The cloud services layer stores the query result cache.", "The query result cache is kept in the virtual warehouse SSD storage."], "explanation": "The query result cache is valid for 24 hours. If a new query matching a previous query is made within those 24 hours, the results are retrieved from the query result cache. The query result cache is maintained in the cloud services layer and can be utilized by any user to return query results. The result cache of a query is initially valid for 24 hours, but it is extended for another 24 hours when a new query uses it. This extension can last up to 31 days before being removed. It is purged if the query result cache is not used for 24 hours.\n  \n  \n https://docs.snowflake.com/en/user-guide/querying-persisted-results"}, "correct_response": ["a", "b", "c", "d"], "section": "Architecture", "question_plain": "Which of the following statements about Query Result Cache are correct? Choose all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70909972, "assessment_type": "multi-select", "prompt": {"question": "The COPY command can load data from which of the following?", "answers": ["External Stages", "Internal Stages", "Tape drives", "Detachable hard disks"], "explanation": "Similar to how data warehouses use staging, Snowflake uses a Stage object. Snowflake uses stages to aid in the loading and unloading of data. The data must first be available in a Snowflake stage to load data into a Snowflake table. COPY command can be used to load data into a table after the data is loaded in a stage. \n  \n Data unloading or exporting is also performed via a Stage object; the data can only be extracted to a stage, internal or external.\n  \n https://docs.snowflake.com/en/user-guide/data-load-overview"}, "correct_response": ["a", "b"], "section": "Data Loading and Unloading", "question_plain": "The COPY command can load data from which of the following?", "related_lectures": []}, {"_class": "assessment", "id": 70909974, "assessment_type": "multiple-choice", "prompt": {"question": "<p><strong>You are unloading data from a table into multiple files. Which COPY command parameter will let you control the maximum size of each file?</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", ""], "explanation": "When data is unloaded from Snowflake, it is automatically compressed using gzip compression. This is the default behavior; however, you can specify alternate compression methods or turn off compression entirely.\n  \n The unloading process automatically exports to multiple files so that it can take advantage of the parallelism offered by Snowflake. However, if needed, you can set the SINGLE parameter to true to ensure the export goes to a single file.\n  \n The default size of each output file is 16 MB but can be changed using the MAX_FILE_SIZE parameter. The maximum allowed size per file is 5GB if you export data to cloud storage. \n  \n  \n https://docs.snowflake.com/en/user-guide/data-unload-considerations#unloading-to-a-single-file", "answers": ["MAX_FILE_SIZE", "MAX_FILE_BYTES", "FILE_SIZE_LIMIT"]}, "correct_response": ["a"], "section": "Data Loading and Unloading", "question_plain": "You are unloading data from a table into multiple files. Which COPY command parameter will let you control the maximum size of each file?", "related_lectures": []}, {"_class": "assessment", "id": 70909976, "assessment_type": "multi-select", "prompt": {"question": "Which of the following are true regarding External tables?", "answers": ["External tables are read-only.", "An external table points to an external stage.", "Data in external tables can be updated using the DML language.", "Data in External tables can be deleted using the DELETE SQL command."], "explanation": "Since external tables point to an external storage location, data manipulation language (DML) operations cannot be done on them. An external table can only be created against an external stage, which points to a cloud object storage location.\n  \n https://docs.snowflake.com/en/user-guide/tables-external-intro"}, "correct_response": ["a", "b"], "section": "Data Loading and Unloading", "question_plain": "Which of the following are true regarding External tables?", "related_lectures": []}, {"_class": "assessment", "id": 70909978, "assessment_type": "multiple-choice", "prompt": {"question": "As an alternative to data loading, Snowflake allows the creation of external tables through which you can query external data without loading it first.", "answers": ["True", "False"], "explanation": "Snowflake provides external tables, which permit the creation of tables with data stored in external cloud storage. Using external tables, you can query data without loading it into Snowflake.\n  \n https://docs.snowflake.com/en/user-guide/data-load-overview#external-tables-data-lake"}, "correct_response": ["a"], "section": "Data Loading and Unloading", "question_plain": "As an alternative to data loading, Snowflake allows the creation of external tables through which you can query external data without loading it first.", "related_lectures": []}, {"_class": "assessment", "id": 70909980, "assessment_type": "multiple-choice", "prompt": {"question": "You are required to download data from a named internal stage to an on-premises system. Which command should you use?", "answers": ["GET", "PUT", "COPY", "VALIDATE"], "explanation": "The GET command is used to download data from an internal stage to an on-premises system.\n  \n The PUT command uploads data from an on-premises system to an internal stage.\n  \n To download or upload data to an external stage, cloud provider utilities or other tools are used to interact with data in the cloud storage pointed to by the external stage.\n  \n  \n https://docs.snowflake.com/en/user-guide/data-unload-overview#bulk-unloading-process"}, "correct_response": ["a"], "section": "Data Loading and Unloading", "question_plain": "You are required to download data from a named internal stage to an on-premises system. Which command should you use?", "related_lectures": []}, {"_class": "assessment", "id": 70909982, "assessment_type": "multiple-choice", "prompt": {"question": "<p><strong>As a data engineer, you are developing jobs to load data into a snowflake table. You have an S3 stage defined, containing a single file containing 100 rows. You have loaded those 100 rows. </strong></p><p><strong>You notice that your COPY command is executing successfully but is not loading any row into the target table. </strong></p><p><strong>What could be the reason?</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", ""], "explanation": "The load metadata stores a variety of information, such as the name of every file that was loaded into that table and the time stamp corresponding to the time that a file was loaded. By utilizing this load metadata, Snowflake ensures that it will not reprocess a previously loaded file.\n  \n Since you have already loaded this file, Snowflake will track through metadata which files have been loaded and will not process them again. If you want to retest your copy command, you must place a new file or force the reload by specifying specific parameters during the load process.\n  \n https://docs.snowflake.com/en/user-guide/data-load-considerations-load#load-metadata", "answers": ["<p><strong>You have already loaded the single file that was in the Snowflake stage. Snowflake tracks in metadata if a file has already been loaded and will not load it again.</strong></p>", "The file in the Snowflake stage is corrupt and, therefore, can&#39;t be loaded.", "The file format you have defined for your data is incorrect; therefore, no data is getting loaded."]}, "correct_response": ["a"], "section": "Data Loading and Unloading", "question_plain": "As a data engineer, you are developing jobs to load data into a snowflake table. You have an S3 stage defined, containing a single file containing 100 rows. You have loaded those 100 rows. You notice that your COPY command is executing successfully but is not loading any row into the target table. What could be the reason?", "related_lectures": []}, {"_class": "assessment", "id": 70909984, "assessment_type": "multiple-choice", "prompt": {"question": "The PUT command can be used in which of the following scenarios?", "answers": ["Transfer data from an on-premises system to a Snowflake stage.", "Load data from the Snowflake Web UI.", "Load data from a Snowflake external stage into a Snowflake table.", "Load data from a Snowflake internal stage into a Snowflake table."], "explanation": "The PUT command uploads data from an on-premises system to an internal stage.\n  \n The GET command is used to download data from an internal stage to an on-premises system.\n  \n To download or upload data to an external stage, cloud provider utilities or other tools are used to interact with data in the cloud storage pointed to by the external stage.\n  \n  \n https://docs.snowflake.com/en/user-guide/data-unload-overview#bulk-unloading-process"}, "correct_response": ["a"], "section": "Data Loading and Unloading", "question_plain": "The PUT command can be used in which of the following scenarios?", "related_lectures": []}, {"_class": "assessment", "id": 70909986, "assessment_type": "multi-select", "prompt": {"question": "Which of the following are serverless features provided by Snowflake?", "answers": ["Snowpipe", "Automatic Clustering", "Virtual warehouses", "Multi-cluster virtual warehouses"], "explanation": "Snowpipe is a serverless service for continuous data loads.\n  \n Automatic clustering is a serverless Snowflake-managed service that maintains micro-partitions for tables according to the defined clustering key."}, "correct_response": ["a", "b"], "section": "Data Loading and Unloading", "question_plain": "Which of the following are serverless features provided by Snowflake?", "related_lectures": []}, {"_class": "assessment", "id": 70909988, "assessment_type": "multiple-choice", "prompt": {"question": "Which of the following transformation is supported by the COPY command?", "answers": ["CAST", "SUM", "AVG", "FLATTEN"], "explanation": "When loading data into a table using the COPY command, Snowflake allows you to do simple transformations on the data as it is being loaded. During the load process, the COPY command allows for modifying the order of columns, omitting one or more columns, casting data into specified data types, and truncating values.\n  \n While loading the data, complex transformations such as joins, filters, aggregations, and the use of FLATTEN are not supported as they are not essential data transformations. Therefore, joining, filtering, and aggregating the data are supported ONLY after the data has been loaded into a table.\n  \n https://docs.snowflake.com/en/user-guide/data-load-overview#id2"}, "correct_response": ["a"], "section": "Data Loading and Unloading", "question_plain": "Which of the following transformation is supported by the COPY command?", "related_lectures": []}, {"_class": "assessment", "id": 70909990, "assessment_type": "multiple-choice", "prompt": {"question": "True or False: Snowflake customers can retrieve data from fail-safe storage using Time Travel SQL extensions.", "answers": ["False", "True"], "explanation": "Once the data is in fail-safe storage, only Snowflake support can help retrieve the data. The customer cannot access fail-safe storage."}, "correct_response": ["a"], "section": "Fail-safe", "question_plain": "True or False: Snowflake customers can retrieve data from fail-safe storage using Time Travel SQL extensions.", "related_lectures": []}, {"_class": "assessment", "id": 70909992, "assessment_type": "multiple-choice", "prompt": {"question": "Snowflake stores data in fail-safe storage for Temporary tables for what duration?", "answers": ["0 days", "7 days", "14 days", "1 day"], "explanation": "Snowflake has transient and temporary tables that don&#39;t provide fail-safe capabilities; hence, data in such tables have 0 days of fail-safe storage.\n  \n https://docs.snowflake.com/en/user-guide/tables-temp-transient"}, "correct_response": ["a"], "section": "Fail-safe", "question_plain": "Snowflake stores data in fail-safe storage for Temporary tables for what duration?", "related_lectures": []}, {"_class": "assessment", "id": 70909994, "assessment_type": "multiple-choice", "prompt": {"question": "When creating a new table, if no type is specified, the table is created automatically as which type?", "answers": ["Permanent", "Transient", "Temporary"], "explanation": "The default &amp; implicit type for a new table is Permanent. To create other types of tables, you must explicitly specify the type as temporary, transient, or external."}, "correct_response": ["a"], "section": "Data Protection", "question_plain": "When creating a new table, if no type is specified, the table is created automatically as which type?", "related_lectures": []}, {"_class": "assessment", "id": 70909996, "assessment_type": "multiple-choice", "prompt": {"question": "True or False: Storage costs are billed to the customer for data stored in Time Travel and fail-safe storage.", "answers": ["True", "False"], "explanation": "Snowflake charges for Time Travel and failsafe data storage. The cost of maintaining data for Time Travel and fail-safe is calculated every 24 hours based on the number of days it is maintained and the time since it was last modified.\n  \n https://docs.snowflake.com/en/user-guide/data-cdp-storage-costs"}, "correct_response": ["a"], "section": "Time Travel", "question_plain": "True or False: Storage costs are billed to the customer for data stored in Time Travel and fail-safe storage.", "related_lectures": []}, {"_class": "assessment", "id": 70909998, "assessment_type": "multiple-choice", "prompt": {"question": "What is the maximum period for Time Travel for Temporary tables?", "answers": ["1 day", "7 days", "14 days", "21 days"], "explanation": "Transient and Temporary tables in Snowflake support Time Travel for up to 1 day, irrespective of the Snowflake edition used.\n  \n https://docs.snowflake.com/en/user-guide/tables-temp-transient"}, "correct_response": ["a"], "section": "Time Travel", "question_plain": "What is the maximum period for Time Travel for Temporary tables?", "related_lectures": []}, {"_class": "assessment", "id": 70910000, "assessment_type": "multi-select", "prompt": {"question": "Which of the following are data-sharing services provided by Snowflake?", "answers": ["Direct Sharing", "Data Exchange", "Snowflake Marketplace", "Seamless Data Share"], "explanation": "Snowflake offers the following data-sharing services.\n Direct Sharing\n Snowflake Marketplace \n Data Exchange \n  \n https://docs.snowflake.com/en/guides-overview-sharing"}, "correct_response": ["a", "b", "c"], "section": "Data Sharing", "question_plain": "Which of the following are data-sharing services provided by Snowflake?", "related_lectures": []}, {"_class": "assessment", "id": 70910002, "assessment_type": "multi-select", "prompt": {"question": "Which of the following statements correctly describe a share?", "answers": ["A share object is a container that contains objects to be shared", "A share object has information about the consumer(s)", "Share objects are available only to enterprise customers."], "explanation": "A share acts as a container for objects that need to be shared. \n A share object encapsulates the database &amp; the schema to be shared, the tables and secure views which will be shared, and the consumer account(s) to which the Share will be available.\n \n Sharing and consequently share objects are available to all Snowflake editions"}, "correct_response": ["a", "b"], "section": "Data Sharing", "question_plain": "Which of the following statements correctly describe a share?", "related_lectures": []}, {"_class": "assessment", "id": 70910004, "assessment_type": "multiple-choice", "prompt": {"question": "You have shared a table with another Snowflake account. A user in the consumer account has executed a query on the shared table. Who will be charged for the query cost?", "answers": ["The data consumer", "The data provider (the account which shared the data)"], "explanation": "In a data-sharing scenario, Snowflake charges the consumer account for the costs of any compute that the consumer account uses.\n  \n \n https://docs.Snowflake.net/manuals/user-guide/data-sharing-intro.html#how-does-secure-data-sharing-work"}, "correct_response": ["a"], "section": "Data Sharing", "question_plain": "You have shared a table with another Snowflake account. A user in the consumer account has executed a query on the shared table. Who will be charged for the query cost?", "related_lectures": []}, {"_class": "assessment", "id": 70910006, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>Which of the following objects can be shared? Select all that apply.</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", "", "", ""], "explanation": "Standard views cannot be shared.\n  \n Direct data sharing enables sharing of the following types of objects:\n Tables, External tables, Secure views, Secure materialized views, Secure UDFs.\n  \n https://docs.snowflake.com/en/user-guide/data-sharing-intro", "answers": ["<p><strong>Materialized Views</strong></p>", "<p><strong>Secure Materialized Views</strong></p>", "<p><strong>Tables</strong></p>", "<p><strong>Secure Views</strong></p>", "<p><strong>Secure UDFs</strong></p>", "<p><strong>Views</strong></p>"]}, "correct_response": ["b", "c", "d", "e"], "section": "Data Sharing", "question_plain": "Which of the following objects can be shared? Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70910008, "assessment_type": "multiple-choice", "prompt": {"question": "<p><strong>Which of the following statement best describes a reader's account in Snowflake?</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "In Snowflake, sharing data with a non-Snowflake user (or organization) is possible by creating a reader account for that user (or organization). This reader account is created and managed by the data provider.\n  \n https://docs.snowflake.com/en/user-guide/data-sharing-reader-create", "answers": ["A reader account is used to share data with a non-Snowflake user (or organization)", "A reader account is used for read-only data-loading operations", "A reader account is a method for access control in Snowflake", "Reader accounts are used to synchronize data across various cloud providers."]}, "correct_response": ["a"], "section": "Data Sharing", "question_plain": "Which of the following statement best describes a reader's account in Snowflake?", "related_lectures": []}, {"_class": "assessment", "id": 70910010, "assessment_type": "multiple-choice", "prompt": {"question": "True or False: The data provider is responsible for and pays for the compute costs of a reader account.", "answers": ["True", "False"], "explanation": "Since the data provider creates and administers the reader account, all the reader account&#39;s compute expenses are invoiced to the provider account. Therefore, the reader account&#39;s use of the virtual warehouse compute is added to the provider account compute charges."}, "correct_response": ["a"], "section": "Data Sharing", "question_plain": "True or False: The data provider is responsible for and pays for the compute costs of a reader account.", "related_lectures": []}, {"_class": "assessment", "id": 70910012, "assessment_type": "multiple-choice", "prompt": {"question": "For a non-ACCOUNTADMIN user, what privileges are required to create a share?", "answers": ["CREATE SHARE privileges", "CREATE ACCOUNT privileges", "MANAGE ACCOUNT privileges", "SECURITY privileges"], "explanation": "Only the ACCOUNTADMIN role or roles specifically granted the CREATE SHARE privilege can create a share.\n  \n https://docs.snowflake.com/en/user-guide/data-sharing-gs"}, "correct_response": ["a"], "section": "Data Sharing", "question_plain": "For a non-ACCOUNTADMIN user, what privileges are required to create a share?", "related_lectures": []}, {"_class": "assessment", "id": 70910014, "assessment_type": "multiple-choice", "prompt": {"question": "Which one of the following is true regarding Snowflake Marketplace?", "answers": ["Any Snowflake account can consume or publish data to the Snowflake Marketplace.", "A Snowflake account can only consume data from the Snowflake Marketplace.", "A separate Snowflake account is needed to publish data to the Snowflake Marketplace.", "Only Snowflake can publish new data sets to Snowflake Marketplace."], "explanation": "Except for Virtual private Snowflake accounts, the Snowflake Marketplace is available to all Snowflake accounts hosted on Amazon Web Services, Google Cloud Platform, and Microsoft Azure. Any Snowflake account (again, except for VPS accounts) can become a data provider and publish datasets to the Marketplace for a cost or for free. In addition, you are required to sign up as a partner first and become an approved data provider.\n  \n https://other-docs.snowflake.com/en/collaboration/collaboration-marketplace-about.html"}, "correct_response": ["a"], "section": "Data Sharing", "question_plain": "Which one of the following is true regarding Snowflake Marketplace?", "related_lectures": []}, {"_class": "assessment", "id": 70910016, "assessment_type": "multiple-choice", "prompt": {"question": "Is it possible to share data with a Snowflake customer whose Snowflake instance exists in a different region than the data provider?", "answers": ["Yes, but you must enable replication first to enable cross-region data sharing.", "Yes. Nothing special needs to be done to enable cross-region data sharing.", "No, it is not possible to share with customers in other regions."], "explanation": "It is possible to share data with other regions, but the provider must enable replication and replicate your existing database to the other region.\n  \n https://docs.snowflake.com/en/user-guide/secure-data-sharing-across-regions-plaforms"}, "correct_response": ["a"], "section": "Data Sharing", "question_plain": "Is it possible to share data with a Snowflake customer whose Snowflake instance exists in a different region than the data provider?", "related_lectures": []}, {"_class": "assessment", "id": 70910018, "assessment_type": "multiple-choice", "prompt": {"question": "In a VARIANT column, the NULL values are stored as a literal string &quot;null&quot;", "answers": ["True", "False"], "explanation": "NULL values are stored as a literal string &quot;null&quot; in a VARIANT column.\n  \n https://docs.snowflake.com/en/user-guide/semistructured-considerations#null-values"}, "correct_response": ["a"], "section": "Data Loading and Unloading", "question_plain": "In a VARIANT column, the NULL values are stored as a literal string &quot;null&quot;", "related_lectures": []}, {"_class": "assessment", "id": 70910020, "assessment_type": "multiple-choice", "prompt": {"question": "True or False: An external function can only be written in C++.", "answers": ["False", "True"], "explanation": "One of the benefits of creating an external function is that it can be written in languages that standard UDFs cannot. Many languages can be used to create external functions since they exist outside of Snowflake. \n  \n https://docs.snowflake.com/en/sql-reference/external-functions-introduction#advantages-of-external-functions"}, "correct_response": ["a"], "section": "Extending Snowflake Functionality", "question_plain": "True or False: An external function can only be written in C++.", "related_lectures": []}, {"_class": "assessment", "id": 70910022, "assessment_type": "multi-select", "prompt": {"question": "Which of the following does Snowflake Scripting support?", "answers": ["Branching constructs such as IF-ELSE and CASE statements", "Looping Constructs such as FOR, WHILE, REPEAT, and LOOP.", "Handling exceptions", "Declaring &amp; using variables"], "explanation": "All of these are supported in Snowflake Scripting.\n  \n Snowflake Scripting allows you to use variables, if-else expressions, looping, cursors, manage result sets, and allows you to handle errors. Snowflake scripting is typically used to create stored procedures, but it may also be used to create procedural code outside of a stored procedure.\n  \n https://docs.snowflake.com/en/developer-guide/snowflake-scripting/index"}, "correct_response": ["a", "b", "c", "d"], "section": "Extending Snowflake Functionality", "question_plain": "Which of the following does Snowflake Scripting support?", "related_lectures": []}, {"_class": "assessment", "id": 70910024, "assessment_type": "multiple-choice", "prompt": {"question": "Which one of the following is functionality provided by Snowpark?", "answers": ["Snowpark automatically converts the data-processing programming constructs to SQL and pushes them down to Snowflake for execution", "Snowpark is the name for the web-based user interface in Snowflake.", "Snowpark is the command line client that allows you to connect to Snowflake and execute queries.", "Snowpark is a diagnostic tool designed to troubleshoot connectivity to Snowflake."], "explanation": "Snowpark is a library created by Snowflake that provides APIs for accessing and processing data in applications written in a programming language other than SQL. Snowpark allows programmers to utilize common programming languages such as Java, Scala, and Python to construct apps that handle data using standard programming structures. \n  \n Snowpark automatically converts the data-processing programming constructs to SQL and pushes it down to Snowflake for execution. As a result, developers may utilize a familiar language while benefiting from Snowflake&#39;s scale and execution engine.\n  \n https://docs.snowflake.com/en/developer-guide/snowpark/index"}, "correct_response": ["a"], "section": "Extending Snowflake Functionality", "question_plain": "Which one of the following is functionality provided by Snowpark?", "related_lectures": []}, {"_class": "assessment", "id": 70910026, "assessment_type": "multiple-choice", "prompt": {"question": "A stored procedure has been configured as a caller&#39;s rights stored procedure. A business user executes the stored procedure. Which of the following statement correctly describes what will happen?", "answers": ["The stored procedure executes using the privileges of the users executing the stored procedure.", "The stored procedure executes using the privileges of ACCOUNTADMIN.", "The stored procedure executes using the privileges of the PUBLIC role.", "The stored procedure executes using the privileges of the role owning the stored procedure."], "explanation": "A stored procedure configured to run with callers&#39; rights executes under the permissions of the calling user. \n  \n https://docs.snowflake.com/en/sql-reference/stored-procedures-rights"}, "correct_response": ["a"], "section": "Extending Snowflake Functionality", "question_plain": "A stored procedure has been configured as a caller&#39;s rights stored procedure. A business user executes the stored procedure. Which of the following statement correctly describes what will happen?", "related_lectures": []}, {"_class": "assessment", "id": 70910028, "assessment_type": "multi-select", "prompt": {"question": "A Table UDF will return what type of result? Select all that apply", "answers": ["For each input, it can return one row containing a single column", "For each input, it can return one-row containing multiple columns", "For each input, it can return multiple rows containing multiple columns", "For each input, it can return multiple rows containing a single columns", "For each input, it can return zero rows"], "explanation": "All of these are valid answers.\n  \n Table UDFs can return zero, one, or several rows for each input, with each result row containing one or multiple columns. UDTFs are another name for user-defined table functions. An example of such a function can be FLATTEN which returns several rows and columns for a single input.\n  \n https://docs.snowflake.com/en/sql-reference/udf-overview#scalar-and-tabular-functions"}, "correct_response": ["a", "b", "c", "d", "e"], "section": "Extending Snowflake Functionality", "question_plain": "A Table UDF will return what type of result? Select all that apply", "related_lectures": []}, {"_class": "assessment", "id": 70910030, "assessment_type": "multiple-choice", "prompt": {"question": "How many Snowflake accounts are required if you need to create two Snowflake instances, one in Europe/Middle East region and one in Asia Pacific Region?", "answers": ["Two", "One", "Four", "Zero"], "explanation": "You will need to create two different accounts, one for each region.\n  \n Each Snowflake account is hosted in a particular Snowflake region. To use Snowflake in multiple regions, a Snowflake customer needs to maintain multiple Snowflake accounts, at least one for each region.\n  \n https://docs.snowflake.com/en/user-guide/intro-regions.html"}, "correct_response": ["a"], "section": "Licensing & Features", "question_plain": "How many Snowflake accounts are required if you need to create two Snowflake instances, one in Europe/Middle East region and one in Asia Pacific Region?", "related_lectures": []}, {"_class": "assessment", "id": 70910032, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>Which of the following Snowflake editions allows using Resource Monitors for monitoring virtual warehouse credit usage? Select all that apply.</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "All Snowflake editions support Resource Monitors.\n  \n  \n https://docs.snowflake.com/en/user-guide/intro-editions.html", "answers": ["Standard", "Enterprise", "Business Critical", "Virtual Private Snowflake"]}, "correct_response": ["a", "b", "c", "d"], "section": "Licensing & Features", "question_plain": "Which of the following Snowflake editions allows using Resource Monitors for monitoring virtual warehouse credit usage? Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70910034, "assessment_type": "multiple-choice", "prompt": {"question": "What is the minimum Snowflake edition which supports automatic encryption of all data?", "answers": ["Standard", "Enterprise", "Business Critical", "Virtual Private Snowflake"], "explanation": "Encryption is provided automatically in all Snowflake editions; thus, the minimum edition that supports it is the Standard edition.\n  \n https://docs.snowflake.com/en/user-guide/intro-editions.html"}, "correct_response": ["a"], "section": "Licensing & Features", "question_plain": "What is the minimum Snowflake edition which supports automatic encryption of all data?", "related_lectures": []}, {"_class": "assessment", "id": 70910036, "assessment_type": "multiple-choice", "prompt": {"question": "What is the minimum Snowflake edition that supports Row Access Policies?", "answers": ["Enterprise", "Business Critical", "Standard", "Virtual Private Snowflake"], "explanation": "The Enterprise edition has several additional capabilities not provided in the Standard edition. These include multi-cluster virtual warehouses, column-level masking, row access policies, materialized views, and search optimization.\n  \n  \n https://docs.snowflake.com/en/user-guide/intro-editions.html"}, "correct_response": ["a"], "section": "Licensing & Features", "question_plain": "What is the minimum Snowflake edition that supports Row Access Policies?", "related_lectures": []}, {"_class": "assessment", "id": 70910038, "assessment_type": "multi-select", "prompt": {"question": "Which of the following editions support user-defined functions?", "answers": ["Standard", "Enterprise", "Business Critical", "Virtual Private Snowflake"], "explanation": "UDFs are a foundational feature and are supported by all Snowflake editions.\n  \n  \n https://docs.snowflake.com/en/user-guide/intro-editions.html"}, "correct_response": ["a", "b", "c", "d"], "section": "Licensing & Features", "question_plain": "Which of the following editions support user-defined functions?", "related_lectures": []}, {"_class": "assessment", "id": 70910040, "assessment_type": "multiple-choice", "prompt": {"question": "If the query result cache for a query is not used by any future query, what is the duration after which it will be purged?", "answers": ["24 hours", "31 days", "3600 seconds", "365 days"], "explanation": "Once a result cache is generated for a query stays valid for 24 hours. If another query that reuses the query result cache is executed within that 24-hour window, the result cache expiry is extended for another 24 hours from that point onwards. If the result cache for a query keeps getting used, it will stay valid for up to 31 days. After 31 days, the result cache for a query will be purged regardless of any other condition. \n  \n https://docs.snowflake.com/en/user-guide/querying-persisted-results"}, "correct_response": ["a"], "section": "Performance Concepts", "question_plain": "If the query result cache for a query is not used by any future query, what is the duration after which it will be purged?", "related_lectures": []}, {"_class": "assessment", "id": 70910042, "assessment_type": "multi-select", "prompt": {"question": "Which of the following is true regarding Query Result Cache for a given query? Select all that apply.", "answers": ["The query result cache may be extended for up to a maximum of 31 days", "If no new query reuses the query result cache, the cache is purged after 24 hours.", "If a query reuses the query result cache, it is extended by another 24 hours.", "The query result cache can be manually purged."], "explanation": "The query result cache for a query has an initial validity period of twenty-four hours. The cache is purged if a new query doesn&#39;t reuse the previously generated cache within 24 hours. If a new query uses the result cache, the validity period for the query result cache is reset to another 24 hours. It is now valid for another 24 hours from when it was reused. This extension of the first query result cache can continue for up to a maximum of 31 days from the point in time when a query result cache was initially produced. After 31 days, the query result cache for a query is purged altogether. \n  \n https://docs.snowflake.com/en/user-guide/querying-persisted-results"}, "correct_response": ["a", "b", "c"], "section": "Performance Concepts", "question_plain": "Which of the following is true regarding Query Result Cache for a given query? Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70910044, "assessment_type": "multiple-choice", "prompt": {"question": "<p><strong>You are the performance DBA at a large airline company with a Snowflake Data warehouse. A large table (&gt;5TB) contains telemetry data from airplane sensors. </strong></p><p><strong>The table is usually accessed by the \"event_date\" on which the data was generated, but often there are queries that access the table through the column \"airplane_id\". </strong></p><p><strong>How can you optimize the table so that queries which use either event_date or the airplane_id in the WHERE clause run faster?</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "Clustering a table on a specific column can optimize queries by eliminating unnecessary partitions from the query processing. A table can be re-clustered by defining a clustering key, which effectively redistributes the data into micro-partitions according to the clustering key, ensuring optimal access to queries that predicate or join on the clustered column.\n  \n Introducing a cluster key on both the event_date &amp; airplane_id columns creates an optimal partitioning scheme for access via either column.\n  \n https://docs.snowflake.com/en/user-guide/tables-clustering-keys", "answers": ["<p><strong>Introduce a cluster key on the combination of the two columns i.e. </strong></p><p><strong>CLUSTER BY(event_date,airplane_id)</strong></p>", "Concatenate the two columns and generate a new column in the table. Cluster the table on that column", "Do nothing; Snowflake will ensure the efficiency of querying itself.", "Increase the size of the virtual warehouse so that queries run faster."]}, "correct_response": ["a"], "section": "Performance Concepts", "question_plain": "You are the performance DBA at a large airline company with a Snowflake Data warehouse. A large table (&gt;5TB) contains telemetry data from airplane sensors. The table is usually accessed by the \"event_date\" on which the data was generated, but often there are queries that access the table through the column \"airplane_id\". How can you optimize the table so that queries which use either event_date or the airplane_id in the WHERE clause run faster?", "related_lectures": []}, {"_class": "assessment", "id": 70910046, "assessment_type": "multiple-choice", "prompt": {"question": "You are the database administrator for a large retailer running Snowflake. There is a transactions table that is clustered on the transaction_date column. You need to remove the clustering from this table. What is the correct way to do this?", "answers": ["ALTER TABLE transactions DROP CLUSTERING KEY;", "ALTER TABLE transactions REMOVE CLUSTER BY;", "Create a new table called transactions_2 with the same structure as transactions without any clustering key defined.\n \n Then insert data from the transactions table into transacctions_2, drop the transactions table, and rename the transactions_2 as transactions."], "explanation": "If you need to drop or alter the clustering keys for a table, you can run the ALTER table command and use the appropriate syntax to drop, add or change clustering keys.\n  \n https://docs.snowflake.com/en/user-guide/tables-clustering-keys#dropping-the-clustering-keys-for-a-table"}, "correct_response": ["a"], "section": "Performance Concepts", "question_plain": "You are the database administrator for a large retailer running Snowflake. There is a transactions table that is clustered on the transaction_date column. You need to remove the clustering from this table. What is the correct way to do this?", "related_lectures": []}, {"_class": "assessment", "id": 70910048, "assessment_type": "multiple-choice", "prompt": {"question": "True or False: When clustering keys are defined for a table, there is a cost for maintaining and re-organizing micro-partitions according to the clustering keys.", "answers": ["True", "False"], "explanation": "For tables with a clustering key defined, Automatic Clustering, a Snowflake service, re-clusters the micro-partitions as needed, distributing data according to the clustering key to achieve appropriate partition pruning. Snowflake internally maintains the clustered tables and any resource requirements with Automatic Clustering. Automatic Clustering only adjusts those micro-partitions which benefit from the re-clustering process. Automatic Clustering does not need a virtual warehouse but uses Snowflake-managed CPU, RAM, etc. Therefore, it has a cost attached, which should appear under serverless costs. Clustering a table uses credits like any other data modification (DML) action in Snowflake. Re-clustering also adds extra storage when data is physically redistributed and new micro-partitions are created. The original micro-partitions are kept for Time Travel and Fail-safe purposes, resulting in increased storage.\n  \n https://docs.snowflake.com/en/user-guide/tables-auto-reclustering#credit-usage-and-warehouses-for-automatic-clustering"}, "correct_response": ["a"], "section": "Performance Concepts", "question_plain": "True or False: When clustering keys are defined for a table, there is a cost for maintaining and re-organizing micro-partitions according to the clustering keys.", "related_lectures": []}, {"_class": "assessment", "id": 70910050, "assessment_type": "multi-select", "prompt": {"question": "Which two system functions are provided by Snowflake to find information about clustering depth? Select all that apply.", "answers": ["SYSTEM$CLUSTERING_DEPTH", "SYSTEM$CLUSTERING_INFORMATION", "SYSTEM$AVERAGE_DEPTH", "SYSTEM$CLUSTERING_HISTORY"], "explanation": "Snowflake provides two system functions that can be used to find out clustering information. The two functions are\n SYSTEM$CLUSTERING_DEPTH\n SYSTEM$CLUSTERING_INFORMATION \n  \n https://docs.snowflake.com/en/user-guide/tables-clustering-micropartitions#clustering-depth"}, "correct_response": ["a", "b"], "section": "Performance Concepts", "question_plain": "Which two system functions are provided by Snowflake to find information about clustering depth? Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70910052, "assessment_type": "multi-select", "prompt": {"question": "From a cardinality (number of distinct values) perspective, which columns should you consider adding to a clustering key?", "answers": ["Columns that have large enough distinct values to enable efficient partition pruning.", "Columns that have small enough distinct values to enable efficient grouping in micro-partition.", "Only columns that have a high cardinality.", "Only columns that have a low cardinality.", "The cardinality of columns doesn&#39;t matter when defining a clustering key."], "explanation": "When defining clustering keys, the initial candidate clustering columns are those columns that are frequently used in the WHERE clause or other selective filters. \n  \n Additionally, columns that are used for joining can also be considered.\n  \n Furthermore, the columns&#39; cardinality (number of distinct values) is also important. It is crucial to choose a column with a high enough cardinality to allow effective partition pruning while having a low enough cardinality for Snowflake to group data into micro-partitions efficiently. A column with too few distinct values (e.g., gender) will result in minimal partition pruning. On the other hand, a column that has too many distinct values (e.g., customer id) will result in too much overhead when maintaining the partitions.\n  \n When creating a multi-column cluster key, order the columns from the lowest cardinality to the higher cardinality; otherwise, the effectiveness of clustering will be reduced.\n  \n https://docs.snowflake.com/en/user-guide/tables-clustering-keys"}, "correct_response": ["a", "b"], "section": "Performance Concepts", "question_plain": "From a cardinality (number of distinct values) perspective, which columns should you consider adding to a clustering key?", "related_lectures": []}, {"_class": "assessment", "id": 70910054, "assessment_type": "multiple-choice", "prompt": {"question": "True or False. A materialized view is automatically updated if the data in the underlying table is changed.", "answers": ["True", "False"], "explanation": "A materialized view is a view that pre-computes data based on a SELECT query. The query&#39;s results are pre-computed and physically stored to enhance performance for similar queries that are executed in the future. When the underlying table is updated, the materialized view refreshes automatically, requiring no additional maintenance. Snowflake-managed services perform the update in the background transparent to the user without interfering with the user&#39;s experience.\n  \n https://docs.snowflake.com/en/user-guide/views-materialized"}, "correct_response": ["a"], "section": "Performance Concepts", "question_plain": "True or False. A materialized view is automatically updated if the data in the underlying table is changed.", "related_lectures": []}, {"_class": "assessment", "id": 70910056, "assessment_type": "multiple-choice", "prompt": {"question": "You have a medium-sized virtual warehouse for executing ad-hoc queries. Due to many queries concurrently executing at peak times, the queries start queuing. What is the best way to reduce queuing?", "answers": ["Configure the virtual warehouse to be a multi-cluster virtual warehouse. The virtual warehouse scales out and back depending on the query demands.", "Create several Medium-sized virtual warehouses and redirect users to use different virtual warehouses.", "Request users to spread their queries throughout the day.", "Kill all long-running queries"], "explanation": "Multi-cluster virtual warehouses are frequently used in scenarios where the number of concurrent queries exceeds the capacity of a single virtual warehouse. When a virtual warehouse&#39;s concurrent workload exceeds its maximum capacity, additional queries are placed in the queue. Multi-cluster virtual warehouses dynamically add additional clusters based on demand to solve the queueing issue. When demand decreases, the additional clusters are decommissioned. This process is also known as scaling out or auto-scaling.\n  \n https://docs.snowflake.com/en/user-guide/warehouses-multicluster"}, "correct_response": ["a"], "section": "Performance Concepts", "question_plain": "You have a medium-sized virtual warehouse for executing ad-hoc queries. Due to many queries concurrently executing at peak times, the queries start queuing. What is the best way to reduce queuing?", "related_lectures": []}, {"_class": "assessment", "id": 70910058, "assessment_type": "multi-select", "prompt": {"question": "Which of the following statements about a multi-cluster virtual warehouse in auto-scale mode is true?", "answers": ["When Snowflake detects that queries are beginning to queue, additional warehouses are started.", "When the query demand decreases, warehouses are progressively shut down.", "Multi-cluster virtual warehouses support the same properties and actions as regular virtual warehouses. They can be suspended, resumed, and modified to a different size.", "Multi-cluster virtual warehouses do not support Suspend, Resume, or Resize operations."], "explanation": "When you start a multi-cluster virtual warehouse in auto-scaling mode, the number of active virtual warehouses equals the minimum warehouse count. Snowflake creates new warehouses based on demand, up to the maximum warehouse count. Snowflake shuts down virtual warehouses when demand decreases until the number equals the minimum warehouse count. \n  \n Multi-cluster virtual warehouses support the standard virtual warehouse attributes and actions, such as specifying and altering warehouse size, suspending or auto-suspending a suspended multi-cluster virtual warehouse, resuming or auto-resuming a suspended multi-cluster virtual warehouse.\n  \n https://docs.snowflake.com/en/user-guide/warehouses-multicluster"}, "correct_response": ["a", "b", "c"], "section": "Performance Concepts", "question_plain": "Which of the following statements about a multi-cluster virtual warehouse in auto-scale mode is true?", "related_lectures": []}, {"_class": "assessment", "id": 70910060, "assessment_type": "multiple-choice", "prompt": {"question": "Which of the following scaling policies aims to minimize query queuing?", "answers": ["Standard", "Economy"], "explanation": "With the scaling policy set to Standard, Snowflake prefers to spin up extra virtual warehouses almost as soon as it detects that queries are starting to queue up. The Standard scaling policy aims to prevent or minimize queuing.\n  \n The Economy scaling policy attempts to conserve credits over performance and user experience. It doesn&#39;t spin up more virtual warehouses as soon as queuing is observed but instead applies additional criteria to ascertain whether or not to spin up new virtual warehouses.\n  \n https://docs.snowflake.com/en/user-guide/warehouses-multicluster#setting-the-scaling-policy-for-a-multi-cluster-warehouse"}, "correct_response": ["a"], "section": "Performance Concepts", "question_plain": "Which of the following scaling policies aims to minimize query queuing?", "related_lectures": []}, {"_class": "assessment", "id": 70910062, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>Which of the following query profile snippet indicates effective micro-partition pruning? </strong>\n&nbsp; \n</p><img src=\"https://img-b.udemycdn.com/redactor/raw/practice_test_question/2023-03-29_20-35-38-eb58bb10ab5066c62121084aac7bb9ef.png\"><p>&nbsp; &nbsp; &nbsp; &nbsp;<strong> Select all that apply.</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "Partition pruning occurs when the number of Partitions scanned is much smaller than Partitions total.\n  \n If the partitions scanned equal the partition total, the query scanned the complete table. Therefore, no partition pruning happened, and the clustering key should be improved.\n  \n https://docs.snowflake.com/en/user-guide/ui-query-profile", "answers": ["2", "3", "1", "4"]}, "correct_response": ["a", "b"], "section": "Performance Concepts", "question_plain": "Which of the following query profile snippet indicates effective micro-partition pruning? \n&nbsp; \n&nbsp; &nbsp; &nbsp; &nbsp; Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70910064, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>Consider the following snippet from the query profile of a finished query. </strong>\n&nbsp; \n</p><img src=\"https://img-b.udemycdn.com/redactor/raw/practice_test_question/2023-03-29_20-36-13-452f4eb19310a9b949eeb1160b37996c.png\"><p>\n&nbsp; \n&nbsp; <strong>\n Which of the following accurately describes the highlighted statistics?</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "Partition pruning occurs when the number of Partitions scanned is much smaller than Partitions total.\n  \n Snowflake saves data on the warehouse&#39;s local disk and sometimes remote cloud storage if it can&#39;t fit an operation into memory. Data spilling slows down queries because it requires more IO operations, and disk access is slower than memory access.\n  \n Each virtual warehouse builds its cache by periodically copying relevant micro-partitions from cloud storage to local SSD storage. A virtual warehouse&#39;s cache may contain data for multiple queries with similar criteria, columns, and rows. The virtual warehouse can retrieve the data from its local cache instead of the cloud storage, speeding up queries.\n  \n https://docs.snowflake.com/en/user-guide/ui-query-profile", "answers": ["The query profile indicates effective partition pruning.", "The query profile indicates that the virtual warehouse cache was used.", "The query profile indicates ineffective partition pruning.", "The query profile indicates that the virtual warehouse used is too small for the query."]}, "correct_response": ["a", "b"], "section": "Performance Concepts", "question_plain": "Consider the following snippet from the query profile of a finished query. \n&nbsp; \n\n&nbsp; \n&nbsp; \n Which of the following accurately describes the highlighted statistics?", "related_lectures": []}, {"_class": "assessment", "id": 70910066, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>Which of the following query profile results indicate that a query used a virtual warehouse sized too small for the query?</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "Snowflake saves data on the warehouse&#39;s local disk if it can&#39;t fit an operation into memory. Data spilling slows down queries because it requires more IO operations, and disk access is slower than memory access. &quot;Bytes spilled to local storage.&quot; indicates local spillage.\n  \n Snowflake will spill data to remote cloud storage if the local disk becomes full, which is even slower storage than the local disk, making this operation even slower. &quot;Bytes spilled to remote storage&quot; in the query profile indicates remote spillage.\n  \n One of the ways to avoid spilling is to use a larger warehouse, which will increase the overall available RAM, local storage, and parallelism and might be able to fit the query in memory.\n  \n https://docs.snowflake.com/en/user-guide/ui-query-profile#queries-too-large-to-fit-in-memory", "answers": ["The query profile shows a significant value for \u201cBytes spilled to remote storage.\u201d", "The query profile shows a significant value for \u201cBytes spilled to local storage.\u201d", "The query performs a full table scan, and no partition pruning occurs.", "There are many Join nodes.", "The Result node returns many rows."]}, "correct_response": ["a", "b"], "section": "Performance Concepts", "question_plain": "Which of the following query profile results indicate that a query used a virtual warehouse sized too small for the query?", "related_lectures": []}, {"_class": "assessment", "id": 70910068, "assessment_type": "multi-select", "prompt": {"question": "Which of the following statements correctly describe Search Optimization in Snowflake? Select all that apply.", "answers": ["The search optimization service is a Snowflake-managed service.", "The search optimization works in the background and updates the search access paths when the underlying table data changes.", "The search optimization service requires an active virtual warehouse."], "explanation": "The search optimization service is a Snowflake-managed service; it executes in the background and doesn&#39;t require a virtual warehouse. However, note that credit and storage costs are associated with Search optimization.\n  \n When the data in the table is changed (for example, by loading new data sets or performing their DML operations), the maintenance service updates the search access path to reflect the changes.\n  \n The search optimization configuration on a table and the maintenance service are transparent to the users.\n  \n https://docs.snowflake.com/en/user-guide/search-optimization-service"}, "correct_response": ["a", "b"], "section": "Performance Concepts", "question_plain": "Which of the following statements correctly describe Search Optimization in Snowflake? Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70910070, "assessment_type": "multi-select", "prompt": {"question": "What is the impact on the existing &amp; new queries when a virtual warehouse is scaled up or down? Select all that apply", "answers": ["Existing queries are not impacted.", "The changed size will impact only new queries.", "Existing queries will be impacted, and will start using the new size immediately."], "explanation": "Only new queries are affected by the changed size; existing queries on the virtual warehouse remain unaffected. \n  \n When a virtual warehouse is scaled down, nodes are removed from the virtual warehouse only when there is no active query on the virtual warehouse. Thus, existing queries are not impacted by resizing.\n  \n  \n https://docs.snowflake.com/en/user-guide/warehouses-considerations#warehouse-resizing-improves-performance"}, "correct_response": ["a", "b"], "section": "Performance Concepts", "question_plain": "What is the impact on the existing &amp; new queries when a virtual warehouse is scaled up or down? Select all that apply", "related_lectures": []}, {"_class": "assessment", "id": 70910080, "assessment_type": "multi-select", "prompt": {"question": "Which of the following security features are supported by Snowflake? Select all that apply", "answers": ["AES 256-bit encryption of data at rest", "Tri-Secret Secure encryption", "Key Rotation", "MD5 encryption of data at rest"], "explanation": "Snowflake uses AES 256-bit encryption as a standard for data at rest to protect all customer data. Snowflake rotates Snowflake-managed keys on an automatic basis every thirty days. When a Snowflake-controlled key and a customer-managed key are combined, the result is a composite master key that protects your data. Tri-Secret Secure is the name used to describe this combination of keys.\n  \n https://docs.snowflake.com/en/user-guide/security-encryption-end-to-end"}, "correct_response": ["a", "b", "c"], "section": "Security", "question_plain": "Which of the following security features are supported by Snowflake? Select all that apply", "related_lectures": []}, {"_class": "assessment", "id": 70910082, "assessment_type": "multiple-choice", "prompt": {"question": "How does Snowflake enforce network policy when an IP address is included in both the block list and the authorized list of the policy?", "answers": ["Snowflake first applies the blocked list, guaranteeing that the IP address is denied access regardless of whether it is also defined in the allow list.", "Snowflake first checks the approved list, guaranteeing that the IP address is permitted to connect, even if it is also defined on the block list.", "The network policy is invalid", "Snowflake network policy doesn&#39;t allow adding an IP address to both the block list and the allowed list"], "explanation": "A network policy comprises of three components: a name, a list of approved IP addresses, and a list of blocked IP addresses. Snowflake applies the blocked list first if both the authorized and blocked lists are populated.\n  \n https://docs.snowflake.com/en/user-guide/network-policies"}, "correct_response": ["a"], "section": "Security", "question_plain": "How does Snowflake enforce network policy when an IP address is included in both the block list and the authorized list of the policy?", "related_lectures": []}, {"_class": "assessment", "id": 70910084, "assessment_type": "multi-select", "prompt": {"question": "Which of the following roles are available out of the box in Snowflake?", "answers": ["PUBLIC", "SYSADMIN", "ORGADMIN", "SUPERUSER"], "explanation": "Built-in Snowflake roles include ORGADMIN, ACCOUNTADMIN, USERADMIN, SECURITYADMIN, SYSADMIN, and PUBLIC.\n  \n https://docs.snowflake.com/en/user-guide/security-access-control-overview#system-defined-roles."}, "correct_response": ["a", "b", "c"], "section": "Security", "question_plain": "Which of the following roles are available out of the box in Snowflake?", "related_lectures": []}, {"_class": "assessment", "id": 70910086, "assessment_type": "multiple-choice", "prompt": {"question": "You need to create a new Reader Account to share a table with a non-Snowflake customer. You are logged in with a SYSADMIN role. When you run the query to create the new Reader Account, you are met with a privilege error. What do you need to do to be able to create the Reader Account?", "answers": ["Switch your role to ACCOUNTADMIN. Only the ACCOUNTADMIN role is allowed to create new reader accounts.", "Switch the role to SECURITYADMIN. Only the SECURITYADMIN role is allowed to create new reader accounts.", "Use the WebUI to create the Reader Account."], "explanation": "Only the ACCOUNTADMIN role can create new Reader Accounts since it is an account-level activity.\n  \n https://docs.snowflake.com/en/user-guide/data-sharing-reader-create"}, "correct_response": ["a"], "section": "Security", "question_plain": "You need to create a new Reader Account to share a table with a non-Snowflake customer. You are logged in with a SYSADMIN role. When you run the query to create the new Reader Account, you are met with a privilege error. What do you need to do to be able to create the Reader Account?", "related_lectures": []}, {"_class": "assessment", "id": 70910088, "assessment_type": "multiple-choice", "prompt": {"question": "True or False: When a security administrator creates a new custom role, the custom role is automatically assigned to all existing users.", "answers": ["False", "True"], "explanation": "A new custom role is not automatically assigned to any user, but all new roles must be assigned manually to users.\n  \n https://docs.snowflake.com/en/user-guide/security-access-control-overview"}, "correct_response": ["a"], "section": "Security", "question_plain": "True or False: When a security administrator creates a new custom role, the custom role is automatically assigned to all existing users.", "related_lectures": []}, {"_class": "assessment", "id": 70910090, "assessment_type": "multi-select", "prompt": {"question": "Which of the following contributes toward the costs of a Snowflake system?", "answers": ["Cloud services layer", "Query processing layer", "Storage layer", "Number of queries"], "explanation": "The query processing layer, storage layer, and cloud services layer all contribute towards the costs of a Snowflake system.\n  \n https://docs.snowflake.com/en/user-guide/cost-understanding-overall"}, "correct_response": ["a", "b", "c"], "section": "Cost & Pricing", "question_plain": "Which of the following contributes toward the costs of a Snowflake system?", "related_lectures": []}, {"_class": "assessment", "id": 70910092, "assessment_type": "multiple-choice", "prompt": {"question": "What value does the CURRENT_CLIENT function return when called from an application using a JDBC driver to connect?", "answers": ["The version of the JDBC driver", "The name of the application", "The string \u2018JDBC.\u2019", "The string \u2018External Application.\u2019"], "explanation": "The CURRENT_CLIENT function returns the client\u2019s version from where the query was executed. When called from a query executed by an application using JDBC or ODBC driver, the version of the driver is returned.\n  \n For example, Calling CURRENT_CLIENT in Snowsight returns \u2018Go 1.1.5\u2019 since it uses the Go Driver.\n CURRENT_CLIENT in Classic Web UI returns \u2018Snowflake UI 20230324175929\u2019 since the Classic Web UI connects directly without a driver.\n Calling CURRENT C_CLIENT in SnowSQL returns \u2018SnowSQL 1.2.24\u2019.\n  \n https://docs.snowflake.com/en/sql-reference/functions/current_client"}, "correct_response": ["a"], "section": "Tools & Interfaces", "question_plain": "What value does the CURRENT_CLIENT function return when called from an application using a JDBC driver to connect?", "related_lectures": []}, {"_class": "assessment", "id": 70910094, "assessment_type": "multiple-choice", "prompt": {"question": "True or False: In the Snowsight worksheet view, you can share a worksheet with another user in the same Snowflake account.", "answers": ["True", "False"], "explanation": "Snowsight lets you share worksheets and folders with other Snowflake users in your account, allowing others to view and execute SQL in your worksheets and folders.\n  \n https://docs.snowflake.com/en/user-guide/ui-snowsight"}, "correct_response": ["a"], "section": "Tools & Interfaces", "question_plain": "True or False: In the Snowsight worksheet view, you can share a worksheet with another user in the same Snowflake account.", "related_lectures": []}, {"_class": "assessment", "id": 70910096, "assessment_type": "multiple-choice", "prompt": {"question": "True or False: Combining Cloning and Time Travel to create clones of data at a certain point in time is possible.", "answers": ["True", "False"], "explanation": "Combining Cloning and Time Travel can generate a clone of a table, database, or schema as it existed at a specific point in time. Because both Time Travel &amp; Cloning are metadata operations, they can easily be combined.\n  \n https://docs.snowflake.com/en/user-guide/data-time-travel#cloning-historical-objects"}, "correct_response": ["a"], "section": "Cloning", "question_plain": "True or False: Combining Cloning and Time Travel to create clones of data at a certain point in time is possible.", "related_lectures": []}, {"_class": "assessment", "id": 70910098, "assessment_type": "multiple-choice", "prompt": {"question": "True or False: A cloned object does not contribute to overall storage until DML operations on the source or target object are done.", "answers": ["True", "False"], "explanation": "When tables, schemas, or databases are cloned, the cloned item does not contribute to total storage until data manipulation language (DML) operations are performed on the source or target, which modify or delete existing data or add additional data.\n  \n https://docs.snowflake.com/en/user-guide/tables-storage-considerations#label-cloning-tables"}, "correct_response": ["a"], "section": "Cloning", "question_plain": "True or False: A cloned object does not contribute to overall storage until DML operations on the source or target object are done.", "related_lectures": []}, {"_class": "assessment", "id": 70910100, "assessment_type": "multi-select", "prompt": {"question": "Which of the following objects can be cloned? Select all that apply.", "answers": ["Stage", "File Format", "Sequence", "Task", "Virtual Warehouse", "Share"], "explanation": "Virtual warehouses &amp; Share objects cannot be cloned.\n \n Tables, Schemas &amp; Databases can be cloned.\n Other objects that can be cloned include Stages, File Formats, Tasks, Sequences, and Streams.\n  \n https://docs.snowflake.com/en/user-guide/object-clone"}, "correct_response": ["a", "b", "c", "d"], "section": "Cloning", "question_plain": "Which of the following objects can be cloned? Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70910102, "assessment_type": "multiple-choice", "prompt": {"question": "<p><strong>An administrator must grant explicit privileges on a cloned database as the cloning does not copy the privileges of the source database.</strong></p>", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "<p>A cloned object does not inherit any privileges from its source object; for instance, a cloned table does not inherit any privileges from its source table. </p><p>However, if a database or schema is cloned, privileges are inherited by the child objects in the database. The database doesn't inherit any privileges.&nbsp; </p><p>https://docs.snowflake.com/en/user-guide/object-clone#access-control-privileges-for-cloned-objects</p>", "answers": ["True", "False"]}, "correct_response": ["a"], "section": "Cloning", "question_plain": "An administrator must grant explicit privileges on a cloned database as the cloning does not copy the privileges of the source database.", "related_lectures": []}, {"_class": "assessment", "id": 70910072, "assessment_type": "multiple-choice", "prompt": {"question": "True or False: Multi-factor authentication, or MFA, is enabled by default for all Snowflake accounts.", "answers": ["True", "False"], "explanation": "MFA is enabled by default for all Snowflake accounts and is available in all Snowflake editions.\n  \n https://docs.snowflake.com/en/user-guide/security-mfa"}, "correct_response": ["a"], "section": "Security", "question_plain": "True or False: Multi-factor authentication, or MFA, is enabled by default for all Snowflake accounts.", "related_lectures": []}, {"_class": "assessment", "id": 70910074, "assessment_type": "multi-select", "prompt": {"question": "Which of the following statements best describe Snowflake&#39;s multi-factor authentication (MFA) capability? Select all that apply", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "Multi-factor authentication (MFA) is enabled by default for all Snowflake accounts, and any Snowflake user can enroll themselves in MFA through the Snowflake web interface. An administrator can disable a user&#39;s MFA enrolment; in this case, the user must re-enroll to access the MFA features and functionality.\n  \n An administrator with the SECURITYADMIN or above role can disable MFA for a user. \n  \n All Snowflake client tools, including the web interface, SnowSQL, and the various connectors and drivers, support MFA.\n  \n https://docs.snowflake.com/en/user-guide/security-mfa", "answers": ["Multi-factor authentication (MFA) is enabled by default for all users; however, users must enroll themselves in MFA manually.", "An administrator can turn off a user&#39;s MFA.", "SnowSQL, Snowflake ODBC, JDBC, and the Python Connector are all MFA-compatible.", "<p><strong>Only Snowflake's Web Interface and SnowSQL allow multi-factor authentication.</strong></p>"]}, "correct_response": ["a", "b", "c"], "section": "Security", "question_plain": "Which of the following statements best describe Snowflake&#39;s multi-factor authentication (MFA) capability? Select all that apply", "related_lectures": []}, {"_class": "assessment", "id": 70910076, "assessment_type": "multiple-choice", "prompt": {"question": "True or False: Snowflake allows single sign-on (SSO) with a SAML 2.0-compliant external identity provider for federated authentication (IdP).", "answers": ["True", "False"], "explanation": "Snowflake supports federated authentication, allowing for single sign-on (SSO). Users authenticate using a SAML 2.0-compliant external identity provider (IdP). After IdP authentication, users can access Snowflake without logging in. Snowflake natively supports the majority of SAML 2.0 compliant identity providers, including Okta, ADFS, OneLogin, and Ping Identity PingOne.\n  \n https://docs.snowflake.com/en/user-guide/admin-security-fed-auth"}, "correct_response": ["a"], "section": "Security", "question_plain": "True or False: Snowflake allows single sign-on (SSO) with a SAML 2.0-compliant external identity provider for federated authentication (IdP).", "related_lectures": []}, {"_class": "assessment", "id": 70910078, "assessment_type": "multiple-choice", "prompt": {"question": "To implement row-level security, what type of policies should be configured?", "answers": ["Row Access Policies", "Masking Policies", "Object Policies", "Table Policies"], "explanation": "Row-level security is implemented by creating row access policies, which include conditions and functions that govern which rows are returned during query execution.\n  \n https://docs.snowflake.com/en/user-guide/security-row-intro"}, "correct_response": ["a"], "section": "Security", "question_plain": "To implement row-level security, what type of policies should be configured?", "related_lectures": []}, {"_class": "assessment", "id": 70910104, "assessment_type": "multiple-choice", "prompt": {"question": "<p><strong>You executed a Time Travel query that attempts to access the state of data as it was 120 days ago. What is the likely outcome?</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>A time travel query will fail, and an error will be returned if the TIMESTAMP, OFFSET, or STATEMENT supplied in the AT | BEFORE clause is outside the Time Travel retention period (90 days max) for the table.</p><p>The same error is thrown if the time travel query attempts to access the table data before it was created.</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/data-time-travel#querying-historical-data</p>", "answers": ["<p><strong>The query fails with the following error. \"Time travel data is not available for the table. The requested time is either beyond the allowed time travel period or before the object creation time.\"</strong></p>", "<p><strong>The query executes successfully but shows no rows.</strong></p>", "<p><strong>The query executes successfully and shows the data as it existed 120 days ago.</strong></p>", "<p><strong>The query executes successfully but returns blank values in each row.</strong></p>"]}, "correct_response": ["a"], "section": "Time Travel", "question_plain": "You executed a Time Travel query that attempts to access the state of data as it was 120 days ago. What is the likely outcome?", "related_lectures": []}, {"_class": "assessment", "id": 70910106, "assessment_type": "multiple-choice", "prompt": {"question": "<p><strong>True or False: A consumer account has created a read-only database on a shared database. The consumer account can further share this database &amp; its tables with other accounts.</strong></p>", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "<p>Consumer accounts can only access and query data but cannot add, modify, or create database objects to a shared database.</p><p><br></p><p>Consumer accounts cannot clone a shared database, its schemas, or any of its tables.</p><p>Consumer accounts cannot use Time Travel on the shared data.</p><p>Consumer accounts cannot further share a shared database.</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/data-share-consumers#general-limitations-for-shared-databases</p>", "answers": ["<p><strong>False</strong></p>", "<p><strong>True</strong></p>"]}, "correct_response": ["a"], "section": "Data Sharing", "question_plain": "True or False: A consumer account has created a read-only database on a shared database. The consumer account can further share this database &amp; its tables with other accounts.", "related_lectures": []}, {"_class": "assessment", "id": 70910108, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>Which of the following table types allow Time Travel queries?</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p>Transient and temporary tables don't have fail-safe functionality; therefore, data in such tables goes through zero days of fail-safe storage. However, Transient and Temporary tables do have a maximum of 1 day of Time Travel.</p><p><br></p><p>Permanent tables also have time travel capability and can go up to 90 days of time travel depending on the configuration.</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/tables-temp-transient</p>", "answers": ["<p><strong>Temporary Tables</strong></p>", "<p><strong>Transient Tables</strong></p>", "<p><strong>Permanent Tables</strong></p>", "<p><strong>External Tables</strong></p>", "<p><strong>View-based Tables</strong></p>"]}, "correct_response": ["a", "b", "c"], "section": "Time Travel", "question_plain": "Which of the following table types allow Time Travel queries?", "related_lectures": []}, {"_class": "assessment", "id": 70910110, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>Which of the following object do NOT support cloning operations?</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p><strong>A database created from a share object can not be cloned.</strong></p><p><br></p><p><strong>Internal Snowflake stages are also not supported by Cloning.</strong></p>", "answers": ["<p><strong>Database created from a share</strong></p>", "<p><strong>Internal Stages</strong></p>", "<p><strong>Transient Tables</strong></p>", "<p><strong>Permanent Tables</strong></p>"]}, "correct_response": ["a", "b"], "section": "Cloning", "question_plain": "Which of the following object do NOT support cloning operations?", "related_lectures": []}, {"_class": "assessment", "id": 70910112, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>When a database or a schema is cloned, which of the following objects will NOT be cloned?</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p>Cloning for an external table is not supported. The data for external tables sits outside Snowflake; therefore, cloning an external table does not work.</p><p><br></p><p>Named Internal Stages cannot be cloned.</p><p><br></p><p>When a database or schema is cloned, any Snowpipe that points to a Named Internal Stage is not cloned.</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/object-clone</p>", "answers": ["<p><strong>External Tables</strong></p>", "<p><strong>Internal Snowflake Stages</strong></p>", "<p><strong>Snowpipes that point to an Internal Snowflake Stage</strong></p>", "<p><strong>Transient Tables</strong></p>", "<p><strong>Permanent Tables</strong></p>"]}, "correct_response": ["a", "b", "c"], "section": "Cloning", "question_plain": "When a database or a schema is cloned, which of the following objects will NOT be cloned?", "related_lectures": []}, {"_class": "assessment", "id": 70910114, "assessment_type": "multiple-choice", "prompt": {"question": "<p><strong>PowerBI, Looker, MicroStrategy, Tableau, Qlik are what type of partners in the Snowflake partner ecosystem?</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>All of these are Business Intelligence partners of Snowflake. Please see https://docs.Snowflake.com/en/user-guide/ecosystem.html</p>", "answers": ["<p><strong>Business Intelligence</strong></p>", "<p><strong>Data Integration</strong></p>", "<p><strong>Machine Learning &amp; Data Science</strong></p>", "<p><strong>Security, Governance &amp; Observability</strong></p>"]}, "correct_response": ["a"], "section": "Partners", "question_plain": "PowerBI, Looker, MicroStrategy, Tableau, Qlik are what type of partners in the Snowflake partner ecosystem?", "related_lectures": []}, {"_class": "assessment", "id": 70910116, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>Which of the following statements are true when a new trial account is created for a partner using Partner Connect?</strong></p><p><br></p><p><strong>Select all that apply.</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", "", "", ""], "explanation": "<p>While connecting to a Partner application, Snowflake automatically creates several objects, such as an empty database, virtual warehouse, default user, and custom role. When the partner app reads or writes to your account, it uses these objects.</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/ecosystem-partner-connect#connecting-with-a-snowflake-partner</p><p><br></p>", "answers": ["<p><strong>A new empty database is created.</strong></p>", "<p><strong>A virtual warehouse is created.</strong></p>", "<p><strong>A new user is created.</strong></p>", "<p><strong>A new custom role is created.</strong></p>", "<p><strong>A new reader account is created.</strong></p>", "<p><strong>Data sharing is disabled.</strong></p>"]}, "correct_response": ["a", "b", "c", "d"], "section": "Partners", "question_plain": "Which of the following statements are true when a new trial account is created for a partner using Partner Connect?Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70910118, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>Which of the following statements is true regarding Resource Monitors in Snowflake?</strong></p><p><strong>Select all that apply.</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>Resource monitors are not meant to precisely control how much is used every hour (or minute). Instead, they are meant to track and control how much is used daily, weekly, monthly, etc. They are not meant to set exact limits on how many credits can be used. When a resource monitor's credit limits are reached, it may take a while for the assigned warehouses to be put on hold, even if the action is \"Suspend Immediately.\", which may result in more credit than the credit limit to be used.</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/resource-monitors</p>", "answers": ["<p><strong>Resource monitors are not meant to tightly control how credit much is used every hour.</strong></p>", "<p><strong>Resource monitors are not meant to set highly precise limits on how much credit can be used.</strong></p>", "<p><strong>Resource monitors can control credit usage to a high degree of precision.</strong></p>", "<p><strong>Resource monitors can monitor credit usage on a per-minute basis.</strong></p>"]}, "correct_response": ["a", "b"], "section": "Account Usage & Monitoring", "question_plain": "Which of the following statements is true regarding Resource Monitors in Snowflake?Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70910120, "assessment_type": "multiple-choice", "prompt": {"question": "<p><strong>When a multi-cluster virtual warehouse is suspended, which one of the following caches will be purged?</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>Every time a virtual warehouse accesses data from a table, it caches that data locally. This data cache can improve the performance of subsequent queries if those queries can reuse the data in the cache instead of reading from the table in the cloud storage. Reading from a local cache is a much more efficient operation than reading data from the cloud storage; therefore, it improves performance for queries that can take advantage of it.</p><p><br></p><p>The warehouse cache is purged if the virtual warehouse is suspended. When the virtual house is resumed, the warehouse cache is rebuilt over time as queries are processed.</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/warehouses-considerations#how-does-warehouse-caching-impact-queries</p>", "answers": ["<p><strong>Warehouse Cache (local disk cache)</strong></p>", "<p><strong>Query Result Cache</strong></p>", "<p><strong>Metadata Cache</strong></p>", "<p><strong>Browser Cache</strong></p>"]}, "correct_response": ["a"], "section": "Performance Concepts", "question_plain": "When a multi-cluster virtual warehouse is suspended, which one of the following caches will be purged?", "related_lectures": []}, {"_class": "assessment", "id": 70910122, "assessment_type": "multiple-choice", "prompt": {"question": "<p><strong>True or False. You can use expressions in the clustering key definition to reduce a column's cardinality.</strong></p>", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "<p>If you need to use a column with high cardinality in a clustering key, you can define the key as an expression, which can help lower the cardinality by lowering the number of distinct values. For example, if a table has a timestamp column you want to use in a clustering key, you can convert the timestamp to a date to reduce the cardinality. This approach will help improve partition pruning.</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/tables-clustering-keys#strategies-for-selecting-clustering-keys</p>", "answers": ["<p><strong>True</strong></p>", "<p><strong>False</strong></p>"]}, "correct_response": ["a"], "section": "Performance Concepts", "question_plain": "True or False. You can use expressions in the clustering key definition to reduce a column's cardinality.", "related_lectures": []}, {"_class": "assessment", "id": 70910124, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>Time Travel can help with which of the following scenarios?</strong></p><p><strong>(Assume a time travel duration of 90 days).</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", ""], "explanation": "<p>You can use Time Travel AT and BEFORE extensions to recover all deleted rows from the production table.</p><p><br></p><p>You can use the UNDROP statement, which can be used to recover tables, schemas, or even complete databases after they have been dropped.</p><p><br></p><p>Using Time Travel, you can not recover from a data issue before the maximum time travel period, i.e., 90 days. You must request Snowflake support to recover data from the fail-safe storage.</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/data-time-travel#time-travel-sql-extensions</p>", "answers": ["<p><strong>A new data pipeline rolled out in production yesterday has deleted all rows from a production table.</strong></p>", "<p><strong>An administrator accidentally dropped a production table last week.</strong></p>", "<p><strong>A data corruption issue that corrupted three production tables 93 days ago was discovered.</strong></p>"]}, "correct_response": ["a", "b"], "section": "Time Travel", "question_plain": "Time Travel can help with which of the following scenarios?(Assume a time travel duration of 90 days).", "related_lectures": []}, {"_class": "assessment", "id": 70910126, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>Which of the following schemas are automatically created with a new database?</strong></p><p><strong>Select all that apply.</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p>The INFORMATION_SCHEMA provides metadata on the objects in the parent database of the INFORMATION_SCHEMA. It is automatically created with every database and can not be dropped, renamed, or moved.</p><p><br></p><p>The PUBLIC schema is also automatically created with every database, but it is just like an ordinary schema. It can be dropped, renamed, or moved. If required, additional schemas may be created under a database.</p><p><br></p><p>https://docs.snowflake.com/en/sql-reference/info-schema#information-schema-views-and-table-functions</p>", "answers": ["<p><strong>INFORMATION_SCHEMA</strong></p>", "<p><strong>PUBLIC</strong></p>", "<p><strong>PRIVATE</strong></p>", "<p><strong>INTERNAL</strong></p>", "<p><strong>CATALOGUE</strong></p>"]}, "correct_response": ["a", "b"], "section": "Snowflake\u2019s catalog and objects", "question_plain": "Which of the following schemas are automatically created with a new database?Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70910128, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>Which of the following is true regarding the default role in Snowflake?</strong></p><p><strong>Select all that apply.</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>Each Snowflake user is automatically assigned the PUBLIC role. Each user can be assigned additional roles, one of which can be set as their default role. A user's default role determines the role automatically used in Snowflake sessions that the user initiates; however, this is only a default. Users can switch roles at any point during a session.</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/admin-user-management#user-roles</p>", "answers": ["<p><strong>When users log in, their role is automatically set to their default role.</strong></p>", "<p><strong>A user can switch their current role if required.</strong></p>", "<p><strong>A user can not use any other role other than their default role.</strong></p>", "<p><strong>When a user switches to another role in a session, their user's default role automatically reconfigures to the new role.</strong></p>"]}, "correct_response": ["a", "b"], "section": "Security", "question_plain": "Which of the following is true regarding the default role in Snowflake?Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70910130, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>Which of the following use cases are suitable to execute on Snowflake?</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p>Snowflake is an analytical database for implementing data lakes, data warehouses, data lakehouses, running data science workloads, executing data engineering processes, business intelligence, ad-hoc analysis, data sharing, etc.</p>", "answers": ["<p><strong>Data Lake Implementation</strong></p>", "<p><strong>Data Warehouse Implementation</strong></p>", "<p><strong>Data Science Processing</strong></p>", "<p><strong>Data Sharing</strong></p>", "<p><strong>Use as an Embedded Database</strong></p><p><br></p>"]}, "correct_response": ["a", "b", "c", "d"], "section": "Licensing & Features", "question_plain": "Which of the following use cases are suitable to execute on Snowflake?", "related_lectures": []}, {"_class": "assessment", "id": 70910132, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>Which of the following are ways to provision a Snowflake instance?</strong></p><p><strong>Select all that apply.</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", "", "", ""], "explanation": "<p>Snowflake is engineered for the cloud and is available only on AWS, Azure &amp; GCP. A Snowflake instance must be provisioned through Snowflake. Instances are hosted by Snowflake using AWS, Azure, or GCP as the underlying infrastructure.</p>", "answers": ["<p><strong>Provision a Snowflake-hosted and managed instance (with AWS as underlying infrastructure)</strong></p>", "<p><strong>Provision a Snowflake-hosted and managed instance (with Azure as the underlying infrastructure)</strong></p>", "<p><strong>Provision a Snowflake-hosted and managed instance (with GCP as underlying infrastructure)</strong></p>", "<p><strong>Perform a hybrid installation using a mix of on-premises technology and cloud infrastructure.</strong></p>", "<p><strong>Install manually on virtual machines on an AWS account.</strong></p>", "<p><strong>Install on-premises on commodity hardware.</strong></p>"]}, "correct_response": ["a", "b", "c"], "section": "Licensing & Features", "question_plain": "Which of the following are ways to provision a Snowflake instance?Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70910134, "assessment_type": "multiple-choice", "prompt": {"question": "<p><strong>An external stage can be enabled during the creation of a stage object or enabled afterward. Which of the following SQL enables the directory table?</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>The correct syntax for enabling (or disabling) a directory table for a stage is to use the DIRECTORY = (ENABLE = TRUE | FALSE) syntax while creating or altering a stage.</p><p><br></p><p>https://docs.snowflake.com/en/sql-reference/sql/alter-stage</p>", "answers": ["<p><strong>ALTER STAGE &lt;STAGE_NAME&gt; SET DIRECTORY = (ENABLE = TRUE);</strong></p>", "<p><strong>ALTER STAGE &lt;STAGE_NAME&gt; ADD DIRECTORY;</strong></p>", "<p><strong>CREATE DIRECTORY TABLE &lt;TABLE_NAME&gt; ON &lt;STAGE_NAME&gt;;</strong></p>", "<p><strong>GENERATE DIRECTORY TABLE ON &lt;STAGE_NAME&gt;;</strong></p>"]}, "correct_response": ["a"], "section": "Data Transformation", "question_plain": "An external stage can be enabled during the creation of a stage object or enabled afterward. Which of the following SQL enables the directory table?", "related_lectures": []}, {"_class": "assessment", "id": 70910136, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>Which of the following actions occur when a directory table's metadata is refreshed?</strong></p><p><br></p><p><strong>Select all that apply.</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", ""], "explanation": "<p>All of these are valid answers.</p><p>A directory table's metadata can be manually refreshed or configured to auto-refresh. When the metadata is refreshed, it synchronizes it with the current state of files in the stage. It will synchronize files that are new in the external stage are added to the directory table's metadata, and deleted files are removed from the directory table's metadata. Additionally, any changes to the file paths are reflected in the directory table's metadata.</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/data-load-dirtables-intro#automatically-refreshing-directory-table-metadata</p>", "answers": ["<p><strong>Files that are new in the external stage are added to the directory table's metadata.</strong></p>", "<p><strong>Files that have been deleted are removed from the directory table's metadata.</strong></p>", "<p><strong>The directory table's metadata reflects changes to the file paths.</strong></p>"]}, "correct_response": ["a", "b", "c"], "section": "Data Transformation", "question_plain": "Which of the following actions occur when a directory table's metadata is refreshed?Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70910138, "assessment_type": "multiple-choice", "prompt": {"question": "<p><strong>The expiry duration can be configured for which of the following URL types?</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", ""], "explanation": "<p>A file URL is a permanent Snowflake-hosted URL to a staged file. File URLs don't expire.</p><p><br></p><p>A scoped URL is a temporary and encoded URL that allows temporary access to a staged file without requiring any privileges on the stage. A scoped URL expires after 24 hours.</p><p><br></p><p>A pre-signed URL is a simple HTTPS URL for accessing a file using a web browser. The expiry duration of a pre-signed URL is configurable and can be set to the required duration.</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/unstructured-intro#types-of-urls-available-to-access-files</p>", "answers": ["<p><strong>Pre-signed URL</strong></p>", "<p><strong>File URL</strong></p>", "<p><strong>Scoped URL</strong></p>"]}, "correct_response": ["a"], "section": "Data Transformation", "question_plain": "The expiry duration can be configured for which of the following URL types?", "related_lectures": []}, {"_class": "assessment", "id": 70910140, "assessment_type": "multiple-choice", "prompt": {"question": "<p><strong>Which of the following approaches will give you the credit used by each virtual warehouse for the last 12 months?</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>The WAREHOUSE_METERING_HISTORY view in the ACCOUNT_USAGE schema provides credit usage for each virtual warehouse in your system, broken down by hour. The view provides information from the last 365 days.</p><p><br></p><p>https://docs.snowflake.com/en/sql-reference/account-usage/warehouse_metering_history</p>", "answers": ["<p><strong>Query the WAREHOUSE_METERING_HISTORY view in the ACCOUNT_USAGE schema</strong></p>", "<p><strong>Query the METERING_DAILY_HISTORY view in the ACCOUNT_USAGE schema</strong></p>", "<p><strong>Query the METERING_HISTORY view in the ACCOUNT_USAGE schema</strong></p>", "<p><strong>Request Snowflake support to provide you with a detailed virtual warehouse credit usage report.</strong></p>"]}, "correct_response": ["a"], "section": "Account Usage & Monitoring", "question_plain": "Which of the following approaches will give you the credit used by each virtual warehouse for the last 12 months?", "related_lectures": []}, {"_class": "assessment", "id": 70910142, "assessment_type": "multiple-choice", "prompt": {"question": "<p><strong>Which of the following ACCOUNT_USAGE view can be used to view roles granted to users?</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>The GRANTS_TO_USERS view can be used to view information about roles that have been granted to users. This view also contains historical information (up to 365 days), so roles that have been granted and revoked in the last 365 days will also be shown.</p><p><br></p><p>https://docs.snowflake.com/en/sql-reference/account-usage/grants_to_users</p>", "answers": ["<p><strong>GRANTS_TO_USERS</strong></p>", "<p><strong>GRANTS_TO_ROLES</strong></p>", "<p><strong>OBJECT_DEPENDENCIES</strong></p>", "<p><strong>ACCESS_HISTORY</strong></p>"]}, "correct_response": ["a"], "section": "Account Usage & Monitoring", "question_plain": "Which of the following ACCOUNT_USAGE view can be used to view roles granted to users?", "related_lectures": []}, {"_class": "assessment", "id": 70910144, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>Database and table cloning can be used to satisfy which of the following scenarios?</strong></p><p><br></p><p><strong>Select all that apply.</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", "", "", ""], "explanation": "<p>Cloning in Snowflake lets you quickly spin up development and testing environments by creating copies of databases, schemas, or tables.</p><p><br></p><p>Snowflake's Time Travel feature allows you to access and clone data at specific points in time within a retention period. By leveraging Time Travel with cloning, you can create testing environments that reflect specific scenarios or historical data states.</p><p><br></p><p>Time Travel automatically provides some back and recovery capability; however, it is limited to the maximum data retention period, which can only be up to 90 days. Therefore, performing regular backups in Snowflake is still a requirement. One way of backing up data in Snowflake is to export data from individual tables to cloud storage; however, you can also utilize the cloning capability in Snowflake to perform backups of critical databases.</p>", "answers": ["<p><strong>Quickly create non-prod databases by creating clones of production objects.</strong></p>", "<p><strong>Create backups of critical databases.</strong></p>", "<p><strong>Create point-in-time backups by cloning with Time Travel.</strong></p>", "<p><strong>Load data incrementally.</strong></p>", "<p><strong>Improve performance for SELECT queries.</strong></p>", "<p><strong>Improve JOIN performance.</strong></p>"]}, "correct_response": ["a", "b", "c"], "section": "Cloning", "question_plain": "Database and table cloning can be used to satisfy which of the following scenarios?Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70910146, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>Consider a database with the name MARKETING. The database has a table called CUSTOMER in the PUBLIC schema. The CUSTOMER table has <em>10,000</em> rows. The PUBLIC schema also has a view called CUSTOMER_COUNT with the following definition.</strong></p><p><br></p><p><strong>\u201cSELECT COUNT(*) FROM MARKETING.PUBLIC.CUSTOMER;\u201d</strong></p><p><br></p><p><strong>You create a temporary table with the same name, i.e., CUSTOMER, in the PUBLIC schema of the MARKETING database. The temporary table has <em>zero </em>rows.</strong></p><p><br></p><p><strong>Which of the following correctly describes the results when the view is queried?</strong></p><p><br></p><p><strong>Select two answers.</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>If a temporary table is created in a schema with the same name as a permanent (or transient) table, the temporary table effectively hides the permanent table in that session. Queries and other operations during the session will affect only the temporary table.</p><p><br></p><p>This behavior can affect the views as well. In the same session where a temporary table was created, a temporary table can hide the permanent table used by a view, resulting in unexpected results. However, the view is unaffected when queried from a different session because temporary tables are limited to the session where they are created.</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/tables-temp-transient#potential-naming-conflicts-with-other-table-types</p>", "answers": ["<p><strong>A \"SELECT * FROM CUSTOMER_COUNT;\" query will return zero as the result when executed in the same session in which the temporary table was created.</strong></p>", "<p><strong>A \"SELECT * FROM CUSTOMER_COUNT;\" query will return 10,000 as the result when executed in a new session.</strong></p>", "<p><strong>A \"SELECT * FROM CUSTOMER_COUNT;\" query will return 10,000 as the result when executed in the same session in which the temporary table was created.</strong></p>", "<p><strong>A \"SELECT * FROM CUSTOMER_COUNT;\" query will return zero rows as the result executed in a new session.</strong></p>"]}, "correct_response": ["a", "b"], "section": "Snowflake\u2019s catalog and objects", "question_plain": "Consider a database with the name MARKETING. The database has a table called CUSTOMER in the PUBLIC schema. The CUSTOMER table has 10,000 rows. The PUBLIC schema also has a view called CUSTOMER_COUNT with the following definition.\u201cSELECT COUNT(*) FROM MARKETING.PUBLIC.CUSTOMER;\u201dYou create a temporary table with the same name, i.e., CUSTOMER, in the PUBLIC schema of the MARKETING database. The temporary table has zero rows.Which of the following correctly describes the results when the view is queried?Select two answers.", "related_lectures": []}, {"_class": "assessment", "id": 70910148, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>Which of the following correctly describes the behavior of a materialized view when its base table is dropped?</strong></p><p><br></p><p><strong>Select two answers.</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>If the base table of a materialized view is dropped, the materialized view is NOT automatically dropped; however, it is suspended. You must manually drop the materialized view.</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/views-materialized#dropping-the-base-table</p>", "answers": ["<p><strong>The materialized view is suspended.</strong></p>", "<p><strong>The materialized view is NOT dropped automatically.</strong></p>", "<p><strong>The materialized view is automatically dropped.</strong></p>", "<p><strong>A table with a materialized view on top can not be dropped. The materialized view must be dropped first.</strong></p>"]}, "correct_response": ["a", "b"], "section": "Performance Concepts", "question_plain": "Which of the following correctly describes the behavior of a materialized view when its base table is dropped?Select two answers.", "related_lectures": []}, {"_class": "assessment", "id": 70910150, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>How does the Search Optimization service in Snowflake improve query performance?</strong></p><p><br></p><p><strong>Select two answers.</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p>The search optimization service can significantly enhance the performance of some lookup and analytical queries that use many predicates for filtering.</p><p>The search optimization service uses a persistent data structure as an optimized search access path to speed up point lookups.</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/search-optimization-service</p>", "answers": ["<p><strong>It improves the performance of queries that use equality predicate.</strong></p>", "<p><strong>It uses a persistent data structure as an optimized search access path to speed up point lookups.</strong></p>", "<p><strong>It re-distributes data according to the defined clustering key.</strong></p>", "<p><strong>It pre-computes the results of common queries.</strong></p>", "<p><strong>It increases the cache time-out so that more queries are answered from the cache</strong>.</p>"]}, "correct_response": ["a", "b"], "section": "Performance Concepts", "question_plain": "How does the Search Optimization service in Snowflake improve query performance?Select two answers.", "related_lectures": []}, {"_class": "assessment", "id": 70910152, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>Which of the following factors influence the cost of maintaining a materialized view?</strong></p><p><strong>Select two answers.</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>The costs of keeping data in materialized views are impacted by</p><p><br></p><p>1) The number of materialized views created for each base table.</p><p>2) The extent of data changes occurring in these materialized views when changes are made to the base table.</p><p>3) The number of these materialized views with a clustering key is defined.</p><p><br></p><p>Each materialized view saves the results of queries, which adds to the amount of storage space your account uses each month.</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/views-materialized#label-materialized-views-maintenance-billing</p>", "answers": ["<p><strong>The amount of data that changes in the materialized view when updates occur in the base table.</strong></p>", "<p><strong>The storage required to store results of the query used in the materialized view definition.</strong></p>", "<p><strong>The total amount of data in the base table.</strong></p>", "<p><strong>The number of columns in the base table.</strong></p>"]}, "correct_response": ["a", "b"], "section": "Performance Concepts", "question_plain": "Which of the following factors influence the cost of maintaining a materialized view?Select two answers.", "related_lectures": []}, {"_class": "assessment", "id": 70910154, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>A permanent table can be cloned to which other table types?</strong></p><p><br></p><p><strong>Select all that apply.</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>A permanent table may be cloned into another permanent table, a transient or temporary table.</p><p><br></p><p>However, a transient or temporary table can not be cloned into a permanent table.</p>", "answers": ["<p><strong>Permanent Table</strong></p>", "<p><strong>Temporary Table</strong></p>", "<p><strong>Transient Table</strong></p>", "<p><strong>External Table</strong></p>"]}, "correct_response": ["a", "b", "c"], "section": "Cloning", "question_plain": "A permanent table can be cloned to which other table types?Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70910156, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>Which of the following can be configured for a user profile in Snowsight?</strong></p><p><br></p><p><strong>Select two answers.</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>Using the profile dialogue in Snowsight, you can enroll in MFA, specify your notification preferences, set your email address, and configure your profile's default role and default warehouse. Other things can also be configured such as name, password, language, etc.</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/ui-snowsight-profile</p>", "answers": ["<p><strong>Multi-factor Authentication</strong></p>", "<p><strong>Notifications</strong></p>", "<p><strong>Single Signon</strong></p>", "<p><strong>Tri Secret Secure</strong></p>"]}, "correct_response": ["a", "b"], "section": "Tools & Interfaces", "question_plain": "Which of the following can be configured for a user profile in Snowsight?Select two answers.", "related_lectures": []}, {"_class": "assessment", "id": 70910158, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>Which information is displayed in the Statistics box in the Query Profile?</strong></p><p><br></p><p><strong>Select two answers.</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>Please see the link for details.</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/ui-query-profile#statistics</p>", "answers": ["<p><strong>Bytes spilled to local storage</strong></p>", "<p><strong>Bytes spilled to remote storage</strong></p>", "<p><strong>Operator tree</strong></p>", "<p><strong>Query Steps</strong></p>"]}, "correct_response": ["a", "b"], "section": "Performance Concepts", "question_plain": "Which information is displayed in the Statistics box in the Query Profile?Select two answers.", "related_lectures": []}, {"_class": "assessment", "id": 70910160, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>Which of the following can be chosen when creating a new Snowflake account?</strong></p><p><br></p><p><strong>Select all that apply.</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", "", "", ""], "explanation": "<p>Using the CREATE ACCOUNT statement, you can specify the account name, the Snowflake edition, the region (which contains the cloud platform information), the region group, and details about the administrative user, including name, password, email, etc.</p><p><br></p><p>https://docs.snowflake.com/en/sql-reference/sql/create-account</p>", "answers": ["<p><strong>Snowflake Edition</strong></p>", "<p><strong>Region</strong></p>", "<p><strong>Administrator user details</strong></p>", "<p><strong>Account Name</strong></p>", "<p><strong>Account Locator</strong></p>", "<p><strong>Organization Name</strong></p>"]}, "correct_response": ["a", "b", "c", "d"], "section": "Licensing & Features", "question_plain": "Which of the following can be chosen when creating a new Snowflake account?Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70910162, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>Which of the following data types can optimally store semi-structured data?</strong></p><p><br></p><p><strong>Select three answers.</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", "", "", ""], "explanation": "<p>OBJECT, ARRAY and VARIANT are suitable data types for storing and processing semi-structured data.</p><p><br></p><p>https://docs.snowflake.com/en/sql-reference/data-types-semistructured</p>", "answers": ["<p><strong>ARRAY</strong></p>", "<p><strong>VARIANT</strong></p>", "<p><strong>OBJECT</strong></p>", "<p><strong>STRING</strong></p>", "<p><strong>VARCHAR</strong></p>", "<p><strong>CHAR</strong></p>"]}, "correct_response": ["a", "b", "c"], "section": "Data Transformation", "question_plain": "Which of the following data types can optimally store semi-structured data?Select three answers.", "related_lectures": []}, {"_class": "assessment", "id": 70910164, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>A suspended virtual warehouse is increased in size. Which of the following correctly describes what will happen?</strong></p><p><br></p><p><strong>Select all that apply.</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p>You can resize a virtual warehouse at any time, even when suspended. When resizing a suspended virtual warehouse, its configuration is updated to reflect the new size. A suspended virtual warehouse has no provisioned nodes; it only has a configuration that tells Snowflake what to provision.</p><p>The provisioning of new nodes only occurs when the warehouse is resumed.</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/warehouses-tasks#resizing-a-warehouse</p>", "answers": ["<p><strong>The warehouse remains suspended.</strong></p>", "<p><strong>Additional nodes are only provisioned when the virtual warehouse is resumed.</strong></p>", "<p><strong>The configuration of the virtual warehouse is updated to reflect the new size.</strong></p>", "<p><strong>Additional nodes are immediately provisioned.</strong></p>", "<p><strong>The virtual warehouse is resumed immediately.</strong></p>"]}, "correct_response": ["a", "b", "c"], "section": "Architecture", "question_plain": "A suspended virtual warehouse is increased in size. Which of the following correctly describes what will happen?Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70910166, "assessment_type": "multiple-choice", "prompt": {"question": "<p><strong>Which Snowflake edition has a dedicated metadata storage,&nbsp; dedicated pool of compute resources and supports protected health information (PHI) data according to HIPAA and HITRUST CSF regulations?</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>The VPS edition is meant to provide isolation from other customers; thus, each instance has its own metadata store and compute resources. It also supports HIPPA &amp; HITRUST CSF regulations.</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/intro-editions.html</p>", "answers": ["<p><strong>Virtual Private Snowflake (VPS) edition</strong></p>", "<p><strong>Enterprise Edition</strong></p>", "<p><strong>Standard Edition</strong></p>", "<p><strong>Business Critical Edition</strong></p>"]}, "correct_response": ["a"], "section": "Licensing & Features", "question_plain": "Which Snowflake edition has a dedicated metadata storage,&nbsp; dedicated pool of compute resources and supports protected health information (PHI) data according to HIPAA and HITRUST CSF regulations?", "related_lectures": []}, {"_class": "assessment", "id": 70910168, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>Which Snowflake table types can be used to manage costs for short-lived tables?</strong></p><p><br></p><p><strong>Select two answers.</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p>Transient and temporary tables are a good option for short-lived data. They don't have fail-safe storage and have only up to 1 day of Time Travel.</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/tables-temp-transient</p>", "answers": ["<p><strong>Temporary</strong></p>", "<p><strong>Transient</strong></p>", "<p><strong>Permanent</strong></p>", "<p><strong>External</strong></p>", "<p><strong>Aggregate</strong></p>"]}, "correct_response": ["a", "b"], "section": "Snowflake\u2019s catalog and objects", "question_plain": "Which Snowflake table types can be used to manage costs for short-lived tables?Select two answers.", "related_lectures": []}, {"_class": "assessment", "id": 70910170, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>Which of the following statements are true for Snowsight?</strong></p><p><br></p><p><strong>Select two.</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p>Each worksheet in Snowsight is a unique session. It can have a different context from other worksheets. A user can run multiple queries using multiple worksheets if required.</p><p><br></p><p>Switching to another worksheet does NOT end the session; instead, it stays active and if a query is running in the previous worksheet, it continues.</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/ui-snowsight-worksheets#change-the-session-context-for-a-worksheet</p><p>https://docs.snowflake.com/en/user-guide/ui-snowsight-worksheets#organizing-worksheets-in-folders</p>", "answers": ["<p><strong>Each worksheet in Snowsight is a distinct Snowflake session.</strong></p>", "<p><strong>Each worksheet in Snowsight can have a different context (role, virtual warehouse, database &amp; schema)</strong></p>", "<p><strong>Worksheets share sessions for a given user.</strong></p>", "<p><strong>One user can run only one query at a given time.</strong></p>", "<p><strong>If a user switches to another worksheet, the Snowflake session ends.</strong></p>"]}, "correct_response": ["a", "b"], "section": "Tools & Interfaces", "question_plain": "Which of the following statements are true for Snowsight?Select two.", "related_lectures": []}, {"_class": "assessment", "id": 70942302, "assessment_type": "multiple-choice", "prompt": {"question": "<p><strong>How does Snowflake improve the performance of queries that exclude a significant amount of data when reading a table?</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>The Snowflake metadata allows the query engine to eliminate partitions to optimize query execution. For example, if the query specifies a WHERE condition, partitions NOT containing the value matching that condition will NOT be scanned.</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/tables-clustering-micropartitions#query-pruning</p>", "answers": ["<p><strong>By using Partition Pruning</strong></p>", "<p><strong>By using a full table scan</strong></p>", "<p><strong>By using materialized views</strong></p>", "<p><strong>By using MFA</strong></p>"]}, "correct_response": ["a"], "section": "Performance Concepts", "question_plain": "How does Snowflake improve the performance of queries that exclude a significant amount of data when reading a table?", "related_lectures": []}]}
4761102
~~~
{"count": 122, "next": null, "previous": null, "results": [{"_class": "assessment", "id": 70908928, "assessment_type": "multiple-choice", "prompt": {"question": "What is the maximum duration of Time Travel allowed in the Snowflake Standard edition?", "answers": ["1 day", "90 days", "45 days", "0 days"], "explanation": "Depending on the Snowflake edition, the Time Travel duration might range from 1 to 90 days. The Standard edition allows for one day of Time Travel. Time Travel is possible for up to 90 days in the Enterprise version and above.\n  \n https://docs.snowflake.com/en/user-guide/data-time-travel#data-retention-period"}, "correct_response": ["a"], "section": "Time Travel", "question_plain": "What is the maximum duration of Time Travel allowed in the Snowflake Standard edition?", "related_lectures": []}, {"_class": "assessment", "id": 70908860, "assessment_type": "multiple-choice", "prompt": {"question": "What is the retention of data in the ACCOUNT_USAGE schema?", "answers": ["365 days", "128 days", "7 days", "Forever", "512 days"], "explanation": "The ACCOUNT USAGE schema consists of several views that provide usage metrics and metadata information at the account level.\n  \n Data provided by the ACCOUNT_USAGE views is NOT real-time and refreshes typically with a lag of 45 minutes to 3 hours, depending on the view. \n  \n The data in these views are retained for up to 365 days.\n  \n https://docs.snowflake.com/en/sql-reference/account-usage#differences-between-account-usage-and-information-schema"}, "correct_response": ["a"], "section": "Account Usage & Monitoring", "question_plain": "What is the retention of data in the ACCOUNT_USAGE schema?", "related_lectures": []}, {"_class": "assessment", "id": 70908862, "assessment_type": "multiple-choice", "prompt": {"question": "What can you expect if the filters specified in an INFORMATION_SCHEMA query are not sufficiently selective?", "answers": ["Error", "Warning", "Success", "Empty resultset"], "explanation": "If the filters supplied in an INFORMATION SCHEMA query are not sufficiently selective, the following error is returned. \n  \n Information schema query returned too much data. Please repeat the query with more selective predicates.\n  \n https://docs.snowflake.com/en/sql-reference/info-schema#general-usage-notes"}, "correct_response": ["a"], "section": "Account Usage & Monitoring", "question_plain": "What can you expect if the filters specified in an INFORMATION_SCHEMA query are not sufficiently selective?", "related_lectures": []}, {"_class": "assessment", "id": 70908864, "assessment_type": "multiple-choice", "prompt": {"question": "What is the range of latency of data in the INFORMATION_SCHEMA schema?", "answers": ["No Latency", "45 mins to 3 hours", "5 - 10 mins", "5 - 10 days"], "explanation": "The data provided via the INFORMATION_SCHEMA views is real-time, and there is no latency in the information provided. So, if you are asked which schema should be used if there is a requirement to view real-time data, then the views in INFORMATION SCHEMA should be used as they contain real-time information.\n  \n https://docs.snowflake.com/en/sql-reference/account-usage#differences-between-account-usage-and-information-schema"}, "correct_response": ["a"], "section": "Account Usage & Monitoring", "question_plain": "What is the range of latency of data in the INFORMATION_SCHEMA schema?", "related_lectures": []}, {"_class": "assessment", "id": 70908866, "assessment_type": "multi-select", "prompt": {"question": "Which of the following are ways to see a history of the queries executed on a Snowflake account?", "answers": ["View the historical queries using the query history page", "Use the QUERY_HISTORY view in the ACCOUNT_USAGE schema", "Use the QUERY_HISTORY table function in the INFORMATION schema", "Request Snowflake support to provide query history"], "explanation": "Query history can be viewed through 3 methods.\n 1) Using the history tab on the Snowflake Web UI\n 2) By querying the QUERY_HISTORY table function in the INFORMATION schema.\n 3) By querying the QUERY_HISTORY view in the ACCOUNT_USAGE schema."}, "correct_response": ["a", "b", "c"], "section": "Account Usage & Monitoring", "question_plain": "Which of the following are ways to see a history of the queries executed on a Snowflake account?", "related_lectures": []}, {"_class": "assessment", "id": 70908868, "assessment_type": "multiple-choice", "prompt": {"question": "True or False: New Resource Monitors can only be created by the ACCOUNTADMIN role.", "answers": ["True", "False"], "explanation": "From a privilege perspective, only Account Administrators (users with ACCOUNTADMIN role) can create resource monitors. However, account administrators can grant privileges to the resource monitor to allow other users to view and modify the resource monitor configuration. The MONITOR and MODIFY privileges on a resource monitor allow other users to view and modify a specific resource monitor.\n  \n https://docs.snowflake.com/en/user-guide/resource-monitors"}, "correct_response": ["a"], "section": "Account Usage & Monitoring", "question_plain": "True or False: New Resource Monitors can only be created by the ACCOUNTADMIN role.", "related_lectures": []}, {"_class": "assessment", "id": 70908870, "assessment_type": "multiple-choice", "prompt": {"question": "Which of the following can help manage virtual warehouse credit usage?", "answers": ["Resource Monitors", "Cloud Notifications", "Billing Alerts", "Snowpark"], "explanation": "Resource monitors help manage virtual warehouse costs and avoid unexpected credit usage. Credit usage can be controlled with resource monitors by monitoring credit usage against a defined upper limit, notifying administrators when a certain percentage of the limit is reached, and even suspending virtual warehouses if necessary.\n  \n https://docs.snowflake.com/en/user-guide/resource-monitors"}, "correct_response": ["a"], "section": "Account Usage & Monitoring", "question_plain": "Which of the following can help manage virtual warehouse credit usage?", "related_lectures": []}, {"_class": "assessment", "id": 70908872, "assessment_type": "multi-select", "prompt": {"question": "Which of the following are the types of releases that Snowflake deploys weekly? Select two answers.", "answers": ["Full Release", "Patch Release", "Alpha Release", "Beta Release"], "explanation": "Two planned or scheduled releases are made by Snowflake every week. The releases can be subdivided into two.\n There are patch releases that only contain fixes to one or more issues. There are also full releases which can include new features, enhancements to existing features, or bug fixes.\n  \n https://docs.snowflake.com/en/user-guide/intro-releases"}, "correct_response": ["a", "b"], "section": "Account", "question_plain": "Which of the following are the types of releases that Snowflake deploys weekly? Select two answers.", "related_lectures": []}, {"_class": "assessment", "id": 70908874, "assessment_type": "multiple-choice", "prompt": {"question": "Snowflake has been built from scratch, specifically designed for execution on cloud platforms.", "answers": ["Yes", "No"], "explanation": "Snowflake has been designed for the cloud and has been designed from scratch.\n  \n Snowflake implements a new hybrid architecture that decouples compute and storage."}, "correct_response": ["a"], "section": "Architecture", "question_plain": "Snowflake has been built from scratch, specifically designed for execution on cloud platforms.", "related_lectures": []}, {"_class": "assessment", "id": 70908876, "assessment_type": "multiple-choice", "prompt": {"question": "True/False: Snowflake uses a unique architecture in which data and compute have been decoupled, and both can be scaled independently.", "answers": ["True", "False"], "explanation": "Snowflake implements a new hybrid architecture that decouples compute and storage. Snowflake architecture combines the best features of shared-disk and shared-nothing architectures. Snowflake stores data similarly to a shared-disk architecture, i.e., the data is shared. But it also allows for using several compute engines on the same shared data, each with its own memory and processing capabilities.\n  \n https://docs.snowflake.com/en/user-guide/intro-key-concepts#snowflake-architecture"}, "correct_response": ["a"], "section": "Architecture", "question_plain": "True/False: Snowflake uses a unique architecture in which data and compute have been decoupled, and both can be scaled independently.", "related_lectures": []}, {"_class": "assessment", "id": 70908878, "assessment_type": "multiple-choice", "prompt": {"question": "True/False: Snowflake automatically determines the most efficient algorithm to compress columns in micro-partition.", "answers": ["True", "False"], "explanation": "Snowflake stores columns in a columnar manner within each micro-partition. A columnar format enables Snowflake to optimize queries by retrieving only the referenced columns. \n  \n In addition to micro-partition compression, each column in a micro-partition is compressed independently. Snowflake automatically chooses the optimum compression algorithm for each column.\n  \n https://docs.snowflake.com/en/user-guide/tables-clustering-micropartitions"}, "correct_response": ["a"], "section": "Architecture", "question_plain": "True/False: Snowflake automatically determines the most efficient algorithm to compress columns in micro-partition.", "related_lectures": []}, {"_class": "assessment", "id": 70908880, "assessment_type": "multi-select", "prompt": {"question": "Which of the following is true regarding how table columns are stored in Snowflake? Select all that apply.", "answers": ["Columns are stored in columnar format within each micro-partition.", "Data in each column is individually compressed.", "Snowflake determines the best compression algorithm for each column automatically.", "Storing data in columnar format allows Snowflake to eliminate unnecessary columns during query execution."], "explanation": "All of these are true. \n Snowflake stores columns in a columnar manner within each micro-partition. A columnar format enables Snowflake to optimize queries by retrieving only the referenced columns. In addition to micro-partition compression, each column in a micro-partition is compressed independently. Snowflake chooses the optimum compression algorithm for each column.\n  \n https://docs.snowflake.com/en/user-guide/tables-clustering-micropartitions"}, "correct_response": ["a", "b", "c", "d"], "section": "Architecture", "question_plain": "Which of the following is true regarding how table columns are stored in Snowflake? Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70908882, "assessment_type": "multi-select", "prompt": {"question": "Which of the following statements about Snowflake&#39;s data clustering are correct?", "answers": ["Snowflake clusters data in a table automatically.", "If necessary, clustering keys can be defined to recluster or reorganize the data.", "Snowflake does not cluster table data automatically.", "The data in a Snowflake table cannot be reclustered."], "explanation": "Snowflake clusters data automatically as it is added to a table. It is possible to manually specify a clustering key and redistribute the data based on that key.\n  \n https://docs.snowflake.com/en/user-guide/tables-clustering-micropartitions.html"}, "correct_response": ["a", "b"], "section": "Architecture", "question_plain": "Which of the following statements about Snowflake&#39;s data clustering are correct?", "related_lectures": []}, {"_class": "assessment", "id": 70908884, "assessment_type": "multiple-choice", "prompt": {"question": "True/False: If required, micro-partitioning can be disabled for specific tables.", "answers": ["False", "True"], "explanation": "The micro-partitioning can not be disabled and is automatically managed by Snowflake. You can only control the clustering key, which changes the micro-partitioning approach but does not disable it\n \n https://docs.snowflake.com/en/user-guide/tables-clustering-micropartitions.html"}, "correct_response": ["a"], "section": "Architecture", "question_plain": "True/False: If required, micro-partitioning can be disabled for specific tables.", "related_lectures": []}, {"_class": "assessment", "id": 70908886, "assessment_type": "multiple-choice", "prompt": {"question": "What is the number of nodes in an X-Small virtual warehouse?", "answers": ["1", "2", "3", "4"], "explanation": "An X-Small virtual warehouse consists of a single node, the smallest possible configuration for a Snowflake virtual warehouse. A Small virtual warehouse consists of two nodes, and a Medium virtual warehouse is composed of four nodes. As the cluster size grows, the number of nodes in that cluster multiplies.\n  \n https://docs.snowflake.com/en/user-guide/warehouses-overview"}, "correct_response": ["a"], "section": "Architecture", "question_plain": "What is the number of nodes in an X-Small virtual warehouse?", "related_lectures": []}, {"_class": "assessment", "id": 70908888, "assessment_type": "multiple-choice", "prompt": {"question": "The compute engines in Snowflake are called ______________?", "answers": ["Virtual Warehouses", "Processors", "Query Processing Units", "Parallel Query Executor"], "explanation": "The compute engines in Snowflake are known as virtual warehouses.\n  \n https://docs.snowflake.com/en/user-guide/warehouses-overview"}, "correct_response": ["a"], "section": "Architecture", "question_plain": "The compute engines in Snowflake are called ______________?", "related_lectures": []}, {"_class": "assessment", "id": 70908890, "assessment_type": "multiple-choice", "prompt": {"question": "A Snowflake customer is billed for credit usage on what basis?", "answers": ["Per second", "Per Minute", "Per Nano Second", "Per hour", "Per Day"], "explanation": "Snowflake credits are billed on a per-second usage basis, which means if a virtual warehouse ran for 1 minute 45 seconds, you would be charged for 105 seconds (60 + 45). \n  \n However, note that a minimum of 60 seconds of billing applies, so if a virtual warehouse were started and shut down within the first 1st minute, a minimum of 60-second credit usage would apply."}, "correct_response": ["a"], "section": "Architecture", "question_plain": "A Snowflake customer is billed for credit usage on what basis?", "related_lectures": []}, {"_class": "assessment", "id": 70908892, "assessment_type": "multiple-choice", "prompt": {"question": "In what scenarios a multi-cluster virtual warehouse is used?", "answers": ["When query concurrency has increased beyond the capacity of one virtual warehouse.", "When the complexity of queries has increased.", "When the complexity of queries has decreased.", "When there is a need to load streaming data."], "explanation": "Multi-cluster virtual warehouses are utilized when the number of concurrent users exceeds a single virtual warehouse&#39;s capacity. When the concurrent workload for a virtual warehouse reaches the maximum, new queries are queued. Multi-cluster virtual warehouses address this by adding clusters as needed. When the demand drops, the extra clusters are removed."}, "correct_response": ["a"], "section": "Architecture", "question_plain": "In what scenarios a multi-cluster virtual warehouse is used?", "related_lectures": []}, {"_class": "assessment", "id": 70908894, "assessment_type": "multiple-choice", "prompt": {"question": "A virtual warehouse has been scaled down. When are nodes removed from the virtual warehouse?", "answers": ["After all existing active queries have finished executing.", "Immediately", "After 60 seconds", "When the virtual warehouse is suspended"], "explanation": "When a virtual warehouse is scaled down, nodes are removed from the virtual warehouse only when they are no longer running a query.\n  \n https://docs.snowflake.com/en/user-guide/warehouses-tasks#resizing-a-warehouse"}, "correct_response": ["a"], "section": "Architecture", "question_plain": "A virtual warehouse has been scaled down. When are nodes removed from the virtual warehouse?", "related_lectures": []}, {"_class": "assessment", "id": 70908896, "assessment_type": "multi-select", "prompt": {"question": "Which statements best describe the cloud services layer in Snowflake architecture? Select all that apply.", "answers": ["It is highly available, fault-tolerant, and always-on service.", "All access to a Snowflake account is via the cloud services layer.", "The cloud services layer can be shut down and restarted by a Snowflake customer.", "Cloud services is an optional service that allows Snowflake customers to manage costs more efficiently."], "explanation": "Snowflake&#39;s cloud services layer is its brain and is a reliable, always-on service. Snowflake accounts are only accessible via cloud services. All requests to Snowflake, whether via the Snowflake web UI or SnowSQL, travel through this layer.\n  \n https://docs.snowflake.com/en/user-guide/intro-key-concepts#cloud-services"}, "correct_response": ["a", "b"], "section": "Architecture", "question_plain": "Which statements best describe the cloud services layer in Snowflake architecture? Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70908898, "assessment_type": "multi-select", "prompt": {"question": "The cloud services layer in Snowflake provides which of the following? Select all that apply.", "answers": ["Authentication", "Authorization", "Query Optimisation", "Query Planning", "Query Execution"], "explanation": "The cloud services layer manages authentication and authorization. When a user logs in, the cloud services layer validates their credentials. \n When a user submits a query, the cloud services layer parses and optimizes the query plan.\n  \n The virtual warehouses perform the execution of queries.\n  \n https://docs.snowflake.com/en/user-guide/intro-key-concepts"}, "correct_response": ["a", "b", "c", "d"], "section": "Architecture", "question_plain": "The cloud services layer in Snowflake provides which of the following? Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70908900, "assessment_type": "multi-select", "prompt": {"question": "A virtual warehouse must generally be running to process SQL queries. \n  \n Which queries can generate results without the need for a running virtual warehouse? Select all that apply.", "answers": ["Queries that have already been run and produced a result cache.", "Queries like row count, minimum, and maximum for a column.", "Queries that produce a result set that is smaller than 100 MB.", "Queries that only use one table."], "explanation": "When Snowflake executes a query, the result is cached for a period of time. The query result cache returns results for subsequent identical searches without re-executing the query and without requiring an active virtual warehouse. \n  \n Snowflake can also fulfill COUNT, MIN, and MAX queries using the metadata cache, eliminating the need for an active warehouse.\n  \n https://docs.snowflake.com/en/user-guide/querying-persisted-results"}, "correct_response": ["a", "b"], "section": "Architecture", "question_plain": "A virtual warehouse must generally be running to process SQL queries. \n  \n Which queries can generate results without the need for a running virtual warehouse? Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70908902, "assessment_type": "multi-select", "prompt": {"question": "The COPY command can unload data from a table into which of the following locations? Select all that apply.", "answers": ["External Stage", "Named Internal Stage", "On-premises system", "Local NAS"], "explanation": "Similar to how data warehouses use staging, Snowflake uses a Stage object. Snowflake uses stages to aid in the loading and unloading of data. The data must first be available in a Snowflake stage to load data into a Snowflake table. COPY command can be used to load data into a table after the data is loaded in a stage. \n  \n Data unloading or exporting is also performed via a Stage object; the data can only be extracted to a stage, internal or external.\n  \n https://docs.snowflake.com/en/user-guide/data-load-overview"}, "correct_response": ["a", "b"], "section": "Data Loading and Unloading", "question_plain": "The COPY command can unload data from a table into which of the following locations? Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70908904, "assessment_type": "multiple-choice", "prompt": {"question": "True or False: The COPY command can load data using a SELECT query.", "answers": ["True", "False"], "explanation": "When loading data into a table using the COPY command, Snowflake allows you to do simple transformations on the data as it is being loaded by using a SELECT statement. During the load process, the COPY command allows for modifying the order of columns, omitting one or more columns, and casting data into specified data types. It is also possible to truncate data using the COPY command if it is larger than the desired column width. \n  \n https://docs.snowflake.com/en/user-guide/data-load-transform"}, "correct_response": ["a"], "section": "Data Loading and Unloading", "question_plain": "True or False: The COPY command can load data using a SELECT query.", "related_lectures": []}, {"_class": "assessment", "id": 70908906, "assessment_type": "multi-select", "prompt": {"question": "Which of the following are true regarding External tables?", "answers": ["To improve performance, materialized views can be created on an external table.", "An external table and a standard Snowflake table can be joined", "Data in external tables can be updated using the UPDATE SQL command", "External tables do not support materialized views."], "explanation": "Since external tables point to an external storage location, data manipulation language (DML) operations cannot be done on them. An external table can only be created against an external stage, which points to a cloud object storage location. Materialized views can be created on an external table to improve performance. These materialized views must either be refreshed manually or through a notification system. \n  \n https://docs.snowflake.com/en/user-guide/tables-external-intro"}, "correct_response": ["a", "b"], "section": "Data Loading and Unloading", "question_plain": "Which of the following are true regarding External tables?", "related_lectures": []}, {"_class": "assessment", "id": 70908908, "assessment_type": "multi-select", "prompt": {"question": "Snowflake provides which of the following methods of data loading?", "answers": ["Bulk", "Continuous", "Tiny", "Intermittent"], "explanation": "Snowflake supports data loading in two primary ways. The COPY command can be used to load bulk data or huge files. To load data into a table, the COPY command requires the usage of a virtual warehouse. \n  \n The other method of loading data into Snowflake is via the Snowpipe. Snowpipe is the ideal technique for loading data when the data is arriving continuously in a messaging or streaming manner. \n  \n  \n https://docs.snowflake.com/en/user-guide/data-load-overview#bulk-vs-continuous-loading"}, "correct_response": ["a", "b"], "section": "Data Loading and Unloading", "question_plain": "Snowflake provides which of the following methods of data loading?", "related_lectures": []}, {"_class": "assessment", "id": 70908910, "assessment_type": "multiple-choice", "prompt": {"question": "Which of the following can be used to download data from an external stage to an on-premises system?", "answers": ["Cloud Provider Utilities", "GET", "PUT", "COPY"], "explanation": "The GET command is used to download data from an internal stage to an on-premises system.\n  \n The PUT command uploads data from an on-premises system to an internal stage.\n  \n To download or upload data to an external stage, cloud provider utilities or other tools are used to interact with data in the cloud storage pointed to by the external stage.\n  \n  \n https://docs.snowflake.com/en/user-guide/data-unload-overview#bulk-unloading-process"}, "correct_response": ["a"], "section": "Data Loading and Unloading", "question_plain": "Which of the following can be used to download data from an external stage to an on-premises system?", "related_lectures": []}, {"_class": "assessment", "id": 70908912, "assessment_type": "multiple-choice", "prompt": {"question": "The load metadata for a table expires after how many days?", "answers": ["64", "128", "365", "30"], "explanation": "The load metadata stores a variety of information, such as the name of every file that was loaded into that table and the time stamp corresponding to the time that a file was loaded. By utilizing this load metadata, Snowflake ensures that it will not reprocess a previously loaded file.\n  \n The load metadata expires after 64 days. Snowflake skips over any older files for which the load status is undetermined.\n  \n https://docs.snowflake.com/en/user-guide/data-load-considerations-load#load-metadata"}, "correct_response": ["a"], "section": "Data Loading and Unloading", "question_plain": "The load metadata for a table expires after how many days?", "related_lectures": []}, {"_class": "assessment", "id": 70908914, "assessment_type": "multiple-choice", "prompt": {"question": "Which one of the following loading methods will use Virtual Warehouse resources?", "answers": ["COPY command", "Snowpipe"], "explanation": "COPY command uses virtual warehouse resources. Snowpipe is billed separately and does not use virtual warehouse resources.\n  \n Snowpipe is serverless and has its own computational capability; therefore, it does not rely on virtual warehouses for processing. Snowflake automatically manages the compute required by a Snowpipe. Snowflake also manages the scaling up and down of a Snowpipe as per the data load requirement. Since a Snowpipe is serverless, its costs are charged separately from virtual warehousing fees.\n  \n  \n https://docs.snowflake.com/en/user-guide/data-load-snowpipe-intro"}, "correct_response": ["a"], "section": "Data Loading and Unloading", "question_plain": "Which one of the following loading methods will use Virtual Warehouse resources?", "related_lectures": []}, {"_class": "assessment", "id": 70908916, "assessment_type": "multi-select", "prompt": {"question": "Which of the following statements are true for Snowpipe? Select all that apply.", "answers": ["Snowpipe uses serverless compute resources managed by Snowflake.", "The resource for Snowpipe are automatically scaled up and down by Snowflake.", "Snowpipe makes use of the active virtual warehouse for compute resources.", "You must scale a virtual warehouse yourself to manage the compute available to Snowpipe."], "explanation": "Snowpipe is serverless and has its own computational capability; therefore, it does not rely on virtual warehouses for processing. Snowflake automatically manages the compute required by a Snowpipe. Snowflake also manages the scaling up and down of a Snowpipe as per the data load requirement. Since a Snowpipe is serverless, its costs are charged separately from virtual warehousing fees.\n  \n  \n https://docs.snowflake.com/en/user-guide/data-load-snowpipe-intro"}, "correct_response": ["a", "b"], "section": "Data Loading and Unloading", "question_plain": "Which of the following statements are true for Snowpipe? Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70908918, "assessment_type": "multiple-choice", "prompt": {"question": "True or False: The COPY command allows only simple or basic transformations while loading data.", "answers": ["True", "False"], "explanation": "When loading data into a table using the COPY command, Snowflake allows you to do simple transformations on the data as it is being loaded. During the load process, the COPY command allows for modifying the order of columns, omitting one or more columns, casting data into specified data types, and truncating values.\n  \n While loading the data, complex transformations such as joins, filters, aggregations, and the use of FLATTEN are not supported as they are not essential data transformations. Therefore, joining, filtering, and aggregating the data are supported ONLY after the data has been loaded into a table.\n  \n https://docs.snowflake.com/en/user-guide/data-load-overview#id2"}, "correct_response": ["a"], "section": "Data Loading and Unloading", "question_plain": "True or False: The COPY command allows only simple or basic transformations while loading data.", "related_lectures": []}, {"_class": "assessment", "id": 70908920, "assessment_type": "multiple-choice", "prompt": {"question": "True or False: Only Snowflake staff can access data in fail-safe storage.", "answers": ["True", "False"], "explanation": "Once the data is in fail-safe storage, only Snowflake support can help retrieve the data. The customer cannot access fail-safe storage.\n  \n https://docs.snowflake.com/en/user-guide/data-failsafe"}, "correct_response": ["a"], "section": "Fail-safe", "question_plain": "True or False: Only Snowflake staff can access data in fail-safe storage.", "related_lectures": []}, {"_class": "assessment", "id": 70908922, "assessment_type": "multiple-choice", "prompt": {"question": "After the Time Travel period has been completed, Snowflake stores data in fail-safe storage. Snowflake keeps data in fail-safe storage for Permanent tables for how long?", "answers": ["7 days", "14 days", "21 days", "1 day"], "explanation": "Data for permanent tables is kept in fail-safe storage for 7 days. Snowflake also provides transient and temporary tables that don&#39;t provide fail-safe capabilities; hence, data in such tables have 0 days of fail-safe storage.\n  \n https://docs.snowflake.com/en/user-guide/data-failsafe"}, "correct_response": ["a"], "section": "Fail-safe", "question_plain": "After the Time Travel period has been completed, Snowflake stores data in fail-safe storage. Snowflake keeps data in fail-safe storage for Permanent tables for how long?", "related_lectures": []}, {"_class": "assessment", "id": 70908924, "assessment_type": "multi-select", "prompt": {"question": "Which of the following table types are not protected by fail-safe storage? Select all that apply.", "answers": ["Temporary", "Transient", "Permanent", "Clustered"], "explanation": "Transient and temporary tables don&#39;t have any failsafe; this is done to reduce storage costs for temporary and transient data.\n \n https://docs.snowflake.com/en/user-guide/tables-temp-transient"}, "correct_response": ["a", "b"], "section": "Data Protection", "question_plain": "Which of the following table types are not protected by fail-safe storage? Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70908926, "assessment_type": "multiple-choice", "prompt": {"question": "Time Travel &amp; failsafe require extra storage with a cost associated with this extra storage.", "answers": ["True", "False"], "explanation": "Snowflake enables Time Travel &amp; fail-safe storage by keeping micro-partitions that have been updated or deleted. These micro-partitions are retained to allow data recovery using Time Travel SQL or fail-safe storage. Keeping these deleted or updated micro-partitions requires storage, resulting in extra costs. \n  \n https://docs.snowflake.com/en/user-guide/data-cdp-storage-costs"}, "correct_response": ["a"], "section": "Time Travel", "question_plain": "Time Travel &amp; failsafe require extra storage with a cost associated with this extra storage.", "related_lectures": []}, {"_class": "assessment", "id": 70908930, "assessment_type": "multi-select", "prompt": {"question": "Using Time Travel SQL, which of the following can be performed by a user?", "answers": ["Retrieve data as it was before a timestamp.", "Retrieve data as it was before a query was executed.", "Retrieve data as it existed 365 days ago.", "Retrieve data as it will exist in the future."], "explanation": "Time Travel SQL extensions allow you to see data as it existed before or at a particular time. It can also be used to see data before an SQL statement is executed or at the point when an SQL statement is run. \n  \n Time Travel does not let you recover data for more than 90 days in the past. \n  \n https://docs.snowflake.com/en/user-guide/data-time-travel#time-travel-sql-extensions"}, "correct_response": ["a", "b"], "section": "Time Travel", "question_plain": "Using Time Travel SQL, which of the following can be performed by a user?", "related_lectures": []}, {"_class": "assessment", "id": 70908932, "assessment_type": "multiple-choice", "prompt": {"question": "In Snowflake architecture, which layer is responsible for managing data sharing?", "answers": ["Cloud Services Layer", "Query Processing Layer", "Cloud Storage Layer", "Data Sharing Layer", "Share Management Layer"], "explanation": "The cloud services layer facilitates data sharing through metadata operations.\n  \n https://docs.snowflake.com/en/user-guide/data-sharing-intro#how-does-secure-data-sharing-work"}, "correct_response": ["a"], "section": "Data Sharing", "question_plain": "In Snowflake architecture, which layer is responsible for managing data sharing?", "related_lectures": []}, {"_class": "assessment", "id": 70908934, "assessment_type": "multi-select", "prompt": {"question": "Which of the following actions cannot be performed by the consumer of a shared database?\n \n Select all that apply.", "answers": ["Create a new table in the shared database.", "Insert data in a shared table.", "View the list of tables in a shared database.", "Use shared data in complex queries."], "explanation": "A shared database is read-only for consumers, so they cannot create new objects or modify/append data."}, "correct_response": ["a", "b"], "section": "Data Sharing", "question_plain": "Which of the following actions cannot be performed by the consumer of a shared database?\n \n Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70908936, "assessment_type": "multiple-choice", "prompt": {"question": "True or False: When a Snowflake data provider shares data with another Snowflake account, the data consumer is charged for the compute charges for any queries they run.", "answers": ["True", "False"], "explanation": "Metadata operations in the cloud services layer allow data sharing without physically copying it. Since the provider account stores and pays for the data storage, the data consumer doesn&#39;t have to pay anything extra for storage. However, the data consumer pays for the compute used to run queries on shared data. When queries are run on shared data, the compute of the data consumer is used.\n  \n https://docs.snowflake.com/en/user-guide/data-sharing-intro#how-does-secure-data-sharing-work"}, "correct_response": ["a"], "section": "Data Sharing", "question_plain": "True or False: When a Snowflake data provider shares data with another Snowflake account, the data consumer is charged for the compute charges for any queries they run.", "related_lectures": []}, {"_class": "assessment", "id": 70908938, "assessment_type": "multiple-choice", "prompt": {"question": "To share data as a producer and consume data as a consumer, you must have two Snowflake accounts, one for sharing and one for consuming shared data.", "answers": ["False", "True"], "explanation": "The same Snowflake account can share (or produce data), and it can also consume data"}, "correct_response": ["a"], "section": "Data Sharing", "question_plain": "To share data as a producer and consume data as a consumer, you must have two Snowflake accounts, one for sharing and one for consuming shared data.", "related_lectures": []}, {"_class": "assessment", "id": 70908940, "assessment_type": "multiple-choice", "prompt": {"question": "True or False: A reader account can consume data from sources other than the data provider that created the reader account.", "answers": ["False", "True"], "explanation": "Incorrect. A reader account can only consume data from the data provider account that created it. \n  \n https://docs.snowflake.com/en/user-guide/data-sharing-reader-create#what-is-restricted-allowed-in-a-reader-account"}, "correct_response": ["a"], "section": "Data Sharing", "question_plain": "True or False: A reader account can consume data from sources other than the data provider that created the reader account.", "related_lectures": []}, {"_class": "assessment", "id": 70908942, "assessment_type": "multi-select", "prompt": {"question": "Users created in a reader account cannot perform which of the following actions?\n \n Select all that apply.", "answers": ["Load new data", "INSERT data", "UPDATE data", "SELECT data"], "explanation": "Users in a reader account can query shared data but cannot perform any DML.\n  \n https://docs.snowflake.com/en/user-guide/data-sharing-reader-create#what-is-restricted-allowed-in-a-reader-account"}, "correct_response": ["a", "b", "c"], "section": "Data Sharing", "question_plain": "Users created in a reader account cannot perform which of the following actions?\n \n Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70908944, "assessment_type": "multi-select", "prompt": {"question": "You are required to create a new Share. Which role could you use to create a new share? Select all that apply.", "answers": ["A role that has the CREATE SHARE privileges.", "ACCOUNTADMIN role", "PUBLIC role", "DATA_SHARE role"], "explanation": "Only the ACCOUNTADMIN role or roles specifically granted the CREATE SHARE privilege can create a share.\n  \n https://docs.snowflake.com/en/user-guide/data-sharing-gs"}, "correct_response": ["a", "b"], "section": "Data Sharing", "question_plain": "You are required to create a new Share. Which role could you use to create a new share? Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70908946, "assessment_type": "multiple-choice", "prompt": {"question": "What is the lowest Snowflake edition required to access the Snowflake Marketplace?", "answers": ["Standard", "Enterprise", "Business Critical", "Virtual Private Snowflake (VPS)"], "explanation": "Except for Virtual private Snowflake accounts, the Snowflake Marketplace is available to all Snowflake accounts hosted on Amazon Web Services, Google Cloud Platform, and Microsoft Azure. \n  \n https://other-docs.snowflake.com/en/collaboration/collaboration-marketplace-about.html#about-the-snowflake-marketplace"}, "correct_response": ["a"], "section": "Data Sharing", "question_plain": "What is the lowest Snowflake edition required to access the Snowflake Marketplace?", "related_lectures": []}, {"_class": "assessment", "id": 70908948, "assessment_type": "multiple-choice", "prompt": {"question": "Is it possible to share data with a Snowflake customer whose Snowflake instance exists in a different cloud platform than the data provider?", "answers": ["Yes, but to enable data sharing to a different cloud platform, you must enable replication first.", "Yes. Nothing special needs to be done to enable cross-cloud platform data sharing.", "No, sharing with customers in other cloud platforms is not possible."], "explanation": "It is possible to share data with Snowflake accounts in another cloud platform, but the provider must enable replication and replicate your existing database to the other cloud platform.\n  \n https://docs.snowflake.com/en/user-guide/secure-data-sharing-across-regions-plaforms"}, "correct_response": ["a"], "section": "Data Sharing", "question_plain": "Is it possible to share data with a Snowflake customer whose Snowflake instance exists in a different cloud platform than the data provider?", "related_lectures": []}, {"_class": "assessment", "id": 70908950, "assessment_type": "multi-select", "prompt": {"question": "Which of the following semi-structured file formats are supported by Snowflake? Select all that apply", "answers": ["JSON", "PARQUET", "XML", "YAML", "HTML"], "explanation": "Snowflake includes built-in support for several semi-structured data formats. Snowflake supports \n JSON\n Avro\n ORC\n Parquet\n XML\n  \n https://docs.snowflake.com/en/user-guide/semistructured-intro.html"}, "correct_response": ["a", "b", "c"], "section": "Data Loading and Unloading", "question_plain": "Which of the following semi-structured file formats are supported by Snowflake? Select all that apply", "related_lectures": []}, {"_class": "assessment", "id": 70908952, "assessment_type": "multiple-choice", "prompt": {"question": "True or False: Snowflake supports only Scalar external functions?", "answers": ["True", "False"], "explanation": "True. Snowflake currently supports only scalar external functions, i.e., the function should return only one value.\n  \n https://docs.snowflake.com/en/sql-reference/external-functions-introduction"}, "correct_response": ["a"], "section": "Extending Snowflake Functionality", "question_plain": "True or False: Snowflake supports only Scalar external functions?", "related_lectures": []}, {"_class": "assessment", "id": 70908954, "assessment_type": "multiple-choice", "prompt": {"question": "Which of the following best describes Snowflake scripting?", "answers": ["Snowflake Scripting is an extension to SQL that allows you to use procedural logic similar to that found in programming languages.", "Snowflake Scripting adds parallel execution capability to the existing Snowflake SQL execution engine.", "Snowflake Scripting is used to create client-side code that runs in web browsers.", "Snowflake Scripting is a flavor of ActionScript code and can be used to create mobile apps."], "explanation": "Snowflake Scripting is an extension to SQL that allows you to use procedural logic similar to that found in programming languages. Snowflake Scripting allows you to use variables, if-else expressions, looping, cursors, manage result sets, and allows you to handle errors. Snowflake scripting is typically used to create stored procedures, but it may also be used to create procedural code outside of a stored procedure.\n  \n https://docs.snowflake.com/en/developer-guide/snowflake-scripting/index"}, "correct_response": ["a"], "section": "Extending Snowflake Functionality", "question_plain": "Which of the following best describes Snowflake scripting?", "related_lectures": []}, {"_class": "assessment", "id": 70908956, "assessment_type": "multiple-choice", "prompt": {"question": "<p>True or False: Snowpark can push down your user-defined functions to the database server, where the code then operates on the data.</p>", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "You can create functions using typical programming languages such as Java, Python, or Scala, and those functions can be exposed in Snowflake as UDFs. So, you can use these UDFs in your SQL just like any other UDFs. To execute these UDFs, Snowflake creates a run-time environment sandbox within the virtual warehouse houses. The UDFs execute inside the sandbox. This approach also ensures default parallel execution of the UDFs because they will use Snowflake infrastructure to scale.", "answers": ["True", "False"]}, "correct_response": ["a"], "section": "Extending Snowflake Functionality", "question_plain": "True or False: Snowpark can push down your user-defined functions to the database server, where the code then operates on the data.", "related_lectures": []}, {"_class": "assessment", "id": 70908958, "assessment_type": "multiple-choice", "prompt": {"question": "A stored procedure has been set up as a stored procedure with owner&#39;s rights. A system administrator runs the stored procedure. Which of the following statement correctly describes how the stored procedure will execute?", "answers": ["The stored procedure executes using the privileges of the role owning the stored procedure.", "The stored procedure executes with ACCOUNTADMIN role permissions.", "The stored procedure executes with SYSADMIN role permissions.", "The stored procedure executes using the privileges of the users executing the stored procedure."], "explanation": "A stored procedure configured to run with the owner&#39;s rights executes under the privileges of the role that created and owns the stored procedure.\n  \n https://docs.snowflake.com/en/sql-reference/stored-procedures-rights"}, "correct_response": ["a"], "section": "Extending Snowflake Functionality", "question_plain": "A stored procedure has been set up as a stored procedure with owner&#39;s rights. A system administrator runs the stored procedure. Which of the following statement correctly describes how the stored procedure will execute?", "related_lectures": []}, {"_class": "assessment", "id": 70908960, "assessment_type": "multiple-choice", "prompt": {"question": "A scalar UDF will return what type of result?", "answers": ["For each input, it will return one row containing a single column", "For each input, it will return one row containing multiple columns", "For each input, it will return multiple rows containing multiple columns", "For each input, it will return multiple rows containing a single columns"], "explanation": "Scalar UDFs return one row for each input row, with each output row containing a single column or value. An example of a UDF is the MAX function, which returns a single value for the given input. \n  \n https://docs.snowflake.com/en/sql-reference/udf-overview#scalar-and-tabular-functions"}, "correct_response": ["a"], "section": "Extending Snowflake Functionality", "question_plain": "A scalar UDF will return what type of result?", "related_lectures": []}, {"_class": "assessment", "id": 70908962, "assessment_type": "multiple-choice", "prompt": {"question": "What is the minimum Snowflake edition that supports Tri-Secret Secure encryption?", "answers": ["Business Critical", "Enterprise", "Standard", "Virtual Private Snowflake"], "explanation": "A minimum of the Business Critical edition is required for Tri-Secret Secure, which can be activated by contacting Snowflake customer service."}, "correct_response": ["a"], "section": "Licensing & Features", "question_plain": "What is the minimum Snowflake edition that supports Tri-Secret Secure encryption?", "related_lectures": []}, {"_class": "assessment", "id": 70908964, "assessment_type": "multiple-choice", "prompt": {"question": "What is the minimum Snowflake edition required to consume data from Snowflake Marketplace?", "answers": ["Standard", "Enterprise", "Business Critical", "Virtual Private Snowflake", "No edition is required"], "explanation": "Data Marketplace is supported in all Snowflake editions; thus, the minimum edition that supports it is the Standard edition. Do note that VPS doesn\u2019t support Data Marketplace.\n  \n https://docs.snowflake.com/en/user-guide/intro-editions.html"}, "correct_response": ["a"], "section": "Licensing & Features", "question_plain": "What is the minimum Snowflake edition required to consume data from Snowflake Marketplace?", "related_lectures": []}, {"_class": "assessment", "id": 70908966, "assessment_type": "multiple-choice", "prompt": {"question": "What is the minimum Snowflake edition that supports federated authentication?", "answers": ["Standard", "Enterprise", "Business Critical", "Virtual Private Snowflake"], "explanation": "Federated authentication is supported in all Snowflake editions; thus, the minimum edition that supports it is Standard.\n  \n https://docs.snowflake.com/en/user-guide/intro-editions.html"}, "correct_response": ["a"], "section": "Licensing & Features", "question_plain": "What is the minimum Snowflake edition that supports federated authentication?", "related_lectures": []}, {"_class": "assessment", "id": 70908968, "assessment_type": "multiple-choice", "prompt": {"question": "What is the minimum Snowflake edition required to use the Search Optimisation service for point lookup queries?", "answers": ["Enterprise", "Business Critical", "Virtual Private Snowflake", "Standard"], "explanation": "The Enterprise edition has several additional capabilities not provided in the Standard edition. These include multi-cluster virtual warehouses, column-level masking, row access policies, materialized views, and search optimization.\n  \n  \n https://docs.snowflake.com/en/user-guide/intro-editions.html"}, "correct_response": ["a"], "section": "Licensing & Features", "question_plain": "What is the minimum Snowflake edition required to use the Search Optimisation service for point lookup queries?", "related_lectures": []}, {"_class": "assessment", "id": 70908970, "assessment_type": "multiple-choice", "prompt": {"question": "What is the minimum Snowflake edition required to create User Defined Functions (UDFs) in Java?", "answers": ["Standard", "Enterprise", "Business Critical", "Virtual Private Snowflake"], "explanation": "UDFs are supported in all Snowflake editions; thus, the minimum edition that supports it is the Standard edition.\n  \n  \n https://docs.snowflake.com/en/user-guide/intro-editions.html"}, "correct_response": ["a"], "section": "Licensing & Features", "question_plain": "What is the minimum Snowflake edition required to create User Defined Functions (UDFs) in Java?", "related_lectures": []}, {"_class": "assessment", "id": 70908972, "assessment_type": "multiple-choice", "prompt": {"question": "What is the maximum duration for which the query result cache for a query can be retained?", "answers": ["31 days", "24 hours", "365 days", "3600 seconds"], "explanation": "Once a result cache is generated for a query stays valid for 24 hours. If another query that reuses the query result cache is executed within that 24-hour window, the result cache expiry is extended for another 24 hours from that point onwards. If the result cache for a query keeps getting used, it will stay valid for up to 31 days. After 31 days, the result cache for a query will be purged regardless of any other condition. \n  \n https://docs.snowflake.com/en/user-guide/querying-persisted-results"}, "correct_response": ["a"], "section": "Performance Concepts", "question_plain": "What is the maximum duration for which the query result cache for a query can be retained?", "related_lectures": []}, {"_class": "assessment", "id": 70908974, "assessment_type": "multi-select", "prompt": {"question": "Under which circumstances will the query result cache fulfill the query result? Select all that apply", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "The underlying data must not change, and the query should be syntactically identical for the query result cache to be used. The cache must have been generated (or last used) less than 24 hours ago.\n \n https://docs.snowflake.com/en/user-guide/querying-persisted-results", "answers": ["The micro-partitions for the tables in the query have not changed.", "<p>The query results cache was generated or used less than 24 hours ago.</p>", "<p>The query is being executed from the same virtual warehouse as the previously executed query.</p>", "<p>The query returns a result set of fewer than 100 thousand rows.</p>"]}, "correct_response": ["a", "b"], "section": "Performance Concepts", "question_plain": "Under which circumstances will the query result cache fulfill the query result? Select all that apply", "related_lectures": []}, {"_class": "assessment", "id": 70908976, "assessment_type": "multiple-choice", "prompt": {"question": "How can clustering keys enhance query performance?", "answers": ["By distributing data into micro-partitions so that a more optimized partition pruning can occur during query execution.", "By pre-calculating query results in advance and physically storing them.", "By compressing data.", "By distributing the data among numerous compute clusters, each of which has a subset of data to process."], "explanation": "Clustering a table on a specific column can optimize queries by eliminating unnecessary partitions from the query processing. A table can be re-clustered by defining a clustering key, which effectively redistributes the data into micro-partitions, ensuring optimal access to the clustered column. \n  \n https://docs.snowflake.com/en/user-guide/tables-clustering-micropartitions#what-is-data-clustering"}, "correct_response": ["a"], "section": "Performance Concepts", "question_plain": "How can clustering keys enhance query performance?", "related_lectures": []}, {"_class": "assessment", "id": 70908978, "assessment_type": "multiple-choice", "prompt": {"question": "True or False: Cluster keys should be changed only during off-peak hours to avoid blocking DML statements.", "answers": ["False", "True"], "explanation": "Snowflake&#39;s re-clustering operation is transparent to the user and does not block any DML or SELECT queries. A table that is being re-clustered will behave exactly like any other table when being queried, updated, or changed.\n  \n https://docs.snowflake.com/en/user-guide/tables-auto-reclustering#non-blocking-dml"}, "correct_response": ["a"], "section": "Performance Concepts", "question_plain": "True or False: Cluster keys should be changed only during off-peak hours to avoid blocking DML statements.", "related_lectures": []}, {"_class": "assessment", "id": 70908980, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>Which of the following illustrations represent the tables that have the same clustering depth? Select all that apply.</strong> &nbsp;&nbsp; </p><p><img src=\"https://img-b.udemycdn.com/redactor/raw/practice_test_question/2023-03-29_20-42-53-0f47eb04296500d4529bab3d85d74e44.png\"></p><p><br></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "For a populated table, the clustering depth is the average depth of overlapping micro-partitions for specific columns. The clustering depth starts at 1 (for a well-clustered table) and can be a larger number.\n If the average depth is smaller, the data for the specified columns are better clustered.\n  \n https://docs.snowflake.com/en/user-guide/tables-clustering-micropartitions#label-clustering-depth", "answers": ["2", "3", "1", "4"]}, "correct_response": ["a", "b", "d"], "section": "Performance Concepts", "question_plain": "Which of the following illustrations represent the tables that have the same clustering depth? Select all that apply. &nbsp;&nbsp;", "related_lectures": []}, {"_class": "assessment", "id": 70908982, "assessment_type": "multi-select", "prompt": {"question": "A clustering key is added or modified for a large table. Which type of queries will likely see performance improvement? \n Select all that apply.", "answers": ["Queries that filter on the columns which are part of the cluster key.", "Queries that sort on the columns that are part of the cluster key.", "Queries that group on the columns that are part of the cluster key.", "Queries that join on the columns which are part of the cluster key.", "Queries that select all rows in the table.", "Queries that select all columns in the table."], "explanation": "Defining a clustering key will generally benefit queries that require filtering or sorting on the clustering keys during the query execution. ORDER BY, GROUP BY &amp; certain joins require sorting during query execution. Queries that use the WHERE clause on the clustering keys will also benefit from an adequately defined clustering key. \n  \n https://docs.snowflake.com/en/user-guide/tables-clustering-keys"}, "correct_response": ["a", "b", "c", "d"], "section": "Performance Concepts", "question_plain": "A clustering key is added or modified for a large table. Which type of queries will likely see performance improvement? \n Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70908984, "assessment_type": "multiple-choice", "prompt": {"question": "When defining a clustering key which type of columns should be considered?", "answers": ["Columns with high enough cardinality to enable efficient partition pruning", "Columns with extremely high cardinality", "Columns with extremely low cardinality"], "explanation": "When defining clustering keys, the initial candidate clustering columns are those columns that are frequently used in the WHERE clause or other selective filters. \n  \n Additionally, columns that are used for joining can also be considered.\n  \n Furthermore, the columns&#39; cardinality (number of distinct values) is also important. It is crucial to choose a column with a high enough cardinality to allow effective partition pruning while having a low enough cardinality for Snowflake to group data into micro-partitions efficiently. A column with too few distinct values (e.g., gender) will result in minimal partition pruning. On the other hand, a column that has too many distinct values (e.g., customer id) will result in too much overhead when maintaining the partitions.\n  \n When creating a multi-column cluster key, order the columns from the lowest cardinality to the higher cardinality; otherwise, the effectiveness of clustering will be reduced.\n  \n https://docs.snowflake.com/en/user-guide/tables-clustering-keys"}, "correct_response": ["a"], "section": "Performance Concepts", "question_plain": "When defining a clustering key which type of columns should be considered?", "related_lectures": []}, {"_class": "assessment", "id": 70908986, "assessment_type": "multi-select", "prompt": {"question": "Which of the following correctly describes a materialized view? Select all that apply.", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "A materialized view is a view that pre-computes data based on a SELECT query. The query&#39;s results are pre-computed and physically stored to enhance performance for similar queries that are executed in the future. When the underlying table is updated, the materialized view refreshes automatically, requiring no additional maintenance. Snowflake-managed services perform the update in the background transparent to the user without interfering with the user&#39;s experience.\n  \n https://docs.snowflake.com/en/user-guide/views-materialized", "answers": ["A materialized view pre-computes the results of an SQL statement.", "A materialized view physically stores the results.", "A materialized view is like a secondary index.", "<p><strong>A materialized view re-computes its results every time a query uses the materialized view.</strong></p>"]}, "correct_response": ["a", "b"], "section": "Performance Concepts", "question_plain": "Which of the following correctly describes a materialized view? Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70908988, "assessment_type": "multiple-choice", "prompt": {"question": "For which one of the following scenarios, Scaling Out a virtual warehouse, is a good option?", "answers": ["There are more active concurrent queries than the current virtual warehouse can handle.", "There is an increase in query complexity.", "A query is accessing more than 5 tables.", "The query uses a materialized view."], "explanation": "Multi-cluster virtual warehouses are frequently used in scenarios where the number of concurrent queries exceeds the capacity of a single virtual warehouse. When a virtual warehouse&#39;s concurrent workload exceeds its maximum capacity, additional queries are placed in the queue. Multi-cluster virtual warehouses dynamically add additional clusters based on demand to solve the queueing issue. When demand decreases, the additional clusters are decommissioned. This process is also known as scaling out or auto-scaling.\n  \n https://docs.snowflake.com/en/user-guide/warehouses-multicluster"}, "correct_response": ["a"], "section": "Performance Concepts", "question_plain": "For which one of the following scenarios, Scaling Out a virtual warehouse, is a good option?", "related_lectures": []}, {"_class": "assessment", "id": 70908990, "assessment_type": "multi-select", "prompt": {"question": "A multi-clustered virtual warehouse can have which two of the following scaling modes?", "answers": ["Maximized", "Auto scale", "Scale on Demand", "Scale on Schedule"], "explanation": "A multi-cluster virtual warehouse can be created in maximized or auto-scaling modes. The maximized mode is enabled by setting the minimum and maximum warehouse count of the multi-cluster to the same value. Therefore, as soon as the multi-cluster virtual warehouse is established, all warehouses in the multi-cluster are started up. Auto-Scaling mode is enabled by selecting different values for the multi-minimum clusters and maximum warehouse count. As a result, Snowflake starts and stops warehouses dynamically based on the workload needs.\n  \n https://docs.snowflake.com/en/user-guide/warehouses-multicluster#setting-the-scaling-policy-for-a-multi-cluster-warehouse"}, "correct_response": ["a", "b"], "section": "Performance Concepts", "question_plain": "A multi-clustered virtual warehouse can have which two of the following scaling modes?", "related_lectures": []}, {"_class": "assessment", "id": 70908992, "assessment_type": "multiple-choice", "prompt": {"question": "<p><strong>You are the data warehouse administrator at an airline company that uses Snowflake Enterprise Edition as its data warehouse. </strong></p><p><strong>You have noticed that there are periods of processing where the number of Marketing users connecting to Snowflake &amp; running queries increases exponentially. These users experience delays &amp; queuing in their queries. There is no identified pattern to this query increase so it can happen at any random time &amp; day of the week. A virtual warehouse of large size (L) is already dedicated to the Marketing department. </strong></p><p><strong>What should be your best course of action?</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", ""], "explanation": "Multi-cluster virtual warehouses are frequently used in scenarios where the number of concurrent queries exceeds the capacity of a single virtual warehouse. When a virtual warehouse&#39;s concurrent workload exceeds its maximum capacity, additional queries are placed in the queue. Multi-cluster virtual warehouses dynamically add additional clusters based on demand to solve the queueing issue. When demand decreases, the additional clusters are decommissioned. This process is also known as scaling out or auto-scaling.\n  \n https://docs.snowflake.com/en/user-guide/warehouses-multicluster", "answers": ["Enable multi-cluster warehouse on the Marketing virtual warehouse. The multi-cluster virtual warehouse will auto-spawn (and auto shutdown) additional virtual warehouses as the demand increases and decreases.", "Increase the size of the virtual warehouse dedicated to Marketing from L to XL during the peak processing periods. This increase will double the processing power of the virtual warehouse and will result in queries finishing faster. Reduce the size of the virtual warehouse after the peak period is complete.", "Force the Marketing users to distribute their queries throughout the week and not run all queries daily."]}, "correct_response": ["a"], "section": "Performance Concepts", "question_plain": "You are the data warehouse administrator at an airline company that uses Snowflake Enterprise Edition as its data warehouse. You have noticed that there are periods of processing where the number of Marketing users connecting to Snowflake &amp; running queries increases exponentially. These users experience delays &amp; queuing in their queries. There is no identified pattern to this query increase so it can happen at any random time &amp; day of the week. A virtual warehouse of large size (L) is already dedicated to the Marketing department. What should be your best course of action?", "related_lectures": []}, {"_class": "assessment", "id": 70908994, "assessment_type": "multiple-choice", "prompt": {"question": "<p><strong>Which of the following query profile snippet indicates ineffective micro-partition pruning? </strong>\n&nbsp; \n</p><img src=\"https://img-b.udemycdn.com/redactor/raw/practice_test_question/2023-03-29_20-40-22-d3b02704abaeb92f7bf357444d6046ea.png\"><p><br></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "Partition pruning occurs when the number of Partitions scanned is much smaller than Partitions total.\n  \n If the partitions scanned equal the partition total, the query scanned the complete table. Therefore, no partition pruning happened, and the clustering key should be improved.\n  \n https://docs.snowflake.com/en/user-guide/ui-query-profile", "answers": ["1", "2", "3", "4"]}, "correct_response": ["a"], "section": "Performance Concepts", "question_plain": "Which of the following query profile snippet indicates ineffective micro-partition pruning? \n&nbsp;", "related_lectures": []}, {"_class": "assessment", "id": 70908996, "assessment_type": "multiple-choice", "prompt": {"question": "<p><strong>Consider the following snippet from the query profile of a finished query. </strong>\n</p><img src=\"https://img-b.udemycdn.com/redactor/raw/practice_test_question/2023-03-29_20-40-45-5d8d3b0b997bf652ae333095780d411c.png\"><p>\n<strong> Which of the following accurately describes the highlighted statistics?</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "Partition pruning occurs when the number of Partitions scanned is much smaller than Partitions total.\n  \n If the partitions scanned equal the partition total, the query scanned the complete table. Therefore, no partition pruning happened, and the clustering key should be improved.\n  \n https://docs.snowflake.com/en/user-guide/ui-query-profile", "answers": ["The query profile indicates effective partition pruning.", "The query profile indicates that the query result cache was used.", "The query profile indicates ineffective partition pruning.", "The query profile indicates that the metadata cache was used."]}, "correct_response": ["a"], "section": "Performance Concepts", "question_plain": "Consider the following snippet from the query profile of a finished query. \n\n Which of the following accurately describes the highlighted statistics?", "related_lectures": []}, {"_class": "assessment", "id": 70908998, "assessment_type": "multiple-choice", "prompt": {"question": "A query required a long time to complete execution. The query profile for the query shows a significant value for \u201cBytes spilled to local storage.\u201d Which one of the following is the reason for data spilling?", "answers": ["The virtual warehouse does not have enough memory to hold intermediate results produced during query processing.", "The cloud services layer needs more memory to hold the query results.", "A multi-cluster virtual warehouse is required for processing queries that are spilling data.", "The virtual warehouse has been active for too long and cannot process any more queries."], "explanation": "Snowflake saves data on the warehouse&#39;s local disk if it can&#39;t fit an operation into memory. Data spilling slows down queries because it requires more IO operations, and disk access is slower than memory access. &quot;Bytes spilled to local storage.&quot; indicates local spillage.\n  \n Snowflake will spill data to remote cloud storage if the local disk becomes full, which is even slower storage than the local disk, making this operation even slower. &quot;Bytes spilled to remote storage&quot; in the query profile indicates remote spillage.\n  \n One of the ways to avoid spilling is to use a larger warehouse, which will increase the overall available RAM, local storage, and parallelism and might be able to fit the query in memory.\n  \n https://docs.snowflake.com/en/user-guide/ui-query-profile#queries-too-large-to-fit-in-memory"}, "correct_response": ["a"], "section": "Performance Concepts", "question_plain": "A query required a long time to complete execution. The query profile for the query shows a significant value for \u201cBytes spilled to local storage.\u201d Which one of the following is the reason for data spilling?", "related_lectures": []}, {"_class": "assessment", "id": 70909000, "assessment_type": "multiple-choice", "prompt": {"question": "True or False: You can set your virtual warehouses to auto-suspend and auto-resume so that when the virtual warehouse is not being used for a set time period, it goes into suspended mode and resumes when a query is executed.", "answers": ["True", "False"], "explanation": ""}, "correct_response": ["a"], "section": "Performance Concepts", "question_plain": "True or False: You can set your virtual warehouses to auto-suspend and auto-resume so that when the virtual warehouse is not being used for a set time period, it goes into suspended mode and resumes when a query is executed.", "related_lectures": []}, {"_class": "assessment", "id": 70909002, "assessment_type": "multiple-choice", "prompt": {"question": "If a virtual warehouse is scaled up to a larger size, when does Snowflake starts charging for the new size?", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "When a virtual warehouse is scaled up, the charging for the new size does not begin until all the new nodes in the larger virtual warehouse have been provisioned. \n  \n https://docs.snowflake.com/en/user-guide/warehouses-considerations#warehouse-resizing-improves-performance", "answers": ["<p><strong>After all new nodes are provisioned</strong></p>", "Immediately", "When the virtual warehouse is suspended and resumed", "After 5 minutes"]}, "correct_response": ["a"], "section": "Performance Concepts", "question_plain": "If a virtual warehouse is scaled up to a larger size, when does Snowflake starts charging for the new size?", "related_lectures": []}, {"_class": "assessment", "id": 70909004, "assessment_type": "multi-select", "prompt": {"question": "Which of the following statement about MFA is correct? Select all that apply.", "answers": ["All Snowflake editions support MFA.", "All Snowflake client tools support MFA.", "MFA is supported only by the Snowflake web interface.", "MFA is only available in the Business Critical edition and above."], "explanation": "MFA is enabled by default for all Snowflake accounts and is available in all Snowflake editions. All Snowflake client tools, including the web interface, SnowSQL, and the various connectors and drivers, support MFA.\n  \n https://docs.snowflake.com/en/user-guide/security-mfa"}, "correct_response": ["a", "b"], "section": "Security", "question_plain": "Which of the following statement about MFA is correct? Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70909006, "assessment_type": "multi-select", "prompt": {"question": "Which of the following statement about MFA is correct? Select all that apply.", "answers": ["MFA enrolment for a user can be disabled by an administrator.", "Users can enroll themselves in MFA through the Snowflake web interface.", "Only administrators can enroll users in MFA.", "Once MFA is enabled for a user, it cannot be disabled"], "explanation": "Multi-factor authentication (MFA) is enabled by default for all Snowflake accounts, and any Snowflake user can enroll themselves in MFA through the Snowflake web interface. An administrator can disable a user&#39;s MFA enrolment; in this case, the user must re-enroll to access the MFA features and functionality.\n  \n An administrator with the SECURITYADMIN or above role can disable MFA for a user. \n  \n https://docs.snowflake.com/en/user-guide/security-mfa"}, "correct_response": ["a", "b"], "section": "Security", "question_plain": "Which of the following statement about MFA is correct? Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70909008, "assessment_type": "multi-select", "prompt": {"question": "Column-level security may be implemented in Snowflake using which of the following methods? (Choose two options.)", "answers": ["Dynamic data masking", "External Tokenization", "Columnar Storage", "Search Optimization"], "explanation": "Snowflake supports masking policies that may be applied to columns and enforced at the column level to provide column-level security. Column-level security is achieved by dynamic data masking or external Tokenization.\n  \n https://docs.snowflake.com/en/user-guide/security-column"}, "correct_response": ["a", "b"], "section": "Security", "question_plain": "Column-level security may be implemented in Snowflake using which of the following methods? (Choose two options.)", "related_lectures": []}, {"_class": "assessment", "id": 70909010, "assessment_type": "multiple-choice", "prompt": {"question": "Which view types ensure that the user cannot see the underlying data?", "answers": ["Secure views", "Permanent Views", "External Views", "Materialized Views"], "explanation": "Secure views can be used to return only certain rows from a table. Additionally, secure views hide the underlying data by removing some of the internal Snowflake optimizations.\n  \n https://docs.snowflake.com/en/user-guide/views-secure"}, "correct_response": ["a"], "section": "Security", "question_plain": "Which view types ensure that the user cannot see the underlying data?", "related_lectures": []}, {"_class": "assessment", "id": 70909012, "assessment_type": "multi-select", "prompt": {"question": "What does Tri-Secret Secure encryption in Snowflake provide? Choose two.", "answers": ["Tri-Secret Secure allows customers to bring their own keys for encryption", "Tri-Secret Secure requires the Business Critical edition or higher.", "Tri-Secret Secure requires the Enterprise edition or higher.", "Tri-Secret Secure provides multi-factor authentication capabilities in Snowflake."], "explanation": "Tri-Secret Secure refers to the combination of a Snowflake-managed key and a customer-managed key, which results in the creation of a composite master key to protect your data. Tri-Secret Secure requires the Business Critical edition as a minimum and can be activated by contacting Snowflake support.\n  \n https://docs.snowflake.com/en/user-guide/security-encryption-manage"}, "correct_response": ["a", "b"], "section": "Security", "question_plain": "What does Tri-Secret Secure encryption in Snowflake provide? Choose two.", "related_lectures": []}, {"_class": "assessment", "id": 70909014, "assessment_type": "multiple-choice", "prompt": {"question": "What is Snowflake&#39;s behavior when enforcing a network policy with an IP address in both the block and allow lists?", "answers": ["Snowflake applies the block list first, preventing the IP address from connecting, even if it is also defined in the allow list.", "Because both the allowed and blocked lists cannot be filled, the network policy is invalid.", "Snowflake uses the allow list first, ensuring that the IP address can connect even if it is also in the block list.", "The specific IP address is ignored from the network policy"], "explanation": "A network policy consists of the policy name, a list of authorized IP addresses separated by commas, and a list of forbidden IP addresses. In the authorized or forbidden IP addresses list, you can specify an individual IP address or an IP address range; however, network policies presently support only IPv4 addresses. If both the allowed and blocked IP address lists are populated, Snowflake applies the block list first, followed by the allowed list.\n  \n https://docs.snowflake.com/en/user-guide/network-policies"}, "correct_response": ["a"], "section": "Security", "question_plain": "What is Snowflake&#39;s behavior when enforcing a network policy with an IP address in both the block and allow lists?", "related_lectures": []}, {"_class": "assessment", "id": 70909016, "assessment_type": "multiple-choice", "prompt": {"question": "Which of the following is NOT a built-in role provided by Snowflake?", "answers": ["SUPERADMIN", "SECURITYADMIN", "ACCOUNTADMIN", "USERADMIN"], "explanation": "Snowflake is pre-configured with the following roles. ACCOUNTADMIN is a full-privilege account administrator role. USERADMIN provides the ability to create USERS and ROLES. SECURITYADMIN receives privileges from USERADMIN and can govern global object grants. SYSADMIN can create and manage the majority of Snowflake objects. ORGADMIN manages the operations at an organizational level.\n There is also the PUBLIC role, which is automatically assigned to everyone.\n  \n https://docs.snowflake.com/en/user-guide/security-access-control-overview#system-defined-roles"}, "correct_response": ["a"], "section": "Security", "question_plain": "Which of the following is NOT a built-in role provided by Snowflake?", "related_lectures": []}, {"_class": "assessment", "id": 70909018, "assessment_type": "multi-select", "prompt": {"question": "Which of the following statements is true regarding the SECURITYADMIN role? Select all that apply.", "answers": ["A user with the SECURITYADMIN role can create new users.", "A user with the SECURITYADMIN role can create new roles.", "A user with the SECURITYADMIN role can manage object grants.", "A user with the SECURITYADMIN can create new Reader accounts."], "explanation": "SECURITYADMIN inherits privileges that USERADMIN has to create USERS and ROLES for your organization. Additionally, this role can also control object grants system-wide. \n  \n https://docs.snowflake.com/en/user-guide/security-access-control-overview#system-defined-roles."}, "correct_response": ["a", "b", "c"], "section": "Security", "question_plain": "Which of the following statements is true regarding the SECURITYADMIN role? Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70909020, "assessment_type": "multi-select", "prompt": {"question": "Which of the following is true regarding roles in Snowflake? Select all that apply", "answers": ["A user can be assigned one or more roles.", "Every user automatically gets the PUBLIC role.", "A user can be assigned only one role.", "Only Snowflake built-in roles are available for use; new custom roles cannot be created."], "explanation": "Snowflake&#39;s access control is built on the role-based access control (RBAC) approach, which assigns rights to roles and roles to users. The privileges given to a role are inherited by all users in that role. \n  \n The PUBLIC role has the fewest privileges and is assigned automatically to all users.\n  \n https://docs.snowflake.com/en/user-guide/security-access-control-overview"}, "correct_response": ["a", "b"], "section": "Security", "question_plain": "Which of the following is true regarding roles in Snowflake? Select all that apply", "related_lectures": []}, {"_class": "assessment", "id": 70909022, "assessment_type": "multiple-choice", "prompt": {"question": "Which of the following tool is used for connectivity diagnostics?", "answers": ["SnowCD", "SnowSQL", "Snowpipe", "Snowsight"], "explanation": "SnowCD is Snowflake Connectivity Diagnostic Tool.\n  \n https://docs.snowflake.com/en/user-guide/snowcd"}, "correct_response": ["a"], "section": "Tools & Interfaces", "question_plain": "Which of the following tool is used for connectivity diagnostics?", "related_lectures": []}, {"_class": "assessment", "id": 70909024, "assessment_type": "multiple-choice", "prompt": {"question": "You have written an SQL statement in the worksheet view. You must share the SQL statement with another user in your Snowflake account. Which would be the simplest way to share the SQL statement?", "answers": ["Share the worksheet containing the SQL with the other user.", "Copy the SQL statement and email it to the other user.", "Save the SQL statement to an internal stage and let the other user load the statement from the internal stage.", "Create a view that contains the SQL statement. Let the other users know about the view name and location."], "explanation": "The simplest method in this scenario is sharing the SQL statement worksheet.\n Snowsight lets you share worksheets and folders with other Snowflake users in your account, allowing others to view and execute SQL in your worksheets and folders.\n  \n https://docs.snowflake.com/en/user-guide/ui-snowsight"}, "correct_response": ["a"], "section": "Tools & Interfaces", "question_plain": "You have written an SQL statement in the worksheet view. You must share the SQL statement with another user in your Snowflake account. Which would be the simplest way to share the SQL statement?", "related_lectures": []}, {"_class": "assessment", "id": 70909026, "assessment_type": "multi-select", "prompt": {"question": "Which of the following statements regarding Zero-Copy cloning are true? Select all that apply.", "answers": ["Zero-copy cloning is a metadata process.", "You can clone tables, schemas, and even databases.", "Only tables can be cloned", "Zero-copy cloning involves the physical copying of data"], "explanation": "Micro-partitions and metadata in the cloud services layer enable rapid and efficient zero-copy cloning because the cloned table&#39;s metadata references the existing micro-partitions.\n The CLONE command can make copies of a wide variety of Snowflake objects, including tables, schemas, and databases.\n  \n https://docs.snowflake.com/en/user-guide/tables-storage-considerations#label-cloning-tables"}, "correct_response": ["a", "b"], "section": "Cloning", "question_plain": "Which of the following statements regarding Zero-Copy cloning are true? Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70909028, "assessment_type": "multiple-choice", "prompt": {"question": "Can files already processed into the source table be loaded again into a cloned table?", "answers": ["Yes", "No"], "explanation": "Cloning does not copy the load metadata; therefore, any files previously loaded in the source table can be reloaded into the cloned table without any issues."}, "correct_response": ["a"], "section": "Cloning", "question_plain": "Can files already processed into the source table be loaded again into a cloned table?", "related_lectures": []}, {"_class": "assessment", "id": 70909030, "assessment_type": "multi-select", "prompt": {"question": "Cloning a database will clone which of the following? Select all that apply.", "answers": ["The database", "All schemas in the database", "All tables within every schema in that database", "ONLY the public schema in the database", "All tables ONLY in the public schema in the database"], "explanation": "When a database is cloned, all child schemas and objects within those schemas are cloned.\n  \n  \n https://docs.snowflake.com/en/sql-reference/sql/create-clone#additional-rules-that-apply-to-cloning-objects"}, "correct_response": ["a", "b", "c"], "section": "Cloning", "question_plain": "Cloning a database will clone which of the following? Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70909032, "assessment_type": "multiple-choice", "prompt": {"question": "When cloning a table, your current role must have which privilege on the source table?", "answers": ["SELECT", "USAGE", "WRITE"], "explanation": "To clone a table, you need SELECT privileges on the source table. For cloning Pipes, Streams &amp; Tasks, you require OWNERSHIP privileges; for all other objects that can be cloned, you need the USAGE privilege.\n  \n https://docs.snowflake.com/en/sql-reference/sql/create-clone#general-usage-notes"}, "correct_response": ["a"], "section": "Cloning", "question_plain": "When cloning a table, your current role must have which privilege on the source table?", "related_lectures": []}, {"_class": "assessment", "id": 70909034, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>True or False: A Snowflake customer can share data with a data consumer in a different cloud platform/region without replicating data.</strong></p>", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "<p>It is possible to share data with Snowflake accounts in another cloud platform, but the provider must enable replication and replicate existing database(s) to the other cloud platform.</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/secure-data-sharing-across-regions-plaforms</p>", "answers": ["<p><strong>False</strong></p>", "<p><strong>True</strong></p>"]}, "correct_response": ["a"], "section": "Data Sharing", "question_plain": "True or False: A Snowflake customer can share data with a data consumer in a different cloud platform/region without replicating data.", "related_lectures": []}, {"_class": "assessment", "id": 70909036, "assessment_type": "multiple-choice", "prompt": {"question": "<p><strong>What is one of the reasons you would create a row access policy?</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>Row-level security (RLS) can be used to return only certain rows. RLS is implemented by creating row access policies, which include conditions and functions that govern which rows are returned during query execution.</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/security-row-intro</p>", "answers": ["<p><strong>To control which rows from a table are returned by a query.</strong></p>", "<p><strong>To stop users from switching to a privileged role.</strong></p>", "<p><strong>To stop users from performing DML operations on a table.</strong></p>", "<p><strong>To prevent data loading activities on a table.</strong></p>"]}, "correct_response": ["a"], "section": "Security", "question_plain": "What is one of the reasons you would create a row access policy?", "related_lectures": []}, {"_class": "assessment", "id": 70909038, "assessment_type": "multiple-choice", "prompt": {"question": "<p><strong>True or False: Network policies in Snowflake currently support only IPv4.</strong></p>", "relatedLectureIds": "", "feedbacks": ["", ""], "explanation": "<p>A network policy consists of the policy name, a list of authorized IP addresses separated by commas, and a list of forbidden IP addresses. In the authorized or forbidden IP addresses list, you can specify an individual IP address or an IP address range; however, network policies presently support only IPv4 addresses.</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/network-policies</p>", "answers": ["<p><strong>True</strong></p>", "<p><strong>False</strong></p>"]}, "correct_response": ["a"], "section": "Security", "question_plain": "True or False: Network policies in Snowflake currently support only IPv4.", "related_lectures": []}, {"_class": "assessment", "id": 70909040, "assessment_type": "multiple-choice", "prompt": {"question": "<p><strong>Snowflake recommends using a maximum of __________ columns in a clustering key.</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>Snowflake recommends using a maximum of 3 or 4 columns in a clustering key. Any more columns in the clustering key result in more maintenance costs and do not provide enough benefits to justify the clustering costs.</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/tables-clustering-keys</p><p><br></p>", "answers": ["<p><strong>3 to 4</strong></p>", "<p><strong>2</strong></p>", "<p><strong>1</strong></p>", "<p><strong>10</strong></p>"]}, "correct_response": ["a"], "section": "Performance Concepts", "question_plain": "Snowflake recommends using a maximum of __________ columns in a clustering key.", "related_lectures": []}, {"_class": "assessment", "id": 70909042, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>Which of the following Snowflake Editions support search optimization service for opitmizing point look up queries? </strong></p><p><strong>Select all that apply.</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>The Enterprise edition has several additional capabilities not provided in the Standard edition, including search optimization. The business-critical edition &amp; the VPS edition (higher editions than Enterprise) also inherit this capability.</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/intro-editions.html</p><p><br></p>", "answers": ["<p><strong>Enterprise Edition</strong></p>", "<p><strong>Business Critical Edition</strong></p>", "<p><strong>Virtual Private Snowflake (VPS) edition</strong></p>", "<p><strong>Standard Edition</strong></p>"]}, "correct_response": ["a", "b", "c"], "section": "Licensing & Features", "question_plain": "Which of the following Snowflake Editions support search optimization service for opitmizing point look up queries? Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70909044, "assessment_type": "multiple-choice", "prompt": {"question": "<p><strong>What kind of partner are Alation, Immuta, and Collibra in the Snowflake partner ecosystem?</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>All of these are Security, Governance &amp; Observability partners of Snowflake. Please see https://docs.Snowflake.com/en/user-guide/ecosystem.html</p>", "answers": ["<p><strong>Security, Governance &amp; Observability</strong></p>", "<p><strong>Data Integration</strong></p>", "<p><strong>Machine Learning &amp; Data Science</strong></p>", "<p><strong>SQL Development and Management</strong></p>"]}, "correct_response": ["a"], "section": "Partners", "question_plain": "What kind of partner are Alation, Immuta, and Collibra in the Snowflake partner ecosystem?", "related_lectures": []}, {"_class": "assessment", "id": 70909046, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>What of the following is true about the virtual warehouse created by Partner Connect during the process of connecting to a partner?</strong></p><p><br></p><p><strong>Select all that apply.</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>During the process of connecting to a Partner application, Snowflake automatically creates several objects, such as an empty database, virtual warehouse, default user, and custom role. When the partner app reads or writes to your account, it uses these objects.</p><p><br></p><p>The automatically created virtual warehouse defaults to X-Small but can be changed if required.</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/ecosystem-partner-connect#connecting-with-a-snowflake-partner</p>", "answers": ["<p><strong>The size of the virtual warehouse defaults to X-Small.</strong></p>", "<p><strong>The virtual warehouse size can be changed if required.</strong></p>", "<p><strong>The virtual warehouse size can NOT be changed once created.</strong></p>", "<p><strong>The size of the virtual warehouse defaults to 6X-Large.</strong></p>"]}, "correct_response": ["a", "b"], "section": "Partners", "question_plain": "What of the following is true about the virtual warehouse created by Partner Connect during the process of connecting to a partner?Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70909048, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>Which of the following statement is correct regarding clustering?</strong></p><p><strong>Select all that apply.</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p>Clustering keys are not required for all tables. You must evaluate the cost &amp; benefit to ascertain if a table should have a clustering key. Generally, Snowflake will cluster the data well enough for most tables without requiring an explicit clustering key.</p><p><br></p><p>Clustering keys can have more than one column, although you should limit the number to 3-4 columns when defining a multi-column clustering key. The columns can generally be of any data type and are not limited to date columns.</p><p><br></p><p>However, a table cannot have multiple clustering keys defined.</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/tables-clustering-keys</p>", "answers": ["<p><strong>A clustering key can have more than one column.</strong></p>", "<p><strong>Defining a clustering key is not mandatory.</strong></p>", "<p><strong>A clustering key must be defined for each table.</strong></p>", "<p><strong>A clustering key can only contain date columns.</strong></p>", "<p><strong>A table can have more than one clustering key.</strong></p>"]}, "correct_response": ["a", "b"], "section": "Performance Concepts", "question_plain": "Which of the following statement is correct regarding clustering?Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70909050, "assessment_type": "multiple-choice", "prompt": {"question": "<p><strong>When executing a typical query, what is the order in which Snowflake may utilize various caches?</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", ""], "explanation": "<p>Snowflake will first validate if the query can be fulfilled through the metadata cache for simple COUNT or SUM queries.</p><p><br></p><p>If the metadata cache can NOT fulfill the query, then Snowflake checks if the query can be fulfilled by the Query Result Cache (in the case of a previously executed query).</p><p><br></p><p>If the metadata cache &amp; query result cache can\u2019t fulfill the query, then Snowflake starts executing the query. In this case, Snowflake will attempt to use the virtual warehouse cache to improve query performance.</p>", "answers": ["<p><strong>1 - Metadata Cache</strong></p><p><strong>2 - Query Result Cache</strong></p><p><strong>3 \u2013 Virtual Warehouse Cache</strong></p>", "<p><strong>1 \u2013 Virtual Warehouse Cache</strong></p><p><strong>2 - Query Result Cache</strong></p><p><strong>3 \u2013 Metadata Cache</strong></p>", "<p><strong>1 - Query Result Cache</strong></p><p><strong>2 \u2013 Virtual Warehouse Cache</strong></p><p><strong>3 \u2013 Metadata Cache</strong></p>"]}, "correct_response": ["a"], "section": "Performance Concepts", "question_plain": "When executing a typical query, what is the order in which Snowflake may utilize various caches?", "related_lectures": []}, {"_class": "assessment", "id": 70909052, "assessment_type": "multiple-choice", "prompt": {"question": "<p><strong>Which scenario requires requesting Snowflake support to recover data from Fail-safe storage?</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", ""], "explanation": "<p>Using Time Travel, you cannot recover from a data issue before the maximum time travel period, i.e., 90 days. You must request Snowflake support to recover data from the fail-safe storage.</p><p><br></p><p>For other scenarios with deleted data and dropped tables, the Time Travel extensions will suffice.</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/data-failsafe</p>", "answers": ["<p><strong>A data corruption issue that corrupted three production tables 93 days ago was discovered.</strong></p>", "<p><strong>An administrator accidentally dropped a production table last week.</strong></p>", "<p><strong>A new data pipeline rolled out in production yesterday has deleted all rows from a production table.</strong></p>"]}, "correct_response": ["a"], "section": "Fail-safe", "question_plain": "Which scenario requires requesting Snowflake support to recover data from Fail-safe storage?", "related_lectures": []}, {"_class": "assessment", "id": 70909054, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>Which of the following activities are not required to be performed by a Snowflake customer?</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>Snowflake, a software-as-a-service product, doesn't require a customer to manage the data center, hardware install hardware or software or manage the high availability.</p>", "answers": ["<p><strong>Provision hardware for installing the Snowflake database</strong></p>", "<p><strong>Installation of Snowflake Software</strong></p>", "<p><strong>Configuration and Testing of High availability of hardware at the data center level</strong></p>", "<p><strong>Management of user access &amp; privileges</strong></p>"]}, "correct_response": ["a", "b", "c"], "section": "Licensing & Features", "question_plain": "Which of the following activities are not required to be performed by a Snowflake customer?", "related_lectures": []}, {"_class": "assessment", "id": 70909056, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>Which of the following is true regarding schemas in Snowflake?</strong></p><p><strong>Select all that apply.</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p>The INFORMATION_SCHEMA provides metadata on the objects in the parent database of the INFORMATION_SCHEMA. It is automatically created with every database and can not be dropped, renamed, or moved.</p><p><br></p><p>The PUBLIC schema is also automatically created with every database, but it is just like an ordinary schema. It can be dropped, renamed, or moved. If required, additional schemas may be created under a database.</p><p><br></p><p>https://docs.snowflake.com/en/sql-reference/info-schema#information-schema-views-and-table-functions</p>", "answers": ["<p><strong>The INFORMATION_SCHEMA can NOT be dropped, renamed, or moved.</strong></p>", "<p><strong>The PUBLIC schema can be dropped, renamed, or moved if required.</strong></p>", "<p><strong>Additional schemas can be created if required.</strong></p>", "<p><strong>The PUBLIC schema can NOT be dropped, renamed, or moved.</strong></p>", "<p><strong>The INFORMATION_SCHEMA schema can be dropped, renamed, or moved if required.</strong></p>"]}, "correct_response": ["a", "b", "c"], "section": "Snowflake\u2019s Catalog and objects", "question_plain": "Which of the following is true regarding schemas in Snowflake?Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70909058, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>Which of the following aspects are considered for calculating the storage costs for a Snowflake account?</strong></p><p><strong>Select all that apply.</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p>The storage costs in Snowflake are calculated based on the average amount of storage used during the month. The calculation is based on the volume of stored data after compression has been applied to the data.</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/cost-understanding-overall</p>", "answers": ["<p><strong>Compressed data</strong></p>", "<p><strong>The daily average of storage used during the month.</strong></p>", "<p><strong>Un-compressed data</strong></p>", "<p><strong>The aggregated amount of storage used during the month.</strong></p>", "<p><strong>The amount of data stored as of the end of the month.</strong></p>"]}, "correct_response": ["a", "b"], "section": "Cost & Pricing", "question_plain": "Which of the following aspects are considered for calculating the storage costs for a Snowflake account?Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70909060, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>Why is Snowflake considered a SaaS (Software-as-a-Service) product?</strong></p><p><strong>Select all that apply.</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>All of these are characteristics of a Software-as-a-Service product.</p>", "answers": ["<p><strong>Snowflake regularly updates the software, and all accounts receive these updates automatically, eliminating the need for manual installations, maintenance, and patches.</strong></p>", "<p><strong>The customer is not required to procure, install, and manage any hardware.</strong></p>", "<p><strong>Snowflake runs in the cloud and is available over the Internet.</strong></p>", "<p><strong>It provides Pay as you Go licensing, allowing users to pay only for the resources and features they use.</strong></p>"]}, "correct_response": ["a", "b", "c", "d"], "section": "Licensing & Features", "question_plain": "Why is Snowflake considered a SaaS (Software-as-a-Service) product?Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70909062, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>Which of the following columns will be part of the result set when a directory table is queried?</strong></p><p><strong>Select all that apply.</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p>When a directory table is queried, the result set contains the FILE_URL for each file in the stage object. The result set also contains additional metadata, such as the file's relative path, which shows the file's path relative to the stage. The result set also has metadata such as the size of the file in bytes and the timestamp of when a file was last modified, the MD5 checksum for the file, and an ETAG file, which changes if the contents of the file change. When querying a directory table, you can filter the result set using the WHERE clause on any of these fields. For example, you can use the size column to limit your results to only those files that are greater than 10MB.</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/data-load-dirtables-manage#output</p>", "answers": ["<p><strong>RELATIVE_PATH</strong></p>", "<p><strong>SIZE</strong></p>", "<p><strong>FILE_URL</strong></p>", "<p><strong>ENCRYPTION_KEY</strong></p>", "<p><strong>IS_COMPRESSED</strong></p>"]}, "correct_response": ["a", "b", "c"], "section": "Data Transformation", "question_plain": "Which of the following columns will be part of the result set when a directory table is queried?Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70909064, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>Which statements are correct regarding the costs when manually refreshing a directory table's metadata through the \"ALTER STAGE &lt;stage-name&gt; REFRESH;\" command?</strong></p><p><br></p><p><strong>Select all that apply.</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>A small maintenance cost is charged for refreshing a directory table's metadata, whether through notifications or manually (through ALTER STAGE &lt;stage-name&gt; REFRESH). This small maintenance cost is accounted for under the cloud services costs.</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/data-load-dirtables-intro#billing-for-directory-tables</p>", "answers": ["<p><strong>A small maintenance cost is charged for the refresh operation.</strong></p>", "<p><strong>The cost appears under the cloud services cost.</strong></p>", "<p><strong>The refresh operation is free.</strong></p>", "<p><strong>The costs appear under virtual warehouse costs.</strong></p>"]}, "correct_response": ["a", "b"], "section": "Data Transformation", "question_plain": "Which statements are correct regarding the costs when manually refreshing a directory table's metadata through the \"ALTER STAGE &lt;stage-name&gt; REFRESH;\" command?Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70909066, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>Which of the following is true regarding Scoped URLs?</strong></p><p><br></p><p><strong>Select all that apply.</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>All of these are correct statements.</p><p><br></p><p>A scoped URL is a temporary and encoded URL that allows temporary access to a staged file without requiring any privileges on the stage. A scoped URL expires after 24 hours.</p><p>Only the user who generates a scoped URL can use the URL to access the referenced file. Scoped URLs are suitable to provide temporary access for a user or an application.</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/unstructured-intro#types-of-urls-available-to-access-files</p>", "answers": ["<p><strong>A scoped URL is a temporary, encoded URL that enables access to a staged file without requiring privileges on the stage.</strong></p>", "<p><strong>A scoped URL expires after 24 hours.</strong></p>", "<p><strong>Only the user who generates a scoped URL can use the URL to access the referenced file.</strong></p>", "<p><strong>Scoped URLs are suitable to provide temporary access for a user or an application.</strong></p>"]}, "correct_response": ["a", "b", "c", "d"], "section": "Data Transformation", "question_plain": "Which of the following is true regarding Scoped URLs?Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70909068, "assessment_type": "multiple-choice", "prompt": {"question": "<p><strong>You need to extract a list of users who logged into the Snowflake account during the past 12 months. Which one of the following options should you use?</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>The history of logins from the past 12 months can only be retrieved using the ACCOUNT_USAGE schema.</p><p>The views in the ACCOUNT_USAGE schema provide up to 365 days of history for various information.</p><p><br></p><p>The LOGIN_HISTORY view has the login attempt information. The ACCESS_HISTORY view provides information on the access history of Snowflake objects.</p><p><br></p><p>https://docs.snowflake.com/en/sql-reference/functions/login_history</p>", "answers": ["<p><strong>Query the ACCOUNT_USAGE.LOGIN_HISTORY view</strong></p>", "<p><strong>Query the ACCOUNT_USAGE.ACCESS_HISTORY view</strong></p>", "<p><strong>Use the LOGIN_HISTORY table function in INFORMATION_SCHEMA</strong></p>", "<p><strong>Use QUERY_HISTORY table function in INFORMATION_SCHEMA</strong></p>"]}, "correct_response": ["a"], "section": "Account Usage & Monitoring", "question_plain": "You need to extract a list of users who logged into the Snowflake account during the past 12 months. Which one of the following options should you use?", "related_lectures": []}, {"_class": "assessment", "id": 70909070, "assessment_type": "multiple-choice", "prompt": {"question": "<p><strong>Which ACCOUNT_USAGE view provides information about which tables &amp; columns were read by queries in the last 12 months?</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>The ACCESS_HISTORY view in the ACCOUNT_USAGE schema provides information on which objects were accessed by queries. This view provides 365 days of history.</p><p><br></p><p>This view provides information on objects accessed, including columns, tables, views, stored procedures, UDFs, etc. The view also provides information regarding the base objects accessed indirectly (e.g., tables &amp; columns accessed through a view) and modified objects.</p><p><br></p><p>https://docs.snowflake.com/en/sql-reference/account-usage/access_history</p>", "answers": ["<p><strong>ACCESS_HISTORY</strong></p>", "<p><strong>WAREHOUSE_EVENTS_HISTORY</strong></p>", "<p><strong>METERING_HISTORY</strong></p>", "<p><br></p><p><strong>QUERY_HISTORY</strong></p>"]}, "correct_response": ["a"], "section": "Account Usage & Monitoring", "question_plain": "Which ACCOUNT_USAGE view provides information about which tables &amp; columns were read by queries in the last 12 months?", "related_lectures": []}, {"_class": "assessment", "id": 70909072, "assessment_type": "multiple-choice", "prompt": {"question": "<p><strong>Which ACCOUNT_USAGE view can be used to identify the most frequently accessed tables?</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>Using the ACCESS_HISTORY view, you can identify what data was accessed, when, and who accessed it. Using this information, you can also identify what data is not being accessed at all.</p><p><br></p><p>There are other benefits of using ACCESS_HISTORY data, which can be found at the following link.</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/access-history#benefits</p>", "answers": ["<p><strong>ACCESS_HISTORY</strong></p>", "<p><strong>OBJECT_DEPENDENCIES</strong></p>", "<p><strong>DATABASE_STORAGE_USAGE_HISTORY</strong></p>", "<p><strong>QUERY_HISTORY</strong></p>"]}, "correct_response": ["a"], "section": "Account Usage & Monitoring", "question_plain": "Which ACCOUNT_USAGE view can be used to identify the most frequently accessed tables?", "related_lectures": []}, {"_class": "assessment", "id": 70909074, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>Consider the following resource monitor configuration.</strong></p><img src=\"https://img-b.udemycdn.com/redactor/raw/practice_test_question/2023-10-01_23-14-13-f9742939a4ce78e720818b83b6c6b6d3.png\"><p><strong>Which three of the following statements are true?</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p>Resource monitors can track &amp; manage a single virtual warehouse against a defined quota. Resource monitors can be created to track the credit usage of multiple virtual warehouses together.</p><p>Resource Monitors can also be created at the account level, which means that such resource monitors track credit usage at the account level, considering the credit usage of all virtual warehouses.</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/resource-monitors#assignment-of-resource-monitors</p>", "answers": ["<p><strong>Warehouse 5 can use up to 5,000 credits if the other Warehouses have not used any credits.</strong></p>", "<p><strong>The combined credit usage of Warehouse 2 and Warehouse 3 can be up to 2000 credits.</strong></p>", "<p><strong>Assuming that Warehouse 1 has used 500 credits, then Warehouse 4 and Warehouse 5 combined credit usage can be up to 4500.</strong></p>", "<p><strong>Warehouse 2 and Warehouse 3 combined credit usage can be up to 2500.</strong></p>", "<p><strong>Warehouse 1 can use up to 5,000 credits if the other Warehouses have not used any credits.</strong></p>"]}, "correct_response": ["a", "b", "c"], "section": "Account Usage & Monitoring", "question_plain": "Consider the following resource monitor configuration.Which three of the following statements are true?", "related_lectures": []}, {"_class": "assessment", "id": 70909076, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>Consider a Snowflake account hosted on the AWS platform. An external table created on this account can read data from which of the following?</strong></p><p><br></p><p><strong>Select all that apply.</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p>It does not matter which cloud platform a Snowflake account is hosted on. It can still read data from object storage on the supported cloud platforms, e.g., Amazon, Azure, and Google.</p><p><br></p><p>An external table is configured to read from an external stage. The external stage, in turn, points to object storage on the cloud, which contains the data for the external table. The object storage pointed to by the external stage could be Amazon S3, Google Cloud Storage, Azure Blob Storage, and other S3-compatible storage options.</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/tables-external-intro#workflow</p>", "answers": ["<p><strong>Amazon S3</strong></p>", "<p><strong>Google Cloud Storage</strong></p>", "<p><strong>Azure Blob Storage</strong></p>", "<p><strong>On-premises SQL server files</strong></p>", "<p><strong>On-premises Postgres data files</strong></p>"]}, "correct_response": ["a", "b", "c"], "section": "Data Loading and Unloading", "question_plain": "Consider a Snowflake account hosted on the AWS platform. An external table created on this account can read data from which of the following?Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70909078, "assessment_type": "multiple-choice", "prompt": {"question": "<p><strong>Consider a database with the name MARKETING. The database has a table called CUSTOMER in the PUBLIC schema.</strong></p><p><br></p><p><strong>You create a temporary table with the same name, i.e., CUSTOMER, in the PUBLIC schema of the MARKETING database.</strong></p><p><br></p><p><strong>What happens when you execute \"DROP TABLE MARKETING.PUBLIC.CUSTOMER;\" within the same session?</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>Like permanent and transient tables, temporary tables belong to a database &amp; schema. However, because they are limited to a session, the naming uniqueness constraints do not apply to them. Therefore, creating a temporary table with the same name as an existing table is possible. This can result in some potential conflicts and unexpected behavior.</p><p><br></p><p>If a temporary table is created in a schema with the same name as a permanent (or transient) table, the temporary table effectively hides the permanent table in that session. Queries and other operations during the session will affect only the temporary table.</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/tables-temp-transient#potential-naming-conflicts-with-other-table-types</p>", "answers": ["<p><strong>The temporary table is dropped.</strong></p>", "<p><strong>The permanent table is dropped.</strong></p>", "<p><strong>The statement fails with an \"object not found\" error.</strong></p>", "<p><strong>The statement fails with a \"duplicate object\" error.</strong></p>"]}, "correct_response": ["a"], "section": "Snowflake\u2019s Catalog and objects", "question_plain": "Consider a database with the name MARKETING. The database has a table called CUSTOMER in the PUBLIC schema.You create a temporary table with the same name, i.e., CUSTOMER, in the PUBLIC schema of the MARKETING database.What happens when you execute \"DROP TABLE MARKETING.PUBLIC.CUSTOMER;\" within the same session?", "related_lectures": []}, {"_class": "assessment", "id": 70909080, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>You need to upload a file to an internal stage in Snowflake using the PUT command. Which of the following can you use to execute the PUT command and upload the file successfully?</strong></p><p><br></p><p><strong>Select two answers.</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p>You can use the PUT command from SnowSQL or any of the Drivers/Connectors provided by Snowflake.</p><p><br></p><p>Although Snowsight can be used to stage files into an internal stage (for small volumes of files), it doesn't allow executing the PUT command.</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/data-load-local-file-system-stage</p>", "answers": ["<p><strong>SnowSQL</strong></p>", "<p><strong>Python Connector</strong></p>", "<p><strong>Snowsight Web Interface</strong></p>", "<p><strong>Snowpipe</strong></p>", "<p><strong>SQL API</strong></p>"]}, "correct_response": ["a", "b"], "section": "Data Loading and Unloading", "question_plain": "You need to upload a file to an internal stage in Snowflake using the PUT command. Which of the following can you use to execute the PUT command and upload the file successfully?Select two answers.", "related_lectures": []}, {"_class": "assessment", "id": 70909082, "assessment_type": "multiple-choice", "prompt": {"question": "<p><strong>What role is required to execute the following statements to enable replication?</strong></p><p><br></p><p><strong>SELECT SYSTEM$GLOBAL_ACCOUNT_SET_PARAMETER('myorg.acct1',</strong></p><p><strong>'ENABLE_ACCOUNT_DATABASE_REPLICATION', 'true');</strong></p><p><br></p><p><strong>SELECT SYSTEM$GLOBAL_ACCOUNT_SET_PARAMETER('myorg.acct2',</strong></p><p><strong>'ENABLE_ACCOUNT_DATABASE_REPLICATION', 'true');</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>Only users with the ORGADMIN role can call the SYSTEM$GLOBAL_ACCOUNT_SET_PARAMETER function.</p><p><br></p><p>https://docs.snowflake.com/en/sql-reference/functions/system_global_account_set_parameter</p>", "answers": ["<p><strong>ORGADMIN</strong></p>", "<p><strong>ACCOUNTADMIN</strong></p>", "<p><strong>SYSADMIN</strong></p>", "<p><strong>SECURITYADMIN</strong></p>"]}, "correct_response": ["a"], "section": "Security", "question_plain": "What role is required to execute the following statements to enable replication?SELECT SYSTEM$GLOBAL_ACCOUNT_SET_PARAMETER('myorg.acct1','ENABLE_ACCOUNT_DATABASE_REPLICATION', 'true');SELECT SYSTEM$GLOBAL_ACCOUNT_SET_PARAMETER('myorg.acct2','ENABLE_ACCOUNT_DATABASE_REPLICATION', 'true');", "related_lectures": []}, {"_class": "assessment", "id": 70909084, "assessment_type": "multi-select", "prompt": {"question": "<p>What privileges are required for a user to add or remove the search optimization for a table?</p><p><br></p><p>Select two answers.</p>", "relatedLectureIds": "", "feedbacks": ["", "", "", "", "", ""], "explanation": "<p>To add, configure, or remove search optimization for a table, you must have</p><p><br></p><p>a) OWNERSHIP privileges on the table.</p><p>b) ADD SEARCH optimization privileges on the schema that contains the table.</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/search-optimization-service#what-access-control-privileges-are-needed-for-the-search-optimization-service</p>", "answers": ["<p>OWNERSHIP privileges on the table</p>", "<p>ADD SEARCH OPTIMIZATION on the schema that contains the table</p>", "<p>SYSADMIN privileges</p>", "<p>ORGADMIN privileges</p>", "<p>SECURITYADMIN privileges</p>", "<p>UPDATE privileges on the table</p>"]}, "correct_response": ["a", "b"], "section": "Security", "question_plain": "What privileges are required for a user to add or remove the search optimization for a table?Select two answers.", "related_lectures": []}, {"_class": "assessment", "id": 70909086, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>Which of the following are the limitations of materialized views?</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>There are certain limitations on defining materialized views (MV). These include</p><p>An MV can only query a single table.</p><p>An MV definition cannot have joins (even self-joins)</p><p>MVs support SOME aggregate functions.</p><p><br></p><p>See the following link for a complete list of limitations.</p><p>https://docs.snowflake.com/en/user-guide/views-materialized#limitations-on-creating-materialized-views</p><p><br></p><p>Do note that when you query a materialized view, you can use it just like any other table so they can be joined with other tables if required.</p>", "answers": ["<p><strong>Materialized views support querying one table only.</strong></p>", "<p><strong>A materialized view definition can NOT have joins with other tables.</strong></p>", "<p><strong>A materialized view can NOT be joined with other tables.</strong></p>", "<p><strong>A materialized view does not support any aggregate functions.</strong></p>"]}, "correct_response": ["a", "b"], "section": "Performance Concepts", "question_plain": "Which of the following are the limitations of materialized views?", "related_lectures": []}, {"_class": "assessment", "id": 70909088, "assessment_type": "multiple-choice", "prompt": {"question": "<p><strong>As a Snowflake administrator, you want to optimize the performance for a query that accesses a small subset of rows in a table. The query requires significant processing each time they are run. The data in the table doesn\u2019t change that often.</strong></p><p><strong>Which of the following approaches should you take?</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>Materialized views can be helpful if a query or slight variation is executed frequently.</p><p>The executed queries are complex and take time and resources; a materialized view can pre-compute the results and speed up the processing.</p><p><br></p><p>The query result is consistent and does not change frequently. This indicates that the data underlying the query doesn\u2019t change too frequently. If it did change frequently, then the resources &amp; compute required to keep the materialized view up-to-date will outweigh the benefit the view provides.</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/views-materialized</p>", "answers": ["<p><strong>Create a materialized view for the query.</strong></p>", "<p><strong>Add a custom clustering key to the table.</strong></p>", "<p><strong>Enable search optimization on the table.</strong></p>", "<p><strong>Create a new table with just the required rows. Change the query to use the new table.</strong></p>"]}, "correct_response": ["a"], "section": "Performance Concepts", "question_plain": "As a Snowflake administrator, you want to optimize the performance for a query that accesses a small subset of rows in a table. The query requires significant processing each time they are run. The data in the table doesn\u2019t change that often.Which of the following approaches should you take?", "related_lectures": []}, {"_class": "assessment", "id": 70909090, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>Which of the following can help reduce data spilling to local &amp; remote storage?</strong></p><p><strong>Select two answers.</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p>One of the ways to avoid spilling is to use a larger warehouse, which will increase the overall available RAM, local storage, and parallelism and might be able to fit the query in memory.</p><p>Another way is to split your processing using temporary tables so intermediate results are not held in memory.</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/ui-query-profile#queries-too-large-to-fit-in-memory</p>", "answers": ["<p><strong>Increasing the size of the virtual warehouse</strong></p>", "<p><strong>Using temporary tables rather than common table expressions (CTE).</strong></p>", "<p><strong>Increasing the size of the metadata cache</strong></p>", "<p><strong>Increasing the size of the query result cache</strong></p>", "<p><strong>Using common table expressions (CTE) rather than temporary tables.</strong></p><p><br></p>"]}, "correct_response": ["a", "b"], "section": "Performance Concepts", "question_plain": "Which of the following can help reduce data spilling to local &amp; remote storage?Select two answers.", "related_lectures": []}, {"_class": "assessment", "id": 70909092, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>Which of the following Single Sign-on workflows may be performed by using federated authentication?</strong></p><p><br></p><p><strong>Select all that apply.</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", "", "", ""], "explanation": "<p>The following SSO workflows are possible with federated authentication in Snowflake.</p><p><br></p><p>Logging into Snowflake</p><p>Logging out of Snowflake</p><p>System timeout due to inactivity</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/admin-security-fed-auth-overview#supported-sso-workflows</p>", "answers": ["<p><strong>Logging into Snowflake</strong></p>", "<p><strong>Logging out of Snowflake</strong></p>", "<p><strong>System timeout due to inactivity</strong></p>", "<p><strong>User Authorization</strong></p>", "<p><strong>Role Authorization</strong></p>", "<p><strong>Row-level Security</strong></p>"]}, "correct_response": ["a", "b", "c"], "section": "Security", "question_plain": "Which of the following Single Sign-on workflows may be performed by using federated authentication?Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70909094, "assessment_type": "multiple-choice", "prompt": {"question": "<p><strong>Which of the following is utilized first when the following query is executed?</strong></p><p><br></p><p><strong>SELECT COUNT(*) FROM TRANSACTIONS;</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p>Snowflake stores information about micro-partitions in the metadata. It stores the range of column values in its metadata, which includes the maximum and minimum values for each column in each micro-partition. Snowflake also stores the count of distinct values for each column in the metadata and certain other information to optimize a query.</p><p><br></p><p>Because this information is stored in the metadata cache, Snowflake does not have to read the data from the tables for specific queries; instead, it may retrieve the information it needs directly from the metadata. These queries include things like count queries and queries containing functions like MIN or MAX. The metadata cache will not be used if you execute MIN or MAX on a column containing only characters.</p>", "answers": ["<p><strong>Metadata Cache</strong></p>", "<p><strong>Query Result Cache</strong></p>", "<p><strong>Local Disk Cache</strong></p>", "<p><strong>Remote Cache</strong></p>", "<p><strong>Browser Cache</strong></p>"]}, "correct_response": ["a"], "section": "Performance Concepts", "question_plain": "Which of the following is utilized first when the following query is executed?SELECT COUNT(*) FROM TRANSACTIONS;", "related_lectures": []}, {"_class": "assessment", "id": 70909096, "assessment_type": "multiple-choice", "prompt": {"question": "<p><strong>Consider a multi-cluster virtual warehouse in auto-scale mode, using an economy scaling policy. How long do queries wait in the queue before another cluster is started?</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>When the scaling policy is set to Economy, it permits queuing to continue for some time before scaling up, conserving costs at the expense of performance. New virtual warehouses are spun up only if the system determines that the new warehouse has sufficient query workload to keep it busy for at least 6 minutes.</p><p><br></p><p>When scaling down, the system conducts 5 to 6 successive checks to determine whether the workload can be reallocated to other warehouses without the need to spin up another warehouse again. If the criteria are met, the virtual warehouse is scaled-down. These checks are carried out at one-minute intervals.</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/warehouses-multicluster#setting-the-scaling-policy-for-a-multi-cluster-warehouse</p>", "answers": ["<p><strong>6 minutes</strong></p>", "<p><strong>1 minute</strong></p>", "<p><strong>10 minutes</strong></p>", "<p><strong>2 minutes</strong></p>"]}, "correct_response": ["a"], "section": "Performance Concepts", "question_plain": "Consider a multi-cluster virtual warehouse in auto-scale mode, using an economy scaling policy. How long do queries wait in the queue before another cluster is started?", "related_lectures": []}, {"_class": "assessment", "id": 70909098, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>Which of the following statistics indicate if partitioning pruning has occurred?</strong></p><p><br></p><p><strong>Select two.</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p>Partition pruning occurs when the number of Partitions scanned is much smaller than Partitions total.</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/ui-query-profile</p>", "answers": ["<p><strong>Partitions total</strong></p>", "<p><strong>Partitions scanned</strong></p>", "<p><strong>Bytes Scanned</strong></p>", "<p><strong>Bytes Written</strong></p>", "<p><strong>Total Bytes</strong></p>"]}, "correct_response": ["a", "b"], "section": "Performance Concepts", "question_plain": "Which of the following statistics indicate if partitioning pruning has occurred?Select two.", "related_lectures": []}, {"_class": "assessment", "id": 70909100, "assessment_type": "multiple-choice", "prompt": {"question": "<p><strong>Which Snowflake database object is derived from a query specification, has results saved for later use, and can be used to speed up expensive aggregations on large tables?</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>A materialized view is a view that pre-computes data based on a SELECT query. The query's results are pre-computed and physically stored to enhance performance for similar queries that are executed in the future. When the underlying table is updated, the materialized view refreshes automatically, requiring no additional maintenance. Snowflake-managed services perform the update in the background transparent to the user without interfering with the user's experience.</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/views-materialized</p>", "answers": ["<p><strong>Materialized View</strong></p>", "<p><strong>Secure View</strong></p>", "<p><strong>Output View</strong></p>", "<p><strong>View</strong></p>"]}, "correct_response": ["a"], "section": "Performance Concepts", "question_plain": "Which Snowflake database object is derived from a query specification, has results saved for later use, and can be used to speed up expensive aggregations on large tables?", "related_lectures": []}, {"_class": "assessment", "id": 70943150, "assessment_type": "multiple-choice", "prompt": {"question": "<p><strong>What is the default retention period for Time Travel across all Snowflake editions?</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p>The default retention period for Time Travel is 1 day across all Snowflake accounts. The default may be changed according to the maximum allowed Time Travel by the Snowflake edition (i.e., 1 day for Standard, up to 90 days for Enterprise &amp; above). Additionally, individual objects such as tables may be configured to a different number then the default.</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/data-time-travel#data-retention-period</p>", "answers": ["<p><strong>1 day</strong></p>", "<p><strong>0 days</strong></p>", "<p><strong>7 days</strong></p>", "<p><strong>14 days</strong></p>", "<p><strong>90 days</strong></p>"]}, "correct_response": ["a"], "section": "Time Travel", "question_plain": "What is the default retention period for Time Travel across all Snowflake editions?", "related_lectures": []}]}
4762402
~~~
{"count": 121, "next": null, "previous": null, "results": [{"_class": "assessment", "id": 70942560, "assessment_type": "multiple-choice", "prompt": {"question": "How many days of historical data can you access through the views in the ACCOUNT_USAGE schema?", "answers": ["365 days", "7 days", "1 day", "90 days"], "explanation": "The ACCOUNT USAGE schema consists of several views that provide usage metrics and metadata information at the account level.\n  \n Data provided by the ACCOUNT_USAGE views is NOT real-time and refreshes typically with a lag of 45 minutes to 3 hours, depending on the view. \n  \n The data in these views are retained for up to 365 days.\n  \n https://docs.snowflake.com/en/sql-reference/account-usage#differences-between-account-usage-and-information-schema"}, "correct_response": ["a"], "section": "Account Usage & Monitoring", "question_plain": "How many days of historical data can you access through the views in the ACCOUNT_USAGE schema?", "related_lectures": []}, {"_class": "assessment", "id": 70942562, "assessment_type": "multiple-choice", "prompt": {"question": "True or False: To prevent performance issues, an error is returned if a query using INFORMATION_SCHEMA is not sufficiently selective.", "answers": ["True", "False"], "explanation": "If the filters supplied in an INFORMATION SCHEMA query are not sufficiently selective, the following error is returned. \n  \n Information schema query returned too much data. Please repeat the query with more selective predicates.\n  \n https://docs.snowflake.com/en/sql-reference/info-schema#general-usage-notes"}, "correct_response": ["a"], "section": "Account Usage & Monitoring", "question_plain": "True or False: To prevent performance issues, an error is returned if a query using INFORMATION_SCHEMA is not sufficiently selective.", "related_lectures": []}, {"_class": "assessment", "id": 70942564, "assessment_type": "multiple-choice", "prompt": {"question": "True or False: The data in the views in the INFORMATION_SCHEMA is real-time.", "answers": ["True", "False"], "explanation": "The data provided via the INFORMATION_SCHEMA views is real-time, and there is no latency in the information provided. So, if you are asked which schema should be used if there is a requirement to view real-time data, then the views in INFORMATION SCHEMA should be used as they contain real-time information.\n  \n https://docs.snowflake.com/en/sql-reference/account-usage#differences-between-account-usage-and-information-schema"}, "correct_response": ["a"], "section": "Account Usage & Monitoring", "question_plain": "True or False: The data in the views in the INFORMATION_SCHEMA is real-time.", "related_lectures": []}, {"_class": "assessment", "id": 70942566, "assessment_type": "multiple-choice", "prompt": {"question": "The query history in the Snowflake Web Interface is kept for how many days?", "answers": ["14 days", "30 days", "6 months", "365 days"], "explanation": "The query history page lets users view the history of executed and currently executing queries. The query history page can show the history of queries executed in the last 14 days.\n  \n  \n https://docs.snowflake.com/en/user-guide/ui-snowsight-activity#query-history"}, "correct_response": ["a"], "section": "Account Usage & Monitoring", "question_plain": "The query history in the Snowflake Web Interface is kept for how many days?", "related_lectures": []}, {"_class": "assessment", "id": 70942568, "assessment_type": "multi-select", "prompt": {"question": "Which of the following can view and modify an existing resource monitor? Select all that apply.", "answers": ["An account administrator (i.e., a person with the ACCOUNTADMIN role)", "A user who has MONITOR and MODIFY privilege on the resource monitor.", "A system administrator (i.e., a person with the SYSADMIN role).", "Any user of the system"], "explanation": "From a privilege perspective, only Account Administrators (users with ACCOUNTADMIN role) can create resource monitors. However, account administrators can grant privileges to the resource monitor to allow other users to view and modify the resource monitor configuration. The MONITOR and MODIFY privileges on a resource monitor allow other users to view and modify a specific resource monitor.\n  \n https://docs.snowflake.com/en/user-guide/resource-monitors#access-control-privileges-for-resource-monitors"}, "correct_response": ["a", "b"], "section": "Account Usage & Monitoring", "question_plain": "Which of the following can view and modify an existing resource monitor? Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70942570, "assessment_type": "multiple-choice", "prompt": {"question": "Snowflake releases a behaviour change release at what frequency?", "answers": ["Once a Month", "Once every week", "Once a year", "Once every fortnight"], "explanation": "Once a month, Snowflake also releases a &quot;behavior change release.&quot; These changes to existing behaviors may affect customers who already use the service. Over two months, the new behavior is adopted by everyone. The behavior change is not enabled during the first month unless the customer opts in. The behavior modification is enabled automatically in the second month, but a customer can opt-out if desired. \n  \n https://docs.snowflake.com/en/user-guide/intro-releases"}, "correct_response": ["a"], "section": "Account", "question_plain": "Snowflake releases a behaviour change release at what frequency?", "related_lectures": []}, {"_class": "assessment", "id": 70942572, "assessment_type": "multiple-choice", "prompt": {"question": "True/False: Snowflake is based on existing database technology, which has been retrofitted to run on the cloud.", "answers": ["False", "True"], "explanation": "Snowflake has been designed for the cloud and has been designed from scratch.\n  \n Snowflake implements a new hybrid architecture that decouples compute and storage."}, "correct_response": ["a"], "section": "Architecture", "question_plain": "True/False: Snowflake is based on existing database technology, which has been retrofitted to run on the cloud.", "related_lectures": []}, {"_class": "assessment", "id": 70942574, "assessment_type": "multi-select", "prompt": {"question": "Which of the following statements are true regarding Snowflake&#39;s architecture? Select all that apply", "answers": ["Snowflake storage &amp; compute are independent of each other.", "You can increase or decrease the compute resources in Snowflake without changing the storage.", "In Snowflake, the compute must be increased whenever the storage is increased.", "Snowflake uses a monolithic architecture in which compute and storage are tightly coupled."], "explanation": "Snowflake implements a new hybrid architecture that decouples compute and storage. Snowflake stores data similarly to a shared-disk architecture, i.e., the data is shared. But it also allows for using several compute engines on the same shared data, each with its own memory and processing capabilities.\n  \n This hybrid architecture allows Snowflake to increase or decrease compute without requiring storage changes and vice versa."}, "correct_response": ["a", "b"], "section": "Architecture", "question_plain": "Which of the following statements are true regarding Snowflake&#39;s architecture? Select all that apply", "related_lectures": []}, {"_class": "assessment", "id": 70942576, "assessment_type": "multiple-choice", "prompt": {"question": "Snowflake stores table data in which format?", "answers": ["A proprietary format", "Parquet format", "JSON", "CSV &amp; TSV files"], "explanation": "Snowflake stores data in a proprietary format on cloud object storage, such as AWS S3, Azure Blob Storage, or Google Cloud Storage. Users cannot see the actual files, or look at how the data is stored, or access the file directly."}, "correct_response": ["a"], "section": "Architecture", "question_plain": "Snowflake stores table data in which format?", "related_lectures": []}, {"_class": "assessment", "id": 70942578, "assessment_type": "multi-select", "prompt": {"question": "Snowflake stores which of the following metadata about data in a micro-partition. Select all that apply.", "answers": ["The range of values for each of the columns in the micro-partition.", "The number of distinct values.", "Additional properties for optimization and efficient processing."], "explanation": "All of these are valid examples of the metadata that Snowflake stores for micro-partition.\n  \n Snowflake stores the range of column values in its metadata: the maximum and the minimum value for each column in each micro-partition. Snowflake can intelligently decide which partitions to read when processing a query using this metadata. Additionally, Snowflake stores the count of distinct values for each column in each partition in the metadata and certain other information to assist in query optimization.\n  \n https://docs.snowflake.com/en/user-guide/tables-clustering-micropartitions"}, "correct_response": ["a", "b", "c"], "section": "Architecture", "question_plain": "Snowflake stores which of the following metadata about data in a micro-partition. Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70942580, "assessment_type": "multi-select", "prompt": {"question": "Which of the following statement describe micro-partitions correctly?", "answers": ["Micro-partitions are immutable.", "Data in micro-partitions is organized in a columnar format.", "Data in micro-partitions is organized in a row storage format.", "Micro-partitions are mutable and can be updated."], "explanation": "Snowflake partitions are immutable, which means they cannot be changed once created. Table data is mapped to individual micro-partitions and is further organized using a columnar format.\n  \n https://docs.snowflake.com/en/user-guide/tables-clustering-micropartitions.html"}, "correct_response": ["a", "b"], "section": "Architecture", "question_plain": "Which of the following statement describe micro-partitions correctly?", "related_lectures": []}, {"_class": "assessment", "id": 70942582, "assessment_type": "multiple-choice", "prompt": {"question": "A large table in Snowflake may contain millions or hundreds of millions of micro-partitions.", "answers": ["True", "False"], "explanation": "The number of micro-partitions for a given table depends mainly on the amount of data in that table. For a very large table, the number of micro-partitions can run into millions or hundreds of millions of micro-partitions.\n  \n https://docs.snowflake.com/en/user-guide/tables-clustering-micropartitions"}, "correct_response": ["a"], "section": "Architecture", "question_plain": "A large table in Snowflake may contain millions or hundreds of millions of micro-partitions.", "related_lectures": []}, {"_class": "assessment", "id": 70942584, "assessment_type": "multi-select", "prompt": {"question": "Which of the following are examples of virtual warehouse sizes?", "answers": ["X-Small", "Medium", "6X-Large", "Low", "High"], "explanation": "Snowflake has made it easy and quick for a user to choose a virtual warehouse by labeling the configuration in T-shirt sizes: X-Small, Small, Medium, Large, and so on\n  \n https://docs.snowflake.com/en/user-guide/warehouses-overview"}, "correct_response": ["a", "b", "c"], "section": "Architecture", "question_plain": "Which of the following are examples of virtual warehouse sizes?", "related_lectures": []}, {"_class": "assessment", "id": 70942586, "assessment_type": "multiple-choice", "prompt": {"question": "The compute layer in Snowflake architecture performs which one of the following?", "answers": ["Query Processing", "Query Planning", "Query Optimization", "Cache Query Results"], "explanation": "The compute layer is responsible for query processing or query execution. \n  \n Query planning &amp; optimization is performed by the cloud services layer.\n  \n The query result cache is stored and managed in the cloud services layer.\n  \n https://docs.snowflake.com/en/user-guide/intro-key-concepts"}, "correct_response": ["a"], "section": "Architecture", "question_plain": "The compute layer in Snowflake architecture performs which one of the following?", "related_lectures": []}, {"_class": "assessment", "id": 70942588, "assessment_type": "multiple-choice", "prompt": {"question": "A virtual warehouse was started, used for 5 minutes and 15 seconds, and shut down afterward. The customer will be charged for how many seconds?", "answers": ["315 seconds", "360 seconds", "0 seconds", "3600 seconds"], "explanation": "Snowflake credits are billed on a per-second usage basis, which means if a virtual warehouse ran for 5 minutes and 15 seconds, you would be charged for 315 seconds (5*60 + 15). \n  \n However, note that a minimum of 60 seconds of billing applies, so if a virtual warehouse were started and shut down within the first 1st minute, a minimum of 60-second credit usage would apply."}, "correct_response": ["a"], "section": "Architecture", "question_plain": "A virtual warehouse was started, used for 5 minutes and 15 seconds, and shut down afterward. The customer will be charged for how many seconds?", "related_lectures": []}, {"_class": "assessment", "id": 70942590, "assessment_type": "multi-select", "prompt": {"question": "Which of the following statements regarding multi-cluster virtual warehouses are true? Select all that apply.", "answers": ["A minimum of Enterprise edition is required for multi-cluster virtual warehouse capability.", "Multi-cluster virtual warehouses automatically add additional clusters when simultaneous queries increase to a number that existing virtual warehouses can not handle.", "Multi-cluster virtual warehouses automatically remove additional clusters when query demand decreases.", "Multi-cluster virtual warehouses cannot be set to auto-suspend or auto-resume."], "explanation": "Multi-cluster virtual warehouses are utilized when the number of concurrent users exceeds a single virtual warehouse&#39;s capacity. When the concurrent workload for a virtual warehouse reaches the maximum, new queries are queued. Multi-cluster virtual warehouses address this by adding clusters as needed. When the demand drops, the extra clusters are removed. Enterprise edition is required to use the multi-cluster virtual warehouse feature.\n  \n Besides the automatic addition and removal of compute clusters, multi-cluster virtual warehouses behave the same as typical virtual warehouses so that they can be suspended or resumed and auto-suspended or auto-resumed. \n  \n https://docs.snowflake.com/en/user-guide/warehouses-multicluster"}, "correct_response": ["a", "b", "c"], "section": "Architecture", "question_plain": "Which of the following statements regarding multi-cluster virtual warehouses are true? Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70942592, "assessment_type": "multi-select", "prompt": {"question": "Which of the following statements regarding multi-cluster virtual warehouses are true? Select all that apply.", "answers": ["Multi-cluster virtual warehouses automatically add or remove virtual warehouses in response to changing workload demands.", "Multi-cluster virtual warehouses can be set to auto-suspend or auto-resume, just like a standard virtual warehouse", "You must manually add or remove clusters in a multi-cluster virtual warehouse.", "Multi-cluster virtual warehouses cannot be set to auto-suspend or auto-resume."], "explanation": "When the concurrent workload for a virtual warehouse reaches the maximum, new queries are queued. Multi-cluster virtual warehouses address this by adding clusters as needed. When demand drops, the extra clusters are removed. \n  \n Multi-cluster virtual warehouses can be suspended or resumed or set to auto-suspend/auto-resume, just like any other virtual warehouse. \n  \n https://docs.snowflake.com/en/user-guide/warehouses-multicluster"}, "correct_response": ["a", "b"], "section": "Architecture", "question_plain": "Which of the following statements regarding multi-cluster virtual warehouses are true? Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70942594, "assessment_type": "multi-select", "prompt": {"question": "The cloud services layer in Snowflake provides which of the following functions? Select all that apply.", "answers": ["Transaction control / ACID compliance", "Data Sharing", "Cloning", "Storage for data"], "explanation": "Snowflake&#39;s data sharing, cloning, and data exchange features are all managed through the cloud services layer using metadata.\n The cloud services layer also provides ACID compliance. ACID means a database system must allow several transactions to run in isolation and commit or roll back a transaction as a unit, assuring system consistency."}, "correct_response": ["a", "b", "c"], "section": "Architecture", "question_plain": "The cloud services layer in Snowflake provides which of the following functions? Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70942596, "assessment_type": "multiple-choice", "prompt": {"question": "What layer in Snowflake&#39;s architecture is responsible for user authentication and authorization?", "answers": ["Cloud Services", "Query Processing", "Database Storage", "Client Tools"], "explanation": "The cloud services layer manages authentication and authorization. When a user logs in, the cloud services layer validates their credentials. When a user submits a query, the cloud services layer parses and optimizes the query plan.\n  \n https://docs.snowflake.com/en/user-guide/intro-key-concepts"}, "correct_response": ["a"], "section": "Architecture", "question_plain": "What layer in Snowflake&#39;s architecture is responsible for user authentication and authorization?", "related_lectures": []}, {"_class": "assessment", "id": 70942598, "assessment_type": "multiple-choice", "prompt": {"question": "True or False: The COPY command can unload data using a SELECT query.", "answers": ["True", "False"], "explanation": "The COPY command allows unloading or exporting data from a table or a view and also allows using queries (SELECT) to unload data.\n  \n https://docs.snowflake.com/en/user-guide/data-unload-overview#bulk-unloading-using-queries"}, "correct_response": ["a"], "section": "Data Loading and Unloading", "question_plain": "True or False: The COPY command can unload data using a SELECT query.", "related_lectures": []}, {"_class": "assessment", "id": 70942600, "assessment_type": "multiple-choice", "prompt": {"question": "<p><strong>You want to load a specific list of files from an S3 stage. What is the correct syntax for achieving this?</strong></p><p><strong>&nbsp; Assume the file names are </strong></p><p><strong> delta1.csv</strong></p><p><strong> delta2.csv</strong></p><p><strong> delta3.csv</strong></p><p><strong> and the stage is called my_stage, and the table is called my_table</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", ""], "explanation": "You can specify the exact file names in the COPY command so that only those files are accessed and loaded. The syntax for that can be found on the link below.\n  \n https://docs.snowflake.com/en/user-guide/data-load-considerations-load#lists-of-files", "answers": ["COPY INTO my_table FROM @my_stage \n files=(&#39;delta1.csv&#39;, &#39;delta2.csv&#39;, &#39;delta3.csv&#39;)", "COPY INTO my_table FROM @my_stage/delta1.csv,@my_stage/delta2.csv,@my_stage/delta3.csv", "COPY delta1.csv,delta2.csv,delta3.csv INTO my_table FROM @my_stage"]}, "correct_response": ["a"], "section": "Data Loading and Unloading", "question_plain": "You want to load a specific list of files from an S3 stage. What is the correct syntax for achieving this?&nbsp; Assume the file names are  delta1.csv delta2.csv delta3.csv and the stage is called my_stage, and the table is called my_table", "related_lectures": []}, {"_class": "assessment", "id": 70942602, "assessment_type": "multiple-choice", "prompt": {"question": "<p><strong>Which mechanism allow a Snowflake customer to query data without loading it first?</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "Snowflake offers an alternative approach for tables called external tables, which permits the creation of tables with data stored in external cloud storage. External tables remove the need for the data to be loaded into Snowflake. In the case of an External table, the definition of the table is still stored in Snowflake metadata and consists of table structure, file locations, filenames, and other attributes. However, the table&#39;s data is saved outside of Snowflake.\n  \n The external table functionality enables you to query external data like a standard table. External tables may be joined to other tables, and views may be created using them.\n  \n https://docs.snowflake.com/en/user-guide/tables-external-intro", "answers": ["External Table", "COPY", "Snowpipe", "Virtual Table"]}, "correct_response": ["a"], "section": "Data Loading and Unloading", "question_plain": "Which mechanism allow a Snowflake customer to query data without loading it first?", "related_lectures": []}, {"_class": "assessment", "id": 70942604, "assessment_type": "multi-select", "prompt": {"question": "Snowflake allows which two of the following approaches for loading data?", "answers": ["Bulk Data Loading", "Continuous Data Loading", "Intermittent Data Loading"], "explanation": "Snowflake supports data loading in two primary ways. The COPY command can be used to load bulk data or huge files. To load data into a table, the COPY command requires the usage of a virtual warehouse. \n  \n The other method of loading data into Snowflake is via the Snowpipe. Snowpipe is the ideal technique for loading data when the data is arriving continuously in a messaging or streaming manner. \n  \n  \n https://docs.snowflake.com/en/user-guide/data-load-overview#bulk-vs-continuous-loading"}, "correct_response": ["a", "b"], "section": "Data Loading and Unloading", "question_plain": "Snowflake allows which two of the following approaches for loading data?", "related_lectures": []}, {"_class": "assessment", "id": 70942606, "assessment_type": "multiple-choice", "prompt": {"question": "The GET command is used for which of the following purposes?", "answers": ["Download data from an internal stage to an on-premises system.", "Download data from an internal stage to the cloud storage.", "Download data from an external stage on an on-premises system.", "Download data from a Snowflake table to any type of stage."], "explanation": "The GET command is used to download data from an internal stage to an on-premises system.\n  \n The PUT command uploads data from an on-premises system to an internal stage.\n  \n To download or upload data to an external stage, cloud provider utilities or other tools are used to interact with data in the cloud storage pointed to by the external stage.\n  \n  \n https://docs.snowflake.com/en/user-guide/data-unload-overview#bulk-unloading-process"}, "correct_response": ["a"], "section": "", "question_plain": "The GET command is used for which of the following purposes?", "related_lectures": []}, {"_class": "assessment", "id": 70942608, "assessment_type": "multiple-choice", "prompt": {"question": "True or False: Snowflake can transform data after a partner software has loaded it.", "answers": ["True", "False"], "explanation": "After data has been loaded into Snowflake through partner software, Snowflake SQL or other mechanisms can transform data within Snowflake."}, "correct_response": ["a"], "section": "Data Loading and Unloading", "question_plain": "True or False: Snowflake can transform data after a partner software has loaded it.", "related_lectures": []}, {"_class": "assessment", "id": 70942610, "assessment_type": "multiple-choice", "prompt": {"question": "In Snowflake, which of the following can be used to load continuously arriving data?", "answers": ["Snowpipe", "SnowTrickle", "SnowFast", "SnowStorm"], "explanation": "Snowflake allows continuous data loading using Snowpipe, a serverless service. Snowpipe enables you to load data in a micro-batch manner, loading small volumes of data on each execution. The micro-batch-based data loading is used when a continuous stream of data, such as transactions or events, must be loaded and made available to enterprises quickly. Snowpipe enables continuous data loading and can load data within a few minutes after it arrives in a stage.\n  \n Snowpipe is serverless and has its own computational capability; therefore, it does not rely on virtual warehouses for processing. Snowflake automatically manages the compute required by a Snowpipe. Snowflake also manages the scaling up and down of a Snowpipe as per the data load requirement. Since a Snowpipe is serverless, its costs are charged separately from virtual warehousing fees.\n  \n  \n https://docs.snowflake.com/en/user-guide/data-load-snowpipe-intro"}, "correct_response": ["a"], "section": "Data Loading and Unloading", "question_plain": "In Snowflake, which of the following can be used to load continuously arriving data?", "related_lectures": []}, {"_class": "assessment", "id": 70942612, "assessment_type": "multiple-choice", "prompt": {"question": "Which of the following is a scenario where using Snowpipe is the optimal choice?", "answers": ["You need to load small volumes of frequently arriving data", "You are loading large files that arrive monthly", "Your users are running frequent tactical queries.", "Your users are running massive data science workloads."], "explanation": "Snowpipe is the ideal method for loading data when the data is arriving continuously in a messaging or streaming manner, and there is a requirement for data to be loaded almost immediately. \n  \n https://docs.snowflake.com/en/user-guide/data-load-snowpipe-intro"}, "correct_response": ["a"], "section": "Data Loading and Unloading", "question_plain": "Which of the following is a scenario where using Snowpipe is the optimal choice?", "related_lectures": []}, {"_class": "assessment", "id": 70942614, "assessment_type": "multi-select", "prompt": {"question": "Which of the following transformations are supported by the COPY command? Select all that apply.", "answers": ["Omit columns", "Reorder columns", "Cast columns", "Join with other tables"], "explanation": "When loading data into a table using the COPY command, Snowflake allows you to do simple transformations on the data as it is being loaded. During the load process, the COPY command allows for modifying the order of columns, omitting one or more columns, casting data into specified data types, and truncating values.\n  \n While loading the data, complex transformations such as joins, filters, aggregations, and the use of FLATTEN are not supported as they are not essential data transformations. Therefore, joining, filtering, and aggregating the data are supported ONLY after the data has been loaded into a table.\n  \n https://docs.snowflake.com/en/user-guide/data-load-overview#id2"}, "correct_response": ["a", "b", "c"], "section": "Data Loading and Unloading", "question_plain": "Which of the following transformations are supported by the COPY command? Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70942616, "assessment_type": "multiple-choice", "prompt": {"question": "Which of the following can retrieve data from fail-safe storage?", "answers": ["Snowflake support", "Customer", "Cloud provider", "Anyone"], "explanation": "Once the data is in fail-safe storage, only Snowflake support can help retrieve the data. The customer cannot access fail-safe storage. The cloud provider cannot access any of the data stored by Snowflake, whether in fail-safe storage or otherwise.\n  \n https://docs.snowflake.com/en/user-guide/data-failsafe"}, "correct_response": ["a"], "section": "Fail-safe", "question_plain": "Which of the following can retrieve data from fail-safe storage?", "related_lectures": []}, {"_class": "assessment", "id": 70942618, "assessment_type": "multiple-choice", "prompt": {"question": "What is the minimum Snowflake edition that supports fail-safe?", "answers": ["Standard", "Enterprise", "Business Critical", "Virtual Private Snowflake"], "explanation": "Fail-safe is supported in all Snowflake editions; therefore, the minimum edition with fail-safe support is the Standard edition.\n  \n https://docs.snowflake.com/en/user-guide/data-failsafe"}, "correct_response": ["a"], "section": "Fail-safe", "question_plain": "What is the minimum Snowflake edition that supports fail-safe?", "related_lectures": []}, {"_class": "assessment", "id": 70942620, "assessment_type": "multiple-choice", "prompt": {"question": "True/False: Once the Time Travel retention period has ended for a temporary table, Historical data in Temporary tables can not be recovered by Snowflake support", "answers": ["True", "False"], "explanation": "Transient and temporary tables don&#39;t have fail-safe functionality; therefore, data in such tables goes through zero days of fail-safe storage. Also, Transient and Temporary tables have a maximum of 1 day of Time Travel.\n  \n Therefore, once the Time Travel period for these tables is complete, there is no way to recover historical data. \n  \n https://docs.snowflake.com/en/user-guide/tables-temp-transient"}, "correct_response": ["a"], "section": "Data Protection", "question_plain": "True/False: Once the Time Travel retention period has ended for a temporary table, Historical data in Temporary tables can not be recovered by Snowflake support", "related_lectures": []}, {"_class": "assessment", "id": 70942622, "assessment_type": "multi-select", "prompt": {"question": "Which of the following statements are correct regarding Time Travel &amp; fail-safe storage? Select all that apply.", "answers": ["The maximum allowed Time Travel duration for a temporary table is 1 day.", "There is no fail-safe storage for a temporary table.", "The maximum allowed Time Travel duration for a temporary table is 7 days.", "A temporary table has 7 days of fail-safe storage."], "explanation": "Transient and temporary tables don&#39;t have fail-safe functionality; therefore, data in such tables goes through zero days of fail-safe storage. Also, Transient and Temporary tables have a maximum of 1 day of Time Travel.\n  \n https://docs.snowflake.com/en/user-guide/tables-temp-transient"}, "correct_response": ["a", "b"], "section": "Time Travel", "question_plain": "Which of the following statements are correct regarding Time Travel &amp; fail-safe storage? Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70942624, "assessment_type": "multiple-choice", "prompt": {"question": "What is the maximum allowed duration for Time Travel in the Snowflake Enterprise edition?", "answers": ["90 days", "1 day", "45 days", "0 days"], "explanation": "Depending on the Snowflake edition, the Time Travel duration might range from 1 to 90 days. The Standard edition allows for one day of Time Travel. Time Travel is possible for up to 90 days in the Enterprise version and above.\n  \n https://docs.snowflake.com/en/user-guide/data-time-travel#data-retention-period"}, "correct_response": ["a"], "section": "Time Travel", "question_plain": "What is the maximum allowed duration for Time Travel in the Snowflake Enterprise edition?", "related_lectures": []}, {"_class": "assessment", "id": 70942626, "assessment_type": "multi-select", "prompt": {"question": "Which of the following are Time Travel SQL extensions?", "answers": ["AT", "BEFORE", "UNDROP", "TIME", "TIMETRAVEL"], "explanation": "To support Time Travel queries, Snowflake supports special SQL extensions. It supports the AT and BEFORE statements which can be used with SELECT statements or while cloning tables, schemas, and databases. Snowflake also supports the UNDROP statement, which can be used to recover tables, schemas, or even complete databases after they have been dropped.\n  \n https://docs.snowflake.com/en/user-guide/data-time-travel#time-travel-sql-extensions"}, "correct_response": ["a", "b", "c"], "section": "Time Travel", "question_plain": "Which of the following are Time Travel SQL extensions?", "related_lectures": []}, {"_class": "assessment", "id": 70942628, "assessment_type": "multiple-choice", "prompt": {"question": "When data is shared between Snowflake accounts, what type of database is created on the consumer side for consuming the shared data?", "answers": ["Read-only", "Temporary", "Permanent", "Writable", "Open Access"], "explanation": "The correct answer is read-only. The consumer creates a database from the Share object as a read-only database.\n  \n https://docs.snowflake.com/en/user-guide/data-sharing-intro#how-does-secure-data-sharing-work"}, "correct_response": ["a"], "section": "Data Sharing", "question_plain": "When data is shared between Snowflake accounts, what type of database is created on the consumer side for consuming the shared data?", "related_lectures": []}, {"_class": "assessment", "id": 70942630, "assessment_type": "multiple-choice", "prompt": {"question": "True or False: A share must have at least one consumer added.", "answers": ["False", "True"], "explanation": "A Snowflake share can be defined without a consumer added to it. One or more consumers can be added to the Share afterward"}, "correct_response": ["a"], "section": "Data Sharing", "question_plain": "True or False: A share must have at least one consumer added.", "related_lectures": []}, {"_class": "assessment", "id": 70942632, "assessment_type": "multiple-choice", "prompt": {"question": "True or False: When a Snowflake data provider shares data with a data consumer, the data consumer is not charged for any additional storage costs.", "answers": ["True", "False"], "explanation": "Metadata operations in the cloud services layer allow data sharing without physically copying it. Since the provider account stores and pays for the data storage, the data consumer doesn&#39;t have to pay anything extra for storage. However, the data consumer pays for the compute used to run queries on shared data. When queries are run on shared data, the compute of the data consumer is used.\n  \n https://docs.snowflake.com/en/user-guide/data-sharing-intro#how-does-secure-data-sharing-work"}, "correct_response": ["a"], "section": "Data Sharing", "question_plain": "True or False: When a Snowflake data provider shares data with a data consumer, the data consumer is not charged for any additional storage costs.", "related_lectures": []}, {"_class": "assessment", "id": 70942634, "assessment_type": "multi-select", "prompt": {"question": "Through Snowflake sharing, a data provider can share data with which of the following?\n \n Select all that apply.", "answers": ["Another Snowflake customer", "A non-Snowflake customer", "Multiple Snowflake customers", "One Drive Users", "Google Drive users"], "explanation": "You can share data with multiple consumers: Snowflake customers, non-Snowflake customers, or a mix of both."}, "correct_response": ["a", "b", "c"], "section": "Data Sharing", "question_plain": "Through Snowflake sharing, a data provider can share data with which of the following?\n \n Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70942636, "assessment_type": "multiple-choice", "prompt": {"question": "Which of the following correctly describes a reader account in Snowflake?", "answers": ["A reader account can be used to share data with non-Snowflake users.", "A reader account is required to access external tables.", "A reader account is exclusively used for testing reasons.", "A reader account is used to distribute query costs between departments."], "explanation": "Sharing data with a non-Snowflake user or organization is possible by creating a reader account. This reader account is created by the data provider solely for sharing purposes.\n  \n https://docs.snowflake.com/en/user-guide/data-sharing-reader-create"}, "correct_response": ["a"], "section": "Data Sharing", "question_plain": "Which of the following correctly describes a reader account in Snowflake?", "related_lectures": []}, {"_class": "assessment", "id": 70942638, "assessment_type": "multi-select", "prompt": {"question": "A share can only be created by which of the following? Select all that apply.", "answers": ["A role with CREATE SHARE privileges.", "ACCOUNTADMIN role", "SYSADMIN role", "SECURITYADMIN role"], "explanation": "A share can be created only by the ACCOUNTADMIN role or roles that have been explicitly granted CREATE SHARE privilege.\n  \n https://docs.snowflake.com/en/user-guide/data-sharing-gs"}, "correct_response": ["a", "b"], "section": "Data Sharing", "question_plain": "A share can only be created by which of the following? Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70942640, "assessment_type": "multi-select", "prompt": {"question": "Which of the following can create a new share? Select all that apply.", "answers": ["A user with a role having the CREATE SHARE privileges", "A user with the ACCOUNTADMIN role", "A user with the SECURITY ADMIN role", "A user with the SYSADMIN role"], "explanation": "Only users with ACCOUNTADMIN roles or with CREATE SHARE permission can create a share.\n  \n https://docs.snowflake.com/en/user-guide/data-sharing-gs"}, "correct_response": ["a", "b"], "section": "Data Sharing", "question_plain": "Which of the following can create a new share? Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70942642, "assessment_type": "multi-select", "prompt": {"question": "Which of the following is true regarding Snowflake Marketplace?", "answers": ["The Snowflake Marketplace is an online marketplace where you can purchase and sell datasets.", "Using the Snowflake Marketplace, a customer can import data from outside your company into their Snowflake instance and utilize it to enrich their data.", "Using the Snowflake Marketplace, A customer can bid on different data sets; only the highest bidder can access the data set.", "All data sets on the Snowflake Marketplace are provided for a cost."], "explanation": "Snowflake Marketplace is a marketplace for finding and accessing third-party datasets made accessible by various organizations. These third-party datasets are generally supplied for a fee but are occasionally made accessible for free. There is no bidding, and the data sets are available to everyone (free or for a cost). \n  \n https://other-docs.snowflake.com/en/collaboration/collaboration-marketplace-about.html"}, "correct_response": ["a", "b"], "section": "Data Sharing", "question_plain": "Which of the following is true regarding Snowflake Marketplace?", "related_lectures": []}, {"_class": "assessment", "id": 70942644, "assessment_type": "multiple-choice", "prompt": {"question": "True or False: When setting up replication for cross-cloud or cross-region data sharing, the data provider must replicate data once for each data consumer.", "answers": ["False", "True"], "explanation": "Only one instance of data per cloud or region must be replicated. Once the instance is replicated, more than one consumer can use this data.\n  \n  https://docs.snowflake.com/en/user-guide/secure-data-sharing-across-regions-plaforms\n  \n https://docs.snowflake.com/en/user-guide/secure-data-sharing-across-regions-plaforms#data-sharing-considerations"}, "correct_response": ["a"], "section": "Data Sharing", "question_plain": "True or False: When setting up replication for cross-cloud or cross-region data sharing, the data provider must replicate data once for each data consumer.", "related_lectures": []}, {"_class": "assessment", "id": 70942646, "assessment_type": "multi-select", "prompt": {"question": "Which of the following semi-structured file formats are supported by Snowflake? Select all that apply", "answers": ["AVRO", "ORC", "JSON", "PDF", "YAML"], "explanation": "Snowflake includes built-in support for several semi-structured data formats. Snowflake supports \n JSON\n Avro\n ORC\n Parquet\n XML\n  \n https://docs.snowflake.com/en/user-guide/semistructured-intro.html"}, "correct_response": ["a", "b", "c"], "section": "Data Loading and Unloading", "question_plain": "Which of the following semi-structured file formats are supported by Snowflake? Select all that apply", "related_lectures": []}, {"_class": "assessment", "id": 70942648, "assessment_type": "multiple-choice", "prompt": {"question": "True or False: Snowflake Scripting be used to create stored procedures.", "answers": ["True", "False"], "explanation": "Snowflake scripting is typically used to create stored procedures, but it may also be used to create procedural code outside of a stored procedure.\n  \n https://docs.snowflake.com/en/sql-reference/stored-procedures-snowflake-scripting"}, "correct_response": ["a"], "section": "Extending Snowflake Functionality", "question_plain": "True or False: Snowflake Scripting be used to create stored procedures.", "related_lectures": []}, {"_class": "assessment", "id": 70942650, "assessment_type": "multiple-choice", "prompt": {"question": "True or False: A stored procedure must return a value.", "answers": ["False", "True"], "explanation": "A stored procedure can also return a single value or tabular data if desired; however, it is not a requirement that a stored procedure must return a value.\n  \n  https://docs.snowflake.com/en/developer-guide/stored-procedures-vs-udfs"}, "correct_response": ["a"], "section": "Extending Snowflake Functionality", "question_plain": "True or False: A stored procedure must return a value.", "related_lectures": []}, {"_class": "assessment", "id": 70942652, "assessment_type": "multiple-choice", "prompt": {"question": "<p>Which of the following requirement is NOT a good reason to create a Stored Procedure?</p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "Even though stored procedures and UDFs look similar, they serve different purposes. The job of a UDF is to take in input, perform computations, and return a value, whereas the job of a stored procedure is to execute one or more SQL queries. Thus in the given options calculating the average of two values is best fulfilled by a UDF.\n  \n https://docs.snowflake.com/en/sql-reference/stored-procedures-overview", "answers": ["Calculate the average of two values", "Execute a series of SQL statements to create a new user and a new database for that user.", "Execute a series of SQLs to clean up shared temporary data every day.", "Find and drop tables that have not been used in a long time"]}, "correct_response": ["a"], "section": "Extending Snowflake Functionality", "question_plain": "Which of the following requirement is NOT a good reason to create a Stored Procedure?", "related_lectures": []}, {"_class": "assessment", "id": 70942654, "assessment_type": "multi-select", "prompt": {"question": "Which of the following languages are supported for creating UDFs in Snowflake?", "answers": ["SQL", "Java", "JavaScript", "Python", "C++", "C#"], "explanation": "SQL, Java, JavaScript, and Python can be used to create UDFs in Snowflake.\n  \n https://docs.snowflake.com/en/sql-reference/udf-overview#supported-languages"}, "correct_response": ["a", "b", "c", "d"], "section": "Extending Snowflake Functionality", "question_plain": "Which of the following languages are supported for creating UDFs in Snowflake?", "related_lectures": []}, {"_class": "assessment", "id": 70942656, "assessment_type": "multiple-choice", "prompt": {"question": "True or False: To create and execute a stored procedure, you must have a minimum of Enterprise edition.", "answers": ["False", "True"], "explanation": "All Snowflake editions stored procedures, so the minimum edition required to create and execute a stored procedure is the Standard edition.\n  \n  \n https://docs.snowflake.com/en/user-guide/intro-editions.html"}, "correct_response": ["a"], "section": "Licensing & Features", "question_plain": "True or False: To create and execute a stored procedure, you must have a minimum of Enterprise edition.", "related_lectures": []}, {"_class": "assessment", "id": 70942658, "assessment_type": "multiple-choice", "prompt": {"question": "What is the minimum Snowflake edition required to share data with other Snowflake accounts?", "answers": ["Standard", "Enterprise", "Business Critical", "Virtual Private Snowflake"], "explanation": "Data sharing is supported in all Snowflake editions; thus, the minimum edition that supports it is the Standard edition.\n  \n  \n https://docs.snowflake.com/en/user-guide/intro-editions.html"}, "correct_response": ["a"], "section": "Licensing & Features", "question_plain": "What is the minimum Snowflake edition required to share data with other Snowflake accounts?", "related_lectures": []}, {"_class": "assessment", "id": 70942662, "assessment_type": "multiple-choice", "prompt": {"question": "What is the minimum Snowflake edition that supports private connectivity to Snowflake?", "answers": ["Business Critical", "Enterprise", "Standard", "Virtual Private Snowflake"], "explanation": "Private connectivity enables you to ensure that access to your Snowflake instance is via a secure connection and, potentially, to block internet-based access completely. Private connectivity to Snowflake requires the Business-Critical edition as a minimum."}, "correct_response": ["a"], "section": "Licensing & Features", "question_plain": "What is the minimum Snowflake edition that supports private connectivity to Snowflake?", "related_lectures": []}, {"_class": "assessment", "id": 70942664, "assessment_type": "multiple-choice", "prompt": {"question": "What is the minimum Snowflake edition that supports materialized views?", "answers": ["Enterprise", "Standard", "Business Critical", "Virtual Private Snowflake"], "explanation": "The minimum Snowflake edition that supports Materialized Views is Enterprise. All editions above the enterprise edition also support martialized views.\n  \n https://docs.snowflake.com/en/user-guide/intro-editions.html"}, "correct_response": ["a"], "section": "Licensing & Features", "question_plain": "What is the minimum Snowflake edition that supports materialized views?", "related_lectures": []}, {"_class": "assessment", "id": 70942720, "assessment_type": "multi-select", "prompt": {"question": "In the Snowsight worksheet view, which of the following can be selected to set the context under which a query executes?", "answers": ["Virtual Warehouse", "Database", "Role", "Schema", "Table", "User"], "explanation": "You can choose the primary role under which the query is executed, and the virtual warehouse used to run the query. You can also choose the database and schema to which the worksheet view defaults, so you don&#39;t need to prefix tables in the specified database &amp; schema. \n  \n https://docs.snowflake.com/en/user-guide/ui-snowsight"}, "correct_response": ["a", "b", "c", "d"], "section": "Tools & Interfaces", "question_plain": "In the Snowsight worksheet view, which of the following can be selected to set the context under which a query executes?", "related_lectures": []}, {"_class": "assessment", "id": 70942722, "assessment_type": "multiple-choice", "prompt": {"question": "True or False: After a table has been cloned, dropping the original table will also drop the clone.", "answers": ["False", "True"], "explanation": "Micro-partitions and metadata in the cloud services layer enable rapid and efficient zero-copy cloning because the cloned table&#39;s metadata references the existing micro-partitions.\n The source and cloned items are independent; thus, modifying data in one will not affect the other. For example, the source table can be dropped altogether, which doesn&#39;t affect the cloned table.\n  \n https://docs.snowflake.com/en/user-guide/tables-storage-considerations#label-cloning-tables"}, "correct_response": ["a"], "section": "Cloning", "question_plain": "True or False: After a table has been cloned, dropping the original table will also drop the clone.", "related_lectures": []}, {"_class": "assessment", "id": 70942724, "assessment_type": "multi-select", "prompt": {"question": "Which of the following can be cloned?", "answers": ["Databases", "Schemas", "Tables", "Internal Named Stages"], "explanation": "Named Internal Stages cannot be cloned. When a database or schema is cloned, any Snowpipe that points to a Named Internal Stage is not cloned. \n Named External Stages can be cloned. Since a table stage is associated with a table, it is automatically cloned when the table is cloned.\n Additionally, external tables cannot be cloned either. Databases, Schema, Tables, etc., can be cloned.\n  \n https://docs.snowflake.com/en/user-guide/object-clone#cloning-and-stages"}, "correct_response": ["a", "b", "c"], "section": "Cloning", "question_plain": "Which of the following can be cloned?", "related_lectures": []}, {"_class": "assessment", "id": 70942726, "assessment_type": "multi-select", "prompt": {"question": "When a database or a schema is cloned, which of the following statements are regarding Snowpipes in that database?", "answers": ["Any Snowpipes that reference an internal stage are NOT cloned", "Any Snowpipes that reference an external stage are cloned", "Any Snowpipes that reference an internal stage are cloned", "Any Snowpipes that reference an external stage are NOT cloned"], "explanation": "When a database or schema is cloned, any Snowpipe that points to a Named Internal Stage is not cloned.\n Snowpipe referencing an external stage is cloned.\n  \n https://docs.snowflake.com/en/user-guide/object-clone#cloning-and-pipes"}, "correct_response": ["a", "b"], "section": "Cloning", "question_plain": "When a database or a schema is cloned, which of the following statements are regarding Snowpipes in that database?", "related_lectures": []}, {"_class": "assessment", "id": 70942728, "assessment_type": "multiple-choice", "prompt": {"question": "<p><strong>When cloning a database, your current role must have which privilege (as a minimum) on the source database?</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", ""], "explanation": "To clone a table, you need SELECT privileges on the source table. For cloning Pipes, Streams &amp; Tasks, you require OWNERSHIP privileges; for all other objects that can be cloned, you need the USAGE privilege.\n  \n https://docs.snowflake.com/en/sql-reference/sql/create-clone#general-usage-notes", "answers": ["USAGE", "SELECT", "WRITE"]}, "correct_response": ["a"], "section": "Cloning", "question_plain": "When cloning a database, your current role must have which privilege (as a minimum) on the source database?", "related_lectures": []}, {"_class": "assessment", "id": 70942730, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>Which of the following multi-cluster virtual warehouse configurations indicate a multi-cluster virtual warehouse running in auto-scale mode?</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p>A multi-cluster virtual warehouse can be created in maximized or auto-scaling modes. Auto-Scaling mode is enabled by selecting different values for the multi-minimum clusters and maximum warehouse count. As a result, Snowflake starts and stops warehouses dynamically based on the workload needs.</p><p>The maximized mode is enabled by setting the minimum and maximum warehouse count of the multi-cluster to the same value. Therefore, as soon as the multi-cluster virtual warehouse is established, all warehouses in the multi-cluster are started up.</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/warehouses-multicluster#setting-the-scaling-policy-for-a-multi-cluster-warehouse</p>", "answers": ["<p><strong>MIN_CLUSTER_COUNT = 2</strong></p><p><strong>MAX_CLUSTER_COUNT = 4</strong></p>", "<p><strong>MIN_CLUSTER_COUNT = 1</strong></p><p><strong>MAX_CLUSTER_COUNT = 5</strong></p>", "<p><strong>MIN_CLUSTER_COUNT = 3</strong></p><p><strong>MAX_CLUSTER_COUNT = 3</strong></p>", "<p><strong>MIN_CLUSTER_COUNT = 1</strong></p><p><strong>MAX_CLUSTER_COUNT = 1</strong></p>", "<p><strong>MIN_CLUSTER_COUNT = 0</strong></p><p><strong>MAX_CLUSTER_COUNT = 0</strong></p>"]}, "correct_response": ["a", "b"], "section": "Performance Concepts", "question_plain": "Which of the following multi-cluster virtual warehouse configurations indicate a multi-cluster virtual warehouse running in auto-scale mode?", "related_lectures": []}, {"_class": "assessment", "id": 70942732, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>Consider the CUSTOMER table in the SNOWFLAKE_SAMPLE_DATA.TPCH_SF1 schema. Your virtual warehouse is in a suspended state but is set to auto-resume. Which of the following queries will result in the virtual warehouse being resumed? Select all that apply.</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p>Metadata cache or cloud services operations do not require an active virtual warehouse. Other queries will need an active virtual warehouse.</p><p><br></p><p>Statistics are kept in the metadata cache in the cloud services layer for each table, micro-partition, and column. The metadata cache can return results if the query simply counts the number of rows.</p><p><br></p><p>Similarly, the cloud services layer can provide table definitions (i.e., DESCRIBE) and a list of tables in a schema (i.e., SHOW TABLES LIKE).</p>", "answers": ["<p><strong>SELECT C_MKTSEGMENT,SUM(C_ACCTBAL) FROM SNOWFLAKE_SAMPLE_DATA.TPCH_SF1.CUSTOMER GROUP BY C_MKTSEGMENT;</strong></p>", "<p><strong>SELECT * FROM SNOWFLAKE_SAMPLE_DATA.TPCH_SF1.CUSTOMER;</strong></p>", "<p><strong>SELECT COUNT(*) FROM SNOWFLAKE_SAMPLE_DATA.TPCH_SF1.CUSTOMER;</strong></p>", "<p><strong>USE SNOWFLAKE_SAMPLE_DATA.TPCH_SF1;</strong></p><p><strong>SHOW TABLES LIKE '%CUSTOMER%';</strong></p>", "<p><strong>DESCRIBE TABLE SNOWFLAKE_SAMPLE_DATA.TPCH_SF1;</strong></p>"]}, "correct_response": ["a", "b"], "section": "Architecture", "question_plain": "Consider the CUSTOMER table in the SNOWFLAKE_SAMPLE_DATA.TPCH_SF1 schema. Your virtual warehouse is in a suspended state but is set to auto-resume. Which of the following queries will result in the virtual warehouse being resumed? Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70942734, "assessment_type": "multiple-choice", "prompt": {"question": "<p><strong>Which of the following Snowflake edition doesn't support data sharing?</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>Virtual Private Snowflake (VPS) cannot use secure data sharing, Marketplace, etc., because VPS accounts have isolated metadata, compute, and storage and therefore don't have sharing capabilities.</p>", "answers": ["<p><strong>Virtual Private Snowflake (VPS)</strong></p>", "<p><strong>Standard</strong></p>", "<p><strong>Enterprise</strong></p>", "<p><strong>Business Critical</strong></p>"]}, "correct_response": ["a"], "section": "Data Sharing", "question_plain": "Which of the following Snowflake edition doesn't support data sharing?", "related_lectures": []}, {"_class": "assessment", "id": 70942736, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>Which of the following Snowflake Editions support private connectivity to Snowflake's internal stages?</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>Private connectivity enables you to ensure that access to your Snowflake instance is via a secure connection and, potentially, to block internet-based access completely. Private connectivity to Snowflake requires the Business-Critical edition as a minimum.</p>", "answers": ["<p><strong>Business Critical Edition</strong></p>", "<p><strong>Virtual Private Snowflake (VPS) edition</strong></p>", "<p><strong>Enterprise Edition</strong></p>", "<p><strong>Standard Edition</strong></p>"]}, "correct_response": ["a", "b"], "section": "Licensing & Features", "question_plain": "Which of the following Snowflake Editions support private connectivity to Snowflake's internal stages?", "related_lectures": []}, {"_class": "assessment", "id": 70942738, "assessment_type": "multiple-choice", "prompt": {"question": "<p><strong>Which view type doesn't use some of the internal Snowflake optimizations?</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>For typical views, internal optimizations can indirectly expose data to users.</p><p>Secure views hide the underlying data by removing some of the internal Snowflake optimizations.</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/views-secure</p>", "answers": ["<p><strong>Secure views</strong></p>", "<p><strong>Permanent Views</strong></p>", "<p><strong>External Views</strong></p>", "<p><strong>Materialized Views</strong></p>"]}, "correct_response": ["a"], "section": "Security", "question_plain": "Which view type doesn't use some of the internal Snowflake optimizations?", "related_lectures": []}, {"_class": "assessment", "id": 70942740, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>You are the owner of a table called CUSTOMER. The table is in the PUBLIC schema in the database called MARKETING. Which permissions do you need to provide on which objects to grant SELECT access to a role called ANALYST on the CUSTOMER table?</strong></p><p><img src=\"https://img-b.udemycdn.com/redactor/raw/practice_test_question/2023-08-11_23-23-40-edd71e881442f7623fb427f14196ccca.png\"></p><p><br></p><p><strong>Select all that apply.</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", "", "", ""], "explanation": "<p>SELECT privilege on the table is required for the ANALYST role to read data from the table. However, users (in the ANALYST role) cannot run their queries if the ANALYST role doesn\u2019t have the privileges to use the schema and the database containing the table. The USAGE privilege allows users to run the USE DATABASE or USE SCHEMA command or access the table using the full namespace i.e. MARKETING.PUBLIC.CUSTOMER. </p><p>Therefore, USAGE privileges on both database and the schema are required.</p>", "answers": ["<p><strong>grant USAGE on database MARKETING to role ANALYST;</strong></p>", "<p><strong>grant USAGE on schema PUBLIC to role ANALYST;</strong></p>", "<p><strong>grant SELECT on table CUSTOMER to role ANALYST;</strong></p>", "<p><strong>grant SELECT on schema PUBLIC to role ANALYST;</strong></p>", "<p><strong>grant READ on schema PUBLIC to role ANALYST;</strong></p>", "<p><strong>grant SELECT on database MARKETING to role ANALYST;</strong></p>"]}, "correct_response": ["a", "b", "c"], "section": "Security", "question_plain": "You are the owner of a table called CUSTOMER. The table is in the PUBLIC schema in the database called MARKETING. Which permissions do you need to provide on which objects to grant SELECT access to a role called ANALYST on the CUSTOMER table?Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70942742, "assessment_type": "multiple-choice", "prompt": {"question": "<p><strong>SQL Workbench, DBeaver &amp; Erwin are what type of partners in the Snowflake partner ecosystem?</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>All of these are SQL Development and Management partners of Snowflake. Please see https://docs.Snowflake.com/en/user-guide/ecosystem.html</p>", "answers": ["<p><strong>SQL Development and Management</strong></p>", "<p><strong>Data Integration</strong></p>", "<p><strong>Machine Learning &amp; Data Science</strong></p>", "<p><strong>Security, Governance &amp; Observability</strong></p>"]}, "correct_response": ["a"], "section": "Partners", "question_plain": "SQL Workbench, DBeaver &amp; Erwin are what type of partners in the Snowflake partner ecosystem?", "related_lectures": []}, {"_class": "assessment", "id": 70942744, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>What of the following is true about the objects created by Partner Connect during the process of connecting to a partner?</strong></p><p><br></p><p><strong>Select all that apply.</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p>The PC_&lt;partner&gt;_DB is created empty. However, you can configure it to use an existing database if required.</p><p><br></p><p>The PC_&lt;partner&gt;_ROLE inherits the PUBLIC role privileges. You can grant additional privileges to this role to allow the partner application to access objects in your system. This role is also granted to SYSADMIN to ensure that SYSADMINs can access the objects and data created by the partner application.</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/ecosystem-partner-connect#connecting-with-a-snowflake-partner</p>", "answers": ["<p><strong>The PC_&lt;partner&gt;_DB database is empty and can be used to load or store data for querying.</strong></p>", "<p><strong>The partner uses the PC_&lt;partner&gt;_USER to connect to your Snowflake instance.</strong></p>", "<p><strong>The PC_&lt;partner&gt;_ROLE allows the partner application to access objects granted to the PUBLIC role.</strong></p>", "<p><strong>The PC_&lt;partner&gt;_DB database is only created if there is no other database in your system.</strong></p>", "<p><strong>The PC_&lt;partner&gt;_WH virtual warehouse is only created if there is no other virtual warehouse in your system.</strong></p>"]}, "correct_response": ["a", "b", "c"], "section": "Partners", "question_plain": "What of the following is true about the objects created by Partner Connect during the process of connecting to a partner?Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70942746, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>Which of the following statements are true regarding Reader Accounts in Snowflake?</strong></p><p><strong>Select all that apply.</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>Reader accounts do not have a Snowflake licensing agreement, so it does not have access to support. Instead, the provider account (that created the reader account) manages the support requests.</p><p>Only data from the provider account that created the reader account can be consumed by the reader account.</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/data-sharing-reader-create</p>", "answers": ["<p><strong>A reader account can only access data shared by the provider account that created the reader account.</strong></p>", "<p><strong>Any support requests for the reader account must be raised through the provider account.</strong></p>", "<p><strong>A single reader account can access data shared by different providers.</strong></p>", "<p><strong>A reader account can raise support requests.</strong></p>"]}, "correct_response": ["a", "b"], "section": "Data Sharing", "question_plain": "Which of the following statements are true regarding Reader Accounts in Snowflake?Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70942748, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>Which of the following statements are true regarding scaling up / down and scaling out virtual warehouses?</strong></p><p><strong>Select all that apply.</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>Multi-cluster virtual warehouses dynamically (and automatically) add additional clusters based on demand to solve the queueing issue. When demand decreases, the additional clusters are decommissioned. This process is also known as scaling out (and scaling back) or auto-scaling.</p><p><br></p><p>Scaling up and down is a manual process, requiring someone to run a statement to increase or decrease the size of the virtual warehouse.</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/warehouses-multicluster</p>", "answers": ["<p><strong>Scaling up &amp; scaling down a virtual warehouse is a manual process.</strong></p>", "<p><strong>Scaling out &amp; scaling back a virtual warehouse is performed automatically by Snowflake.</strong></p>", "<p><strong>Scaling out &amp; scaling back a virtual warehouse is a manual process.</strong></p>", "<p><strong>Scaling up &amp; scaling down is managed automatically by Snowflake.</strong></p>"]}, "correct_response": ["a", "b"], "section": "Performance Concepts", "question_plain": "Which of the following statements are true regarding scaling up / down and scaling out virtual warehouses?Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70942750, "assessment_type": "multiple-choice", "prompt": {"question": "<p><strong>For a multi-cluster virtual warehouse, what is the maximum number of clusters?</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>A multi-cluster virtual warehouse supports anywhere from one and ten different clusters simultaneously. The minimum number of clusters supported is one, and the maximum number of allowed clusters is ten.</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/warehouses-multicluster#what-is-a-multi-cluster-warehouse</p>", "answers": ["<p><strong>10</strong></p>", "<p><strong>1</strong></p>", "<p><strong>50</strong></p>", "<p><strong>24</strong></p>"]}, "correct_response": ["a"], "section": "Performance Concepts", "question_plain": "For a multi-cluster virtual warehouse, what is the maximum number of clusters?", "related_lectures": []}, {"_class": "assessment", "id": 70942752, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>Which of the following scenario requires you to have replication configured to recover?</strong></p><p><strong>Select all that apply.</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p>If a cloud provider or a region goes down, Snowflake users may be affected. To ensure the least impact, you must be ready for cloud provider outages to keep Snowflake available to your users.</p><p><br></p><p>Snowflake account-level replication &amp; database replication synchronizes critical account objects and data from the primary account to one or more secondary accounts in a different region or cloud platform. Database replication allows read-only copies of databases from a primary Snowflake account to a new region or cloud provider. In the event of a failure on the primary site, switch your workloads from the primary to one of the secondary locations.</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/account-replication-intro</p>", "answers": ["<p><strong>The cloud region hosting your primary Snowflake instance has gone down due to a catastrophic failure, and data is unavailable.</strong></p>", "<p><strong>The cloud platform hosting your primary Snowflake instance failed and has become unavailable.</strong></p>", "<p><strong>A data corruption issue that corrupted three production tables 93 days ago was discovered.</strong></p>", "<p><strong>An administrator accidentally dropped a production table last week.</strong></p>", "<p><strong>A new data pipeline rolled out in production yesterday has deleted all rows from a production table.</strong></p>"]}, "correct_response": ["a", "b"], "section": "Data Protection", "question_plain": "Which of the following scenario requires you to have replication configured to recover?Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70942754, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>Why is Snowflake considered a SaaS (Software-as-a-Service) product?</strong></p><p><strong>Select all that apply.</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>All of these are characteristics of a Software-as-a-Service product.</p>", "answers": ["<p><strong>Snowflake regularly updates the software, and all accounts receive these updates automatically, eliminating the need for manual installations, maintenance, and patches.</strong></p>", "<p><strong>The customer is not required to procure, install and manage any hardware.</strong></p>", "<p><strong>Snowflake runs in the cloud and is available over the Internet.</strong></p>", "<p><strong>It provides Pay as you Go licensing, allowing users to pay only for the resources and features they use.</strong></p>"]}, "correct_response": ["a", "b", "c", "d"], "section": "Licensing & Features", "question_plain": "Why is Snowflake considered a SaaS (Software-as-a-Service) product?Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70942756, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>Which of the following contributes towards the storage costs in Snowflake?</strong></p><p><strong>Select all that apply.</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p>Data stored in permanent tables counts towards the storage costs.</p><p>Data stored in temporary &amp; transient tables also contribute towards the storage costs until they are dropped or data is cleared.</p><p><br></p><p>Data in Fail-safe storage and Time Travel storage also contribute to the storage costs.</p><p><br>Transient and temporary tables, however, do not contribute towards Fail-safe storage costs and have a maximum of 1-day Time Travel costs.</p><p><br></p><p>Caching is NOT considered for determining storage costs. The query result cache &amp; metadata cache are part of the cloud services layer.</p><p><br></p><p>The warehouse cache (local disk cache) is part of a virtual warehouse and does NOT contribute to storage costs.</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/cost-understanding-overall</p>", "answers": ["<p><strong>Permanent Tables</strong></p>", "<p><strong>Transient Tables</strong></p>", "<p><strong>Temporary Tables</strong></p>", "<p><strong>Query Result Cache</strong></p>", "<p><strong>Warehouse Cache</strong></p>"]}, "correct_response": ["a", "b", "c"], "section": "Cost & Pricing", "question_plain": "Which of the following contributes towards the storage costs in Snowflake?Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70942666, "assessment_type": "multiple-choice", "prompt": {"question": "Query Result Cache reuse can be turned off using which parameter?", "answers": ["USE_CACHED_RESULT", "PURGE_CACHED_RESULTS", "DISABLE_QUERY_RESULT_CACHE", "ENABLE_QUERY_RESULT_CACHE"], "explanation": "Query result cache is enabled by default but can be turned off at a session, user, or account level using the USE_CACHED_RESULT parameter.\n  \n https://docs.snowflake.com/en/user-guide/querying-persisted-results"}, "correct_response": ["a"], "section": "Performance Concepts", "question_plain": "Query Result Cache reuse can be turned off using which parameter?", "related_lectures": []}, {"_class": "assessment", "id": 70942668, "assessment_type": "multiple-choice", "prompt": {"question": "A user ran a complex query that took 2 hours to complete on a medium size virtual warehouse. The user re-ran the query 6 hours later in a new session. The query returned results almost immediately. What is the reason for this quick execution?", "answers": ["The results were returned immediately by using the query result cache.", "Data in the underlying tables has been deleted. The query ran fast because it had nothing to process.", "The results were retrieved from the user stage; therefore, the execution was fast.", "The results were retrieved from the browser cache."], "explanation": "When Snowflake runs a query, it caches the results of that query for a predetermined amount of time. The stored query results are referred to as the Query Result Cache. The Query Result Cache can be used to fulfill future queries if they are similar to a previously executed query &amp; there have been no changes to the data in the tables being queried.\n  \n When Snowflake returns query results using a query result cache, the procedure is exceptionally quick since it does not include the actual execution of the query. Because the query is not being executed, there is no need for any virtual warehouses, reducing computing costs. \n  \n  \n https://docs.snowflake.com/en/user-guide/querying-persisted-results"}, "correct_response": ["a"], "section": "Performance Concepts", "question_plain": "A user ran a complex query that took 2 hours to complete on a medium size virtual warehouse. The user re-ran the query 6 hours later in a new session. The query returned results almost immediately. What is the reason for this quick execution?", "related_lectures": []}, {"_class": "assessment", "id": 70942670, "assessment_type": "multiple-choice", "prompt": {"question": "Which of the following is a way to improve query performance in Snowflake?", "answers": ["Clustering Keys", "Join Indices", "Secondary Indices", "Query Hints"], "explanation": "Clustering a table on a specific column can optimize queries by eliminating unnecessary partitions from the query processing. A table can be re-clustered by defining a clustering key, which effectively redistributes the data into micro-partitions according to the clustering key, ensuring optimal access to queries that predicate or join on the clustered column\n  \n https://docs.snowflake.com/en/user-guide/tables-clustering-keys"}, "correct_response": ["a"], "section": "Performance Concepts", "question_plain": "Which of the following is a way to improve query performance in Snowflake?", "related_lectures": []}, {"_class": "assessment", "id": 70942672, "assessment_type": "multi-select", "prompt": {"question": "As the database administrator, you defined new clustering keys for a large table. So, while Snowflake re-clusters data, what should you expect? Select all that apply.", "answers": ["SELECT queries continue to execute as normal while Snowflake redistributes data in micro-partitions.", "DML queries continue to execute as normal while Snowflake redistributes data in micro-partitions.", "SELECT queries are blocked from execution while Snowflake redistributes data in micro-partitions.", "DML queries are disallowed while Snowflake redistributes data in micro-partitions."], "explanation": "Snowflake&#39;s re-clustering operation is transparent to the user and does not block any DML or SELECT queries. A table that is being re-clustered will behave exactly like any other table when being queried, updated, or changed.\n  \n https://docs.snowflake.com/en/user-guide/tables-auto-reclustering#non-blocking-dml"}, "correct_response": ["a", "b"], "section": "Performance Concepts", "question_plain": "As the database administrator, you defined new clustering keys for a large table. So, while Snowflake re-clusters data, what should you expect? Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70942674, "assessment_type": "multiple-choice", "prompt": {"question": "For an unpopulated table, the clustering depth is ________?", "answers": ["Zero", "1", "-1", "1000"], "explanation": "For a populated table, the clustering depth is the average depth of overlapping micro-partitions for specific columns. The clustering depth starts at 1 (for a well-clustered table) and can be a larger number. For an unpopulated table, the clustering depth is zero.\n  \n https://docs.snowflake.com/en/user-guide/tables-clustering-micropartitions#label-clustering-depth"}, "correct_response": ["a"], "section": "Performance Concepts", "question_plain": "For an unpopulated table, the clustering depth is ________?", "related_lectures": []}, {"_class": "assessment", "id": 70942676, "assessment_type": "multiple-choice", "prompt": {"question": "True or False: Snowflake recommends a maximum of 3 or 4 columns in a clustering key.", "answers": ["True", "False"], "explanation": "Snowflake recommends using a maximum of 3 or 4 columns in a clustering key. Any more columns in the clustering key result in more maintenance costs and do not provide enough benefits to justify the clustering costs.\n  \n https://docs.snowflake.com/en/user-guide/tables-clustering-keys"}, "correct_response": ["a"], "section": "Performance Concepts", "question_plain": "True or False: Snowflake recommends a maximum of 3 or 4 columns in a clustering key.", "related_lectures": []}, {"_class": "assessment", "id": 70942678, "assessment_type": "multi-select", "prompt": {"question": "Which of the following aspects should you consider when defining a clustering key for a large table?", "answers": ["Cluster columns that are used frequently in WHERE clauses", "Cluster columns that are frequently used in join statements", "Cluster all numeric columns", "Cluster all character columns"], "explanation": "When defining clustering keys, the initial candidate clustering columns are those columns that are frequently used in the WHERE clause or other selective filters. \n  \n Additionally, columns that are used for joining can also be considered.\n  \n Furthermore, the columns&#39; cardinality (number of distinct values) is also important. It is crucial to choose a column with a high enough cardinality to allow effective partition pruning while having a low enough cardinality for Snowflake to group data into micro-partitions efficiently. A column with too few distinct values (e.g., gender) will result in minimal partition pruning. On the other hand, a column that has too many distinct values (e.g., customer id) will result in too much overhead when maintaining the partitions.\n  \n When creating a multi-column cluster key, order the columns from the lowest cardinality to the higher cardinality; otherwise, the effectiveness of clustering will be reduced.\n  \n https://docs.snowflake.com/en/user-guide/tables-clustering-keys"}, "correct_response": ["a", "b"], "section": "Performance Concepts", "question_plain": "Which of the following aspects should you consider when defining a clustering key for a large table?", "related_lectures": []}, {"_class": "assessment", "id": 70942680, "assessment_type": "multi-select", "prompt": {"question": "Which of the following correctly describes a materialized view? Select all that apply.", "answers": ["A materialized view is automatically updated if the data in the underlying table is changed.", "A Snowflake-managed service keeps a materialized view in sync with the base table.", "A materialized view must be manually updated if the underlying table&#39;s data is changed.", "An active virtual warehouse is required to sync a materialized view with its base table."], "explanation": "A materialized view is a view that pre-computes data based on a SELECT query. The query&#39;s results are pre-computed and physically stored to enhance performance for similar queries that are executed in the future. When the underlying table is updated, the materialized view refreshes automatically, requiring no additional maintenance. Snowflake-managed services perform the update in the background transparent to the user without interfering with the user&#39;s experience.\n  \n https://docs.snowflake.com/en/user-guide/views-materialized"}, "correct_response": ["a", "b"], "section": "Performance Concepts", "question_plain": "Which of the following correctly describes a materialized view? Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70942682, "assessment_type": "multi-select", "prompt": {"question": "Which of the following sentences accurately describes scaling out in Snowflake? Choose all that apply.", "answers": ["Scaling out is accomplished through the usage of multi-cluster virtual warehouses.", "Scaling out can assist in reducing query queuing.", "Scaling out is accomplished by increasing or decreasing the size of a virtual warehouse."], "explanation": "Typically, a virtual warehouse has a defined set of computing resources that it can use to execute queries. When queries are sent to a warehouse, the warehouse allocates the resources required for each query and begins running the queries. If there aren&#39;t enough resources to run all the queries sent to the warehouse, Snowflake queues the extra queries until the resources are available again. Snowflake provides multi-cluster virtual warehouses to overcome this issue. \n  \n Multi-cluster virtual warehouses are frequently used in scenarios where the number of concurrent queries exceeds the capacity of a single virtual warehouse. When a virtual warehouse&#39;s concurrent workload exceeds its maximum capacity, additional queries are placed in the queue. Multi-cluster virtual warehouses dynamically add additional clusters based on demand to solve the queueing issue. When demand decreases, the additional clusters are decommissioned. This process is also known as scaling out or auto-scaling."}, "correct_response": ["a", "b"], "section": "Performance Concepts", "question_plain": "Which of the following sentences accurately describes scaling out in Snowflake? Choose all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70942684, "assessment_type": "multiple-choice", "prompt": {"question": "Suppose a multi-cluster virtual warehouse is configured with a minimum cluster count of 1\n and maximum cluster count of 3.\n  \n Is the virtual warehouse in Maximized mode?", "answers": ["No", "Yes"], "explanation": "A multi-cluster virtual warehouse can be created in maximized or auto-scaling modes. The maximized mode is enabled by setting the minimum and maximum warehouse count of the multi-cluster to the same value. Therefore, as soon as the multi-cluster virtual warehouse is established, all warehouses in the multi-cluster are started up. Auto-Scaling mode is enabled by selecting different values for the multi-minimum clusters and maximum warehouse count. As a result, Snowflake starts and stops warehouses dynamically based on the workload needs.\n  \n https://docs.snowflake.com/en/user-guide/warehouses-multicluster#setting-the-scaling-policy-for-a-multi-cluster-warehouse"}, "correct_response": ["a"], "section": "Performance Concepts", "question_plain": "Suppose a multi-cluster virtual warehouse is configured with a minimum cluster count of 1\n and maximum cluster count of 3.\n  \n Is the virtual warehouse in Maximized mode?", "related_lectures": []}, {"_class": "assessment", "id": 70942686, "assessment_type": "multiple-choice", "prompt": {"question": "How does defining a clustering key help with improving query performance?", "answers": ["Optimal partition pruning occurs if the queries use predicates on columns that are part of the clustering key", "Defining clustering keys results in Snowflake pre-computing query results.", "Snowflake distributes data on different compute clusters when clustering keys are defined"], "explanation": "Clustering a table on a specific column can optimize queries by eliminating unnecessary partitions from the query processing. A table can be re-clustered by defining a clustering key, which effectively redistributes the data into micro-partitions according to the clustering key, ensuring optimal access to queries that predicate or join on the clustered column\n  \n  \n https://docs.snowflake.com/en/user-guide/tables-clustering-keys"}, "correct_response": ["a"], "section": "Performance Concepts", "question_plain": "How does defining a clustering key help with improving query performance?", "related_lectures": []}, {"_class": "assessment", "id": 70942688, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>Consider the following snippet from the query profile of a finished query. </strong></p><p><br></p><img src=\"https://img-b.udemycdn.com/redactor/raw/practice_test_question/2023-03-29_20-48-22-0f9590a84e39378dedb152ab21ac74bf.png\"><p><strong>Which of the following accurately describes the highlighted statistics?</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "Partition pruning occurs when the number of Partitions scanned is much smaller than Partitions total.\n  \n Snowflake saves data on the warehouse&#39;s local disk if it can&#39;t fit an operation into memory. Data spilling slows down queries because it requires more IO operations, and disk access is slower than memory access\n  \n https://docs.snowflake.com/en/user-guide/ui-query-profile", "answers": ["The query profile indicates effective partition pruning.", "The query profile indicates that the virtual warehouse used is too small for the query.", "The query profile indicates that the virtual warehouse cache was used.", "The query profile indicates ineffective partition pruning."]}, "correct_response": ["a", "b"], "section": "Performance Concepts", "question_plain": "Consider the following snippet from the query profile of a finished query. Which of the following accurately describes the highlighted statistics?", "related_lectures": []}, {"_class": "assessment", "id": 70942690, "assessment_type": "multi-select", "prompt": {"question": "Which of the following is true regarding Query Profile? Select all that apply.", "answers": ["It shows the query plan for a query.", "It shows a graphical representation of all steps.", "A query profile is available for all queries, whether running, completed, or failed.", "A query profile is not available for queries that have not been completed."], "explanation": "Query Profile provides query execution details. It displays a graphical representation of the main components of the processing plan for the specified query, as well as statistics for each component and overall query information and statistics.\n  \n Query Profile is available for all queries, whether running, completed, or failed.\n  \n Query Profile is a valuable tool for learning how queries work. It can be used if you want or need to know more about how a query executes. It is designed to assist you in identifying typical errors in SQL query expressions so that you may identify potential performance bottlenecks and devise strategies to improve. \n  \n https://docs.snowflake.com/en/user-guide/ui-query-profile"}, "correct_response": ["a", "b", "c"], "section": "Performance Concepts", "question_plain": "Which of the following is true regarding Query Profile? Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70942692, "assessment_type": "multiple-choice", "prompt": {"question": "Which of the following best describes \u201cBytes spilled to local storage\u201d shown in a query profile?", "answers": ["\u201cBytes spilled to local storage\u201d indicates the volume of data that couldn\u2019t fit in memory and had to be spilled to a virtual warehouse temporary storage.", "\u201cBytes spilled to local storage\u201d indicates the amount of data downloaded using the GET command.", "\u201cBytes spilled to local storage\u201d indicates the amount of data downloaded using Snowsight.", "\u201cBytes spilled to local storage\u201d is the number of micro-partitions pruned during query execution."], "explanation": "Snowflake saves data on the warehouse&#39;s local disk if it can&#39;t fit an operation into memory. Data spilling slows down queries because it requires more IO operations, and disk access is slower than memory access. &quot;Bytes spilled to local storage.&quot; indicates local spillage.\n  \n Snowflake will spill data to remote cloud storage if the local disk becomes full, which is even slower storage than the local disk, making this operation even slower. &quot;Bytes spilled to remote storage&quot; in the query profile indicates remote spillage.\n  \n https://docs.snowflake.com/en/user-guide/ui-query-profile#queries-too-large-to-fit-in-memory"}, "correct_response": ["a"], "section": "Performance Concepts", "question_plain": "Which of the following best describes \u201cBytes spilled to local storage\u201d shown in a query profile?", "related_lectures": []}, {"_class": "assessment", "id": 70942694, "assessment_type": "multiple-choice", "prompt": {"question": "True or False: You can increase or decrease the size of a virtual warehouse as required.", "answers": ["True", "False"], "explanation": "A virtual warehouse can be scaled up to ensure satisfactory performance when the complexity of the queries has increased. Scaling up allows the virtual warehouse to expand in size to keep up with the increasing complexity of the tasks. When a virtual warehouse is scaled up, the number of nodes in the compute cluster increases.\n Scaling down a virtual warehouse is generally done in response to decreased query complexity, where a smaller virtual warehouse may be sufficient to meet the performance requirements. \n  \n When a virtual warehouse is scaled down, nodes are removed from the virtual warehouse.\n  \n https://docs.snowflake.com/en/user-guide/warehouses-considerations"}, "correct_response": ["a"], "section": "Performance Concepts", "question_plain": "True or False: You can increase or decrease the size of a virtual warehouse as required.", "related_lectures": []}, {"_class": "assessment", "id": 70942696, "assessment_type": "multi-select", "prompt": {"question": "Which of the following is true when a virtual warehouse is scaled up to a larger size? Select all that apply.", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "When a virtual warehouse is scaled up, the charging for the new size does not begin until all the new nodes in the larger virtual warehouse have been provisioned.\n  \n Only new queries are affected by the changed size; existing queries on the virtual warehouse remain unaffected. \n  \n https://docs.snowflake.com/en/user-guide/warehouses-", "answers": ["The charging for the new size is not started until all new nodes in the larger virtual warehouse are provisioned.", "The increased size does not affect any queries already executing on the virtual warehouse.", "<p><strong>Only new queries benefit from the larger virtual warehouse size.</strong></p>", "The virtual warehouse cannot be scaled down to a smaller size.", "All existing queries are terminated and must be re-submitted."]}, "correct_response": ["a", "b", "c"], "section": "Performance Concepts", "question_plain": "Which of the following is true when a virtual warehouse is scaled up to a larger size? Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70942698, "assessment_type": "multi-select", "prompt": {"question": "Multi-factor authentication can be enabled for which of the following? Select all that apply.", "answers": ["Snowflake WebUI", "ODBC", "Python", "Snowpipe"], "explanation": "MFA is enabled by default for all Snowflake accounts and is available in all Snowflake editions. All Snowflake client tools, including the web interface, SnowSQL, and the various connectors and drivers, support MFA.\n  \n Snowpipe is a snowflake-managed serverless service. A Snowflake user can not log into it; therefore, it doesn&#39;t require MFA.\n  \n https://docs.snowflake.com/en/user-guide/security-mfa"}, "correct_response": ["a", "b", "c"], "section": "Security", "question_plain": "Multi-factor authentication can be enabled for which of the following? Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70942700, "assessment_type": "multi-select", "prompt": {"question": "Snowflake supports which of the following authentication mechanisms? Select all that apply", "answers": ["Multi-factor authentication", "Key Pair Authentication", "Plain Text Password authentication", "MD5 authentication"], "explanation": "Multi-factor authentication adds additional protection to the login process in Snowflake.\n  \n Snowflake provides key pair authentication as a more secure alternative to the traditional username/password authentication approach.\n Additionally, Snowflake offers federated authentication, enabling users to access their accounts via a single sign-on (SSO). Users authenticate using SAML 2.0-compliant single sign-on (SSO) via an external identity provider (IdP)."}, "correct_response": ["a", "b"], "section": "Security", "question_plain": "Snowflake supports which of the following authentication mechanisms? Select all that apply", "related_lectures": []}, {"_class": "assessment", "id": 70942702, "assessment_type": "multi-select", "prompt": {"question": "You are required to implement column-level security in Snowflake. Which techniques can you use? Select two.", "answers": ["Dynamic Data Masking", "External Tokenization", "Row-level security", "Object Security"], "explanation": "Snowflake supports masking policies that may be applied to columns and enforced at the column level to provide column-level security. Column-level security is achieved by dynamic data masking or external Tokenization.\n  \n https://docs.snowflake.com/en/user-guide/security-column"}, "correct_response": ["a", "b"], "section": "Security", "question_plain": "You are required to implement column-level security in Snowflake. Which techniques can you use? Select two.", "related_lectures": []}, {"_class": "assessment", "id": 70942704, "assessment_type": "multi-select", "prompt": {"question": "Your organization&#39;s security policies require that certain rows in tables are unavailable to users for querying. Which of the following Snowflake features can you use to meet these requirements? Select two.", "answers": ["Secure Views", "Row Access Policies", "External Views", "Column Level Security"], "explanation": "Secure views can be used to return only certain rows from a table. Additionally, secure views hide the underlying data by removing some of the internal Snowflake optimizations.\n  \n Alternatively, Row-level security (RLS) can be used to return only certain rows. RLS is implemented by creating row access policies, which include conditions and functions that govern which rows are returned during query execution.\n  \n https://docs.snowflake.com/en/user-guide/views-secure\n  \n https://docs.snowflake.com/en/user-guide/security-row-intro"}, "correct_response": ["a", "b"], "section": "Security", "question_plain": "Your organization&#39;s security policies require that certain rows in tables are unavailable to users for querying. Which of the following Snowflake features can you use to meet these requirements? Select two.", "related_lectures": []}, {"_class": "assessment", "id": 70942706, "assessment_type": "multi-select", "prompt": {"question": "Which of the following keys are combined in Tri-Secret Secure encryption? Choose two.", "answers": ["Snowflake-managed", "Customer-managed", "Public key", "Hash key"], "explanation": "Tri-Secret Secure refers to the combination of a Snowflake-managed key and a customer-managed key, which results in the creation of a composite master key to protect your data. Tri-Secret Secure requires the Business Critical edition as a minimum and can be activated by contacting Snowflake support.\n  \n https://docs.snowflake.com/en/user-guide/security-encryption-manage"}, "correct_response": ["a", "b"], "section": "Security", "question_plain": "Which of the following keys are combined in Tri-Secret Secure encryption? Choose two.", "related_lectures": []}, {"_class": "assessment", "id": 70942708, "assessment_type": "multiple-choice", "prompt": {"question": "True or False: Network policies can be used to allow or deny access to specific IP addresses.", "answers": ["True", "False"], "explanation": "Administrators can configure the system to allow or deny access to specific IP addresses through network policies. A network policy consists of the policy name, a comma-separated list of allowed IP addresses, and a list of blocked IP addresses\n  \n https://docs.snowflake.com/en/user-guide/network-policies"}, "correct_response": ["a"], "section": "Security", "question_plain": "True or False: Network policies can be used to allow or deny access to specific IP addresses.", "related_lectures": []}, {"_class": "assessment", "id": 70942710, "assessment_type": "multi-select", "prompt": {"question": "Which of the following statements is true regarding the PUBLIC role? Select all that apply.", "answers": ["The PUBLIC role is automatically assigned to every user in Snowflake.", "The PUBLIC role is the least privileged role in a Snowflake system.", "The PUBLIC role is the most privileged role in a Snowflake system.", "The PUBLIC role is not pre-defined and must be created by an account administrator."], "explanation": "The PUBLIC role is one of the out-of-the-box roles in Snowflake. The PUBLIC role has the fewest privileges and is assigned automatically to all users.\n  \n https://docs.snowflake.com/en/user-guide/security-access-control-overview#system-defined-roles."}, "correct_response": ["a", "b"], "section": "Security", "question_plain": "Which of the following statements is true regarding the PUBLIC role? Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70942712, "assessment_type": "multi-select", "prompt": {"question": "Which of the following is true regarding privileges and roles in Snowflake? Select all that apply", "answers": ["Privileges can be assigned to roles.", "Roles can be assigned to users.", "Privileges can be assigned to users directly.", "New custom roles cannot be created."], "explanation": "Snowflake&#39;s access control is built on the role-based access control (RBAC) approach, which assigns rights to roles and roles to users. The privileges given to a role are inherited by all users in that role. \n  \n https://docs.snowflake.com/en/user-guide/security-access-control-overview"}, "correct_response": ["a", "b"], "section": "Security", "question_plain": "Which of the following is true regarding privileges and roles in Snowflake? Select all that apply", "related_lectures": []}, {"_class": "assessment", "id": 70942714, "assessment_type": "multi-select", "prompt": {"question": "Snowflake allows which of the following access control methods? Select all that apply.", "answers": ["Role-based access control (RBAC)", "Discretionary access control (DAC)", "Management access control (MAC)", "Global access control (GAC)"], "explanation": "Snowflake&#39;s access control system is built on the RBAC idea, which means that privileges are issued to roles and roles to users. The privileges associated with a role are given to all users assigned to it. Snowflake also supports discretionary access control (DAC), which means that the role that created an object owns it and can provide access to other roles to that item.\n  \n https://docs.snowflake.com/en/user-guide/security-access-control-overview"}, "correct_response": ["a", "b"], "section": "Security", "question_plain": "Snowflake allows which of the following access control methods? Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70942716, "assessment_type": "multi-select", "prompt": {"question": "Which of the following contributes toward the storage costs in a Snowflake system?", "answers": ["Permanent tables", "Transient tables", "Temporary Tables", "External tables"], "explanation": "External tables do not contribute towards storage costs because the data for External tables are stored outside of Snowflake on cloud storage. However, permanent, temporary, and transient tables contribute to varying storage costs.\n  \n https://docs.snowflake.com/en/user-guide/cost-understanding-data-storage#temporary-and-transient-tables-costs"}, "correct_response": ["a", "b", "c"], "section": "Cost & Pricing", "question_plain": "Which of the following contributes toward the storage costs in a Snowflake system?", "related_lectures": []}, {"_class": "assessment", "id": 70942718, "assessment_type": "multi-select", "prompt": {"question": "Which statements are true regarding Worksheets in Snowsight?", "answers": ["You can set a different context (role, warehouse, schema, and database) for each worksheet.", "Each worksheet acts as a different session.", "You can not change the context (role, warehouse, schema, and database) for any worksheet.", "All worksheets share the same session."], "explanation": "In the worksheet view, you can choose the primary role under which the query is executed, and the virtual warehouse used to run the query. You can also choose the database and schema to which the worksheet view defaults, so you don&#39;t need to prefix tables in the specified database &amp; schema. Each worksheet is an independent session.\n  \n https://docs.snowflake.com/en/user-guide/ui-snowsight"}, "correct_response": ["a", "b"], "section": "Tools & Interfaces", "question_plain": "Which statements are true regarding Worksheets in Snowsight?", "related_lectures": []}, {"_class": "assessment", "id": 70942758, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>Which of the following terms refers to the same layer in Snowflake architecture? Select all that apply.</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>The terms Cloud Services Layer or Services Layer are used interchangeably.</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/intro-key-concepts#cloud-services</p>", "answers": ["<p><strong>Cloud Services Layer</strong></p>", "<p><strong>Services Layer</strong></p>", "<p><strong>Virtual Warehouses</strong></p>", "<p><strong>Storage Layer</strong></p>"]}, "correct_response": ["a", "b"], "section": "Architecture", "question_plain": "Which of the following terms refers to the same layer in Snowflake architecture? Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70942760, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>Which of the following activities are not required to be performed by a Snowflake customer?</strong></p><p><strong>Select all that apply.</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p>Snowflake, a software-as-a-service product, doesn't require a customer to manage the data center and its physical security, hardware install hardware or software or manage high availability.</p>", "answers": ["<p><strong>Provision hardware for installing the Snowflake database</strong></p>", "<p><strong>Installation of Snowflake database Software</strong></p>", "<p><strong>Configuration and Testing of High availability of hardware at the data center level</strong></p>", "<p><strong>Ensure the physical security of a data center.</strong></p>", "<p><strong>Management of user access &amp; privileges</strong></p>"]}, "correct_response": ["a", "b", "c", "d"], "section": "Licensing & Features", "question_plain": "Which of the following activities are not required to be performed by a Snowflake customer?Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70942762, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>Which columns will be part of the result set when a directory table is queried?</strong></p><p><strong>Select all that apply.</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p>When a directory table is queried, the result set contains the FILE_URL for each file in the stage object. The result set also contains additional metadata, such as the file's relative path, which shows the file's path relative to the stage. The result set also has metadata such as the size of the file in bytes and the timestamp of when a file was last modified, the MD5 checksum for the file, and an ETAG file, which changes if the contents of the file change. When querying a directory table, you can filter the result set using the WHERE clause on any of these fields. For example, you can use the size column to limit your results to only those files that are greater than 10MB.</p><p><br></p><p><br></p><p>https://docs.snowflake.com/en/user-guide/data-load-dirtables-manage#output</p>", "answers": ["<p><strong>LAST_MODIFIED</strong></p>", "<p><strong>MD5</strong></p>", "<p><strong>ETAG</strong></p>", "<p><strong>IS_ENCRYPTED</strong></p>", "<p><strong>IS_DELETED</strong></p>"]}, "correct_response": ["a", "b", "c"], "section": "Data Transformation", "question_plain": "Which columns will be part of the result set when a directory table is queried?Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70942764, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>Which statements are correct regarding the costs of using event notifications to refresh a directory table's metadata?</strong></p><p><br></p><p><strong>Select all that apply.</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>A small maintenance cost is charged for refreshing a directory table's metadata, whether through notifications or manually (through ALTER STAGE &lt;stage-name&gt; REFRESH). This small maintenance cost is accounted for under the cloud services costs.</p><p><br></p><p>Additionally, when using cloud platform notifications, an additional cost is charged, which appears as Snowpipe charges in your billing statement. The Snowpipe cost is charged because Snowpipe is used for event notifications to trigger the automatic refresh.</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/data-load-dirtables-intro#billing-for-directory-tables</p>", "answers": ["<p><strong>A small maintenance cost is charged for the refresh operation.</strong></p>", "<p><strong>An additional cost is charged for the event notifications.</strong></p>", "<p><strong>The refresh operation is free.</strong></p>", "<p><strong>The event notifications are free.</strong></p>"]}, "correct_response": ["a", "b"], "section": "Data Transformation", "question_plain": "Which statements are correct regarding the costs of using event notifications to refresh a directory table's metadata?Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70942766, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>Which of the following is true regarding Pre-signed URLs?</strong></p><p><strong>Select all that apply.</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p>A pre-signed URL is a simple HTTPS URL for accessing a file using a web browser. A pre-signed URL is generated using a pre-signed access token. Users can temporarily access a file via a pre-signed URL without authorization. The expiry duration of a pre-signed URL is configurable and can be set to the required duration.</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/unstructured-intro#types-of-urls-available-to-access-files</p>", "answers": ["<p><strong>A pre-signed URL is generated with an access token and can be accessed without requiring authentication.</strong></p>", "<p><strong>The expiry time for a pre-signed URL can be configured.</strong></p>", "<p><strong>Anyone with the pre-signed URL can use the URL to access the referenced file.</strong></p>", "<p><strong>Scoped URLs are suitable to provide access to users &amp; applications without needing authentication or authorization.</strong></p>", "<p><strong>A pre-signed URL expires after 24 hours.</strong></p>"]}, "correct_response": ["a", "b", "c", "d"], "section": "Data Transformation", "question_plain": "Which of the following is true regarding Pre-signed URLs?Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70942768, "assessment_type": "multiple-choice", "prompt": {"question": "<p><strong>Which method can you use to retrieve the history of data loaded into tables through Snowpipe and the COPY INTO command?</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>The COPY_HISTORY view in the ACCOUNT_USAGE schema can be used to view history for data loaded through either the COPY command or continuous data loaded through Snowpipe. The COPY_HISTORY view shows the history for the last 365 days.</p><p><br></p><p>The LOAD_HISTORY view shows data only for the COPY command. The PIPE_USAGE_HISTORY view shows only the Snowpipe history.</p><p><br></p><p>https://docs.snowflake.com/en/sql-reference/account-usage/copy_history</p>", "answers": ["<p><strong>Query the COPY_HISTORY view in the ACCOUNT_USAGE schema</strong></p>", "<p><strong>Query the LOAD_HISTORY view in the ACCOUNT_USAGE schema</strong></p>", "<p><strong>Query the PIPE_USAGE_HISTORY view in the ACCOUNT_USAGE schema</strong></p>", "<p><strong>Use QUERY_HISTORY table function in INFORMATION_SCHEMA</strong></p>"]}, "correct_response": ["a"], "section": "Account Usage & Monitoring", "question_plain": "Which method can you use to retrieve the history of data loaded into tables through Snowpipe and the COPY INTO command?", "related_lectures": []}, {"_class": "assessment", "id": 70942770, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>Which of the following can be fulfilled through the ACCESS_HISTORY view in the ACCOUNT_USAGE schema?</strong></p><p><br></p><p><strong>Select two answers.</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>Using the ACCESS_HISTORY view, you can identify what data was accessed, when, and who accessed it. Using this information, you can also identify what data is not being accessed at all.</p><p><br></p><p>There are other benefits of using ACCESS_HISTORY data, which can be found at the following link.</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/access-history#benefits</p>", "answers": ["<p><strong>Help identify data that is unused and is not being queried.</strong></p>", "<p><strong>Identify what data was accessed, when, and who accessed it.</strong></p>", "<p><strong>Identify who logged into the system.</strong></p>", "<p><strong>Identify which roles were used by the logged-in user.</strong></p>"]}, "correct_response": ["a", "b"], "section": "Account Usage & Monitoring", "question_plain": "Which of the following can be fulfilled through the ACCESS_HISTORY view in the ACCOUNT_USAGE schema?Select two answers.", "related_lectures": []}, {"_class": "assessment", "id": 70942772, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>Once created, which of the following cannot be converted to any other table type?</strong></p><p><br></p><p><strong>Select two answers.</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", ""], "explanation": "<p>Once created, temporary and transient tables cannot be changed into any other table type.</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/tables-temp-transient#creating-a-temporary-table</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/tables-temp-transient#creating-a-transient-table-schema-or-database</p>", "answers": ["<p><strong>Temporary</strong></p>", "<p><strong>Transient</strong></p>", "<p><strong>Permanent</strong></p>"]}, "correct_response": ["a", "b"], "section": "Snowflake\u2019s Catalog and objects", "question_plain": "Once created, which of the following cannot be converted to any other table type?Select two answers.", "related_lectures": []}, {"_class": "assessment", "id": 70942774, "assessment_type": "multiple-choice", "prompt": {"question": "<p><strong>What role is required to execute the following command successfully?</strong></p><p><br></p><p><strong>SHOW ORGANIZATION ACCOUNTS;</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>Only users with the ORGADMIN role can execute the \"SHOW ORGANIZATION ACCOUNTS\" command.</p><p><br></p><p>https://docs.snowflake.com/en/sql-reference/sql/show-organization-accounts</p>", "answers": ["<p><strong>ORGADMIN</strong></p>", "<p><strong>ACCOUNTADMIN</strong></p>", "<p><strong>SYSADMIN</strong></p>", "<p><strong>SECURITYADMIN</strong></p>"]}, "correct_response": ["a"], "section": "Security", "question_plain": "What role is required to execute the following command successfully?SHOW ORGANIZATION ACCOUNTS;", "related_lectures": []}, {"_class": "assessment", "id": 70942776, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>Which of the following can be used to find the query ID of the most recent query executed in the current session?</strong></p><p><br></p><p><strong>Select two answers.</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p>The LAST_QUERY_ID function returns the query ID of a specified query in the current session. The function takes a number as the parameter, which specifies the position of the query in the session.</p><p>The parameter can take positive or negative values. A negative value means you are attempting to fetch the most recent query in the session, where</p><p>-1 = most recent query</p><p>-2 = 2nd most recent query</p><p>, and so on. The function defaults to -1, so if no value is provided, it will return the query id of the most recent query.</p><p>A positive number returns the earliest queries in the session. i.e.</p><p>1 = first query</p><p>2 = 2nd query</p><p><br></p><p>https://docs.snowflake.com/en/sql-reference/functions/last_query_id</p>", "answers": ["<p><strong>SELECT LAST_QUERY_ID();</strong></p>", "<p><strong>SELECT LAST_QUERY_ID(-1);</strong></p>", "<p><strong>SELECT LAST_QUERY_ID(1);</strong></p>", "<p><strong>SELECT LAST_QUERY_ID(2);</strong></p>", "<p><strong>SELECT LAST_QUERY_ID(-2);</strong></p>"]}, "correct_response": ["a", "b"], "section": "General", "question_plain": "Which of the following can be used to find the query ID of the most recent query executed in the current session?Select two answers.", "related_lectures": []}, {"_class": "assessment", "id": 70942778, "assessment_type": "multiple-choice", "prompt": {"question": "<p><strong>Which of the following are the correct privileges to allow a role (named MKT_USERS) to add, configure, or remove Search Optimization for a table called CUSTOMER in a schema called MARKETING?</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>To add, configure, or remove search optimization for a table, you must have</p><p><br></p><p>a) OWNERSHIP privileges on the table.</p><p>b) ADD SEARCH optimization privileges on the schema that contains the table. The syntax is GRANT ADD SEARCH OPTIMIZATION ON SCHEMA &lt;schema_name&gt; TO ROLE &lt;role&gt;</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/search-optimization-service#what-access-control-privileges-are-needed-for-the-search-optimization-service</p>", "answers": ["<p><strong>GRANT ADD SEARCH OPTIMIZATION ON SCHEMA MARKETING TO ROLE MKT_USERS;</strong></p>", "<p><strong>GRANT SEARCH OPTIMIZATION ON SCHEMA MARKETING TO ROLE MKT_USERS;</strong></p>", "<p><strong>GRANT SEARCH OPTIMIZATION ON TABLE CUSTOMER TO ROLE MKT_USERS;</strong></p>", "<p><strong>GRANT ADD SEARCH OPTIMIZATION ON TABLE CUSTOMER TO ROLE MKT_USERS;</strong></p>"]}, "correct_response": ["a"], "section": "Security", "question_plain": "Which of the following are the correct privileges to allow a role (named MKT_USERS) to add, configure, or remove Search Optimization for a table called CUSTOMER in a schema called MARKETING?", "related_lectures": []}, {"_class": "assessment", "id": 70942780, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>Which of the following correctly describes how materialized views are refreshed?</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p>When the underlying table is updated, the materialized view refreshes automatically, requiring no additional maintenance. Snowflake-managed services perform the update in the background transparent to the user without interfering with the user's experience.</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/views-materialized</p>", "answers": ["<p><strong>Materialized views are automatically refreshed by Snowflake managed service.</strong></p>", "<p><strong>A materialized view is automatically updated if the data in the underlying table is changed.</strong></p>", "<p><strong>Materialized can ONLY be refreshed manually.</strong></p>", "<p><strong>Additional SQL statements need to be scheduled to refresh a materialized view.</strong></p>", "<p><strong>A materialized view can be set to auto-refresh using the REFRESH_ON_BASE_TABLE_UPDATE parameter.</strong></p>"]}, "correct_response": ["a", "b"], "section": "Performance Concepts", "question_plain": "Which of the following correctly describes how materialized views are refreshed?", "related_lectures": []}, {"_class": "assessment", "id": 70942782, "assessment_type": "multiple-choice", "prompt": {"question": "<p><strong>An administrator needs to grant access to a role so that they can create a materialized view in the database MARKETING and schema PUBLIC. Which statement will provide the required privileges to the role?</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>The correct syntax is GRANT CREATE MATERIALIZED VIEW ON SCHEMA &lt;schema_name&gt; TO ROLE &lt;role_name&gt;;</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/views-materialized#privileges-on-a-materialized-view-s-schema</p>", "answers": ["<p><strong>GRANT CREATE MATERIALIZED VIEW ON SCHEMA MARKETING.PUBLIC TO ROLE &lt;role_name&gt;;</strong></p>", "<p><strong>GRANT CREATE MATERIALIZED VIEW ON SCHEMA MARKETING.PUBLIC TO &lt;role_name&gt;;</strong></p>", "<p><strong>GRANT MATERIALIZED VIEW ON SCHEMA MARKETING.PUBLIC TO &lt;role_name&gt;;</strong></p>", "<p><strong>GRANT MATERIALIZED VIEW ON SCHEMA MARKETING.PUBLIC TO ROLE &lt;role_name&gt;;</strong></p>"]}, "correct_response": ["a"], "section": "Security", "question_plain": "An administrator needs to grant access to a role so that they can create a materialized view in the database MARKETING and schema PUBLIC. Which statement will provide the required privileges to the role?", "related_lectures": []}, {"_class": "assessment", "id": 70942784, "assessment_type": "multiple-choice", "prompt": {"question": "<p><strong>What are resource monitors used for?</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>Resource monitors help manage virtual warehouse costs and avoid unexpected credit usage. Resource monitors can control credit usage by monitoring credit usage against a defined upper limit, notifying administrators when a certain percentage of the limit is reached, and even suspending virtual warehouses if necessary.</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/resource-monitors</p>", "answers": ["<p><strong>Control costs and credit use by virtual warehouses</strong></p>", "<p><strong>Scale virtual warehouses up and down automatically</strong></p>", "<p><strong>Monitor the resource allocation for each virtual warehouse</strong></p>", "<p><strong>Monitor how many queries are queued</strong></p>"]}, "correct_response": ["a"], "section": "Account Usage & Monitoring", "question_plain": "What are resource monitors used for?", "related_lectures": []}, {"_class": "assessment", "id": 70942786, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>Which of the following are valid statements when loading data into a table (called EMPLOYEE) using the table stage?</strong></p><p><br></p><p><strong>Select two answers.</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>The FROM clause can be omitted when loading data from a table stage. In such a case, Snowflake automatically assumes data is being loaded from the table stage.</p><p><br></p><p>So both <strong>COPY INTO EMPLOYEE;</strong> and <strong>COPY INTO EMPLOYEE FROM @%EMPLOYEE;</strong> are correct.</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/data-load-local-file-system-copy#table-stage</p>", "answers": ["<p><strong>COPY INTO EMPLOYEE;</strong></p>", "<p><strong>COPY INTO EMPLOYEE FROM @%EMPLOYEE;</strong></p>", "<p><strong>COPY INTO EMPLOYEE FROM TABLE_STAGE;</strong></p>", "<p><strong>COPY INTO EMPLOYEE SELECT * FROM TABLE_STAGE;</strong></p>"]}, "correct_response": ["a", "b"], "section": "Data Loading and Unloading", "question_plain": "Which of the following are valid statements when loading data into a table (called EMPLOYEE) using the table stage?Select two answers.", "related_lectures": []}, {"_class": "assessment", "id": 70942788, "assessment_type": "multiple-choice", "prompt": {"question": "<p><strong>What term is used for a pre-computed dataset obtained from a SELECT query specification and stored for future use?</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>A materialized view is a view that pre-computes data based on a SELECT query. The query's results are pre-computed and physically stored to enhance performance for similar queries that are executed in the future. When the underlying table is updated, the materialized view refreshes automatically, requiring no additional maintenance. Snowflake-managed services perform the update in the background transparent to the user without interfering with the user's experience.</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/views-materialized</p>", "answers": ["<p><strong>Materialized View</strong></p>", "<p><strong>Secure View</strong></p>", "<p><strong>Output View</strong></p>", "<p><strong>View</strong></p>"]}, "correct_response": ["a"], "section": "Performance Concepts", "question_plain": "What term is used for a pre-computed dataset obtained from a SELECT query specification and stored for future use?", "related_lectures": []}, {"_class": "assessment", "id": 70942790, "assessment_type": "multiple-choice", "prompt": {"question": "<p><strong>In the Query Profile, what does the TableScan operator represent?</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>The TableScan operator represents access to a single table. Please see</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/ui-query-profile#data-access-and-generation-operators</p>", "answers": ["<p><strong>Access to a single table</strong></p>", "<p><strong>Combining two inputs on a given condition</strong></p>", "<p><strong>Adding records to a table</strong></p>", "<p><strong>Access to data stored in stage objects</strong></p>"]}, "correct_response": ["a"], "section": "Performance Concepts", "question_plain": "In the Query Profile, what does the TableScan operator represent?", "related_lectures": []}, {"_class": "assessment", "id": 70942792, "assessment_type": "multi-select", "prompt": {"question": "<p><strong>Which of the following chart types are supported by Snowsight?</strong></p><p><br></p><p><strong>Select all that apply.</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", "", ""], "explanation": "<p>Snowsight supports</p><p>Bar charts,</p><p>Line charts,</p><p>Scatterplots,</p><p>Heat grids and</p><p>Scorecards</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/ui-snowsight-visualizations</p>", "answers": ["<p><strong>Bar Charts</strong></p>", "<p><strong>Scorecards</strong></p>", "<p><strong>Area charts</strong></p>", "<p><strong>Pareto Charts</strong></p>", "<p><strong>Pie Charts</strong></p>"]}, "correct_response": ["a", "b"], "section": "Tools & Interfaces", "question_plain": "Which of the following chart types are supported by Snowsight?Select all that apply.", "related_lectures": []}, {"_class": "assessment", "id": 70942794, "assessment_type": "multiple-choice", "prompt": {"question": "<p><strong>What role is required to enable replication for multiple accounts?</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>The ORGADMIN must be used to enable replication for source and target databases.</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/database-replication-config#prerequisite-enable-replication-for-accounts-in-the-organization</p>", "answers": ["<p><strong>ORGADMIN</strong></p>", "<p><strong>ACCOUNTADMIN</strong></p>", "<p><strong>SYSADMIN</strong></p>", "<p><strong>SECURITYADMIN</strong></p>"]}, "correct_response": ["a"], "section": "Security", "question_plain": "What role is required to enable replication for multiple accounts?", "related_lectures": []}, {"_class": "assessment", "id": 70942796, "assessment_type": "multiple-choice", "prompt": {"question": "<p><strong>How are privileges inherited in a Snowflake role hierarchy?</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>Roles may also be granted to other roles, creating a role hierarchy. The privileges associated with a role are inherited by all roles in the hierarchy above that role.</p><p><br></p><p><br></p><p>https://docs.snowflake.com/en/user-guide/security-access-control-overview#:~:text=Roles%20can%20be%20also%20granted%20to%20other%20roles%2C%20creating%20a%20hierarchy%20of%20roles.%20The%20privileges%20associated%20with%20a%20role%20are%20inherited%20by%20any%20roles%20above%20that%20role%20in%20the%20hierarchy.</p>", "answers": ["<p><strong>The privileges of a role are inherited by all roles above it in the hierarchy.</strong></p>", "<p><strong>Only the direct parent role inherits privileges.</strong></p>", "<p><strong>Only the direct child role inherits privileges.</strong></p>", "<p><strong>Only roles at the same level of the hierarchy inherit the privileges.</strong></p>"]}, "correct_response": ["a"], "section": "Security", "question_plain": "How are privileges inherited in a Snowflake role hierarchy?", "related_lectures": []}, {"_class": "assessment", "id": 70942798, "assessment_type": "multiple-choice", "prompt": {"question": "<p><strong>John, who has the SYSADMIN role, ran a query. Another user, Jane, attempts to view the result of the query executed by John using the Snowsight query history.</strong></p><p><br></p><p><strong>Which of the following correctly describes the outcome?</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>You can only see the results of historical queries that you have run. For privacy reasons, the Query Detail page doesn't show the query results for queries run by other users, even if you have the privilege to see the query details for those queries.</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/ui-history#viewing-query-details-and-results</p>", "answers": ["<p><strong>Jane can NOT see the result set of queries executed by John.</strong></p>", "<p><strong>Jane can see the result set of queries executed by John only if she is also part of the SYSADMIN role.</strong></p>", "<p><strong>Jane can see the result set of queries executed by John only if she has the ACCOUNTADMIN role.</strong></p>", "<p><strong>Jane can only see the result set of queries executed by John if John grants her permission.</strong></p>"]}, "correct_response": ["a"], "section": "Security", "question_plain": "John, who has the SYSADMIN role, ran a query. Another user, Jane, attempts to view the result of the query executed by John using the Snowsight query history.Which of the following correctly describes the outcome?", "related_lectures": []}, {"_class": "assessment", "id": 70942800, "assessment_type": "multiple-choice", "prompt": {"question": "<p><strong>Which function is used to determine the fully qualified URL and port for Snowight when configuring Snowight for access through a proxy or a firewall?</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>You need to add the fully qualified URL and port values to the proxy servers or firewall settings to use a proxy or firewall to connect to Snowsight.</p><p><br></p><p>Use the SNOWSIGHT_DEPLOYMENT item in the return value of the SYSTEM$ALLOWLIST function to find out the fully qualified Snowsight URL and port.</p><p><br></p><p>https://docs.snowflake.com/en/user-guide/ui-snowsight-gs#accessing-sf-web-interface-through-a-proxy-or-firewall</p>", "answers": ["<p><strong>SYSTEM$ALLOWLIST</strong></p>", "<p><strong>SYSTEM$REFERENCE</strong></p>", "<p><strong>SYSTEM$GENERATE_SAML_CSR</strong></p>", "<p><strong>SYSTEM$GET_TAG</strong></p>"]}, "correct_response": ["a"], "section": "Security", "question_plain": "Which function is used to determine the fully qualified URL and port for Snowight when configuring Snowight for access through a proxy or a firewall?", "related_lectures": []}, {"_class": "assessment", "id": 70942804, "assessment_type": "multiple-choice", "prompt": {"question": "<p><strong>What privilege is required to resize a virtual warehouse?</strong></p>", "relatedLectureIds": "", "feedbacks": ["", "", "", ""], "explanation": "<p>The MODIFY privilege allows a role to alter the size of a virtual warehouse.</p><p><br></p><p>https://docs.snowflake.com/en/sql-reference/sql/alter-warehouse#access-control-requirements</p>", "answers": ["<p><strong>MODIFY</strong></p>", "<p><strong>ALTER</strong></p>", "<p><strong>USAGE</strong></p>", "<p><strong>MONITOR</strong></p>"]}, "correct_response": ["a"], "section": "Security", "question_plain": "What privilege is required to resize a virtual warehouse?", "related_lectures": []}]}
